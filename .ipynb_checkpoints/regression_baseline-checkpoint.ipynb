{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "np.random.seed(601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "train = pd.DataFrame(boston.data , columns = boston.feature_names)\n",
    "\n",
    "train['PRICE'] = boston.target\n",
    "\n",
    "# 결정자 할당\n",
    "target = train['PRICE']\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[컬럼 설명]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[shape]\\t',train.shape)\n",
    "print('\\n[info]\\n')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 컬럼 타입\n",
    "* null check\n",
    "* object 타입 - category 컬럼 확인 => 숫자형 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n전체 feature 들의 type \\n',train.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ! 숫자형(int, float) 컬럼만 조사 \n",
    "* 컬럼별 분포 파악 - 왜곡, 이상치\n",
    "* max == count 라면, id 같은 숫자형 카테코리 컬럼일 가능성이 높음(삭제 대상)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 분포 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_value_counts(df):\n",
    "    for col in df.columns:\n",
    "        print('col:', df[col].value_counts())\n",
    "    \n",
    "# df_value_counts(train[['CRIM', 'ZN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결손 데이터 처리\n",
    "**넘파이의 NaN 으로 표시(머신러닝 알고리즘에서 처리하지 않으므로 대체해야함)**\n",
    "* isna() : NaN 여부 확인\n",
    "* fillna(): NaN 대체 \n",
    "    *fillna(value=None,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULL 확인 \n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULL 변환 \n",
    "# train['Cabin'] = train['Cabin'].fillna('C000') \n",
    "# train['Cabin'].fillna('C000',inplace=True) \n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['CRIM'].fillna(df['CRIM'].mean(),inplace=True)\n",
    "    return df\n",
    "\n",
    "train = fillna(train)\n",
    "\n",
    "print('데이터 세트 Null 값 갯수 ',train.isnull().sum().sum())\n",
    "print(train.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('데이터 세트 Null 값 갯수 ',train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['B'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "train = drop_features(train)\n",
    "print(train.shape, target.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['PRICE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train[['RM','PRICE']].sample(n=100,random_state=0)\n",
    "plt.figure()\n",
    "plt.scatter(sample.RM , sample.PRICE,c=\"darkorange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 숫자만\n",
    "\n",
    "# 2개의 행과 4개의 열을 가진 subplots를 이용. axs는 4x2개의 ax를 가짐.\n",
    "fig, axs = plt.subplots(figsize=(16,8) , ncols=4 , nrows=2)\n",
    "lm_features = ['RM','ZN','INDUS','NOX','AGE','PTRATIO','LSTAT','RAD']\n",
    "for i , feature in enumerate(lm_features):\n",
    "    row = int(i/4)\n",
    "    col = i%4\n",
    "    # 시본의 regplot을 이용해 산점도와 선형 회귀 직선을 함께 표현\n",
    "    sns.regplot(x=feature , y='PRICE',data=train , ax=axs[row][col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형성이 큰 컬럼 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이상치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier(df=None, column=None, weight=1.5):\n",
    "    # fraud에 해당하는 column 데이터만 추출, 1/4 분위와 3/4 분위 지점을 np.percentile로 구함. \n",
    "    \n",
    "    fraud = df[column]\n",
    "    quantile_25 = np.percentile(fraud.values, 25)\n",
    "    quantile_75 = np.percentile(fraud.values, 75)\n",
    "    \n",
    "    # IQR을 구하고, IQR에 1.5를 곱하여 최대값과 최소값 지점 구함. \n",
    "    iqr = quantile_75 - quantile_25\n",
    "    iqr_weight = iqr * weight\n",
    "    lowest_val = quantile_25 - iqr_weight\n",
    "    highest_val = quantile_75 + iqr_weight\n",
    "    \n",
    "    # 최대값 보다 크거나, 최소값 보다 작은 값을 아웃라이어로 설정하고 DataFrame index 반환. \n",
    "    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n",
    "    \n",
    "    return outlier_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_index = get_outlier(df=train, column='PTRATIO', weight=1.5)\n",
    "print('이상치 데이터 인덱스:', outlier_index)\n",
    "train.drop(outlier_index, axis=0, inplace=True)\n",
    "target.drop(outlier_index, axis=0, inplace=True)\n",
    "\n",
    "print(train.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카테고리 타입 -> 변환 대상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 명 변경 \n",
    "\n",
    "# data_df_reset.rename(columns={'index':'old_index'})\n",
    "\n",
    "# Dataframe.drop(labels=None, axis=1, inplace=False) #  axis=0 : col 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컬럼 데이터 세트 생성/수정/삭제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 조작 \n",
    "train['NOX'] = train['NOX'].str[:1]\n",
    "train['NOX'].value_counts()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "* 1. 스케일링과 정규화(StandardScaler, MinMaxScaler)\n",
    "* 2. 1번으로 향상 없을 시, 다항 적용(PolynomialFeatures)\n",
    "* 3. 1,2 보다 많이 사용되는 **로그 변환**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜곡\n",
    "* target 왜곡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(target, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜곡 시 log 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log1p(target)\n",
    "target.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜곡 log -> 지수 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.expm1(target)\n",
    "target.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train 왜곡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# object가 아닌 숫자형 피쳐의 컬럼 index 객체 추출.\n",
    "features_index = train.dtypes[train.dtypes != 'object'].index\n",
    "\n",
    "# house_df에 컬럼 index를 [ ]로 입력하면 해당하는 컬럼 데이터 셋 반환. apply lambda로 skew( )호출 \n",
    "skew_features = train[features_index].apply(lambda x : skew(x))\n",
    "\n",
    "# skew 정도가 1 이상인 컬럼들만 추출. \n",
    "skew_features_top = skew_features[skew_features > 1]\n",
    "print(skew_features_top.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 왜곡도가 1인 피처들은 로그 변환 적용하고 다시 하이퍼 파라미터 튜닝 후 재 학습/예측/평가\n",
    "train[skew_features_top.index] = np.log1p(train[skew_features_top.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 회귀 모델을 위한 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "# method는 표준 정규 분포 변환(Standard), 최대값/최소값 정규화(MinMax), 로그변환(Log) 결정\n",
    "# p_degree는 다향식 특성을 추가할 때 적용. p_degree는 2이상 부여하지 않음. \n",
    "def get_scaled_data(method='None', p_degree=None, input_data=None):\n",
    "    if method == 'Standard':\n",
    "        scaled_data = StandardScaler().fit_transform(input_data)\n",
    "    elif method == 'MinMax':\n",
    "        scaled_data = MinMaxScaler().fit_transform(input_data)\n",
    "    elif method == 'Log':\n",
    "        scaled_data = np.log1p(input_data)\n",
    "    else:\n",
    "        scaled_data = input_data\n",
    "\n",
    "    if p_degree != None:\n",
    "        scaled_data = PolynomialFeatures(degree=p_degree, \n",
    "                                         include_bias=False).fit_transform(scaled_data)\n",
    "    \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ridge의 alpha값을 다르게 적용하고 다양한 데이터 변환방법에 따른 RMSE 추출. \n",
    "alphas = [0.1, 1, 10, 100]\n",
    "#변환 방법은 모두 6개, 원본 그대로, 표준정규분포, 표준정규분포+다항식 특성\n",
    "# 최대/최소 정규화, 최대/최소 정규화+다항식 특성, 로그변환 \n",
    "scale_methods=[(None, None), ('Standard', None), ('Standard', 2), \n",
    "               ('MinMax', None), ('MinMax', 2), ('Log', None)]\n",
    "for scale_method in scale_methods:\n",
    "    X_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1], \n",
    "                                    input_data=train)\n",
    "    print('\\n## 변환 유형:{0}, Polynomial Degree:{1}'.format(scale_method[0], scale_method[1]))\n",
    "    \n",
    "    #get_linear_reg_eval('Ridge', params=alphas, X_data_n=X_data_scaled, \n",
    "    #                    y_target_n=train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코딩\n",
    "* 원-핫 인코딩(One-Hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "train.head(3)\n",
    "print(train.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 9))\n",
    "corr = train.corr()\n",
    "sns.heatmap(corr, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ! 모두 숫자형으로 변환이 완료 되었는가?\n",
    "\n",
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터와 테스트 데이터 세트로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터에서 결정자 삭제 \n",
    "train.drop('PRICE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression 는 스케일링 적용하고 train_test_split\n",
    "\n",
    "# StandardScaler( )로 평균이 0, 분산 1로 데이터 분포도 변환\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "train = pd.DataFrame(train , columns = boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(train , target ,test_size=0.3, shuffle=True, random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE 오버 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_over, y_train_over = smote.fit_sample(X_train, y_train)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', X_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_train_over.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습\n",
    "* LinearRegression: RSS(Residual Sum of Squares) 최소화해 OLS(Ordinary Least Squares) 추정방식\n",
    "* LogisticRegression: 정규 분포에 영향 받으므로 스케일링 적용 후 적용\n",
    "    * 선형 회귀 기반 + 시그모이드 함수\n",
    "    * 분류, 희소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_reg = LinearRegression(\n",
    "    fit_intercept=True, # 절편값 계산, False: 절편 사용되지 않고 0 \n",
    "    normalize=False, # fit_intercept=True 일때만 사용, 회귀 수행 전 정규화 수행\n",
    "    copy_X=True,\n",
    "    n_jobs=None,\n",
    ")\n",
    "\n",
    "lo_reg = LogisticRegression()\n",
    "\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "\n",
    "gb_reg = GradientBoostingRegressor(random_state=0, n_estimators=1000)\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "xgb_reg = XGBRegressor(n_estimators=1000)\n",
    "lgb_reg = LGBMRegressor(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_reg.fit(X_train ,y_train)\n",
    "#lo_reg.fit(X_train ,y_train.astype('int'))\n",
    "#rf_reg.fit(X_train ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = li_reg.predict(X_test)\n",
    "#y_preds = lo_reg.predict(X_test)\n",
    "#y_preds = rf_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cv_prediction(model, X_data, y_target):\n",
    "    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    print('##### ',model.__class__.__name__ , ' #####')\n",
    "    print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리 기반의 회귀 모델을 반복하면서 평가 수행 \n",
    "models = [dt_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
    "for model in models:  \n",
    "    get_model_cv_prediction(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegression max_depth 변경할 때 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 회귀와 결정 트리 기반의 Regressor 생성. DecisionTreeRegressor의 max_depth는 각각 2, 7\n",
    "lr_reg = LinearRegression()\n",
    "rf_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "rf_reg7 = DecisionTreeRegressor(max_depth=7)\n",
    "\n",
    "# 실제 예측을 적용할 테스트용 데이터 셋을 4.5 ~ 8.5 까지 100개 데이터 셋 생성. \n",
    "X_test_reshape = np.arange(4.5, 8.5, 0.04).reshape(-1, 1)\n",
    "\n",
    "# 보스턴 주택가격 데이터에서 시각화를 위해 피처는 RM만, 그리고 결정 데이터인 PRICE 추출\n",
    "X_feature = train['RM'].values.reshape(-1,1)\n",
    "y_target = target.values.reshape(-1,1)\n",
    "\n",
    "# 학습과 예측 수행. \n",
    "lr_reg.fit(X_feature, y_target)\n",
    "rf_reg2.fit(X_feature, y_target)\n",
    "rf_reg7.fit(X_feature, y_target)\n",
    "\n",
    "pred_lr = lr_reg.predict(X_test_reshape)\n",
    "pred_rf2 = rf_reg2.predict(X_test_reshape)\n",
    "pred_rf7 = rf_reg7.predict(X_test_reshape)\n",
    "\n",
    "fig , (ax1, ax2, ax3) = plt.subplots(figsize=(14,4), ncols=3)\n",
    "\n",
    "# X축값을 4.5 ~ 8.5로 변환하며 입력했을 때, 선형 회귀와 결정 트리 회귀 예측 선 시각화\n",
    "# 선형 회귀로 학습된 모델 회귀 예측선 \n",
    "ax1.set_title('Linear Regression')\n",
    "ax1.scatter(train.RM, target, c=\"darkorange\")\n",
    "ax1.plot(X_test_reshape, pred_lr,label=\"linear\", linewidth=2 )\n",
    "\n",
    "# DecisionTreeRegressor의 max_depth를 2로 했을 때 회귀 예측선 \n",
    "ax2.set_title('Decision Tree Regression: \\n max_depth=2')\n",
    "ax2.scatter(train.RM, target, c=\"darkorange\")\n",
    "ax2.plot(X_test_reshape, pred_rf2, label=\"max_depth:3\", linewidth=2 )\n",
    "\n",
    "# DecisionTreeRegressor의 max_depth를 7로 했을 때 회귀 예측선 \n",
    "ax3.set_title('Decision Tree Regression: \\n max_depth=7')\n",
    "ax3.scatter(train.RM, target, c=\"darkorange\")\n",
    "ax3.plot(X_test_reshape, pred_rf7, label=\"max_depth:7\", linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가\n",
    "* 회귀: Mean(오차(실제값 - 예측값)) : 오차 평균에 기반 \n",
    "* 분류: 일반적으로 오차에 기반 + **성능 평가 지표**\n",
    "    * **이진분류:** 정확도 << 성능 평가 지표\n",
    "    \n",
    "### 평가 지표\n",
    "* MAE(Mean Absolute Error): 차이 절댓값 평균\n",
    "* MSE(Mean Sqared Error): 차이 제곱 평균\n",
    "    * MSLE(MS Log Error): 로그 MSE\n",
    "* RMSE(Root MSE): 루트 MSE\n",
    "    * RMSLE(RMS Log Error) 로그 RMSE\n",
    "* R^2: 분산 기반, 실제값고 분산 대비 예측 값의 분산비율, 1에 가까울수록 정확\n",
    "\n",
    "### 평가 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = [\"평가방법\",\"사이킷런 평가 지표 API\",\"Scoring 함수 적용 값\"]\n",
    "arr_method = [ [\"MAE\", \"metric.mean_absolute_error\",\"neg_mean_absolute_error\"]\n",
    "              ,[\"MSE\", \"metric.mean_squared_error\",\"neg_mean_squared_error\"]\n",
    "              ,[\"R^2\", \"metric.r2_score\",\"r2\"]]\n",
    "pd.DataFrame(arr_method, columns=col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**neg_: -1 * metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error , r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log 값 변환 시 언더플로우 영향으로 log() 가 아닌 log1p() 를 이용하여 RMSLE 계산\n",
    "def rmsle(y, pred):\n",
    "    log_y = np.log1p(y)\n",
    "    log_pred = np.log1p(pred)\n",
    "    squared_error = (log_y - log_pred) ** 2\n",
    "    rmsle = np.sqrt(np.mean(squared_error))\n",
    "    return rmsle\n",
    "\n",
    "# 사이킷런의 mean_square_error() 를 이용하여 RMSE 계산\n",
    "def rmse(y,pred):\n",
    "    return np.sqrt(mean_squared_error(y,pred))\n",
    "\n",
    "def mse(y,pred):\n",
    "    return mean_squared_error(y,pred)\n",
    "\n",
    "# 책에서는 mean_absolute_error()를 MSE로 잘못 기재함. \n",
    "# MAE, RMSE, RMSLE 를 모두 계산 \n",
    "def evaluate_regr(y,pred):\n",
    "    rmsle_val = rmsle(y,pred)\n",
    "    rmse_val = rmse(y,pred)\n",
    "    mse_val = mse(y,pred)\n",
    "    # MAE 는 scikit learn의 mean_absolute_error() 로 계산\n",
    "    mae_val = mean_absolute_error(y,pred)\n",
    "    print('RMSLE: {0:.3f}, RMSE: {1:.3F}, MAE: {2:.3F}, MSE: {3:.3F}'.format(rmsle_val, rmse_val, mae_val, mse_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_regr(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오류값이 큰 순으로 5개 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_error_data(y_test, pred, n_tops = 5):\n",
    "    # DataFrame에 컬럼들로 실제 대여횟수(count)와 예측 값을 서로 비교 할 수 있도록 생성. \n",
    "    result_df = pd.DataFrame(y_test.values, columns=['real_count'])\n",
    "    result_df['predicted_count']= np.round(pred)\n",
    "    result_df['diff'] = np.abs(result_df['real_count'] - result_df['predicted_count'])\n",
    "    # 예측값과 실제값이 가장 큰 데이터 순으로 출력. \n",
    "    print(result_df.sort_values('diff', ascending=False)[:n_tops])\n",
    "    \n",
    "get_top_error_data(y_test,y_preds,n_tops=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**선형회귀**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressor 클래스에는 없음 \n",
    "\n",
    "print('절편 값:',li_reg.intercept_)\n",
    "print('회귀 계수값:', np.round(li_reg.coef_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef_ 는 회귀 계수 값만 가지므로 피처와 매핑해서 내림차순 정렬\n",
    "\n",
    "# 회귀 계수를 큰 값 순으로 정렬하기 위해 Series로 생성. index가 컬럼명에 유의\n",
    "coeff = pd.Series(data=np.round(li_reg.coef_, 1), index=X_train.columns )\n",
    "coeff.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**회귀 트리는 선형 회귀의 회귀 계수 대신, 피처 중요도로 피처의 상대적 중요도를 알 수 있음**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
    "\n",
    "# 앞 예제에서 만들어진 X_data, y_target 데이터 셋을 적용하여 학습합니다.   \n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "feature_series = pd.Series(data=rf_reg.feature_importances_, index=X_train.columns )\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x= feature_series, y=feature_series.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV = 교차 검증 + 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'penalty':['l2', 'l1'],\n",
    "        'C':[0.01, 0.1, 1, 1, 5, 10]}\n",
    "\n",
    "grid_clf = GridSearchCV(lo_reg, param_grid=params, scoring='accuracy', cv=3 )\n",
    "grid_clf.fit(train, target.astype(int))\n",
    "print('최적 하이퍼 파라미터:{0}, 최적 평균 정확도:{1:.3f}'.format(grid_clf.best_params_, \n",
    "                                                  grid_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "**cross_val_score = KFold/StratifiedKFold + train_test_split + fit/predict/evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score( )로 5 Fold 셋으로 MSE 를 구한 뒤 이를 기반으로 다시  RMSE 구함. \n",
    "neg_mse_scores = cross_val_score(li_reg, train, target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "# cross_val_score(scoring=\"neg_mean_squared_error\")로 반환된 값은 모두 음수 \n",
    "print(' 5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 2))\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores, 2))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 규제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 10)\n",
    "neg_mse_scores = cross_val_score(ridge, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(' 5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 3))\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores,3))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge에 사용될 alpha 파라미터의 값들을 정의\n",
    "alphas = [0 , 0.1 , 1 , 10 , 100]\n",
    "\n",
    "# alphas list 값을 iteration하면서 alpha에 따른 평균 rmse 구함.\n",
    "for alpha in alphas :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    #cross_val_score를 이용하여 5 fold의 평균 RMSE 계산\n",
    "    neg_mse_scores = cross_val_score(ridge, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "    print('alpha {0} 일 때 5 folds 의 평균 RMSE : {1:.3f} '.format(alpha,avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 alpha에 따른 회귀 계수 값을 시각화하기 위해 5개의 열로 된 맷플롯립 축 생성  \n",
    "fig , axs = plt.subplots(figsize=(18,6) , nrows=1 , ncols=5)\n",
    "# 각 alpha에 따른 회귀 계수 값을 데이터로 저장하기 위한 DataFrame 생성  \n",
    "coeff_df = pd.DataFrame()\n",
    "\n",
    "# alphas 리스트 값을 차례로 입력해 회귀 계수 값 시각화 및 데이터 저장. pos는 axis의 위치 지정\n",
    "for pos , alpha in enumerate(alphas) :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_train , y_train)\n",
    "    # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가.  \n",
    "    coeff = pd.Series(data=ridge.coef_ , index=train.columns )\n",
    "    colname='alpha:'+str(alpha)\n",
    "    coeff_df[colname] = coeff\n",
    "    # 막대 그래프로 각 alpha 값에서의 회귀 계수를 시각화. 회귀 계수값이 높은 순으로 표현\n",
    "    coeff = coeff.sort_values(ascending=False)\n",
    "    axs[pos].set_title(colname)\n",
    "    axs[pos].set_xlim(-3,6)\n",
    "    sns.barplot(x=coeff.values , y=coeff.index, ax=axs[pos])\n",
    "\n",
    "# for 문 바깥에서 맷플롯립의 show 호출 및 alpha에 따른 피처별 회귀 계수를 DataFrame으로 표시\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_alphas = [0 , 0.1 , 1 , 10 , 100]\n",
    "sort_column = 'alpha:'+str(ridge_alphas[0])\n",
    "coeff_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라쏘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고 회귀 계수값들을 DataFrame으로 반환 \n",
    "def get_linear_reg_eval(model_name, params=None, X_data_n=None, y_target_n=None, verbose=True):\n",
    "    coeff_df = pd.DataFrame()\n",
    "    if verbose : print('####### ', model_name , '#######')\n",
    "    for param in params:\n",
    "        if model_name =='Ridge': model = Ridge(alpha=param)\n",
    "        elif model_name =='Lasso': model = Lasso(alpha=param)\n",
    "        elif model_name =='ElasticNet': model = ElasticNet(alpha=param, l1_ratio=0.7)\n",
    "        neg_mse_scores = cross_val_score(model, X_data_n, \n",
    "                                             y_target_n, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "        avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "        print('alpha {0}일 때 5 폴드 세트의 평균 RMSE: {1:.3f} '.format(param, avg_rmse))\n",
    "        # cross_val_score는 evaluation metric만 반환하므로 모델을 다시 학습하여 회귀 계수 추출\n",
    "        \n",
    "        model.fit(X_train , y_train)\n",
    "        # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가. \n",
    "        coeff = pd.Series(data=model.coef_ , index=train.columns )\n",
    "        colname='alpha:'+str(param)\n",
    "        coeff_df[colname] = coeff\n",
    "    return coeff_df\n",
    "# end of get_linear_regre_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라쏘에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "lasso_alphas = [ 0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_lasso_df =get_linear_reg_eval('Lasso', params=lasso_alphas, X_data_n=X_train, y_target_n=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반환된 coeff_lasso_df를 첫번째 컬럼순으로 내림차순 정렬하여 회귀계수 DataFrame출력\n",
    "sort_column = 'alpha:'+str(lasso_alphas[0])\n",
    "coeff_lasso_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 엘라스틱넷 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엘라스틱넷에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "# l1_ratio는 0.7로 고정\n",
    "elastic_alphas = [ 0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_elastic_df =get_linear_reg_eval('ElasticNet', params=elastic_alphas,\n",
    "                                      X_data_n=X_train, y_target_n=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반환된 coeff_elastic_df를 첫번째 컬럼순으로 내림차순 정렬하여 회귀계수 DataFrame출력\n",
    "sort_column = 'alpha:'+str(elastic_alphas[0])\n",
    "coeff_elastic_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다항 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline을 이용하여 PolynomialFeatures 변환과 LinearRegression 적용을 순차적으로 결합. \n",
    "p_model = Pipeline([('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "                  ('linear', LinearRegression())])\n",
    "\n",
    "p_model.fit(X_train, y_train)\n",
    "y_preds = p_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(mse , rmse))\n",
    "print('Variance score : {0:.3f}'.format(r2_score(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly= PolynomialFeatures(degree=2, include_bias=False).fit_transform(X_train, y_train)\n",
    "X_train_poly.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "            \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha=10)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_stacking_base_datasets( )은 넘파이 ndarray를 인자로 사용하므로 DataFrame을 넘파이로 변환. \n",
    "X_train_n = X_train.values\n",
    "X_test_n = X_test.values\n",
    "y_train_n = y_train.values\n",
    "\n",
    "# 각 개별 기반(Base)모델이 생성한 학습용/테스트용 데이터 반환. \n",
    "ridge_train, ridge_test = get_stacking_base_datasets(ridge_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "lasso_train, lasso_test = get_stacking_base_datasets(lasso_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "xgb_train, xgb_test = get_stacking_base_datasets(xgb_reg, X_train_n, y_train_n, X_test_n, 5)  \n",
    "lgbm_train, lgbm_test = get_stacking_base_datasets(lgbm_reg, X_train_n, y_train_n, X_test_n, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
