{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error \n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "gender_submission = pd.read_csv('data/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape, gender_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)\n",
    "test.head(3)\n",
    "gender_submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((train, test)) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  EDA & 전처리 -> Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공통 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts(df, cols):\n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        print(df[col].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_plotting(data, xlabel, ylabel, n=20):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    ax = data.tail(n).plot(kind='barh')\n",
    "    \n",
    "    ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 컬럼과 생존률 관계 \n",
    "def survpct(col):\n",
    "    return train.groupby(col)['Survived'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - categorical: Pclass, Sex, Embarked     \n",
    " - String: Name, Ticket   \n",
    " - ??: Cabin        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## id 중복 확인\n",
    "train[train.duplicated(['PassengerId'])]\n",
    "test[test.duplicated(['PassengerId'])]\n",
    "# 중복 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing Value: Age, Cabin, Embarked\n",
    "- Categorical: Sex(2), Embarked(3)\n",
    "- Name 중복 없음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()    # Age, Fare, Cabin, Embarked\n",
    "train.isnull().sum() # Age      , Cabin, Embarked\n",
    "test.isnull().sum()  # Age, Fare, Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value: Fare - only test(1건)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.Fare.isna()].index\n",
    "test[test.Fare.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fare 가 null 인 컬럼<br>\n",
    "Pclass: 3<br>\n",
    "Ticket: 3701<br>\n",
    "Embarked: S<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일 조건을 가진 다른 컬럼의 Fare 검색\n",
    "cond = (df.Pclass==3) & (df.Ticket.str.contains('3701')) & (df.Embarked == 'S')\n",
    "df[cond]\n",
    "# 동일한 값을 가지는것으로 파악 Fare -> Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare: 20.2125\n",
    "# Ticket: 3701 -> 370129 (동일한 조건의 오기재된 정보로 보여 업데이트)\n",
    "test.loc[152,'Fare'] = 20.2125\n",
    "test.loc[152,'Ticket'] = '370129'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value: Embarked - only train(2건)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.Embarked.isna()].index\n",
    "train[train.Embarked.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null값을 가지는 다른 공통 정보로 검색 \n",
    "df[df.Cabin.str.contains('B2')==True]\n",
    "# Cabin BX 로 시작하는 데이터는 Embarked = 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[train.Embarked.isna()].index, 'Embarked'] = 'S'\n",
    "train.loc[[61, 829]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value: Age - train test (263건)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Age.isna()].index\n",
    "df[df.Age.isna()]\n",
    "# Name 에서 정보 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial: Title 추출 XXXX.\n",
    "train['Initial'] = train.Name.str.extract('([A-Za-z]+)\\.') \n",
    "test['Initial'] = test.Name.str.extract('([A-Za-z]+)\\.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name2: 성 추출 .XXXX\n",
    "train['Name2'] = train.Name.str.extract('(([A-Za-z])+(?=,))')[0]\n",
    "test['Name2'] = test.Name.str.extract('(([A-Za-z])+(?=,))')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family: 가족 수 = 형제자매 + 부모/자녀 + 나자신 \n",
    "train['Family'] = (train['SibSp'] + train['Parch'] + 1).astype('int')\n",
    "test['Family'] = (test['SibSp'] + test['Parch'] + 1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age_NA: 나이가 null 인건은 -1, null 이 아닌 건은 0으로 표현하는 컬럼을 추가 \n",
    "train['Age_NA'] = 0\n",
    "test['Age_NA'] = 0\n",
    "\n",
    "train_idx = train[train['Age'].isna()].index\n",
    "test_idx = test[test['Age'].isna()].index\n",
    "\n",
    "train.loc[train_idx, 'Age_NA'] = -1\n",
    "test.loc[test_idx, 'Age_NA'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial 중 Age_NA 값이 0이 아닌 경우 null 이 존재하는 Initial 로 판단\n",
    "\n",
    "train.groupby(by='Initial').agg({'Initial':['count'],'Age':['min','max', 'mean'], 'Age_NA':['sum']})\n",
    "# Initial(null건수/총건수): Dr(1/7), Master(4/40), Miss(36/182), Mr(119/517), Mrs(17/125)\n",
    "\n",
    "test.groupby(by='Initial').agg({'Initial':['count'],'Age':['min','max', 'mean'], 'Age_NA':['sum']})\n",
    "# Initial(null건수/총건수): Master(4/21), Miss(14/78), Mr(240/517), Mrs(10/72), Ms(1/1)\n",
    "\n",
    "df = pd.concat((train, test)) \n",
    "df.groupby(by='Initial').agg({'Initial':['count'],'Age':['min','max', 'mean'], 'Age_NA':['sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ms(1건)\n",
    "## train 에 없던 test Ms 1건이 존재하며 Null 값임 \n",
    "# train 데이터의 Ms(1건)을 참고로 test Ms 를 28.0세로 세팅\n",
    "df[df.Initial == 'Ms']\n",
    "test.loc[88, 'Age'] = 28.0\n",
    "test.loc[test.Initial == 'Ms', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dr(1건)\n",
    "# 8건 중에 1건 null\n",
    "# Age: 23.00~54.0, 평균: 43.571429\n",
    "df[df.Initial == 'Dr']\n",
    "\n",
    "# 1건의 세부 정보와 동일한 조건의(Pclass == 1 & Sex=='male') 평균으로 업데이트\n",
    "train.loc[766, 'Age'] = df[(df.Initial == 'Dr') & (df.Pclass==1) & (df.Sex=='male')]['Age'].mean() # 44.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Master ~ 14세 이하(생존률 높음 주의!)\n",
    "# 61건 중에 8건 NULL\n",
    "# Age: 0.33~14.5 평균: 5.482642\n",
    "df[((df.Initial == 'Master') & (df.Age.isna()))]\n",
    "\n",
    "# null건의 세부 정보와 동일한 조건의(Pclass == 3 & Sex == 'male') 평균으로 업데이트\n",
    "df[((df.Initial == 'Master') & (df.Pclass==3) & (df.Sex=='male'))]['Age'].mean() # 6.09\n",
    "\n",
    "train.loc[((train.Initial == 'Master') & (train.Age.isna())), 'Age'] = 6.09\n",
    "test.loc[((test.Initial == 'Master') & (test.Age.isna())), 'Age'] = 6.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Mrs (Sex == 'female' )\n",
    "# 197건 중에 27건 NULL\n",
    "# Age: 14.00~76.0 평균: 36.994118\n",
    "df[((df.Initial == 'Mrs') & (df.Age.isna()))].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SibSp(형제자매)가 있는 경우 또래로 가정하고 동일한 나이 세팅\n",
    "df[((df.Initial == 'Mrs') & (df.Age.isna()) & (df.SibSp > 0))].SibSp.unique()\n",
    "# SibSp 모두 1임을 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 성(Name2)을 사용하는 SibSp(형제자매)의 성을 추출\n",
    "SibSp_Name2 = df[((df.Initial == 'Mrs') & (df.Age.isna()) & (df.SibSp > 0))]['Name2'].unique()\n",
    "SibSp_Name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 성(Name2)을 가지는 형제자매의 나이를 동일하게 세팅 \n",
    "#df[((df['Name2'].isin(SibSp_Name2)) & (df.SibSp == 1))].sort_values('Name2')\n",
    "\n",
    "# Name2가 같은 14개 중 5개의 나이를 채울 수 있음 - train / test 혼용되 있어 index로 바로 처리\n",
    "train.loc[334, 'Age'] = 43.0\n",
    "train.loc[849, 'Age'] = 49.0\n",
    "train.loc[457, 'Age'] = 41.0\n",
    "train.loc[375, 'Age'] = 28.0\n",
    "test.loc[316, 'Age'] = 57.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남은 Null Age 평균으로 일괄처리\n",
    "\n",
    "# | Initial | null건수/총건수 | 최소나이~최대나이 | 평균나이\n",
    "# | Miss    | 50/260          | 0.17~63.0         | 21.774238\n",
    "# | Mr      | 176/757         | 11.00~80.0        | 32.252151\n",
    "# | Mrs     | 23/197          | 14.00~76.0        | 37.068966\n",
    "\n",
    "train.loc[((train.Initial == 'Miss') & (train.Age.isna())), 'Age'] = 21.77\n",
    "train.loc[((train.Initial == 'Mr') & (train.Age.isna())), 'Age'] = 32.25\n",
    "train.loc[((train.Initial == 'Mrs') & (train.Age.isna())), 'Age'] = 37.07\n",
    "\n",
    "test.loc[((test.Initial == 'Miss') & (test.Age.isna())), 'Age'] = 21.77\n",
    "test.loc[((test.Initial == 'Mr') & (test.Age.isna())), 'Age'] = 32.25\n",
    "test.loc[((test.Initial == 'Mrs') & (test.Age.isna())), 'Age'] = 37.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial grouping\n",
    "\n",
    "- Initial 유지\n",
    "Mr          757<br>\n",
    "Miss        260<br>\n",
    "Mrs         197<br>\n",
    "Master       61<br>\n",
    "Rev           8 -> X (모든 성직자가 Survived=0)<br>\n",
    "<br>\n",
    "- 성별에 따라 Initial 분리\n",
    "Dr            8 -> Mr(7) Miss(1)<br>\n",
    "<br>\n",
    "- Initial Mr 통일\n",
    "Col           4 -> Mr<br>\n",
    "Major         2 -> Mr<br>\n",
    "Don           1 -> Mr<br>\n",
    "Jonkheer      1 -> Mr<br>\n",
    "Capt          1 -> Mr<br>\n",
    "Sir           1 -> Mr<br>\n",
    "<br>\n",
    "- Initial Miss 통일\n",
    "Dona          1 -> Miss<br>\n",
    "Lady          1 -> Miss<br>\n",
    "Countess      1 -> Miss<br>\n",
    "Mme           1 -> Miss<br>\n",
    "Ms            2 -> Miss<br>\n",
    "Mlle          2 -> Miss<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts(df, ['Initial'])   \n",
    "\n",
    "train.loc[796, 'Initial'] = 'Miss'\n",
    "train['Initial'] = train['Initial'].map({'Mr':'Mr','Miss':'Miss','Mrs':'Mrs','Master':'Master','Rev':'Rev',\n",
    "                                         'Dr':'Mr', 'Col':'Mr', 'Major':'Mr', 'Don':'Mr', 'Jonkheer':'Mr', 'Capt':'Mr', 'Sir':'Mr'\n",
    "                                         , 'Dona':'Miss', 'Lady':'Miss', 'Countess':'Miss', 'Mme':'Miss', 'Ms':'Miss', 'Mlle':'Miss'})\n",
    "test['Initial'] = test['Initial'].map({'Mr':'Mr','Miss':'Miss','Mrs':'Mrs','Master':'Master','Rev':'Rev',\n",
    "                                         'Dr':'Mr', 'Col':'Mr', 'Major':'Mr', 'Don':'Mr', 'Jonkheer':'Mr', 'Capt':'Mr', 'Sir':'Mr'\n",
    "                                         , 'Dona':'Miss', 'Lady':'Miss', 'Countess':'Miss', 'Mme':'Miss', 'Ms':'Miss', 'Mlle':'Miss'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age_NA 컬럼 삭제 \n",
    "train.drop(['Age_NA'], axis=1, inplace=True)\n",
    "test.drop(['Age_NA'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value: Cabin - train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabin을 첫자리 알파벳만으로 구성\n",
    "train.Cabin = train.Cabin.str.slice(0,1)\n",
    "test.Cabin = test.Cabin.str.slice(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((train, test)) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Cabin, df.Pclass)\n",
    "\n",
    "df.groupby(by='Cabin').agg({'Cabin':['count'], 'Fare':['min','max', 'mean'], 'Family': 'mean'})\n",
    "\n",
    "# Cabin 과 Class 로 Null Cabin 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[((train.Pclass==1) & (train.Family==1) & (train.Cabin.isna())), 'Cabin'] = 'A'\n",
    "train.loc[((train.Pclass==1) & (train.Family==2) & (train.Cabin.isna())), 'Cabin'] = 'B'\n",
    "train.loc[((train.Pclass==1) & (train.Family>=3) & (train.Cabin.isna())), 'Cabin'] = 'C'\n",
    "train.loc[((train.Pclass==2) & (train.Family==1) & (train.Cabin.isna())), 'Cabin'] = 'D'\n",
    "train.loc[((train.Pclass==2) & (train.Family>=2) & (train.Cabin.isna())), 'Cabin'] = 'F'\n",
    "train.loc[((train.Pclass==3) & (train.Family<=2) & (train.Cabin.isna())), 'Cabin'] = 'F'\n",
    "train.loc[((train.Pclass==3) & (train.Family>=3) & (train.Cabin.isna())), 'Cabin'] = 'G'\n",
    "test.loc[((test.Pclass==1) & (test.Family==1) & (test.Cabin.isna())), 'Cabin'] = 'A'\n",
    "test.loc[((test.Pclass==1) & (test.Family==2) & (test.Cabin.isna())), 'Cabin'] = 'B'\n",
    "test.loc[((test.Pclass==1) & (test.Family>=3) & (test.Cabin.isna())), 'Cabin'] = 'C'\n",
    "test.loc[((test.Pclass==2) & (test.Family==1) & (test.Cabin.isna())), 'Cabin'] = 'D'\n",
    "test.loc[((test.Pclass==2) & (test.Family>=2) & (test.Cabin.isna())), 'Cabin'] = 'F'\n",
    "test.loc[((test.Pclass==3) & (test.Family<=2) & (test.Cabin.isna())), 'Cabin'] = 'F'\n",
    "test.loc[((test.Pclass==3) & (test.Family>=3) & (test.Cabin.isna())), 'Cabin'] = 'G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 Null 처리가 되었는지 확인\n",
    "train.isna().any().sum()\n",
    "test.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((train, test)) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Survived\n",
    "value_counts(df, ['Survived'])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- categorical: Pclass, Sex, Embarked     \n",
    "- String: Name, Ticket   \n",
    "- ??: Cabin        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts(df, ['Pclass', 'Sex', 'Embarked'])        \n",
    "\n",
    "# one-hot 대상: 'Pclass', 'Sex', 'Embarked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name> 파생컬럼(2):Initial, Name2\n",
    "value_counts(df, ['Name', 'Initial', 'Name2'])   \n",
    "# Name(1307)  Initial(5)  Name2(872)\n",
    "# => Initial 만 사용\n",
    "\n",
    "train.drop(['Name', 'Name2'], axis=1, inplace=True)\n",
    "test.drop(['Name', 'Name2'], axis=1, inplace=True)\n",
    "\n",
    "# one-hot 대상: 'Pclass', 'Sex', 'Embarked', 'Initial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket\n",
    "value_counts(df, ['Ticket'])   \n",
    "\n",
    "# 숫자만 추출 \n",
    "train['Ticket'] = train['Ticket'].str.extract('(([0-9])+(?!.)+)')[0]\n",
    "test['Ticket'] = test['Ticket'].str.extract('(([0-9])+(?!.)+)')[0]\n",
    "# 1자리 추출 \n",
    "train['Ticket'] = train['Ticket'].str.slice(start=0, stop=1)\n",
    "test['Ticket'] = test['Ticket'].str.slice(start=0, stop=1)\n",
    "# 전체 문자(LINE) NULL 값 처리(가장 많은 3으로 처리)\n",
    "train.Ticket.fillna('3', inplace=True)\n",
    "test.Ticket.fillna('3', inplace=True)\n",
    "\n",
    "# one-hot 대상: 'Pclass', 'Sex', 'Embarked', 'Initial', 'Ticket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabin\n",
    "value_counts(df, ['Cabin'])   \n",
    "\n",
    "# Cabin:T 가 1건이라 유사한 정보를 가진 사람의 A 로 업데이트\n",
    "df[df.Cabin=='T']\n",
    "df[((df.Fare == 35.50) & (df.Ticket.str.contains('11378')) & (df.Embarked == 'S'))]\n",
    "train.loc[339, 'Cabin'] = 'A'\n",
    "\n",
    "# one-hot 대상: 'Pclass', 'Sex', 'Embarked', 'Initial', 'Ticket', 'Cabin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((train, test)) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted( (train.Age*0.1).astype(np.int8).unique() )\n",
    "sorted( (test.Age*0.1).astype(np.int8).unique() )\n",
    "# train 80대 1명이 one-hot 할때 shape가 안 맞아 7로 수정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[(train.Age*0.1).astype(np.int8) == 8]\n",
    "train.loc[train.Age == 80.0, 'Age'] = 79.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'] = (train.Age*0.1).astype(np.int8)\n",
    "test['Age'] = (test.Age*0.1).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Cabin', 'Embarked'\n",
    "train.Embarked.unique()\n",
    "test.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'].replace(['S', 'C', 'Q'], [1,2,3], inplace=True)\n",
    "test['Embarked'].replace(['S', 'C', 'Q'], [1,2,3], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lable encoding \n",
    "train.loc[(train['Sex'] == 'male'), 'Sex'] = 1\n",
    "train.loc[(train['Sex'] == 'female'), 'Sex'] = 2\n",
    "train.loc[(train['Age'] < 1), 'Sex'] = 3\n",
    "test.loc[(test['Sex'] == 'male'), 'Sex'] = 1\n",
    "test.loc[(test['Sex'] == 'female'), 'Sex'] = 2\n",
    "test.loc[(test['Age'] < 1), 'Sex'] = 3\n",
    "\n",
    "train['Initial'].replace(['Mr', 'Mrs', 'Miss', 'Master', 'Rev'], [1,2,3,4,5], inplace=True)\n",
    "test['Initial'].replace(['Mr', 'Mrs', 'Miss', 'Master', 'Rev'], [1,2,3,4,5], inplace=True)\n",
    "\n",
    "train['Cabin'].replace(['A', 'B', 'C', 'D', 'E', 'F', 'G'], [1,2,3,4,5,6,7], inplace=True)\n",
    "test['Cabin'].replace(['A', 'B', 'C', 'D', 'E', 'F', 'G'], [1,2,3,4,5,6,7], inplace=True)\n",
    "\n",
    "train['Embarked'].replace(['S', 'C', 'Q'], [1,2,3], inplace=True)\n",
    "test['Embarked'].replace(['S', 'C', 'Q'], [1,2,3], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신상 'Pclass', 'Sex', 'Age'\n",
    "personal = np.vstack((train[['Pclass','Sex', 'Age']].values,\n",
    "                    test[['Pclass','Sex', 'Age']].values\n",
    "                   ))\n",
    "kmeans = MiniBatchKMeans(n_clusters=5, init='k-means++').fit(personal)\n",
    "train.loc[:, 'personal_cluster'] = kmeans.predict(train[['Pclass','Sex', 'Age']])\n",
    "test.loc[:, 'personal_cluster'] = kmeans.predict(test[['Pclass','Sex', 'Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가족 'SibSp', 'Parch', 'Initial'\n",
    "fam = np.vstack((train[['SibSp', 'Parch', 'Initial']].values,\n",
    "                 test[['SibSp', 'Parch', 'Initial']].values\n",
    "               ))\n",
    "kmeans = MiniBatchKMeans(n_clusters=5, init='k-means++').fit(personal)\n",
    "train.loc[:, 'fam_cluster'] = kmeans.predict(train[['SibSp', 'Parch', 'Initial']])\n",
    "test.loc[:, 'fam_cluster'] = kmeans.predict(test[['SibSp', 'Parch', 'Initial']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항구/선실정보 'Fare', 'Cabin', 'Embarked',\n",
    "ship = np.vstack((train[['Fare', 'Cabin', 'Embarked']].values,\n",
    "                 test[['Fare', 'Cabin', 'Embarked']].values\n",
    "               ))\n",
    "kmeans = MiniBatchKMeans(n_clusters=5, init='k-means++').fit(personal)\n",
    "train.loc[:, 'ship_cluster'] = kmeans.predict(train[['Fare', 'Cabin', 'Embarked']])\n",
    "test.loc[:, 'ship_cluster'] = kmeans.predict(test[['Fare', 'Cabin', 'Embarked']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot 대상: \n",
    "- 'Pclass', 'Sex', 'Embarked', 'Initial', 'Ticket', 'Cabin' + 'Age'\n",
    "- + 'personal_cluster', 'fam_cluster', 'ship_cluster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns = ['Pclass', 'Sex', 'Embarked', 'Initial', 'Ticket', 'Cabin'\n",
    "                                         ,'Age','personal_cluster', 'fam_cluster', 'ship_cluster'])\n",
    "test= pd.get_dummies(test, columns = ['Pclass', 'Sex', 'Embarked', 'Initial', 'Ticket', 'Cabin'\n",
    "                                      ,'Age','personal_cluster', 'fam_cluster', 'ship_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 8))\n",
    "sns.heatmap(train.corr(),annot=True,cmap='RdYlGn', linewidths=0.2, annot_kws={'size':10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 및 머신 러닝 알고리즘\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [#'PassengerId'\n",
    "        #, 'Survived'\n",
    "        # 'Age', \n",
    "       'SibSp', 'Parch', 'Fare', 'Family',\n",
    "       'Pclass_1', 'Pclass_2', 'Pclass_3'\n",
    "       , 'Sex_1', 'Sex_2', 'Sex_3',\n",
    "       'Embarked_1', 'Embarked_2', 'Embarked_3'\n",
    "       , 'Initial_1', 'Initial_2', 'Initial_3', 'Initial_4', 'Initial_5'\n",
    "       , 'Ticket_1', 'Ticket_2', 'Ticket_3', 'Ticket_4', 'Ticket_5', 'Ticket_6', 'Ticket_7', 'Ticket_8', 'Ticket_9'\n",
    "       , 'Cabin_1', 'Cabin_2', 'Cabin_3', 'Cabin_4', 'Cabin_5', 'Cabin_6', 'Cabin_7'\n",
    "       , 'Age_0', 'Age_1', 'Age_2', 'Age_3', 'Age_4', 'Age_5', 'Age_6', 'Age_7'\n",
    "       , 'personal_cluster_0', 'personal_cluster_1', 'personal_cluster_2', 'personal_cluster_3', 'personal_cluster_4',\n",
    "       'fam_cluster_0', 'fam_cluster_1', 'fam_cluster_2', 'fam_cluster_3', 'fam_cluster_4'\n",
    "    , 'ship_cluster_0', 'ship_cluster_1', 'ship_cluster_4'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train[cols], train['Survived'], test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 모델; 건수가 적어 lightgbm 은 생략 \n",
    "ran = RandomForestClassifier(random_state=42)\n",
    "log = LogisticRegression(random_state=42)\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "ext = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# 리스트 준비\n",
    "models = [ran, log, xgb, gbc, ext]         \n",
    "model_names = ['Random Forest', 'Logistic Regression', 'XGBoost', 'Gradient Boosting', 'Extra Trees']\n",
    "scores2 = {}\n",
    "\n",
    "# 학습 및 교차 검증\n",
    "for ind, mod in enumerate(models):\n",
    "    mod.fit(X_train, y_train)\n",
    "    acc = cross_val_score(mod, X_train, y_train, scoring = \"accuracy\", cv = 10)\n",
    "    scores2[model_names[ind]] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 테이블을 만듭니다.\n",
    "results = pd.DataFrame(scores2).T\n",
    "results['mean'] = results.mean(1)\n",
    "\n",
    "result_df = results.sort_values(by='mean', ascending=False)#.reset_index()\n",
    "result_df.head(11)\n",
    "result_df = result_df.drop(['mean'], axis=1)\n",
    "sns.boxplot(data=result_df.T, orient='h')\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.sort_values('mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#RandomForestClassifier()\n",
    "\n",
    "#cv15 - \n",
    "\n",
    "#cv 10 - \n",
    "\n",
    "#cv 5 - 0.8398896877770117\n",
    "#{'criterion': 'gini', 'max_depth': 7, 'max_features': 0.4, 'min_samples_leaf': 3\n",
    "#, 'min_samples_split': 2, 'n_estimators': 8}\n",
    "\n",
    "criterion = ['gini','entropy']\n",
    "max_depth = [6,7,8,9]\n",
    "min_samples_leaf = [2,3,4]\n",
    "min_samples_split = [1,2,3,4]\n",
    "max_features = [0.3,0.4,0.5]\n",
    "n_estimators = [7,8,9]\n",
    "\n",
    "hyperparams = {'n_estimators':n_estimators\n",
    "               ,'criterion':criterion\n",
    "               ,'max_depth':max_depth\n",
    "               ,'max_features':max_features\n",
    "               ,'min_samples_split':min_samples_split\n",
    "               ,'min_samples_leaf':min_samples_leaf\n",
    "               ,'max_features': max_features}\n",
    "\n",
    "gd=GridSearchCV(estimator = RandomForestClassifier(random_state=42\n",
    ", criterion='entropy', max_depth=8, max_features='auto'\n",
    ", min_samples_leaf=3, min_samples_split=3, n_estimators=11)\n",
    "                , param_grid = hyperparams, \n",
    "                verbose=True, cv=5, scoring = \"accuracy\", n_jobs=-1)\n",
    "\n",
    "gd.fit(X_train, y_train)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LogisticRegression()\n",
    "\n",
    "#cv=15 - \n",
    "\n",
    "#cv=10 - 0.8399843505477309\n",
    "#{'C': 2.7825594022071245, 'max_iter': 10, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "\n",
    "#cv=5 - 0.8413079877868611\n",
    "#{'C': 464.15888336127773, 'max_iter': 100, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "\n",
    "penalty = ['l1','l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga']\n",
    "max_iter=[5, 10, 25]\n",
    "multi_class=['auto', 'ovr', 'multinomial']\n",
    "\n",
    "hyperparams = {'penalty': penalty\n",
    "              ,'C': C\n",
    "               ,'solver': solver\n",
    "               ,'max_iter': max_iter\n",
    "               ,'multi_class': multi_class}\n",
    "\n",
    "gd=GridSearchCV(estimator = LogisticRegression(random_state=42)\n",
    "                , param_grid = hyperparams, \n",
    "                verbose=True, cv=10, scoring = \"accuracy\", n_jobs=-1)\n",
    "\n",
    "gd.fit(X_train, y_train)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#XGBClassifier\n",
    "\n",
    "#cv=15 - \n",
    "\n",
    "#cv=10 - \n",
    "\n",
    "#cv=5 - 0.8454939426770413\n",
    "#{'colsample_bytree': 0.85, 'gamma': 0.0, 'learning_rate': 0.5\n",
    "#, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50\n",
    "#, 'reg_alpha': 0.1, 'subsample': 1}\n",
    "\n",
    "colsample_bytree = [0.75, 0.8, 0.85, 0.9]#0.6, 0.65, 0.7, 0.75, 0.8, 0.95\n",
    "gamma = [i*0.1 for i in range(0,5)]\n",
    "learning_rate = [0.3, 0.4, 0.5,0.6]#0.001, 0.005,  0.01,0.1, \n",
    "max_depth = [2, 3, 4] #  ,5, 6, 7 , 8, 9, 10\n",
    "min_child_weight = [2,3,4]#, 3, 4, 5, 6\n",
    "n_estimators = [25, 50, 100]# 10,, 250, 500, 1000]\n",
    "reg_alpha = [0.1, 0.3, 0.5, 0.7, 1]#1e-5, , 1, 100]\n",
    "subsample = [0.95, 1]#0.6, 0.65, 0.7, 0.75, 0.8, 0.85,0.9, , 1\n",
    "    \n",
    "hyperparams = {'learning_rate': learning_rate, 'n_estimators': n_estimators\n",
    "               ,'max_depth': max_depth, 'min_child_weight': min_child_weight\n",
    "               ,'gamma': gamma\n",
    "               ,'subsample': subsample, 'colsample_bytree': colsample_bytree \n",
    "               ,'reg_alpha': reg_alpha\n",
    "              }\n",
    "\n",
    "gd=GridSearchCV(estimator = XGBClassifier(random_state=42)\n",
    "                , param_grid = hyperparams, \n",
    "                verbose=True, cv=5, scoring = \"accuracy\", n_jobs=-1)\n",
    "\n",
    "gd.fit(X_train, y_train)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#GradientBoostingClassifier\n",
    "\n",
    "#cv=15 - \n",
    "\n",
    "#cv=10 -\n",
    "\n",
    "#cv=5 - 0.8342164877376146\n",
    "#{'learning_rate': 0.05, 'max_depth': 1, 'n_estimators': 120}\n",
    "\n",
    "learning_rate = [0.01, 0.05, 0.15, 0.25] # 0.01, , 0.15, 0.1, 0.2, 0.5\n",
    "max_depth = [1, 3, 5, 7] # 1, 8, 10, 15\n",
    "n_estimators = [50, 75, 100, 120, 150] # , 100, 1000, 2000\n",
    "\n",
    "hyperparams = {'learning_rate': learning_rate, 'n_estimators': n_estimators, 'max_depth':max_depth}\n",
    "\n",
    "gd=GridSearchCV(estimator = GradientBoostingClassifier(random_state=42), param_grid = hyperparams, \n",
    "                verbose=True, cv=5, scoring = \"accuracy\", n_jobs=-1)\n",
    "\n",
    "gd.fit(X_train, y_train)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "#cv=15 - \n",
    "\n",
    "#cv=10 - \n",
    "\n",
    "#cv=5 - 0.8342361863488625\n",
    "#{'max_depth': 8, 'max_features': 0.1, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 20}\n",
    "\n",
    "max_depth = [5, 8, 10] # 1,3,  , None\n",
    "max_features = [0.1, 0.2] # , 0.5,, 0.7 0.8\n",
    "min_samples_leaf = [1, 2, 3]#, 10, 15\n",
    "min_samples_split = [8, 10,12, 15, 18] # 1, 2, , 15\n",
    "n_estimators = [15, 20, 25, 50] # 25, 5, 10,\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators\n",
    "               , 'max_depth': max_depth\n",
    "               , 'max_features': max_features\n",
    "               , 'min_samples_split': min_samples_split\n",
    "               , 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "gd=GridSearchCV(estimator = ExtraTreesClassifier(random_state=42), param_grid = hyperparams, \n",
    "                verbose=True, cv=5, scoring = \"accuracy\", n_jobs=-1)\n",
    "\n",
    "gd.fit(X_train, y_train)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝 모델\n",
    "ran = RandomForestClassifier(random_state=42\n",
    ", criterion='entropy', max_depth=8, max_features='auto'\n",
    ", min_samples_leaf=3, min_samples_split=3, n_estimators=11)\n",
    "log = LogisticRegression(random_state=42, C=1291.5496650148827)\n",
    "xgb = XGBClassifier(random_state=42, learning_rate=0.2, n_estimators=10,\n",
    "                                         max_depth=6, min_child_weight=1, gamma=0.1\n",
    "                                         , subsample=1, colsample_bytree=1, reg_alpha=1e-05)\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "ext = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# 리스트 준비\n",
    "models = [ran, log, xgb, gbc, ext]         \n",
    "model_names = ['Random Forest', 'Logistic Regression', 'XGBoost', 'Gradient Boosting', 'Extra Trees']\n",
    "scores2 = {}\n",
    "\n",
    "# 학습 및 교차 검증\n",
    "for ind, mod in enumerate(models):\n",
    "    mod.fit(X_train, y_train)\n",
    "    acc = cross_val_score(mod, X_train, y_train, scoring = \"accuracy\", cv = 10)\n",
    "    scores2[model_names[ind]] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 테이블을 만듭니다.\n",
    "results = pd.DataFrame(scores2).T\n",
    "results['mean'] = results.mean(1)\n",
    "\n",
    "result_df = results.sort_values(by='mean', ascending=False)#.reset_index()\n",
    "result_df.head(11)\n",
    "result_df = result_df.drop(['mean'], axis=1)\n",
    "sns.boxplot(data=result_df.T, orient='h')\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values('mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'C': 2.7825594022071245, 'max_iter': 400, 'multi_class': 'auto', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "# {'C': 59.94842503189409, 'max_iter': 100, 'multi_class': 'auto', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "# {'C': 464.15888336127773, 'max_iter': 100, 'multi_class': 'auto', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "# 'C': 464.15888336127773, 'max_iter': 100, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'lbfgs'\n",
    "log = LogisticRegression(random_state=42\n",
    "                         , C=464.15888336127773\n",
    "                         , max_iter=100\n",
    "                         , multi_class='multinomial'\n",
    "                         , penalty='l2'\n",
    "                         , solver='lbfgs'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(train[cols], train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.3\n",
    "#, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 100, 'reg_alpha': 0.05, 'subsample': 1}\n",
    "#'colsample_bytree': 0.85, 'gamma': 0.0, 'learning_rate': 0.5, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50\n",
    "#, 'reg_alpha': 0.1, 'subsample': 1\n",
    "xgb = XGBClassifier(random_state=42, learning_rate=0.5, n_estimators=50,\n",
    "                                         max_depth=2, min_child_weight=2, gamma=0.0\n",
    "                                         , subsample=1, colsample_bytree=0.85, reg_alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(train[cols], train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log.predict(test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb.predict(test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n",
    "submission.to_csv(\"./output/20200910-2-1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n",
    "submission.to_csv(\"./output/20200910-3-2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
