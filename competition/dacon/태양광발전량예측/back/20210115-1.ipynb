{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, is_train=True):\n",
    "    \n",
    "    temp = data.copy()\n",
    "    temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "\n",
    "    if is_train==True:          \n",
    "    \n",
    "        temp['Target1'] = temp['TARGET'].shift(-48).fillna(method='ffill')\n",
    "        temp['Target2'] = temp['TARGET'].shift(-48*2).fillna(method='ffill')\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        return temp.iloc[:-96]\n",
    "\n",
    "    elif is_train==False:\n",
    "        \n",
    "        temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "                              \n",
    "        return temp.iloc[-48:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train/train.csv')\n",
    "\n",
    "test = []\n",
    "\n",
    "for i in range(81):\n",
    "    file_path = './data/test/' + str(i) + '.csv'\n",
    "    temp = pd.read_csv(file_path)\n",
    "    temp = preprocess_data(temp, is_train=False)\n",
    "    test.append(temp)\n",
    "\n",
    "df_test = pd.concat(test)\n",
    "\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52464, 9), (3888, 7))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess_data(train)\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>Target1</th>\n",
       "      <th>Target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>69.08</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>69.06</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>71.78</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>71.75</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>75.20</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>69.29</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>72.56</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>72.55</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>74.62</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>74.61</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.74</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.73</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>72.22</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>72.22</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>70.27</td>\n",
       "      <td>-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>64.83</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>7.039287</td>\n",
       "      <td>29</td>\n",
       "      <td>494</td>\n",
       "      <td>1.8</td>\n",
       "      <td>65.45</td>\n",
       "      <td>-9</td>\n",
       "      <td>7.133144</td>\n",
       "      <td>0.750808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>5.912871</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>55.90</td>\n",
       "      <td>-7</td>\n",
       "      <td>14.922796</td>\n",
       "      <td>1.689299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>22.337268</td>\n",
       "      <td>58</td>\n",
       "      <td>743</td>\n",
       "      <td>2.1</td>\n",
       "      <td>57.39</td>\n",
       "      <td>-6</td>\n",
       "      <td>22.806037</td>\n",
       "      <td>5.161690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>29.469529</td>\n",
       "      <td>67</td>\n",
       "      <td>811</td>\n",
       "      <td>1.9</td>\n",
       "      <td>53.15</td>\n",
       "      <td>-4</td>\n",
       "      <td>2.158549</td>\n",
       "      <td>4.973992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>25.339762</td>\n",
       "      <td>138</td>\n",
       "      <td>368</td>\n",
       "      <td>1.8</td>\n",
       "      <td>55.99</td>\n",
       "      <td>-3</td>\n",
       "      <td>36.225679</td>\n",
       "      <td>16.517408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>25.152060</td>\n",
       "      <td>178</td>\n",
       "      <td>224</td>\n",
       "      <td>1.9</td>\n",
       "      <td>55.97</td>\n",
       "      <td>-3</td>\n",
       "      <td>41.386914</td>\n",
       "      <td>9.760179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11</td>\n",
       "      <td>28.718397</td>\n",
       "      <td>193</td>\n",
       "      <td>261</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.43</td>\n",
       "      <td>-3</td>\n",
       "      <td>45.140829</td>\n",
       "      <td>7.601678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11</td>\n",
       "      <td>33.129393</td>\n",
       "      <td>189</td>\n",
       "      <td>364</td>\n",
       "      <td>2.3</td>\n",
       "      <td>58.41</td>\n",
       "      <td>-3</td>\n",
       "      <td>47.580874</td>\n",
       "      <td>10.980202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12</td>\n",
       "      <td>19.427151</td>\n",
       "      <td>190</td>\n",
       "      <td>37</td>\n",
       "      <td>2.6</td>\n",
       "      <td>59.19</td>\n",
       "      <td>-3</td>\n",
       "      <td>48.612666</td>\n",
       "      <td>17.361857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>25.715166</td>\n",
       "      <td>213</td>\n",
       "      <td>133</td>\n",
       "      <td>2.9</td>\n",
       "      <td>59.18</td>\n",
       "      <td>-3</td>\n",
       "      <td>48.143432</td>\n",
       "      <td>4.880090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>24.589225</td>\n",
       "      <td>211</td>\n",
       "      <td>114</td>\n",
       "      <td>3.2</td>\n",
       "      <td>63.27</td>\n",
       "      <td>-4</td>\n",
       "      <td>46.172141</td>\n",
       "      <td>13.326545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13</td>\n",
       "      <td>21.304405</td>\n",
       "      <td>185</td>\n",
       "      <td>101</td>\n",
       "      <td>3.1</td>\n",
       "      <td>63.27</td>\n",
       "      <td>-4</td>\n",
       "      <td>42.794162</td>\n",
       "      <td>9.478740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14</td>\n",
       "      <td>11.731500</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.84</td>\n",
       "      <td>-4</td>\n",
       "      <td>38.195666</td>\n",
       "      <td>4.504797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>14.734764</td>\n",
       "      <td>135</td>\n",
       "      <td>69</td>\n",
       "      <td>2.7</td>\n",
       "      <td>62.85</td>\n",
       "      <td>-4</td>\n",
       "      <td>32.283670</td>\n",
       "      <td>2.627827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15</td>\n",
       "      <td>5.818888</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>68.55</td>\n",
       "      <td>-5</td>\n",
       "      <td>25.432775</td>\n",
       "      <td>14.265504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15</td>\n",
       "      <td>7.602096</td>\n",
       "      <td>73</td>\n",
       "      <td>39</td>\n",
       "      <td>2.2</td>\n",
       "      <td>68.55</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.737444</td>\n",
       "      <td>16.611987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16</td>\n",
       "      <td>4.035725</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.27</td>\n",
       "      <td>-6</td>\n",
       "      <td>9.854244</td>\n",
       "      <td>9.010089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16</td>\n",
       "      <td>0.938541</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.28</td>\n",
       "      <td>-6</td>\n",
       "      <td>2.627827</td>\n",
       "      <td>2.440259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.33</td>\n",
       "      <td>-7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.35</td>\n",
       "      <td>-7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>76.43</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>76.44</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>76.72</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>76.72</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>77.51</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.51</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>83.46</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>83.46</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>83.36</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>83.36</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>90.86</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>90.85</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hour     TARGET  DHI  DNI   WS     RH   T    Target1    Target2\n",
       "0      0   0.000000    0    0  1.5  69.08 -12   0.000000   0.000000\n",
       "1      0   0.000000    0    0  1.5  69.06 -12   0.000000   0.000000\n",
       "2      1   0.000000    0    0  1.6  71.78 -12   0.000000   0.000000\n",
       "3      1   0.000000    0    0  1.6  71.75 -12   0.000000   0.000000\n",
       "4      2   0.000000    0    0  1.6  75.20 -12   0.000000   0.000000\n",
       "5      2   0.000000    0    0  1.5  69.29 -11   0.000000   0.000000\n",
       "6      3   0.000000    0    0  1.5  72.56 -11   0.000000   0.000000\n",
       "7      3   0.000000    0    0  1.4  72.55 -11   0.000000   0.000000\n",
       "8      4   0.000000    0    0  1.3  74.62 -11   0.000000   0.000000\n",
       "9      4   0.000000    0    0  1.3  74.61 -11   0.000000   0.000000\n",
       "10     5   0.000000    0    0  1.3  73.74 -11   0.000000   0.000000\n",
       "11     5   0.000000    0    0  1.3  73.73 -11   0.000000   0.000000\n",
       "12     6   0.000000    0    0  1.4  72.22 -12   0.000000   0.000000\n",
       "13     6   0.000000    0    0  1.4  72.22 -12   0.000000   0.000000\n",
       "14     7   0.000000    0    0  1.4  70.27 -12   0.000000   0.000000\n",
       "15     7   0.000000    0    0  1.6  64.83 -10   0.000000   0.000000\n",
       "16     8   7.039287   29  494  1.8  65.45  -9   7.133144   0.750808\n",
       "17     8   5.912871   61    7  1.9  55.90  -7  14.922796   1.689299\n",
       "18     9  22.337268   58  743  2.1  57.39  -6  22.806037   5.161690\n",
       "19     9  29.469529   67  811  1.9  53.15  -4   2.158549   4.973992\n",
       "20    10  25.339762  138  368  1.8  55.99  -3  36.225679  16.517408\n",
       "21    10  25.152060  178  224  1.9  55.97  -3  41.386914   9.760179\n",
       "22    11  28.718397  193  261  2.0  58.43  -3  45.140829   7.601678\n",
       "23    11  33.129393  189  364  2.3  58.41  -3  47.580874  10.980202\n",
       "24    12  19.427151  190   37  2.6  59.19  -3  48.612666  17.361857\n",
       "25    12  25.715166  213  133  2.9  59.18  -3  48.143432   4.880090\n",
       "26    13  24.589225  211  114  3.2  63.27  -4  46.172141  13.326545\n",
       "27    13  21.304405  185  101  3.1  63.27  -4  42.794162   9.478740\n",
       "28    14  11.731500  124    2  3.0  62.84  -4  38.195666   4.504797\n",
       "29    14  14.734764  135   69  2.7  62.85  -4  32.283670   2.627827\n",
       "30    15   5.818888   62    0  2.5  68.55  -5  25.432775  14.265504\n",
       "31    15   7.602096   73   39  2.2  68.55  -5  17.737444  16.611987\n",
       "32    16   4.035725   41   11  2.0  70.27  -6   9.854244   9.010089\n",
       "33    16   0.938541   10    0  2.0  70.28  -6   2.627827   2.440259\n",
       "34    17   0.000000    0    0  2.0  71.33  -7   0.000000   0.000000\n",
       "35    17   0.000000    0    0  2.0  71.35  -7   0.000000   0.000000\n",
       "36    18   0.000000    0    0  2.1  76.43  -8   0.000000   0.000000\n",
       "37    18   0.000000    0    0  2.2  76.44  -8   0.000000   0.000000\n",
       "38    19   0.000000    0    0  2.3  76.72  -8   0.000000   0.000000\n",
       "39    19   0.000000    0    0  2.2  76.72  -8   0.000000   0.000000\n",
       "40    20   0.000000    0    0  2.2  77.51  -8   0.000000   0.000000\n",
       "41    20   0.000000    0    0  2.0  77.51  -8   0.000000   0.000000\n",
       "42    21   0.000000    0    0  1.9  83.46  -9   0.000000   0.000000\n",
       "43    21   0.000000    0    0  1.8  83.46  -9   0.000000   0.000000\n",
       "44    22   0.000000    0    0  1.8  83.36  -9   0.000000   0.000000\n",
       "45    22   0.000000    0    0  1.7  83.36  -9   0.000000   0.000000\n",
       "46    23   0.000000    0    0  1.7  90.86 -10   0.000000   0.000000\n",
       "47    23   0.000000    0    0  1.6  90.85 -10   0.000000   0.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_train[['Hour','TARGET','DHI','DNI','WS','RH','T']] = scaler.fit_transform(df_train[['Hour','TARGET','DHI','DNI','WS','RH','T']])\n",
    "df_test[['Hour','TARGET','DHI','DNI','WS','RH','T']] = scaler.fit_transform(df_test[['Hour','TARGET','DHI','DNI','WS','RH','T']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day  = df_train.iloc[:, :-2]\n",
    "Day7 = df_train.iloc[:, -2]\n",
    "Day8 = df_train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import mean, maximum\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(q, y, pred):\n",
    "    err = (y-pred)\n",
    "    return mean(maximum(q*err, (q-1)*err), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lst = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39348, 7), (13116, 7), (39348,), (13116,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_1, X_valid_1, Y_train_1, Y_valid_1 = train_test_split(Day, Day7, test_size=0.25, random_state=0)\n",
    "X_train_2, X_valid_2, Y_train_2, Y_valid_2 = train_test_split(Day, Day8, test_size=0.25, random_state=0)\n",
    "\n",
    "X_train_1.shape, X_valid_1.shape, Y_train_1.shape, Y_valid_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(Day.shape)),\n",
    "    layers.Dense(64, activation='tanh'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "575/615 [===========================>..] - ETA: 0s - loss: 401.0807- ETA: 0s - loss: 462.6WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 389.1689 - val_loss: 149.8066\n",
      "Epoch 2/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 131.8642 - val_loss: 137.0590\n",
      "Epoch 3/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 130.1184 - val_loss: 134.2835\n",
      "Epoch 4/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 125.9470 - val_loss: 136.8763\n",
      "Epoch 5/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 126.4707 - val_loss: 134.3242\n",
      "Epoch 6/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 126.2591 - val_loss: 133.9323\n",
      "Epoch 7/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 126.0818 - val_loss: 131.2322\n",
      "Epoch 8/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 125.3097 - val_loss: 132.4099\n",
      "Epoch 9/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 122.2781 - val_loss: 136.3881\n",
      "Epoch 10/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 120.9359 - val_loss: 131.7504\n",
      "Epoch 11/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 123.8486 - val_loss: 131.0881\n",
      "Epoch 12/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 125.9672 - val_loss: 129.4873\n",
      "Epoch 13/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 120.0720 - val_loss: 128.9783\n",
      "Epoch 14/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 119.6327 - val_loss: 129.0975\n",
      "Epoch 15/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 120.7688 - val_loss: 129.0084\n",
      "Epoch 16/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 120.5264 - val_loss: 128.8734\n",
      "Epoch 17/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 123.7938 - val_loss: 130.6461\n",
      "Epoch 18/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 123.5038 - val_loss: 128.6086\n",
      "Epoch 19/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 122.6296 - val_loss: 128.6252\n",
      "Epoch 20/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 120.3622 - val_loss: 129.8300\n",
      "Epoch 21/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 118.7433 - val_loss: 130.3545\n",
      "Epoch 22/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 114.9764 - val_loss: 127.7814\n",
      "Epoch 23/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 117.7864 - val_loss: 127.9701\n",
      "Epoch 24/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 120.6601 - val_loss: 136.1239\n",
      "Epoch 25/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 116.1699 - val_loss: 127.2274\n",
      "410/410 [==============================] - 0s 702us/step - loss: 124.4231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "124.4230728149414"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.compile(loss='mse', optimizer='adam')\n",
    "hist7 = model7.fit(X_train_1, Y_train_1, epochs=25, batch_size=48, validation_split=0.25)\n",
    "model7.evaluate(X_valid_1, Y_valid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist7.history['loss'], 'b-', label='loss')\n",
    "plt.plot(hist7.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(Day.shape)),\n",
    "    layers.Dense(64, activation='tanh'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_10_input'), name='dense_10_input', description=\"created by layer 'dense_10_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_10_input'), name='dense_10_input', description=\"created by layer 'dense_10_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "572/615 [==========================>...] - ETA: 0s - loss: 441.6196WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_10_input'), name='dense_10_input', description=\"created by layer 'dense_10_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 427.9678 - val_loss: 151.3596\n",
      "Epoch 2/10\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 141.2088 - val_loss: 137.7951\n",
      "Epoch 3/10\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 141.7846 - val_loss: 136.4093\n",
      "Epoch 4/10\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.8628 - val_loss: 135.8161\n",
      "Epoch 5/10\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.7970 - val_loss: 135.5182\n",
      "Epoch 6/10\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 134.4700 - val_loss: 139.7175\n",
      "Epoch 7/10\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 134.6391 - val_loss: 137.5637\n",
      "Epoch 8/10\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.0480 - val_loss: 133.3245\n",
      "Epoch 9/10\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.8710 - val_loss: 132.5259\n",
      "Epoch 10/10\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.2135 - val_loss: 132.2055\n",
      "410/410 [==============================] - 0s 641us/step - loss: 131.8175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "131.81753540039062"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.compile(loss='mse', optimizer='adam')\n",
    "hist8 = model8.fit(X_train_2, Y_train_2, epochs=10, batch_size=48, validation_split=0.25)\n",
    "model8.evaluate(X_valid_2, Y_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist8.history['loss'], 'b-', label='loss')\n",
    "plt.plot(hist8.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "770/820 [===========================>..] - ETA: 0s - loss: 1.4728WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4695 - val_loss: 1.5751\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3692 - val_loss: 1.5562\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3468 - val_loss: 1.5557\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3363 - val_loss: 1.5501\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3417 - val_loss: 1.5650\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3161 - val_loss: 1.6461\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3212 - val_loss: 1.5654\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3365 - val_loss: 1.5859\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3255 - val_loss: 1.5950\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3330 - val_loss: 1.5589\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2957 - val_loss: 1.5569\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2938 - val_loss: 1.5989\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3076 - val_loss: 1.5670\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2910 - val_loss: 1.5729\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3214 - val_loss: 1.5747\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2995 - val_loss: 1.5976\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3050 - val_loss: 1.6181\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2953 - val_loss: 1.5821\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2971 - val_loss: 1.5827\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2984 - val_loss: 1.5884\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2829 - val_loss: 1.5903\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2754 - val_loss: 1.5856\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2712 - val_loss: 1.5962\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2877 - val_loss: 1.5828\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2742 - val_loss: 1.5942\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "815/820 [============================>.] - ETA: 0s - loss: 2.0813WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 2.0813 - val_loss: 2.5662\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0482 - val_loss: 2.5535\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0388 - val_loss: 2.5600\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0049 - val_loss: 2.5426\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0317 - val_loss: 2.5712\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0065 - val_loss: 2.6148\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0134 - val_loss: 2.5429\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0469 - val_loss: 2.5920\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0053 - val_loss: 2.6026\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0319 - val_loss: 2.5080\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9492 - val_loss: 2.5361\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9552 - val_loss: 2.6001\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9993 - val_loss: 2.5947\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9745 - val_loss: 2.5724\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9958 - val_loss: 2.5743\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9596 - val_loss: 2.6067\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9719 - val_loss: 2.6012\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9631 - val_loss: 2.6188\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9532 - val_loss: 2.5500\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9729 - val_loss: 2.5678\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9708 - val_loss: 2.5780\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9295 - val_loss: 2.5980\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9385 - val_loss: 2.6585\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9551 - val_loss: 2.5749\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9262 - val_loss: 2.5879\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819/820 [============================>.] - ETA: 0s - loss: 2.3534WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3534 - val_loss: 3.1271\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3076 - val_loss: 3.0675\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3067 - val_loss: 3.0831\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2701 - val_loss: 3.0643\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3026 - val_loss: 3.0820\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2752 - val_loss: 3.0484\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2841 - val_loss: 3.0567\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3274 - val_loss: 3.1001\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2624 - val_loss: 3.1070\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3179 - val_loss: 3.0013\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2177 - val_loss: 3.0664\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2319 - val_loss: 3.1313\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2574 - val_loss: 3.1115\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2398 - val_loss: 3.0911\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2504 - val_loss: 3.1015\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2241 - val_loss: 3.1113\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2367 - val_loss: 3.0748\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2327 - val_loss: 3.1183\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2203 - val_loss: 3.1162\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2372 - val_loss: 3.1061\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2373 - val_loss: 3.0412\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1930 - val_loss: 3.0693\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1964 - val_loss: 3.1204\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2076 - val_loss: 3.0382\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1712 - val_loss: 3.0843\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "812/820 [============================>.] - ETA: 0s - loss: 2.3506WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3507 - val_loss: 3.2674\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3003 - val_loss: 3.2571\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3110 - val_loss: 3.2144\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2843 - val_loss: 3.2664\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2983 - val_loss: 3.2840\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2831 - val_loss: 3.1834\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3013 - val_loss: 3.2202\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3231 - val_loss: 3.2623\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2580 - val_loss: 3.2434\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3208 - val_loss: 3.2420\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2120 - val_loss: 3.2619\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2337 - val_loss: 3.2510\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2554 - val_loss: 3.2853\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2427 - val_loss: 3.2759\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2468 - val_loss: 3.2489\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2276 - val_loss: 3.2527\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2421 - val_loss: 3.2913\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2321 - val_loss: 3.2992\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2269 - val_loss: 3.2701\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2346 - val_loss: 3.2550\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2276 - val_loss: 3.2269\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1950 - val_loss: 3.2396\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1945 - val_loss: 3.2781\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2052 - val_loss: 3.2288\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1670 - val_loss: 3.2416\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "819/820 [============================>.] - ETA: 0s - loss: 2.1735WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1735 - val_loss: 3.2384\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1213 - val_loss: 3.2217\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1380 - val_loss: 3.1589\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1284 - val_loss: 3.2005\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1213 - val_loss: 3.2320\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1260 - val_loss: 3.1724\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1366 - val_loss: 3.1728\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1613 - val_loss: 3.1897\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0959 - val_loss: 3.1757\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1534 - val_loss: 3.1981\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0578 - val_loss: 3.2083\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0745 - val_loss: 3.2172\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0929 - val_loss: 3.2349\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0792 - val_loss: 3.2598\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0945 - val_loss: 3.1922\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0796 - val_loss: 3.1798\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0853 - val_loss: 3.1996\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0832 - val_loss: 3.2017\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0770 - val_loss: 3.2187\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0824 - val_loss: 3.2059\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0737 - val_loss: 3.1783\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0421 - val_loss: 3.2108\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0366 - val_loss: 3.1835\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0474 - val_loss: 3.1755\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0139 - val_loss: 3.2428\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "813/820 [============================>.] - ETA: 0s - loss: 1.8976WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 1.8977 - val_loss: 3.0595\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8395 - val_loss: 2.9762\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8603 - val_loss: 2.9438\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8601 - val_loss: 2.9966\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8515 - val_loss: 2.9849\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8503 - val_loss: 2.9408\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8664 - val_loss: 2.9414\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8839 - val_loss: 2.9414\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8301 - val_loss: 2.9670\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8728 - val_loss: 2.9431\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7897 - val_loss: 3.0687\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8089 - val_loss: 2.9732\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8203 - val_loss: 2.9881\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8179 - val_loss: 3.0169\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8202 - val_loss: 2.9654\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7932 - val_loss: 2.9365\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8200 - val_loss: 2.9346\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8107 - val_loss: 2.9803\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8063 - val_loss: 2.9771\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8214 - val_loss: 2.9947\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8080 - val_loss: 2.9396\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7866 - val_loss: 2.9941\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7798 - val_loss: 2.9630\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7942 - val_loss: 2.9678\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7528 - val_loss: 2.9797\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "779/820 [===========================>..] - ETA: 0s - loss: 1.5432WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5432 - val_loss: 2.7016\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4984 - val_loss: 2.6127\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5036 - val_loss: 2.5496\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5113 - val_loss: 2.5737\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5055 - val_loss: 2.5930\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5002 - val_loss: 2.5661\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5167 - val_loss: 2.6489\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5290 - val_loss: 2.5437\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4959 - val_loss: 2.5873\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5214 - val_loss: 2.5552\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4567 - val_loss: 2.6960\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4685 - val_loss: 2.5953\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4805 - val_loss: 2.5799\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4810 - val_loss: 2.5828\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4799 - val_loss: 2.5624\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4650 - val_loss: 2.5319\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4902 - val_loss: 2.5634\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4718 - val_loss: 2.5629\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4649 - val_loss: 2.5589\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4884 - val_loss: 2.5645\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4744 - val_loss: 2.4521\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4756 - val_loss: 2.5999\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4573 - val_loss: 2.5531\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4696 - val_loss: 2.5611\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4358 - val_loss: 2.6454\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "775/820 [===========================>..] - ETA: 0s - loss: 1.1276WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1277 - val_loss: 2.1780\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0930 - val_loss: 2.1229\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1079 - val_loss: 2.0270\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1056 - val_loss: 2.0909\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0952 - val_loss: 2.0381\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0910 - val_loss: 2.0959\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1159 - val_loss: 2.1414\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1155 - val_loss: 2.0124\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0938 - val_loss: 2.1042\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1190 - val_loss: 2.0008\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0624 - val_loss: 2.1190\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0798 - val_loss: 1.9992\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0883 - val_loss: 2.0428\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0798 - val_loss: 2.1019\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0761 - val_loss: 2.0350\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0699 - val_loss: 2.0576\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0830 - val_loss: 1.9912\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0830 - val_loss: 2.1362\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0730 - val_loss: 2.0707\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0869 - val_loss: 2.0710\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0801 - val_loss: 1.9636\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0710 - val_loss: 2.0163\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0781 - val_loss: 2.0417\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0687 - val_loss: 2.0829\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.0553 - val_loss: 2.0495\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "814/820 [============================>.] - ETA: 0s - loss: 0.6423WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6424 - val_loss: 1.3086\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6311 - val_loss: 1.4661\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6298 - val_loss: 1.3870\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6311 - val_loss: 1.3740\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6196 - val_loss: 1.2884\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6257 - val_loss: 1.3915\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6318 - val_loss: 1.3378\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6318 - val_loss: 1.3535\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6196 - val_loss: 1.4052\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6368 - val_loss: 1.3433\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6031 - val_loss: 1.3594\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6102 - val_loss: 1.4140\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6172 - val_loss: 1.2930\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6116 - val_loss: 1.4040\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6103 - val_loss: 1.2799\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6094 - val_loss: 1.2851\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6076 - val_loss: 1.3351\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6190 - val_loss: 1.3318\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6112 - val_loss: 1.3762\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6147 - val_loss: 1.3657\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6065 - val_loss: 1.2910\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6103 - val_loss: 1.4466\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6098 - val_loss: 1.2402\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6101 - val_loss: 1.3603\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.5982 - val_loss: 1.3116\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_18_input'), name='dense_18_input', description=\"created by layer 'dense_18_input'\"), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results7 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    model7.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model7.fit(Day, Day7, epochs=25, batch_size=48, validation_split=0.25)\n",
    "    pred = pd.DataFrame(model7.predict(df_test))\n",
    "    results7 = pd.concat([results7, pred], axis=1)\n",
    "\n",
    "results7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "803/820 [============================>.] - ETA: 0s - loss: 1.5074WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 1.5062 - val_loss: 1.5976\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4142 - val_loss: 1.5571\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3848 - val_loss: 1.5662\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3682 - val_loss: 1.5434\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3791 - val_loss: 1.5510\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3681 - val_loss: 1.5615\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3737 - val_loss: 1.5537\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3756 - val_loss: 1.5650\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3798 - val_loss: 1.5662\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3720 - val_loss: 1.5507\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3444 - val_loss: 1.5729\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3417 - val_loss: 1.5617\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3564 - val_loss: 1.5737\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3286 - val_loss: 1.5634\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3620 - val_loss: 1.5826\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3412 - val_loss: 1.5678\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3342 - val_loss: 1.5893\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3442 - val_loss: 1.5772\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3299 - val_loss: 1.5599\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3356 - val_loss: 1.5739\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3289 - val_loss: 1.5523\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3151 - val_loss: 1.5864\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3116 - val_loss: 1.6121\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3107 - val_loss: 1.5779\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3126 - val_loss: 1.5879\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "811/820 [============================>.] - ETA: 0s - loss: 2.1841WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1839 - val_loss: 2.5757\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1567 - val_loss: 2.5584\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1554 - val_loss: 2.5602\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1236 - val_loss: 2.5713\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1302 - val_loss: 2.5995\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1115 - val_loss: 2.5515\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1336 - val_loss: 2.5908\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1204 - val_loss: 2.5752\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1153 - val_loss: 2.5819\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1085 - val_loss: 2.5953\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0779 - val_loss: 2.6114\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0545 - val_loss: 2.6019\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0859 - val_loss: 2.6870\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0502 - val_loss: 2.6059\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0929 - val_loss: 2.6230\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0655 - val_loss: 2.6032\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0551 - val_loss: 2.6502\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0580 - val_loss: 2.6082\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0327 - val_loss: 2.6083\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0305 - val_loss: 2.6312\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0379 - val_loss: 2.6045\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0282 - val_loss: 2.6354\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9963 - val_loss: 2.6582\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0054 - val_loss: 2.6213\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9967 - val_loss: 2.6476\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813/820 [============================>.] - ETA: 0s - loss: 2.4993WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4991 - val_loss: 3.1482\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4600 - val_loss: 3.2207\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4701 - val_loss: 3.1357\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4379 - val_loss: 3.1721\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4444 - val_loss: 3.1680\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4066 - val_loss: 3.1348\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4487 - val_loss: 3.1703\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4290 - val_loss: 3.1919\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4209 - val_loss: 3.2050\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4151 - val_loss: 3.2071\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3806 - val_loss: 3.1821\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3548 - val_loss: 3.1818\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3843 - val_loss: 3.2324\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3452 - val_loss: 3.2023\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3831 - val_loss: 3.2131\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3515 - val_loss: 3.2323\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3644 - val_loss: 3.2173\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3564 - val_loss: 3.2103\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3369 - val_loss: 3.1823\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3189 - val_loss: 3.2139\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3423 - val_loss: 3.2696\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3143 - val_loss: 3.2353\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2737 - val_loss: 3.2910\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2916 - val_loss: 3.2313\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2710 - val_loss: 3.3046\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "818/820 [============================>.] - ETA: 0s - loss: 2.4904WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4904 - val_loss: 3.4044\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4637 - val_loss: 3.4928\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4705 - val_loss: 3.4077\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4501 - val_loss: 3.4283\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4424 - val_loss: 3.4439\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3875 - val_loss: 3.3682\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4406 - val_loss: 3.3984\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4293 - val_loss: 3.3938\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4148 - val_loss: 3.4230\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4148 - val_loss: 3.4158\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3938 - val_loss: 3.4214\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3612 - val_loss: 3.4310\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3952 - val_loss: 3.4684\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3510 - val_loss: 3.4415\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3698 - val_loss: 3.4944\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3377 - val_loss: 3.4423\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3640 - val_loss: 3.4707\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3504 - val_loss: 3.4221\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3473 - val_loss: 3.4270\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3171 - val_loss: 3.4468\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3256 - val_loss: 3.5245\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3077 - val_loss: 3.5053\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2716 - val_loss: 3.5357\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3041 - val_loss: 3.5222\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2643 - val_loss: 3.5250\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "811/820 [============================>.] - ETA: 0s - loss: 2.2825WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2825 - val_loss: 3.4438\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2712 - val_loss: 3.5000\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2790 - val_loss: 3.3869\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2778 - val_loss: 3.3665\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2651 - val_loss: 3.4013\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1964 - val_loss: 3.3441\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2485 - val_loss: 3.3808\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2448 - val_loss: 3.4334\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2266 - val_loss: 3.4500\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2503 - val_loss: 3.4369\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2142 - val_loss: 3.4408\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1961 - val_loss: 3.4129\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2168 - val_loss: 3.4891\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1742 - val_loss: 3.4182\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1913 - val_loss: 3.4303\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1661 - val_loss: 3.4103\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2041 - val_loss: 3.4108\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1757 - val_loss: 3.4685\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1757 - val_loss: 3.4669\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1497 - val_loss: 3.4487\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1703 - val_loss: 3.4584\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1411 - val_loss: 3.4681\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1133 - val_loss: 3.4979\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1413 - val_loss: 3.5248\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1094 - val_loss: 3.5073\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "808/820 [============================>.] - ETA: 0s - loss: 1.9883WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9883 - val_loss: 3.2300\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9762 - val_loss: 3.3376\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9748 - val_loss: 3.1481\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9804 - val_loss: 3.1594\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9539 - val_loss: 3.1775\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9094 - val_loss: 3.1844\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9578 - val_loss: 3.2458\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9686 - val_loss: 3.1636\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9398 - val_loss: 3.2368\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9634 - val_loss: 3.2262\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9285 - val_loss: 3.2196\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9246 - val_loss: 3.2335\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9290 - val_loss: 3.1948\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9080 - val_loss: 3.2174\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9170 - val_loss: 3.2024\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8895 - val_loss: 3.1751\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9248 - val_loss: 3.1787\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8968 - val_loss: 3.3084\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9116 - val_loss: 3.1904\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8862 - val_loss: 3.1981\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9054 - val_loss: 3.2389\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8764 - val_loss: 3.2279\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8554 - val_loss: 3.2840\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8868 - val_loss: 3.3227\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8582 - val_loss: 3.2657\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "771/820 [===========================>..] - ETA: 0s - loss: 1.6193WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.6194 - val_loss: 2.8173\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.6042 - val_loss: 2.8730\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5946 - val_loss: 2.7349\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.6114 - val_loss: 2.7444\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5950 - val_loss: 2.7677\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5618 - val_loss: 2.7352\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 2s 2ms/step - loss: 1.5895 - val_loss: 2.8867\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.5912 - val_loss: 2.7601\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5812 - val_loss: 2.9138\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.6035 - val_loss: 2.8064\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5577 - val_loss: 2.7654\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5694 - val_loss: 2.8664\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5828 - val_loss: 2.7846\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5570 - val_loss: 2.8087\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5609 - val_loss: 2.7454\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5365 - val_loss: 2.7579\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5755 - val_loss: 2.8345\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5440 - val_loss: 2.8613\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5512 - val_loss: 2.7592\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5398 - val_loss: 2.7552\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5646 - val_loss: 2.8728\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5383 - val_loss: 2.8527\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5188 - val_loss: 2.8597\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5474 - val_loss: 2.8598\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5210 - val_loss: 2.7763\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "819/820 [============================>.] - ETA: 0s - loss: 1.1761WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 1.1761 - val_loss: 2.2982\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1666 - val_loss: 2.3622\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1611 - val_loss: 2.2343\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1737 - val_loss: 2.2138\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1671 - val_loss: 2.1910\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1350 - val_loss: 2.2543\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1601 - val_loss: 2.2187\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1601 - val_loss: 2.1549\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1507 - val_loss: 2.1941\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1594 - val_loss: 2.2233\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1386 - val_loss: 2.2839\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1411 - val_loss: 2.3102\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1437 - val_loss: 2.1671\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1335 - val_loss: 2.2399\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1347 - val_loss: 2.1695\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1238 - val_loss: 2.1915\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1488 - val_loss: 2.2898\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1238 - val_loss: 2.3896\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1339 - val_loss: 2.2152\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1279 - val_loss: 2.1831\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1368 - val_loss: 2.2307\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1202 - val_loss: 2.2138\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1159 - val_loss: 2.3069\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1333 - val_loss: 2.2766\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.1024 - val_loss: 2.2575\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "782/820 [===========================>..] - ETA: 0s - loss: 0.6699WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 0.6699 - val_loss: 1.5527\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6617 - val_loss: 1.5003\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6586 - val_loss: 1.4236\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6632 - val_loss: 1.4767\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6605 - val_loss: 1.3909\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6483 - val_loss: 1.5721\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6638 - val_loss: 1.5082\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6524 - val_loss: 1.4097\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6514 - val_loss: 1.4085\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6506 - val_loss: 1.4399\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6433 - val_loss: 1.5327\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6478 - val_loss: 1.4764\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6447 - val_loss: 1.4923\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6411 - val_loss: 1.4286\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6406 - val_loss: 1.4475\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6342 - val_loss: 1.4506\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6477 - val_loss: 1.5273\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6280 - val_loss: 1.6255\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6434 - val_loss: 1.4261\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6328 - val_loss: 1.4610\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6417 - val_loss: 1.4561\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6338 - val_loss: 1.4104\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6269 - val_loss: 1.5697\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6347 - val_loss: 1.5022\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.6224 - val_loss: 1.3623\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_14_input'), name='dense_14_input', description=\"created by layer 'dense_14_input'\"), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results8 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    model8.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model8.fit(Day, Day8, epochs=25, batch_size=48, validation_split=0.25)\n",
    "    pred = pd.DataFrame(model8.predict(df_test))\n",
    "    results8 = pd.concat([results8, pred], axis=1)\n",
    "\n",
    "results8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>-0.006363</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>-0.006583</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>-0.006424</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>-0.006452</td>\n",
       "      <td>-0.001205</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>-0.006089</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>80.csv_Day8_21h30m</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>-0.002122</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>80.csv_Day8_22h00m</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>80.csv_Day8_22h30m</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>80.csv_Day8_23h00m</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>-0.002548</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>80.csv_Day8_23h30m</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     q_0.1     q_0.2     q_0.3     q_0.4     q_0.5  \\\n",
       "0       0.csv_Day7_0h00m -0.006363 -0.001344 -0.000477 -0.000091  0.000025   \n",
       "1       0.csv_Day7_0h30m -0.006583 -0.001250 -0.000477 -0.000091  0.000025   \n",
       "2       0.csv_Day7_1h00m -0.006424 -0.001127 -0.000477 -0.000091  0.000025   \n",
       "3       0.csv_Day7_1h30m -0.006452 -0.001205 -0.000477 -0.000091  0.000025   \n",
       "4       0.csv_Day7_2h00m -0.006089 -0.001196 -0.000477 -0.000091  0.000025   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "7771  80.csv_Day8_21h30m  0.003785 -0.002122 -0.000005  0.000027 -0.000070   \n",
       "7772  80.csv_Day8_22h00m  0.003576 -0.002403 -0.000005  0.000027 -0.000070   \n",
       "7773  80.csv_Day8_22h30m  0.003818 -0.002303 -0.000005  0.000027 -0.000070   \n",
       "7774  80.csv_Day8_23h00m  0.003872 -0.002548 -0.000005  0.000027 -0.000070   \n",
       "7775  80.csv_Day8_23h30m  0.004264 -0.002394 -0.000005  0.000027 -0.000070   \n",
       "\n",
       "         q_0.6     q_0.7     q_0.8     q_0.9  \n",
       "0     0.000019  0.000267  0.000341 -0.000128  \n",
       "1     0.000019  0.000267  0.000341 -0.000128  \n",
       "2     0.000019  0.000267  0.000341 -0.000128  \n",
       "3     0.000019  0.000267  0.000341 -0.000128  \n",
       "4     0.000019  0.000267  0.000341 -0.000128  \n",
       "...        ...       ...       ...       ...  \n",
       "7771  0.000049  0.000095  0.000096  0.000428  \n",
       "7772  0.000049  0.000095  0.000096  0.000428  \n",
       "7773  0.000049  0.000095  0.000096  0.000428  \n",
       "7774  0.000049  0.000095  0.000096  0.000428  \n",
       "7775  0.000049  0.000095  0.000096  0.000428  \n",
       "\n",
       "[7776 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.loc[submission.id.str.contains(\"Day7\"), \"q_0.1\":] = results7.sort_index().values\n",
    "submission.loc[submission.id.str.contains(\"Day8\"), \"q_0.1\":] = results8.sort_index().values\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>-0.006363</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>-0.006583</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>-0.006424</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>-0.006452</td>\n",
       "      <td>-0.001205</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>-0.006089</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>-0.006354</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>-0.006593</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>-0.007519</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>-0.008617</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>-0.010055</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>-0.012060</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>-0.012646</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>-0.013610</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.922747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>-0.013958</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.937790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>-0.015241</td>\n",
       "      <td>-0.001352</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.248892</td>\n",
       "      <td>5.061938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>-0.006065</td>\n",
       "      <td>0.172082</td>\n",
       "      <td>0.054861</td>\n",
       "      <td>0.940653</td>\n",
       "      <td>1.967855</td>\n",
       "      <td>0.190639</td>\n",
       "      <td>1.161434</td>\n",
       "      <td>1.466672</td>\n",
       "      <td>6.064527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>2.168166</td>\n",
       "      <td>9.935078</td>\n",
       "      <td>10.101877</td>\n",
       "      <td>13.071778</td>\n",
       "      <td>10.875632</td>\n",
       "      <td>9.723827</td>\n",
       "      <td>11.893978</td>\n",
       "      <td>17.305061</td>\n",
       "      <td>21.256166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>8.219138</td>\n",
       "      <td>16.149208</td>\n",
       "      <td>15.131013</td>\n",
       "      <td>18.112816</td>\n",
       "      <td>17.869654</td>\n",
       "      <td>18.714479</td>\n",
       "      <td>23.518169</td>\n",
       "      <td>27.355486</td>\n",
       "      <td>24.726851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>15.809849</td>\n",
       "      <td>27.461298</td>\n",
       "      <td>24.748907</td>\n",
       "      <td>25.318283</td>\n",
       "      <td>24.552172</td>\n",
       "      <td>25.124680</td>\n",
       "      <td>29.679285</td>\n",
       "      <td>30.384979</td>\n",
       "      <td>29.552382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>18.161575</td>\n",
       "      <td>29.813841</td>\n",
       "      <td>26.426388</td>\n",
       "      <td>27.757332</td>\n",
       "      <td>28.369947</td>\n",
       "      <td>27.659504</td>\n",
       "      <td>30.497345</td>\n",
       "      <td>31.418499</td>\n",
       "      <td>31.690540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>21.438902</td>\n",
       "      <td>35.082375</td>\n",
       "      <td>36.723213</td>\n",
       "      <td>40.679344</td>\n",
       "      <td>41.418743</td>\n",
       "      <td>39.356953</td>\n",
       "      <td>38.052567</td>\n",
       "      <td>38.174858</td>\n",
       "      <td>43.391884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>21.592306</td>\n",
       "      <td>34.259342</td>\n",
       "      <td>37.586926</td>\n",
       "      <td>41.411938</td>\n",
       "      <td>41.245426</td>\n",
       "      <td>40.158268</td>\n",
       "      <td>38.634254</td>\n",
       "      <td>36.906734</td>\n",
       "      <td>43.577946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>24.594522</td>\n",
       "      <td>37.492794</td>\n",
       "      <td>40.919483</td>\n",
       "      <td>47.528526</td>\n",
       "      <td>48.757259</td>\n",
       "      <td>49.316769</td>\n",
       "      <td>47.960419</td>\n",
       "      <td>48.299988</td>\n",
       "      <td>53.895020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>24.639568</td>\n",
       "      <td>38.271423</td>\n",
       "      <td>39.843517</td>\n",
       "      <td>46.359558</td>\n",
       "      <td>47.634098</td>\n",
       "      <td>47.191517</td>\n",
       "      <td>46.372513</td>\n",
       "      <td>48.066967</td>\n",
       "      <td>51.758163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>24.952517</td>\n",
       "      <td>35.493206</td>\n",
       "      <td>37.543751</td>\n",
       "      <td>42.653866</td>\n",
       "      <td>45.656307</td>\n",
       "      <td>48.077084</td>\n",
       "      <td>49.973759</td>\n",
       "      <td>48.392189</td>\n",
       "      <td>50.591724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>24.993122</td>\n",
       "      <td>34.937168</td>\n",
       "      <td>37.905022</td>\n",
       "      <td>43.882797</td>\n",
       "      <td>45.877621</td>\n",
       "      <td>48.354843</td>\n",
       "      <td>49.438465</td>\n",
       "      <td>47.119659</td>\n",
       "      <td>51.389545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>24.392855</td>\n",
       "      <td>31.258072</td>\n",
       "      <td>32.847046</td>\n",
       "      <td>37.576630</td>\n",
       "      <td>41.157932</td>\n",
       "      <td>46.527805</td>\n",
       "      <td>50.472324</td>\n",
       "      <td>47.828259</td>\n",
       "      <td>50.070557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>24.188114</td>\n",
       "      <td>31.546381</td>\n",
       "      <td>34.680557</td>\n",
       "      <td>41.165028</td>\n",
       "      <td>44.555111</td>\n",
       "      <td>51.021282</td>\n",
       "      <td>59.621376</td>\n",
       "      <td>57.372925</td>\n",
       "      <td>55.818192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>22.689211</td>\n",
       "      <td>25.659964</td>\n",
       "      <td>26.723389</td>\n",
       "      <td>30.455311</td>\n",
       "      <td>36.693802</td>\n",
       "      <td>43.787117</td>\n",
       "      <td>54.318577</td>\n",
       "      <td>50.227959</td>\n",
       "      <td>51.349548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>22.087637</td>\n",
       "      <td>24.815351</td>\n",
       "      <td>24.367188</td>\n",
       "      <td>28.383661</td>\n",
       "      <td>34.606121</td>\n",
       "      <td>40.954967</td>\n",
       "      <td>50.641411</td>\n",
       "      <td>46.185673</td>\n",
       "      <td>46.939655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>19.708658</td>\n",
       "      <td>19.952797</td>\n",
       "      <td>18.879871</td>\n",
       "      <td>21.047159</td>\n",
       "      <td>27.768536</td>\n",
       "      <td>36.456612</td>\n",
       "      <td>43.150063</td>\n",
       "      <td>38.752357</td>\n",
       "      <td>38.905273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>17.316366</td>\n",
       "      <td>19.320276</td>\n",
       "      <td>19.995483</td>\n",
       "      <td>23.462261</td>\n",
       "      <td>28.777628</td>\n",
       "      <td>34.717106</td>\n",
       "      <td>40.114491</td>\n",
       "      <td>34.379795</td>\n",
       "      <td>36.643185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>9.041524</td>\n",
       "      <td>11.084370</td>\n",
       "      <td>10.268464</td>\n",
       "      <td>9.953065</td>\n",
       "      <td>14.313321</td>\n",
       "      <td>18.298862</td>\n",
       "      <td>21.354954</td>\n",
       "      <td>19.388554</td>\n",
       "      <td>20.243980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>1.926115</td>\n",
       "      <td>2.643765</td>\n",
       "      <td>4.167500</td>\n",
       "      <td>4.753918</td>\n",
       "      <td>8.014334</td>\n",
       "      <td>6.076043</td>\n",
       "      <td>6.950895</td>\n",
       "      <td>6.521307</td>\n",
       "      <td>6.648596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>-0.012797</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>0.433509</td>\n",
       "      <td>1.041787</td>\n",
       "      <td>1.386083</td>\n",
       "      <td>2.072238</td>\n",
       "      <td>1.362743</td>\n",
       "      <td>0.025943</td>\n",
       "      <td>0.470843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>-0.012924</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>0.488379</td>\n",
       "      <td>1.138104</td>\n",
       "      <td>1.389329</td>\n",
       "      <td>2.314170</td>\n",
       "      <td>1.967573</td>\n",
       "      <td>0.155685</td>\n",
       "      <td>0.911990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>-0.014969</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>0.131171</td>\n",
       "      <td>0.456177</td>\n",
       "      <td>0.150420</td>\n",
       "      <td>0.579307</td>\n",
       "      <td>0.662274</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.233350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>-0.015020</td>\n",
       "      <td>-0.001731</td>\n",
       "      <td>0.142221</td>\n",
       "      <td>0.361618</td>\n",
       "      <td>0.190918</td>\n",
       "      <td>0.538357</td>\n",
       "      <td>0.692349</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.285127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>-0.016063</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>-0.016323</td>\n",
       "      <td>-0.001512</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>-0.018388</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>-0.017898</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>-0.017477</td>\n",
       "      <td>-0.001170</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>-0.016011</td>\n",
       "      <td>-0.001206</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>-0.014084</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>-0.014065</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>-0.012559</td>\n",
       "      <td>-0.001244</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>-0.012559</td>\n",
       "      <td>-0.001244</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m  -0.006363  -0.001344  -0.000477  -0.000091   0.000025   \n",
       "1    0.csv_Day7_0h30m  -0.006583  -0.001250  -0.000477  -0.000091   0.000025   \n",
       "2    0.csv_Day7_1h00m  -0.006424  -0.001127  -0.000477  -0.000091   0.000025   \n",
       "3    0.csv_Day7_1h30m  -0.006452  -0.001205  -0.000477  -0.000091   0.000025   \n",
       "4    0.csv_Day7_2h00m  -0.006089  -0.001196  -0.000477  -0.000091   0.000025   \n",
       "5    0.csv_Day7_2h30m  -0.006354  -0.001000  -0.000477  -0.000091   0.000025   \n",
       "6    0.csv_Day7_3h00m  -0.006593  -0.000923  -0.000477  -0.000091   0.000025   \n",
       "7    0.csv_Day7_3h30m  -0.007519  -0.000797  -0.000477  -0.000091   0.000025   \n",
       "8    0.csv_Day7_4h00m  -0.008617  -0.000870  -0.000477  -0.000091   0.000025   \n",
       "9    0.csv_Day7_4h30m  -0.010055  -0.000841  -0.000477  -0.000091   0.000025   \n",
       "10   0.csv_Day7_5h00m  -0.012060  -0.000939  -0.000477  -0.000091   0.000025   \n",
       "11   0.csv_Day7_5h30m  -0.012646  -0.000880  -0.000477  -0.000091   0.000025   \n",
       "12   0.csv_Day7_6h00m  -0.013610  -0.001171  -0.000477  -0.000091   0.000025   \n",
       "13   0.csv_Day7_6h30m  -0.013958  -0.001124  -0.000477  -0.000091   0.000025   \n",
       "14   0.csv_Day7_7h00m  -0.015241  -0.001352  -0.000477  -0.000091   0.000025   \n",
       "15   0.csv_Day7_7h30m  -0.006065   0.172082   0.054861   0.940653   1.967855   \n",
       "16   0.csv_Day7_8h00m   2.168166   9.935078  10.101877  13.071778  10.875632   \n",
       "17   0.csv_Day7_8h30m   8.219138  16.149208  15.131013  18.112816  17.869654   \n",
       "18   0.csv_Day7_9h00m  15.809849  27.461298  24.748907  25.318283  24.552172   \n",
       "19   0.csv_Day7_9h30m  18.161575  29.813841  26.426388  27.757332  28.369947   \n",
       "20  0.csv_Day7_10h00m  21.438902  35.082375  36.723213  40.679344  41.418743   \n",
       "21  0.csv_Day7_10h30m  21.592306  34.259342  37.586926  41.411938  41.245426   \n",
       "22  0.csv_Day7_11h00m  24.594522  37.492794  40.919483  47.528526  48.757259   \n",
       "23  0.csv_Day7_11h30m  24.639568  38.271423  39.843517  46.359558  47.634098   \n",
       "24  0.csv_Day7_12h00m  24.952517  35.493206  37.543751  42.653866  45.656307   \n",
       "25  0.csv_Day7_12h30m  24.993122  34.937168  37.905022  43.882797  45.877621   \n",
       "26  0.csv_Day7_13h00m  24.392855  31.258072  32.847046  37.576630  41.157932   \n",
       "27  0.csv_Day7_13h30m  24.188114  31.546381  34.680557  41.165028  44.555111   \n",
       "28  0.csv_Day7_14h00m  22.689211  25.659964  26.723389  30.455311  36.693802   \n",
       "29  0.csv_Day7_14h30m  22.087637  24.815351  24.367188  28.383661  34.606121   \n",
       "30  0.csv_Day7_15h00m  19.708658  19.952797  18.879871  21.047159  27.768536   \n",
       "31  0.csv_Day7_15h30m  17.316366  19.320276  19.995483  23.462261  28.777628   \n",
       "32  0.csv_Day7_16h00m   9.041524  11.084370  10.268464   9.953065  14.313321   \n",
       "33  0.csv_Day7_16h30m   1.926115   2.643765   4.167500   4.753918   8.014334   \n",
       "34  0.csv_Day7_17h00m  -0.012797  -0.002021   0.433509   1.041787   1.386083   \n",
       "35  0.csv_Day7_17h30m  -0.012924  -0.001885   0.488379   1.138104   1.389329   \n",
       "36  0.csv_Day7_18h00m  -0.014969  -0.001814   0.131171   0.456177   0.150420   \n",
       "37  0.csv_Day7_18h30m  -0.015020  -0.001731   0.142221   0.361618   0.190918   \n",
       "38  0.csv_Day7_19h00m  -0.016063  -0.001592  -0.000477  -0.000091   0.000025   \n",
       "39  0.csv_Day7_19h30m  -0.016323  -0.001512  -0.000477  -0.000091   0.000025   \n",
       "40  0.csv_Day7_20h00m  -0.018388  -0.001315  -0.000477  -0.000091   0.000025   \n",
       "41  0.csv_Day7_20h30m  -0.017898  -0.001300  -0.000477  -0.000091   0.000025   \n",
       "42  0.csv_Day7_21h00m  -0.017477  -0.001170  -0.000477  -0.000091   0.000025   \n",
       "43  0.csv_Day7_21h30m  -0.016011  -0.001206  -0.000477  -0.000091   0.000025   \n",
       "44  0.csv_Day7_22h00m  -0.014084  -0.001212  -0.000477  -0.000091   0.000025   \n",
       "45  0.csv_Day7_22h30m  -0.014065  -0.001215  -0.000477  -0.000091   0.000025   \n",
       "46  0.csv_Day7_23h00m  -0.012559  -0.001244  -0.000477  -0.000091   0.000025   \n",
       "47  0.csv_Day7_23h30m  -0.012559  -0.001244  -0.000477  -0.000091   0.000025   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.000019   0.000267   0.000341  -0.000128  \n",
       "1    0.000019   0.000267   0.000341  -0.000128  \n",
       "2    0.000019   0.000267   0.000341  -0.000128  \n",
       "3    0.000019   0.000267   0.000341  -0.000128  \n",
       "4    0.000019   0.000267   0.000341  -0.000128  \n",
       "5    0.000019   0.000267   0.000341  -0.000128  \n",
       "6    0.000019   0.000267   0.000341  -0.000128  \n",
       "7    0.000019   0.000267   0.000341  -0.000128  \n",
       "8    0.000019   0.000267   0.000341  -0.000128  \n",
       "9    0.000019   0.000267   0.000341  -0.000128  \n",
       "10   0.000019   0.000267   0.000341  -0.000128  \n",
       "11   0.000019   0.000267   0.000341  -0.000128  \n",
       "12   0.000019   0.000267   0.000341   0.922747  \n",
       "13   0.000019   0.000267   0.000341   0.937790  \n",
       "14   0.000019   0.000267   0.248892   5.061938  \n",
       "15   0.190639   1.161434   1.466672   6.064527  \n",
       "16   9.723827  11.893978  17.305061  21.256166  \n",
       "17  18.714479  23.518169  27.355486  24.726851  \n",
       "18  25.124680  29.679285  30.384979  29.552382  \n",
       "19  27.659504  30.497345  31.418499  31.690540  \n",
       "20  39.356953  38.052567  38.174858  43.391884  \n",
       "21  40.158268  38.634254  36.906734  43.577946  \n",
       "22  49.316769  47.960419  48.299988  53.895020  \n",
       "23  47.191517  46.372513  48.066967  51.758163  \n",
       "24  48.077084  49.973759  48.392189  50.591724  \n",
       "25  48.354843  49.438465  47.119659  51.389545  \n",
       "26  46.527805  50.472324  47.828259  50.070557  \n",
       "27  51.021282  59.621376  57.372925  55.818192  \n",
       "28  43.787117  54.318577  50.227959  51.349548  \n",
       "29  40.954967  50.641411  46.185673  46.939655  \n",
       "30  36.456612  43.150063  38.752357  38.905273  \n",
       "31  34.717106  40.114491  34.379795  36.643185  \n",
       "32  18.298862  21.354954  19.388554  20.243980  \n",
       "33   6.076043   6.950895   6.521307   6.648596  \n",
       "34   2.072238   1.362743   0.025943   0.470843  \n",
       "35   2.314170   1.967573   0.155685   0.911990  \n",
       "36   0.579307   0.662274   0.000341   0.233350  \n",
       "37   0.538357   0.692349   0.000341   0.285127  \n",
       "38   0.007024   0.000267   0.000341  -0.000128  \n",
       "39   0.000019   0.000267   0.000341  -0.000128  \n",
       "40   0.000019   0.000267   0.000341  -0.000128  \n",
       "41   0.000019   0.000267   0.000341  -0.000128  \n",
       "42   0.000019   0.000267   0.000341  -0.000128  \n",
       "43   0.000019   0.000267   0.000341  -0.000128  \n",
       "44   0.000019   0.000267   0.000341  -0.000128  \n",
       "45   0.000019   0.000267   0.000341  -0.000128  \n",
       "46   0.000019   0.000267   0.000341  -0.000128  \n",
       "47   0.000019   0.000267   0.000341  -0.000128  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7723</th>\n",
       "      <td>80.csv_Day7_21h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724</th>\n",
       "      <td>80.csv_Day7_22h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7725</th>\n",
       "      <td>80.csv_Day7_22h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>80.csv_Day7_23h00m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7727</th>\n",
       "      <td>80.csv_Day7_23h30m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7728 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  q_0.1  q_0.2  q_0.3  q_0.4  q_0.5  q_0.6  q_0.7  \\\n",
       "0       0.csv_Day7_0h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1       0.csv_Day7_0h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2       0.csv_Day7_1h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3       0.csv_Day7_1h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4       0.csv_Day7_2h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...                  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "7723  80.csv_Day7_21h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7724  80.csv_Day7_22h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7725  80.csv_Day7_22h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7726  80.csv_Day7_23h00m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7727  80.csv_Day7_23h30m    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      q_0.8  q_0.9  \n",
       "0       0.0    0.0  \n",
       "1       0.0    0.0  \n",
       "2       0.0    0.0  \n",
       "3       0.0    0.0  \n",
       "4       0.0    0.0  \n",
       "...     ...    ...  \n",
       "7723    0.0    0.0  \n",
       "7724    0.0    0.0  \n",
       "7725    0.0    0.0  \n",
       "7726    0.0    0.0  \n",
       "7727    0.0    0.0  \n",
       "\n",
       "[7728 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[:-48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission/submission_20210115-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7776.0</td>\n",
       "      <td>7776.0</td>\n",
       "      <td>7776.0</td>\n",
       "      <td>7776.0</td>\n",
       "      <td>7776.0</td>\n",
       "      <td>7776.0</td>\n",
       "      <td>7776.0</td>\n",
       "      <td>7776.0</td>\n",
       "      <td>7776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        q_0.1   q_0.2   q_0.3   q_0.4   q_0.5   q_0.6   q_0.7   q_0.8   q_0.9\n",
       "count  7776.0  7776.0  7776.0  7776.0  7776.0  7776.0  7776.0  7776.0  7776.0\n",
       "mean      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n",
       "std       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n",
       "min       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n",
       "25%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n",
       "50%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n",
       "75%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n",
       "max       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
