{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from math import cos, pi, radians\n",
    "from numpy import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, is_train=True):\n",
    "    \n",
    "    temp = data.copy()\n",
    "    temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "\n",
    "    if is_train==True:          \n",
    "    \n",
    "        temp['Target1'] = temp['TARGET'].shift(-48).fillna(method='ffill')\n",
    "        temp['Target2'] = temp['TARGET'].shift(-48*2).fillna(method='ffill')\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        return temp.iloc[:-96]\n",
    "\n",
    "    elif is_train==False:\n",
    "        \n",
    "        temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "                              \n",
    "        return temp.iloc[-48:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train/train.csv')\n",
    "\n",
    "test = []\n",
    "\n",
    "for i in range(81):\n",
    "    file_path = './data/test/' + str(i) + '.csv'\n",
    "    temp = pd.read_csv(file_path)\n",
    "    temp = preprocess_data(temp, is_train=False)\n",
    "    test.append(temp)\n",
    "\n",
    "df_test = pd.concat(test)\n",
    "\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52464, 9), (3888, 7))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess_data(train)\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['theta'] = (list(cos(radians(np.array(range(1, 49)).astype(float)*7.5))) * int(df_train.shape[0]/48))\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['DNI'].skew())\n",
    "print(np.log1p(df_train['DNI']).skew())\n",
    "print(np.sqrt(df_train['DNI']).skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log1p(df_train['DNI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_train['DNI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']:\n",
    "    plt.title(col)\n",
    "    plt.boxplot(df_train[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']:\n",
    "    plt.title(col)\n",
    "    sns.distplot(df_train[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['DNI'] = np.log1p(df_train['DNI'])\n",
    "df_test['DNI'] = np.log1p(df_test['DNI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = df_train[['Hour','DHI','DNI','WS','RH','T']].min()\n",
    "max  = df_train[['Hour','DHI','DNI','WS','RH','T']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Hour','DHI','DNI','WS','RH','T']):\n",
    "    df_train[col] = (df_train[col] - min[i]) / (max[i] - min[i])\n",
    "    df_test[col] = (df_test[col] - min[i]) / (max[i] - min[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.describe())\n",
    "display(df_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_train[['Hour','DHI','DNI','WS','RH','T']] = scaler.fit_transform(df_train[['Hour','DHI','DNI','WS','RH','T']])\n",
    "df_test[['Hour','DHI','DNI','WS','RH','T']] = scaler.fit_transform(df_test[['Hour','DHI','DNI','WS','RH','T']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>Target1</th>\n",
       "      <th>Target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.665404</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.665188</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.694622</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.694297</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.731631</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52459</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.523536</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52460</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.504707</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52461</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.504491</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52462</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.528839</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52463</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.528622</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52464 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Hour  TARGET  DHI  DNI        WS        RH         T  Target1  \\\n",
       "0      0.000000     0.0  0.0  0.0  0.125000  0.665404  0.129630      0.0   \n",
       "1      0.000000     0.0  0.0  0.0  0.125000  0.665188  0.129630      0.0   \n",
       "2      0.043478     0.0  0.0  0.0  0.133333  0.694622  0.129630      0.0   \n",
       "3      0.043478     0.0  0.0  0.0  0.133333  0.694297  0.129630      0.0   \n",
       "4      0.086957     0.0  0.0  0.0  0.133333  0.731631  0.129630      0.0   \n",
       "...         ...     ...  ...  ...       ...       ...       ...      ...   \n",
       "52459  0.913043     0.0  0.0  0.0  0.291667  0.523536  0.333333      0.0   \n",
       "52460  0.956522     0.0  0.0  0.0  0.325000  0.504707  0.314815      0.0   \n",
       "52461  0.956522     0.0  0.0  0.0  0.341667  0.504491  0.314815      0.0   \n",
       "52462  1.000000     0.0  0.0  0.0  0.358333  0.528839  0.314815      0.0   \n",
       "52463  1.000000     0.0  0.0  0.0  0.341667  0.528622  0.314815      0.0   \n",
       "\n",
       "       Target2  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "52459      0.0  \n",
       "52460      0.0  \n",
       "52461      0.0  \n",
       "52462      0.0  \n",
       "52463      0.0  \n",
       "\n",
       "[52464 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day  = df_train.iloc[:, :4]\n",
    "#Day  = df_train.iloc[:, :-2]\n",
    "#Day7 = df_train.iloc[:, -2]\n",
    "#Day8 = df_train.iloc[:, -1]\n",
    "Day78 = df_train.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52459</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52460</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52461</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52462</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52463</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52464 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Hour  TARGET  DHI  DNI\n",
       "0      0.000000     0.0  0.0  0.0\n",
       "1      0.000000     0.0  0.0  0.0\n",
       "2      0.043478     0.0  0.0  0.0\n",
       "3      0.043478     0.0  0.0  0.0\n",
       "4      0.086957     0.0  0.0  0.0\n",
       "...         ...     ...  ...  ...\n",
       "52459  0.913043     0.0  0.0  0.0\n",
       "52460  0.956522     0.0  0.0  0.0\n",
       "52461  0.956522     0.0  0.0  0.0\n",
       "52462  1.000000     0.0  0.0  0.0\n",
       "52463  1.000000     0.0  0.0  0.0\n",
       "\n",
       "[52464 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[:, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52464, 4), (52464, 2))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Day.shape, Day78.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import mean, maximum\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(q, y, pred):\n",
    "    err = (y-pred)\n",
    "    return mean(maximum(q*err, (q-1)*err), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lst = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39348, 4), (13116, 4), (39348, 2), (13116, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_1, X_valid_1, Y_train_1, Y_valid_1 = train_test_split(Day, Day78, test_size=0.25, random_state=0)\n",
    "#X_train_2, X_valid_2, Y_train_2, Y_valid_2 = train_test_split(Day, Day8, test_size=0.25, random_state=0)\n",
    "\n",
    "X_train_1.shape, X_valid_1.shape, Y_train_1.shape, Y_valid_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(Day.shape)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_48_input'), name='dense_48_input', description=\"created by layer 'dense_48_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_48_input'), name='dense_48_input', description=\"created by layer 'dense_48_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "592/615 [===========================>..] - ETA: 0s - loss: 478.3932 - ETA: 0s - loss: 67WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_48_input'), name='dense_48_input', description=\"created by layer 'dense_48_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 471.1194 - val_loss: 196.2597\n",
      "Epoch 2/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 179.6546 - val_loss: 175.3358\n",
      "Epoch 3/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 169.9092 - val_loss: 168.8129\n",
      "Epoch 4/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 161.8048 - val_loss: 163.7940\n",
      "Epoch 5/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 159.5688 - val_loss: 160.7504\n",
      "Epoch 6/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 156.1180 - val_loss: 161.1466\n",
      "Epoch 7/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 155.6545 - val_loss: 158.8603\n",
      "Epoch 8/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 154.1661 - val_loss: 157.0417\n",
      "Epoch 9/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 151.1912 - val_loss: 160.0465\n",
      "Epoch 10/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 151.7499 - val_loss: 158.3962\n",
      "Epoch 11/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 151.4424 - val_loss: 154.8807\n",
      "Epoch 12/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 154.3528 - val_loss: 154.8193\n",
      "Epoch 13/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 148.6576 - val_loss: 154.9300\n",
      "Epoch 14/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 148.8833 - val_loss: 154.2821\n",
      "Epoch 15/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 151.1801 - val_loss: 153.0270\n",
      "Epoch 16/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 149.5090 - val_loss: 152.8316\n",
      "Epoch 17/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 149.4176 - val_loss: 152.6043\n",
      "Epoch 18/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 148.7826 - val_loss: 152.0639\n",
      "Epoch 19/100\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 150.0704 - val_loss: 151.2755\n",
      "Epoch 20/100\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 147.4321 - val_loss: 153.7306\n",
      "Epoch 21/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 146.3987 - val_loss: 153.5552\n",
      "Epoch 22/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 144.9715 - val_loss: 153.3614\n",
      "Epoch 23/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 144.7467 - val_loss: 149.5397\n",
      "Epoch 24/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 149.3469 - val_loss: 149.2038\n",
      "Epoch 25/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 141.9525 - val_loss: 148.9639\n",
      "Epoch 26/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 148.2229 - val_loss: 148.2812\n",
      "Epoch 27/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 146.0918 - val_loss: 147.9626\n",
      "Epoch 28/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 145.8876 - val_loss: 145.7514\n",
      "Epoch 29/100\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 149.5478 - val_loss: 144.9308\n",
      "Epoch 30/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 139.2717 - val_loss: 145.2573\n",
      "Epoch 31/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 142.9298 - val_loss: 143.9010\n",
      "Epoch 32/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 139.3080 - val_loss: 146.1240\n",
      "Epoch 33/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 139.5197 - val_loss: 143.0348\n",
      "Epoch 34/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 141.1266 - val_loss: 141.8614\n",
      "Epoch 35/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 140.8980 - val_loss: 145.7937\n",
      "Epoch 36/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.9658 - val_loss: 145.7671\n",
      "Epoch 37/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.8804 - val_loss: 145.8627\n",
      "Epoch 38/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.3503 - val_loss: 138.5726\n",
      "Epoch 39/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.9639 - val_loss: 139.6451\n",
      "Epoch 40/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.7865 - val_loss: 140.0571\n",
      "Epoch 41/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.7374 - val_loss: 139.6591\n",
      "Epoch 42/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 136.3364 - val_loss: 137.5352\n",
      "Epoch 43/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 140.8919 - val_loss: 137.2319\n",
      "Epoch 44/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 139.3871 - val_loss: 138.2853\n",
      "Epoch 45/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 139.6437 - val_loss: 141.7192\n",
      "Epoch 46/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 136.2097 - val_loss: 137.2957\n",
      "Epoch 47/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.0498 - val_loss: 139.1227\n",
      "Epoch 48/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 136.2843 - val_loss: 137.2053\n",
      "Epoch 49/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 136.1791 - val_loss: 137.1802\n",
      "Epoch 50/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.2840 - val_loss: 136.6794\n",
      "Epoch 51/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.9266 - val_loss: 136.6345\n",
      "Epoch 52/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.5389 - val_loss: 139.1929\n",
      "Epoch 53/100\n",
      "615/615 [==============================] - ETA: 0s - loss: 137.610 - 1s 1ms/step - loss: 137.5541 - val_loss: 138.4803\n",
      "Epoch 54/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.7447 - val_loss: 137.3406\n",
      "Epoch 55/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.0642 - val_loss: 136.2084\n",
      "Epoch 56/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.7438 - val_loss: 137.4799\n",
      "Epoch 57/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 134.5447 - val_loss: 138.6520\n",
      "Epoch 58/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.5305 - val_loss: 142.2747\n",
      "Epoch 59/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 135.2184 - val_loss: 137.0520\n",
      "Epoch 60/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 135.0588 - val_loss: 137.3242\n",
      "Epoch 00060: early stopping\n",
      "410/410 [==============================] - 0s 691us/step - loss: 136.1852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "136.18516540527344"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "hist = model.fit(X_train_1, Y_train_1, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "model.evaluate(X_valid_1, Y_valid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], 'b-', label='loss')\n",
    "plt.plot(hist.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3888 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Hour  TARGET  DHI  DNI\n",
       "288  0.000000     0.0  0.0  0.0\n",
       "289  0.000000     0.0  0.0  0.0\n",
       "290  0.043478     0.0  0.0  0.0\n",
       "291  0.043478     0.0  0.0  0.0\n",
       "292  0.086957     0.0  0.0  0.0\n",
       "..        ...     ...  ...  ...\n",
       "331  0.913043     0.0  0.0  0.0\n",
       "332  0.956522     0.0  0.0  0.0\n",
       "333  0.956522     0.0  0.0  0.0\n",
       "334  1.000000     0.0  0.0  0.0\n",
       "335  1.000000     0.0  0.0  0.0\n",
       "\n",
       "[3888 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "818/820 [============================>.] - ETA: 0s - loss: 1.5400WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5397 - val_loss: 1.6256\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4295 - val_loss: 1.6247\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4209 - val_loss: 1.6218\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4181 - val_loss: 1.6224\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4321 - val_loss: 1.6218\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4245 - val_loss: 1.6301\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4317 - val_loss: 1.6271\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4414 - val_loss: 1.6212\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4364 - val_loss: 1.6266\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4499 - val_loss: 1.6242\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4159 - val_loss: 1.6209\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4247 - val_loss: 1.6346\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4319 - val_loss: 1.6209\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4120 - val_loss: 1.6307\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4427 - val_loss: 1.6244\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4338 - val_loss: 1.6209\n",
      "Epoch 17/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4313 - val_loss: 1.6364\n",
      "Epoch 18/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4363 - val_loss: 1.6197\n",
      "Epoch 19/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4347 - val_loss: 1.6218\n",
      "Epoch 20/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4349 - val_loss: 1.6225\n",
      "Epoch 21/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4391 - val_loss: 1.6278\n",
      "Epoch 22/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4181 - val_loss: 1.6216\n",
      "Epoch 23/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4176 - val_loss: 1.6242\n",
      "Epoch 00023: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "813/820 [============================>.] - ETA: 0s - loss: 2.3516WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3514 - val_loss: 2.6802\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3219 - val_loss: 2.6772\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3138 - val_loss: 2.6754\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3139 - val_loss: 2.6753\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3286 - val_loss: 2.6747\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3236 - val_loss: 2.6803\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3414 - val_loss: 2.6727\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3462 - val_loss: 2.6699\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3313 - val_loss: 2.6678\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3594 - val_loss: 2.6635\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2975 - val_loss: 2.6668\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3111 - val_loss: 2.6651\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3172 - val_loss: 2.6597\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3020 - val_loss: 2.6614\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3258 - val_loss: 2.6614\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3096 - val_loss: 2.6540\n",
      "Epoch 17/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3177 - val_loss: 2.6909\n",
      "Epoch 18/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3178 - val_loss: 2.6479\n",
      "Epoch 19/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3109 - val_loss: 2.6165\n",
      "Epoch 20/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3148 - val_loss: 2.6392\n",
      "Epoch 21/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3185 - val_loss: 2.6096\n",
      "Epoch 22/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2788 - val_loss: 2.6109\n",
      "Epoch 23/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2814 - val_loss: 2.6813\n",
      "Epoch 24/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3026 - val_loss: 2.6058\n",
      "Epoch 25/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2716 - val_loss: 2.6133\n",
      "Epoch 26/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2645 - val_loss: 2.6552\n",
      "Epoch 27/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2866 - val_loss: 2.5930\n",
      "Epoch 28/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2715 - val_loss: 2.5835\n",
      "Epoch 29/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2477 - val_loss: 2.5838\n",
      "Epoch 30/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2695 - val_loss: 2.5801\n",
      "Epoch 31/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.2709 - val_loss: 2.5816\n",
      "Epoch 32/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2799 - val_loss: 2.5633\n",
      "Epoch 33/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2556 - val_loss: 2.5968\n",
      "Epoch 34/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2606 - val_loss: 2.5699\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2489 - val_loss: 2.5570\n",
      "Epoch 36/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2712 - val_loss: 2.6034\n",
      "Epoch 37/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2640 - val_loss: 2.6051\n",
      "Epoch 38/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2851 - val_loss: 2.5679\n",
      "Epoch 39/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2727 - val_loss: 2.5860\n",
      "Epoch 40/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2790 - val_loss: 2.5504\n",
      "Epoch 41/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2445 - val_loss: 2.5571\n",
      "Epoch 42/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2429 - val_loss: 2.5697\n",
      "Epoch 43/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2496 - val_loss: 2.5619\n",
      "Epoch 44/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2342 - val_loss: 2.5427\n",
      "Epoch 45/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2336 - val_loss: 2.5483\n",
      "Epoch 46/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2648 - val_loss: 2.5444\n",
      "Epoch 47/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2547 - val_loss: 2.5447\n",
      "Epoch 48/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2453 - val_loss: 2.5531\n",
      "Epoch 49/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2800 - val_loss: 2.5425\n",
      "Epoch 50/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2460 - val_loss: 2.5570\n",
      "Epoch 51/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2253 - val_loss: 2.5524\n",
      "Epoch 52/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2482 - val_loss: 2.5498\n",
      "Epoch 53/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2862 - val_loss: 2.5377\n",
      "Epoch 54/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2537 - val_loss: 2.5537\n",
      "Epoch 55/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2282 - val_loss: 2.5347\n",
      "Epoch 56/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2528 - val_loss: 2.5578\n",
      "Epoch 57/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2533 - val_loss: 2.5345\n",
      "Epoch 58/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2767 - val_loss: 2.5535\n",
      "Epoch 59/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2366 - val_loss: 2.5900\n",
      "Epoch 60/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2329 - val_loss: 2.5637\n",
      "Epoch 61/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2360 - val_loss: 2.5414\n",
      "Epoch 62/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2560 - val_loss: 2.6251\n",
      "Epoch 00062: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "800/820 [============================>.] - ETA: 0s - loss: 2.7218WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 2.7216 - val_loss: 3.0500\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6980 - val_loss: 3.0894\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6983 - val_loss: 3.0444\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6850 - val_loss: 3.0356\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7045 - val_loss: 3.1009\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7083 - val_loss: 3.0124\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7215 - val_loss: 2.9990\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7329 - val_loss: 3.0293\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7145 - val_loss: 3.0305\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7418 - val_loss: 2.9918\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6570 - val_loss: 3.0012\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6745 - val_loss: 3.0348\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6968 - val_loss: 3.0339\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6913 - val_loss: 3.0083\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6972 - val_loss: 3.0646\n",
      "Epoch 00015: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "799/820 [============================>.] - ETA: 0s - loss: 2.8553WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8550 - val_loss: 3.1506\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8227 - val_loss: 3.2109\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8270 - val_loss: 3.1727\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8201 - val_loss: 3.1636\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8344 - val_loss: 3.1876\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8316 - val_loss: 3.1291\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8558 - val_loss: 3.1446\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8698 - val_loss: 3.1466\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.8332 - val_loss: 3.1209\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8718 - val_loss: 3.1082\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7826 - val_loss: 3.1039\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8009 - val_loss: 3.1438\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8268 - val_loss: 3.1315\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8171 - val_loss: 3.1308\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8261 - val_loss: 3.1690\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7986 - val_loss: 3.1340\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "818/820 [============================>.] - ETA: 0s - loss: 2.7379WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7378 - val_loss: 3.0260\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7109 - val_loss: 3.0730\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7184 - val_loss: 3.0544\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7137 - val_loss: 3.0335\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7199 - val_loss: 3.0188\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7145 - val_loss: 2.9997\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7410 - val_loss: 3.0018\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7559 - val_loss: 3.0005\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7106 - val_loss: 2.9985\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7529 - val_loss: 3.0016\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6718 - val_loss: 2.9866\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6912 - val_loss: 3.0070\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7081 - val_loss: 3.0402\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7018 - val_loss: 3.0122\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7050 - val_loss: 3.0255\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6768 - val_loss: 3.0279\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "805/820 [============================>.] - ETA: 0s - loss: 2.4422WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 2.4421 - val_loss: 2.7099\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4131 - val_loss: 2.7310\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4262 - val_loss: 2.7246\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.4239 - val_loss: 2.7519\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4277 - val_loss: 2.6956\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4227 - val_loss: 2.6953\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4459 - val_loss: 2.6833\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4624 - val_loss: 2.7022\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4234 - val_loss: 2.6932\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4598 - val_loss: 2.6754\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3872 - val_loss: 2.6722\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4086 - val_loss: 2.7087\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4243 - val_loss: 2.7078\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4124 - val_loss: 2.6916\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4173 - val_loss: 2.6839\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3923 - val_loss: 2.6869\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "780/820 [===========================>..] - ETA: 0s - loss: 2.0284WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.0283 - val_loss: 2.2462\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0037 - val_loss: 2.2671\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0158 - val_loss: 2.2717\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0126 - val_loss: 2.2567\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0134 - val_loss: 2.2179\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0086 - val_loss: 2.2080\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0305 - val_loss: 2.2207\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0428 - val_loss: 2.2110\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0124 - val_loss: 2.2062\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0395 - val_loss: 2.2077\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9819 - val_loss: 2.2118\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0021 - val_loss: 2.2417\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0059 - val_loss: 2.2134\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0000 - val_loss: 2.2405\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "793/820 [============================>.] - ETA: 0s - loss: 1.4993WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4993 - val_loss: 1.6479\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4771 - val_loss: 1.6334\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4908 - val_loss: 1.6468\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4824 - val_loss: 1.6251\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4815 - val_loss: 1.6202\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4816 - val_loss: 1.6200\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4952 - val_loss: 1.6159\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5026 - val_loss: 1.6179\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4710 - val_loss: 1.6561\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.5038 - val_loss: 1.6114\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4539 - val_loss: 1.5986\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4732 - val_loss: 1.6374\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4703 - val_loss: 1.6297\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4689 - val_loss: 1.6207\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4662 - val_loss: 1.6227\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4607 - val_loss: 1.6363\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "777/820 [===========================>..] - ETA: 0s - loss: 0.8383WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8380 - val_loss: 0.9166\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8212 - val_loss: 0.9198\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8301 - val_loss: 0.9299\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8255 - val_loss: 0.9016\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8212 - val_loss: 0.8989\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8233 - val_loss: 0.9013\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8323 - val_loss: 0.8949\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8328 - val_loss: 0.8985\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8209 - val_loss: 0.9054\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8387 - val_loss: 0.8999\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8121 - val_loss: 0.8918\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8225 - val_loss: 0.9277\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8204 - val_loss: 0.9290\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8205 - val_loss: 0.9017\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8120 - val_loss: 0.9093\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.8149 - val_loss: 0.9063\n",
      "Epoch 00016: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 4), dtype=tf.float32, name='dense_56_input'), name='dense_56_input', description=\"created by layer 'dense_56_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 18)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    model.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model.fit(Day, Day78, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred = pd.DataFrame(model.predict(df_test.iloc[:, :4]))\n",
    "    results = pd.concat([results, pred], axis=1)\n",
    "\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>-0.045247</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.010112</td>\n",
       "      <td>-0.013026</td>\n",
       "      <td>0.105362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>-0.045247</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.010112</td>\n",
       "      <td>-0.013026</td>\n",
       "      <td>0.105362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.042111</td>\n",
       "      <td>-0.043603</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>0.105730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.042111</td>\n",
       "      <td>-0.043603</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>0.105730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.043800</td>\n",
       "      <td>-0.040414</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>-0.005745</td>\n",
       "      <td>0.106097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3883</th>\n",
       "      <td>-0.001704</td>\n",
       "      <td>-0.049501</td>\n",
       "      <td>-0.003235</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.046531</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.059479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>-0.001638</td>\n",
       "      <td>-0.049620</td>\n",
       "      <td>-0.002996</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.048645</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.062236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>-0.001638</td>\n",
       "      <td>-0.049620</td>\n",
       "      <td>-0.002996</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.048645</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.062236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>-0.001572</td>\n",
       "      <td>-0.047543</td>\n",
       "      <td>-0.005344</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.050760</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.064994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3887</th>\n",
       "      <td>-0.001572</td>\n",
       "      <td>-0.047543</td>\n",
       "      <td>-0.005344</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.050760</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.064994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3888 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         0         0         0         0         0         0  \\\n",
       "0    -0.000837 -0.039923 -0.045247  0.010049  0.015852  0.000209  0.010112   \n",
       "1    -0.000837 -0.039923 -0.045247  0.010049  0.015852  0.000209  0.010112   \n",
       "2    -0.000411 -0.042111 -0.043603  0.008113  0.013845 -0.000008  0.010933   \n",
       "3    -0.000411 -0.042111 -0.043603  0.008113  0.013845 -0.000008  0.010933   \n",
       "4     0.000040 -0.043800 -0.040414  0.008481  0.013972  0.000591  0.011752   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3883 -0.001704 -0.049501 -0.003235  0.002799  0.001767  0.002961  0.046531   \n",
       "3884 -0.001638 -0.049620 -0.002996  0.001594  0.002424  0.004327  0.048645   \n",
       "3885 -0.001638 -0.049620 -0.002996  0.001594  0.002424  0.004327  0.048645   \n",
       "3886 -0.001572 -0.047543 -0.005344  0.000389  0.003080  0.005693  0.050760   \n",
       "3887 -0.001572 -0.047543 -0.005344  0.000389  0.003080  0.005693  0.050760   \n",
       "\n",
       "             0         0  \n",
       "0    -0.013026  0.105362  \n",
       "1    -0.013026  0.105362  \n",
       "2    -0.009386  0.105730  \n",
       "3    -0.009386  0.105730  \n",
       "4    -0.005745  0.106097  \n",
       "...        ...       ...  \n",
       "3883  0.010257  0.059479  \n",
       "3884  0.011374  0.062236  \n",
       "3885  0.011374  0.062236  \n",
       "3886  0.012492  0.064994  \n",
       "3887  0.012492  0.064994  \n",
       "\n",
       "[3888 rows x 9 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>-0.045247</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.010112</td>\n",
       "      <td>-0.013026</td>\n",
       "      <td>0.105362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>-0.000837</td>\n",
       "      <td>-0.039923</td>\n",
       "      <td>-0.045247</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.010112</td>\n",
       "      <td>-0.013026</td>\n",
       "      <td>0.105362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.042111</td>\n",
       "      <td>-0.043603</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>0.105730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.042111</td>\n",
       "      <td>-0.043603</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>0.105730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.043800</td>\n",
       "      <td>-0.040414</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>-0.005745</td>\n",
       "      <td>0.106097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.043800</td>\n",
       "      <td>-0.040414</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>-0.005745</td>\n",
       "      <td>0.106097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>-0.000755</td>\n",
       "      <td>-0.045489</td>\n",
       "      <td>-0.037225</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>-0.002104</td>\n",
       "      <td>0.106466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>-0.000755</td>\n",
       "      <td>-0.045489</td>\n",
       "      <td>-0.037225</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>-0.002104</td>\n",
       "      <td>0.106466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>-0.047177</td>\n",
       "      <td>-0.034036</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.106836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>-0.047177</td>\n",
       "      <td>-0.034036</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.106836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>-0.048865</td>\n",
       "      <td>-0.030846</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.014213</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.107203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>-0.048865</td>\n",
       "      <td>-0.030846</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.014213</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.107203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.050554</td>\n",
       "      <td>-0.027657</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>0.014482</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.015034</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>0.107572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.050554</td>\n",
       "      <td>-0.027657</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>0.014482</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.015034</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>0.107572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>-0.003934</td>\n",
       "      <td>-0.052242</td>\n",
       "      <td>-0.024468</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>0.012460</td>\n",
       "      <td>0.107941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>0.399313</td>\n",
       "      <td>0.972425</td>\n",
       "      <td>1.523693</td>\n",
       "      <td>1.839844</td>\n",
       "      <td>2.793092</td>\n",
       "      <td>3.529341</td>\n",
       "      <td>4.776173</td>\n",
       "      <td>6.683688</td>\n",
       "      <td>11.556775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>1.129569</td>\n",
       "      <td>1.798336</td>\n",
       "      <td>3.802062</td>\n",
       "      <td>4.696050</td>\n",
       "      <td>7.102689</td>\n",
       "      <td>10.683746</td>\n",
       "      <td>14.577641</td>\n",
       "      <td>20.790667</td>\n",
       "      <td>28.862370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>1.859040</td>\n",
       "      <td>4.246626</td>\n",
       "      <td>7.368085</td>\n",
       "      <td>8.581008</td>\n",
       "      <td>12.857533</td>\n",
       "      <td>17.090330</td>\n",
       "      <td>22.157398</td>\n",
       "      <td>29.999813</td>\n",
       "      <td>39.124065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>2.372812</td>\n",
       "      <td>8.395699</td>\n",
       "      <td>13.417376</td>\n",
       "      <td>14.943073</td>\n",
       "      <td>21.136986</td>\n",
       "      <td>26.740725</td>\n",
       "      <td>32.356213</td>\n",
       "      <td>40.745777</td>\n",
       "      <td>52.850639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>2.987112</td>\n",
       "      <td>10.056934</td>\n",
       "      <td>15.713940</td>\n",
       "      <td>17.439754</td>\n",
       "      <td>23.529316</td>\n",
       "      <td>28.580246</td>\n",
       "      <td>33.821922</td>\n",
       "      <td>41.965492</td>\n",
       "      <td>53.440262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>5.223249</td>\n",
       "      <td>16.058170</td>\n",
       "      <td>23.878881</td>\n",
       "      <td>27.586266</td>\n",
       "      <td>33.768772</td>\n",
       "      <td>37.899033</td>\n",
       "      <td>40.290680</td>\n",
       "      <td>47.401810</td>\n",
       "      <td>52.223118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>6.461700</td>\n",
       "      <td>18.418468</td>\n",
       "      <td>25.744076</td>\n",
       "      <td>30.980938</td>\n",
       "      <td>34.171642</td>\n",
       "      <td>35.003242</td>\n",
       "      <td>34.431103</td>\n",
       "      <td>36.131508</td>\n",
       "      <td>37.184601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>5.652254</td>\n",
       "      <td>18.724279</td>\n",
       "      <td>26.553665</td>\n",
       "      <td>33.221012</td>\n",
       "      <td>40.570210</td>\n",
       "      <td>45.925945</td>\n",
       "      <td>49.228172</td>\n",
       "      <td>59.981838</td>\n",
       "      <td>68.054512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>4.549119</td>\n",
       "      <td>16.049818</td>\n",
       "      <td>23.463299</td>\n",
       "      <td>28.765173</td>\n",
       "      <td>37.696705</td>\n",
       "      <td>43.718754</td>\n",
       "      <td>48.561398</td>\n",
       "      <td>60.498646</td>\n",
       "      <td>71.416359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>4.667053</td>\n",
       "      <td>17.099720</td>\n",
       "      <td>23.709328</td>\n",
       "      <td>30.425671</td>\n",
       "      <td>37.990421</td>\n",
       "      <td>43.745258</td>\n",
       "      <td>48.120605</td>\n",
       "      <td>59.018425</td>\n",
       "      <td>69.489090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>5.805973</td>\n",
       "      <td>19.300650</td>\n",
       "      <td>26.117224</td>\n",
       "      <td>33.191628</td>\n",
       "      <td>39.361702</td>\n",
       "      <td>43.735683</td>\n",
       "      <td>45.785023</td>\n",
       "      <td>53.759228</td>\n",
       "      <td>60.725914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>4.923470</td>\n",
       "      <td>17.542967</td>\n",
       "      <td>23.303501</td>\n",
       "      <td>30.037992</td>\n",
       "      <td>37.209164</td>\n",
       "      <td>42.613087</td>\n",
       "      <td>46.764915</td>\n",
       "      <td>56.877361</td>\n",
       "      <td>64.996490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>3.267330</td>\n",
       "      <td>14.266121</td>\n",
       "      <td>20.091326</td>\n",
       "      <td>26.702265</td>\n",
       "      <td>35.392029</td>\n",
       "      <td>42.095375</td>\n",
       "      <td>49.592079</td>\n",
       "      <td>63.360619</td>\n",
       "      <td>76.569908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>3.801124</td>\n",
       "      <td>14.711641</td>\n",
       "      <td>18.867514</td>\n",
       "      <td>24.506018</td>\n",
       "      <td>33.075405</td>\n",
       "      <td>38.600624</td>\n",
       "      <td>41.928257</td>\n",
       "      <td>48.137722</td>\n",
       "      <td>54.599869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>4.219489</td>\n",
       "      <td>15.168439</td>\n",
       "      <td>19.317802</td>\n",
       "      <td>24.992876</td>\n",
       "      <td>33.501007</td>\n",
       "      <td>38.699333</td>\n",
       "      <td>41.403275</td>\n",
       "      <td>46.135437</td>\n",
       "      <td>51.049576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>3.938370</td>\n",
       "      <td>11.534098</td>\n",
       "      <td>15.157492</td>\n",
       "      <td>19.809141</td>\n",
       "      <td>26.309748</td>\n",
       "      <td>29.342178</td>\n",
       "      <td>29.618582</td>\n",
       "      <td>27.852417</td>\n",
       "      <td>29.617077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>2.607774</td>\n",
       "      <td>10.037601</td>\n",
       "      <td>13.784523</td>\n",
       "      <td>17.896814</td>\n",
       "      <td>24.186085</td>\n",
       "      <td>28.040462</td>\n",
       "      <td>29.262938</td>\n",
       "      <td>33.655460</td>\n",
       "      <td>39.736660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>1.440331</td>\n",
       "      <td>4.758574</td>\n",
       "      <td>6.894101</td>\n",
       "      <td>9.223953</td>\n",
       "      <td>13.139255</td>\n",
       "      <td>15.204524</td>\n",
       "      <td>17.315777</td>\n",
       "      <td>20.616762</td>\n",
       "      <td>26.919970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>0.474964</td>\n",
       "      <td>2.453782</td>\n",
       "      <td>3.837551</td>\n",
       "      <td>5.946784</td>\n",
       "      <td>9.096980</td>\n",
       "      <td>12.838325</td>\n",
       "      <td>19.260521</td>\n",
       "      <td>25.339651</td>\n",
       "      <td>34.077198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>-0.001797</td>\n",
       "      <td>-0.041166</td>\n",
       "      <td>-0.002305</td>\n",
       "      <td>-0.020962</td>\n",
       "      <td>-0.005783</td>\n",
       "      <td>-0.011823</td>\n",
       "      <td>0.029488</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>0.054867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>-0.001797</td>\n",
       "      <td>-0.041166</td>\n",
       "      <td>-0.002305</td>\n",
       "      <td>-0.020962</td>\n",
       "      <td>-0.005783</td>\n",
       "      <td>-0.011823</td>\n",
       "      <td>0.029488</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>0.054867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>-0.043249</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.051488</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>0.055766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>-0.043249</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.051488</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>0.055766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>-0.001836</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.046723</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.054588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>-0.001836</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.046723</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.054588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>-0.001770</td>\n",
       "      <td>-0.047417</td>\n",
       "      <td>-0.002638</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.056722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>-0.001770</td>\n",
       "      <td>-0.047417</td>\n",
       "      <td>-0.002638</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.056722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>-0.001704</td>\n",
       "      <td>-0.049501</td>\n",
       "      <td>-0.003235</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.046531</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.059479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>-0.001704</td>\n",
       "      <td>-0.049501</td>\n",
       "      <td>-0.003235</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.046531</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.059479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>-0.001638</td>\n",
       "      <td>-0.049620</td>\n",
       "      <td>-0.002996</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.048645</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.062236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>-0.001638</td>\n",
       "      <td>-0.049620</td>\n",
       "      <td>-0.002996</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.048645</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.062236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>-0.047543</td>\n",
       "      <td>-0.005344</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.050760</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.064994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>-0.047543</td>\n",
       "      <td>-0.005344</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.050760</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.064994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id     q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m -0.000837  -0.039923  -0.045247   0.010049   0.015852   \n",
       "1    0.csv_Day7_0h30m -0.000837  -0.039923  -0.045247   0.010049   0.015852   \n",
       "2    0.csv_Day7_1h00m -0.000411  -0.042111  -0.043603   0.008113   0.013845   \n",
       "3    0.csv_Day7_1h30m -0.000411  -0.042111  -0.043603   0.008113   0.013845   \n",
       "4    0.csv_Day7_2h00m  0.000040  -0.043800  -0.040414   0.008481   0.013972   \n",
       "5    0.csv_Day7_2h30m  0.000040  -0.043800  -0.040414   0.008481   0.013972   \n",
       "6    0.csv_Day7_3h00m -0.000755  -0.045489  -0.037225   0.008848   0.014100   \n",
       "7    0.csv_Day7_3h30m -0.000755  -0.045489  -0.037225   0.008848   0.014100   \n",
       "8    0.csv_Day7_4h00m -0.001550  -0.047177  -0.034036   0.009216   0.014227   \n",
       "9    0.csv_Day7_4h30m -0.001550  -0.047177  -0.034036   0.009216   0.014227   \n",
       "10   0.csv_Day7_5h00m -0.002344  -0.048865  -0.030846   0.009583   0.014355   \n",
       "11   0.csv_Day7_5h30m -0.002344  -0.048865  -0.030846   0.009583   0.014355   \n",
       "12   0.csv_Day7_6h00m -0.003139  -0.050554  -0.027657   0.009951   0.014482   \n",
       "13   0.csv_Day7_6h30m -0.003139  -0.050554  -0.027657   0.009951   0.014482   \n",
       "14   0.csv_Day7_7h00m -0.003934  -0.052242  -0.024468   0.010319   0.014610   \n",
       "15   0.csv_Day7_7h30m  0.399313   0.972425   1.523693   1.839844   2.793092   \n",
       "16   0.csv_Day7_8h00m  1.129569   1.798336   3.802062   4.696050   7.102689   \n",
       "17   0.csv_Day7_8h30m  1.859040   4.246626   7.368085   8.581008  12.857533   \n",
       "18   0.csv_Day7_9h00m  2.372812   8.395699  13.417376  14.943073  21.136986   \n",
       "19   0.csv_Day7_9h30m  2.987112  10.056934  15.713940  17.439754  23.529316   \n",
       "20  0.csv_Day7_10h00m  5.223249  16.058170  23.878881  27.586266  33.768772   \n",
       "21  0.csv_Day7_10h30m  6.461700  18.418468  25.744076  30.980938  34.171642   \n",
       "22  0.csv_Day7_11h00m  5.652254  18.724279  26.553665  33.221012  40.570210   \n",
       "23  0.csv_Day7_11h30m  4.549119  16.049818  23.463299  28.765173  37.696705   \n",
       "24  0.csv_Day7_12h00m  4.667053  17.099720  23.709328  30.425671  37.990421   \n",
       "25  0.csv_Day7_12h30m  5.805973  19.300650  26.117224  33.191628  39.361702   \n",
       "26  0.csv_Day7_13h00m  4.923470  17.542967  23.303501  30.037992  37.209164   \n",
       "27  0.csv_Day7_13h30m  3.267330  14.266121  20.091326  26.702265  35.392029   \n",
       "28  0.csv_Day7_14h00m  3.801124  14.711641  18.867514  24.506018  33.075405   \n",
       "29  0.csv_Day7_14h30m  4.219489  15.168439  19.317802  24.992876  33.501007   \n",
       "30  0.csv_Day7_15h00m  3.938370  11.534098  15.157492  19.809141  26.309748   \n",
       "31  0.csv_Day7_15h30m  2.607774  10.037601  13.784523  17.896814  24.186085   \n",
       "32  0.csv_Day7_16h00m  1.440331   4.758574   6.894101   9.223953  13.139255   \n",
       "33  0.csv_Day7_16h30m  0.474964   2.453782   3.837551   5.946784   9.096980   \n",
       "34  0.csv_Day7_17h00m -0.001797  -0.041166  -0.002305  -0.020962  -0.005783   \n",
       "35  0.csv_Day7_17h30m -0.001797  -0.041166  -0.002305  -0.020962  -0.005783   \n",
       "36  0.csv_Day7_18h00m -0.001902  -0.043249  -0.000977   0.006389   0.003275   \n",
       "37  0.csv_Day7_18h30m -0.001902  -0.043249  -0.000977   0.006389   0.003275   \n",
       "38  0.csv_Day7_19h00m -0.001836  -0.045333  -0.002041   0.005209   0.001498   \n",
       "39  0.csv_Day7_19h30m -0.001836  -0.045333  -0.002041   0.005209   0.001498   \n",
       "40  0.csv_Day7_20h00m -0.001770  -0.047417  -0.002638   0.004004   0.001110   \n",
       "41  0.csv_Day7_20h30m -0.001770  -0.047417  -0.002638   0.004004   0.001110   \n",
       "42  0.csv_Day7_21h00m -0.001704  -0.049501  -0.003235   0.002799   0.001767   \n",
       "43  0.csv_Day7_21h30m -0.001704  -0.049501  -0.003235   0.002799   0.001767   \n",
       "44  0.csv_Day7_22h00m -0.001638  -0.049620  -0.002996   0.001594   0.002424   \n",
       "45  0.csv_Day7_22h30m -0.001638  -0.049620  -0.002996   0.001594   0.002424   \n",
       "46  0.csv_Day7_23h00m -0.001572  -0.047543  -0.005344   0.000389   0.003080   \n",
       "47  0.csv_Day7_23h30m -0.001572  -0.047543  -0.005344   0.000389   0.003080   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.000209   0.010112  -0.013026   0.105362  \n",
       "1    0.000209   0.010112  -0.013026   0.105362  \n",
       "2   -0.000008   0.010933  -0.009386   0.105730  \n",
       "3   -0.000008   0.010933  -0.009386   0.105730  \n",
       "4    0.000591   0.011752  -0.005745   0.106097  \n",
       "5    0.000591   0.011752  -0.005745   0.106097  \n",
       "6    0.001190   0.012573  -0.002104   0.106466  \n",
       "7    0.001190   0.012573  -0.002104   0.106466  \n",
       "8    0.001790   0.013394   0.001537   0.106836  \n",
       "9    0.001790   0.013394   0.001537   0.106836  \n",
       "10   0.002390   0.014213   0.005177   0.107203  \n",
       "11   0.002390   0.014213   0.005177   0.107203  \n",
       "12   0.002990   0.015034   0.008821   0.107572  \n",
       "13   0.002990   0.015034   0.008821   0.107572  \n",
       "14   0.003590   0.015854   0.012460   0.107941  \n",
       "15   3.529341   4.776173   6.683688  11.556775  \n",
       "16  10.683746  14.577641  20.790667  28.862370  \n",
       "17  17.090330  22.157398  29.999813  39.124065  \n",
       "18  26.740725  32.356213  40.745777  52.850639  \n",
       "19  28.580246  33.821922  41.965492  53.440262  \n",
       "20  37.899033  40.290680  47.401810  52.223118  \n",
       "21  35.003242  34.431103  36.131508  37.184601  \n",
       "22  45.925945  49.228172  59.981838  68.054512  \n",
       "23  43.718754  48.561398  60.498646  71.416359  \n",
       "24  43.745258  48.120605  59.018425  69.489090  \n",
       "25  43.735683  45.785023  53.759228  60.725914  \n",
       "26  42.613087  46.764915  56.877361  64.996490  \n",
       "27  42.095375  49.592079  63.360619  76.569908  \n",
       "28  38.600624  41.928257  48.137722  54.599869  \n",
       "29  38.699333  41.403275  46.135437  51.049576  \n",
       "30  29.342178  29.618582  27.852417  29.617077  \n",
       "31  28.040462  29.262938  33.655460  39.736660  \n",
       "32  15.204524  17.315777  20.616762  26.919970  \n",
       "33  12.838325  19.260521  25.339651  34.077198  \n",
       "34  -0.011823   0.029488  -0.001513   0.054867  \n",
       "35  -0.011823   0.029488  -0.001513   0.054867  \n",
       "36   0.004099   0.051488   0.006506   0.055766  \n",
       "37   0.004099   0.051488   0.006506   0.055766  \n",
       "38   0.002597   0.046723   0.008024   0.054588  \n",
       "39   0.002597   0.046723   0.008024   0.054588  \n",
       "40   0.001935   0.044418   0.009140   0.056722  \n",
       "41   0.001935   0.044418   0.009140   0.056722  \n",
       "42   0.002961   0.046531   0.010257   0.059479  \n",
       "43   0.002961   0.046531   0.010257   0.059479  \n",
       "44   0.004327   0.048645   0.011374   0.062236  \n",
       "45   0.004327   0.048645   0.011374   0.062236  \n",
       "46   0.005693   0.050760   0.012492   0.064994  \n",
       "47   0.005693   0.050760   0.012492   0.064994  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.loc[submission.id.str.contains(\"Day7\"), \"q_0.1\":] = results[0].sort_index().values\n",
    "submission.loc[submission.id.str.contains(\"Day8\"), \"q_0.1\":] = results[1].sort_index().values\n",
    "submission[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission/submission_20210117-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
