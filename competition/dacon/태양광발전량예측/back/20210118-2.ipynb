{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, is_train=True):\n",
    "    \n",
    "    temp = data.copy()\n",
    "    temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "\n",
    "    if is_train==True:          \n",
    "    \n",
    "        temp['Target1'] = temp['TARGET'].shift(-48).fillna(method='ffill')\n",
    "        temp['Target2'] = temp['TARGET'].shift(-48*2).fillna(method='ffill')\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        return temp.iloc[:-96]\n",
    "\n",
    "    elif is_train==False:\n",
    "        \n",
    "        temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "                              \n",
    "        return temp.iloc[-48:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train/train.csv')\n",
    "\n",
    "test = []\n",
    "\n",
    "for i in range(81):\n",
    "    file_path = './data/test/' + str(i) + '.csv'\n",
    "    temp = pd.read_csv(file_path)\n",
    "    temp = preprocess_data(temp, is_train=False)\n",
    "    test.append(temp)\n",
    "\n",
    "df_test = pd.concat(test)\n",
    "\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52464, 9), (3888, 7))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess_data(train)\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = df_train[['Hour','DHI','DNI','WS','RH','T']].min()\n",
    "max  = df_train[['Hour','DHI','DNI','WS','RH','T']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Hour','DHI','DNI','WS','RH','T']):\n",
    "    df_train[col] = (df_train[col] - min[i]) / (max[i] - min[i])\n",
    "    df_test[col] = (df_test[col] - min[i]) / (max[i] - min[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day  = df_train.iloc[:, :-2]\n",
    "Day7 = df_train.iloc[:, -2]\n",
    "Day8 = df_train.iloc[:, -1]\n",
    "Day78 = df_train.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(q, y, pred):\n",
    "    err = (y-pred)\n",
    "    return mean(maximum(q*err, (q-1)*err), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lst = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39348, 7), (13116, 7), (39348, 2), (13116, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(Day, Day78, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train_1, X_valid_1, Y_train_1, Y_valid_1 = train_test_split(Day, Day7, test_size=0.25, random_state=42)\n",
    "X_train_2, X_valid_2, Y_train_2, Y_valid_2 = train_test_split(Day, Day8, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import mean, maximum\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(Day.shape)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "591/615 [===========================>..] - ETA: 0s - loss: 376.0026WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "615/615 [==============================] - 2s 2ms/step - loss: 370.4143 - val_loss: 175.5633\n",
      "Epoch 2/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 169.9044 - val_loss: 157.3284\n",
      "Epoch 3/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 152.4468 - val_loss: 149.5892\n",
      "Epoch 4/100\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 153.5761 - val_loss: 147.8619\n",
      "Epoch 5/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 147.7484 - val_loss: 147.8122\n",
      "Epoch 6/100\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 149.6038 - val_loss: 151.3657\n",
      "Epoch 7/100\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 149.6172 - val_loss: 147.0415\n",
      "Epoch 8/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 142.2509 - val_loss: 152.3711\n",
      "Epoch 9/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 149.2954 - val_loss: 147.6583\n",
      "Epoch 10/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 148.8397 - val_loss: 142.7948\n",
      "Epoch 11/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 152.9332 - val_loss: 147.6022\n",
      "Epoch 12/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 145.1340 - val_loss: 142.4872\n",
      "Epoch 13/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 143.8952 - val_loss: 140.3544\n",
      "Epoch 14/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 145.1227 - val_loss: 139.6483\n",
      "Epoch 15/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.3808 - val_loss: 139.4052\n",
      "Epoch 16/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 144.1668 - val_loss: 138.1532\n",
      "Epoch 17/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 145.2854 - val_loss: 139.9868\n",
      "Epoch 18/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.7452 - val_loss: 138.5823\n",
      "Epoch 19/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 140.9201 - val_loss: 135.6353\n",
      "Epoch 20/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 134.4722 - val_loss: 136.5116\n",
      "Epoch 21/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.2686 - val_loss: 146.1366\n",
      "Epoch 22/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 140.0425 - val_loss: 135.1114\n",
      "Epoch 23/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.0929 - val_loss: 143.9767\n",
      "Epoch 24/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.3309 - val_loss: 132.7405\n",
      "Epoch 25/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 134.1046 - val_loss: 132.9609\n",
      "Epoch 26/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.0068 - val_loss: 137.5400\n",
      "Epoch 27/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 139.6765 - val_loss: 131.6952\n",
      "Epoch 28/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.0996 - val_loss: 134.0677\n",
      "Epoch 29/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 136.2175 - val_loss: 132.8486\n",
      "Epoch 30/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 135.3982 - val_loss: 138.0644\n",
      "Epoch 00030: early stopping\n",
      "410/410 [==============================] - 0s 729us/step - loss: 136.3020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "136.302001953125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "hist = model.fit(X_train, Y_train, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsqklEQVR4nO3deXxU1fnH8c+TEBZlJwjI0oAbFqiKAa1VxPZXXKqiVUHrUrEtreJCa11rrbW1WvWnldran1ZUWjdErai4oKKAFWURZFUBgyZsCcq+J8/vjzNjJpA9IcPc+b5fr/uayZmZO+cy+syZ557zXHN3REQkejKS3QEREdkzFOBFRCJKAV5EJKIU4EVEIkoBXkQkoholuwMA2dnZnpOTk+xuiIiklJkzZxa5e/uKHt8rAnxOTg4zZsxIdjdERFKKmS2r7PEqUzRm1tXMJpnZAjObb2ZX7fL41WbmZpYd+9vMbJSZLTazj8ysb90OQUREaqM6I/idwNXuPsvMWgAzzWyiuy8ws67AIODzhOefDBwU244CHojdiohIA6pyBO/uK9x9Vuz+BmAh0Dn28L3AtUDictjBwBgPpgGtzaxT/XZbRESqUqMcvJnlAEcA75vZYKDA3eeYWeLTOgNfJPydH2tbscu+hgPDAbp161bjjotI6tuxYwf5+fls3bo12V3ZqzVt2pQuXbqQlZVVo9dVO8CbWXPgWWAkIW1zIyE9Uyvu/iDwIEBubq4K4oikofz8fFq0aEFOTg67DBQlxt1Zs2YN+fn5dO/evUavrdY8eDPLIgT3x939OeAAoDswx8zygC7ALDPrCBQAXRNe3iXWJiJSxtatW2nXrp2CeyXMjHbt2tXqV051ZtEY8DCw0N3vAXD3ue6+n7vnuHsOIQ3T191XAuOBi2KzaY4G1rn7ior2LyLpTcG9arX9N6rOCP47wIXAd81sdmw7pZLnTwCWAouBh4DLatWzapg3D266Cdas2VPvICKSuqrMwbv7VKDSr4/YKD5+34ERde5ZNXz6Kdx2G5x1FrRr1xDvKCJR07x5czZu3JjsbuwRKV2LJjs73GoELyKyu5QO8PFRe1FRcvshIqnP3bnmmmvo3bs3ffr04emnnwZgxYoVDBgwgMMPP5zevXszZcoUiouLufjii79+7r333pvk3pdvr6hFU1vxEbwCvEjqGzkSZs+u330efjj85S/Ve+5zzz3H7NmzmTNnDkVFRfTr148BAwbwxBNPcOKJJ/Kb3/yG4uJiNm/ezOzZsykoKGDevHkArF27tn47Xk9SegTftm24VYAXkbqaOnUq5513HpmZmXTo0IHjjz+e6dOn069fPx555BFuueUW5s6dS4sWLejRowdLly7liiuu4NVXX6Vly5bJ7n65UnoE36gRtGmjHLxIFFR3pN3QBgwYwOTJk3n55Ze5+OKL+dWvfsVFF13EnDlzeO211/jHP/7B2LFjGT16dLK7upuUHsFDyMNrBC8idXXcccfx9NNPU1xcTGFhIZMnT6Z///4sW7aMDh068LOf/Yyf/vSnzJo1i6KiIkpKSjjrrLP44x//yKxZs5Ld/XKl9AgeQh5eAV5E6urMM8/kvffe47DDDsPMuPPOO+nYsSOPPfYYd911F1lZWTRv3pwxY8ZQUFDAsGHDKCkpAeD2229Pcu/LZ2HaenLl5uZ6bS/4cdppUFAAe+kXqIhUYuHChRx66KHJ7kZKKO/fysxmuntuRa9J+RSNRvAiIuVL+QCvHLyISPlSPsBnZ8OWLbB5c7J7IiKyd4lEgAdNlRQR2VXKB3iVKxARKV/KB3iVKxARKZ8CvIhIREUmwCsHLyJ7WvPmzSt8LC8vj969ezdgb6qW8gG+TZtwqxG8iEhZKV+qIF5wTAFeJAIGDty9bcgQuOyyMBf6lHKuFnrxxWErKoKzzy772NtvV/p2119/PV27dmXEiHARultuuYVGjRoxadIkvvrqK3bs2MEf//hHBg8eXKPD2Lp1K5deeikzZsygUaNG3HPPPZxwwgnMnz+fYcOGsX37dkpKSnj22WfZf//9GTJkCPn5+RQXF/Pb3/6WoUOH1uj9KpLyAR5CmkYpGhGpqaFDhzJy5MivA/zYsWN57bXXuPLKK2nZsiVFRUUcffTRnH766TW68PXf/vY3zIy5c+eyaNEiBg0axCeffMI//vEPrrrqKs4//3y2b99OcXExEyZMYP/99+fll18GYN26dfV2fJEJ8BrBi0RAZSPuffap/PHs7CpH7Ls64ogjWL16NcuXL6ewsJA2bdrQsWNHfvnLXzJ58mQyMjIoKChg1apVdOzYsdr7nTp1KldccQUAPXv25Bvf+AaffPIJ3/72t7ntttvIz8/nhz/8IQcddBB9+vTh6quv5rrrruPUU0/luOOOq9ExVCblc/CgcgUiUnvnnHMO48aN4+mnn2bo0KE8/vjjFBYWMnPmTGbPnk2HDh3YunVrvbzXj370I8aPH0+zZs045ZRTeOuttzj44IOZNWsWffr04aabbuLWW2+tl/eCiAR4jeBFpLaGDh3KU089xbhx4zjnnHNYt24d++23H1lZWUyaNIlly5bVeJ/HHXccjz/+OACffPIJn3/+OYcccghLly6lR48eXHnllQwePJiPPvqI5cuXs88++3DBBRdwzTXX1Gtt+cikaJSDF5Ha6NWrFxs2bKBz58506tSJ888/n9NOO40+ffqQm5tLz549a7zPyy67jEsvvZQ+ffrQqFEjHn30UZo0acLYsWP517/+RVZWFh07duTGG29k+vTpXHPNNWRkZJCVlcUDDzxQb8eW8vXgAe64A264ATZtCmk6EUkNqgdffWlZDx60mlVEpDyRSdFACPDduiW3LyISbXPnzuXCCy8s09akSRPef//9JPWoYpEK8MrDi6Qed6/RHPNk69OnD7Nnz27Q96xtKj0SKRqVDBZJTU2bNmXNmjW1DmDpwN1Zs2YNTZs2rfFrqxzBm1lXYAzQAXDgQXe/z8zuAk4DtgNLgGHuvjb2mhuAnwDFwJXu/lqNe1YDysGLpKYuXbqQn59PYWFhsruyV2vatCldunSp8euqk6LZCVzt7rPMrAUw08wmAhOBG9x9p5n9GbgBuM7MvgmcC/QC9gfeMLOD3b24xr2rpjZtwEwpGpFUk5WVRffu3ZPdjciqMkXj7ivcfVbs/gZgIdDZ3V93952xp00D4l8vg4Gn3H2bu38GLAb613/XS6ngmIjI7mqUgzezHOAIYNfTxZcAr8Tudwa+SHgsP9a2676Gm9kMM5tRHz/PVK5ARKSsagd4M2sOPAuMdPf1Ce2/IaRxHq/JG7v7g+6e6+657du3r8lLy6VyBSIiZVVrmqSZZRGC++Pu/lxC+8XAqcD3vPQ0eAHQNeHlXWJte1R2NnzxRdXPExFJF1WO4C1MUH0YWOju9yS0nwRcC5zu7psTXjIeONfMmphZd+Ag4IP67fbuNIIXESmrOiP47wAXAnPNbHas7UZgFNAEmBhbpDDN3X/h7vPNbCywgJC6GbEnZ9DExXPw7mFGjYhIuqsywLv7VKC8kDmhktfcBtxWh37VWHY2bN0aruq1774N+c4iInunSKxkBZUrEBHZVWQCvMoViIiUFZkAr3IFIiJlKcCLiERU5AK8cvAiIkFkAny84JhG8CIiQWQCfGamCo6JiCSKTICHkKZRikZEJIhcgNcIXkQkiFSAV8lgEZFSkQrwGsGLiJSKXIBfsyYUHBMRSXeRCvDt2pUWHBMRSXeRCvBazSoiUkoBXkQkoiIZ4DUXXkQkYgFeJYNFREpFKsArRSMiUipSAT5ecEwpGhGRiAX4zExo21YjeBERiFiAB5UrEBGJi1yAV7kCEZEgkgFeOXgRkQgGeKVoRESCyAX4eIpGBcdEJN1FMsBv2wabNiW7JyIiyRXJAA/Kw4uIRC7Aq1yBiEgQuQCvcgUiIkGVAd7MuprZJDNbYGbzzeyqWHtbM5toZp/GbtvE2s3MRpnZYjP7yMz67umDSKQALyISVGcEvxO42t2/CRwNjDCzbwLXA2+6+0HAm7G/AU4GDoptw4EH6r3XlVAOXkQkqDLAu/sKd58Vu78BWAh0BgYDj8We9hhwRuz+YGCMB9OA1mbWqb47XpHWrUPBMY3gRSTd1SgHb2Y5wBHA+0AHd18Re2gl0CF2vzPwRcLL8mNtu+5ruJnNMLMZhYWFNe13hVRwTEQkqHaAN7PmwLPASHdfn/iYuztQo6VF7v6gu+e6e2779u1r8tIqqVyBiEg1A7yZZRGC++Pu/lyseVU89RK7XR1rLwC6Jry8S6ytwahcgYhI9WbRGPAwsNDd70l4aDzw49j9HwMvJLRfFJtNczSwLiGV0yBUUVJEBBpV4znfAS4E5prZ7FjbjcAdwFgz+wmwDBgSe2wCcAqwGNgMDKvPDldHdjbMmNHQ7yoisnepMsC7+1TAKnj4e+U834ERdexXncRz8O5hRo2ISDqK3EpWCDl4FRwTkXQXyQCv1awiIgrwIiKRFekAr7nwIpLOIhngVTJYRCSiAV4pGhGRiAb41q0hI0MpGhFJb5EM8JmZ0KaNRvAikt4iGeBB5QpERBTgRUQiKtIBXjl4EUlnkQ3wKhksIukusgE+nqLxGl2GREQkOiId4Ldvh40bk90TEZHkiHSAB+XhRSR9RTbAq1yBiKS7yAZ4lSsQkXQX+QCvFI2IpKvIBnilaEQk3UU2wMcLjinAi0i6imyAz8yEtm0V4EUkfUU2wIPKFYhIeot0gFe5AhFJZ5EO8KooKSLpTAFeRCSiIh/g16xRwTERSU+RDvDt2qngmIikr0gHeJUrEJF0VmWAN7PRZrbazOYltB1uZtPMbLaZzTCz/rF2M7NRZrbYzD4ys757svNVUYAXkXRWnRH8o8BJu7TdCfze3Q8Hbo79DXAycFBsGw48UC+9rKV4uQLNhReRdFRlgHf3ycCXuzYDLWP3WwHLY/cHA2M8mAa0NrNO9dXZmtIIXkTSWaNavm4k8JqZ3U34kjgm1t4Z+CLhefmxthW77sDMhhNG+XTr1q2W3aicAryIpLPanmS9FPilu3cFfgk8XNMduPuD7p7r7rnt27evZTcqFy84phSNiKSj2gb4HwPPxe4/A/SP3S8AuiY8r0usLSkyMlRwTETSV20D/HLg+Nj97wKfxu6PBy6KzaY5Gljn7rulZxqSVrOKSLqqMgdvZk8CA4FsM8sHfgf8DLjPzBoBW4nl0oEJwCnAYmAzMGwP9LlGFOBFJF1VGeDd/bwKHjqynOc6MKKunapP2dmwZEmyeyEi0vAivZIVVDJYRNJX5AN8PEWjgmMikm5SO8CvWwcPPghLl1b4lOxs2LEDNmxowH6JiOwFUjvAb9wIP/85jB1b4VNUrkBE0lVqB/jOnSE3F154ocKnaDWriKSr1A7wAKefDu+/DytXlvuwAryIpKvUD/CDB4czqC+/XO7D8QCvFI2IpJvUD/B9+kBODsyfX+7D8Ry8RvAikm5qW01y72EGc+dC8+blPhwvOKYALyLpJvVH8FBhcIcQ3LXYSUTSUTQCPMBFF8GI8qskZGcrBy8i6Sc6Ab64GJ55JtzuQiN4EUlH0Qnwp58OhYUwbdpuD6mipIiko+gE+JNOgqwsGD9+t4cU4EUkHUUnwLdqBQMHlruqNZ6DV8ExEUknqT9NMtHw4WE+/M6d0Kj00Nq1Ky041rJlEvsnItKAohXgzz47bLtILFegAC8i6SI6KZq4LVtgypQyTSpXICLpKHoB/q674PjjYfXqr5tUrkBE0lH0Avxpp+1WfEwVJUUkHUUvwB9+OHTtWma6pAK8iKSj6AV4s7Do6fXXQz6eMIMyM1M5eBFJL9EL8BAC/ObN8PbbQCg41ratRvAikl6iNU0ybuBAmDED+vb9uqlbN3j33VCqJjMzeV0TEWko0RzBN24MRx4Z0jUx11wD8+bBY48lsV8iIg0omgEeYPly+PnPYeZMAIYMgaOPhptugk2bktw3EZEGEN0A36wZjB4N48YBYTD/v/8LK1bA3XcnuW8iIg0gugG+TRsYMKDMdMljjoFzzoE77wwDfBGRKItugAcYPBgWLIDFi79uuv32UHjst79NYr9ERBpAlQHezEab2Wozm7dL+xVmtsjM5pvZnQntN5jZYjP72MxO3BOdrrbTTw+3CaP4Aw6AK66ARx6Bjz5KUr9ERBpAdUbwjwInJTaY2QnAYOAwd+8F3B1r/yZwLtAr9pq/m1nyJiXm5MCJJ4aJ8Aluuglat4Zf/1o14kUkuqoM8O4+Gfhyl+ZLgTvcfVvsOfHKXoOBp9x9m7t/BiwG+tdjf2vu1Vdh5MgyTW3awM03w8SJ4WERkSiqbQ7+YOA4M3vfzN4xs36x9s7AFwnPy4+17cbMhpvZDDObUVhYWMtuVFNJCaxdW6bpssvgwAPDKH7nzj379iIiyVDbAN8IaAscDVwDjDVLWFVUDe7+oLvnuntu+/bta9mNavr2t+EnPynT1Lgx/PnP4Rzs6NF79u1FRJKhtgE+H3jOgw+AEiAbKAC6JjyvS6wtufr2hddeg61byzSfeSYce2yYUbNhQ5L6JiKyh9Q2wP8HOAHAzA4GGgNFwHjgXDNrYmbdgYOAD+qhn3UzeHBYvvrWW2Wa44ufVq8Oo3kRkSipzjTJJ4H3gEPMLN/MfgKMBnrEpk4+Bfw4NpqfD4wFFgCvAiPcvXjPdb+aTjgBmjeHf/97t4f694fzzguBPj8/CX0TEdlDzPeCeYK5ubk+Y8aMPfsmN9wAd9wBH3wA/fqVeSgvD3r2hKFDVYxMRFKHmc1099yKHo/2StZEv/89vPjibsEdwnT5q66CMWNg1qyG75qIyJ6QPgG+cWM49dRw/5NPQmH4BDfeGC7td/XVWvwkItGQPgE+7tNP4Vvfgj/9qUxzq1Zwyy3hIlAvvZSUnomI1Kv0C/AHHghnnx1SNu++W+ah4cPhkEPC4qepU7UASkRSW/oFeDP4+9/hG9+AH/2ozArXrCwYNSqcdD3uOGjfHs49N+TmV6+ucI8iInul9AvwAC1bwhNPlF71KSHpPmgQrFoFzzwTFkK9/Tb8+MfQsSMcdVQY+E+fHqofiIjszdJnmmR5/vxnKCoK0ycruBJ3SQnMng0TJoRt2rTwfdC+PZx8cvgRMGhQmcu/iog0iKqmSaZ3gK+FoiJ4/fUQ7F95Bb78MlRCuOGGMOKv4Hsiedzh/vtDSipeH19EIkHz4Kvj3XdDdN62rcqnZmeHUfu//x2u7/rww6GOzTnnQK9e8Oij4YpRe4WSEhgxAq68MpRrmDQp2T0SkQakAA9hWP6f/8BvflOjlzVuDJdcAgsXwtix4Trfw4aFq0b99a+weXMt+vLMM/CXv9R9Mv7OnaEzDzwQpgXdfz8cf3zd9ikiqcXdk74deeSRnnSXXeYO7q+8UutdlJS4T5jgfuyxYVft27vfdpv7V19V44Vffhnuf/hhePEZZ7ivXVvrvvizz4b9/OEPYf9xeXnugwe7r1xZ+32LyF4BmOGVxFbl4OO2bAmVx1avDhdr7dChTrubMiVc4PuVV8KknUsuCfVu9tsvnKDdb7+wtfoqD7v0F+FXxLRpIYk/alQYdefkwLhxcNhhtevE1KmhHnKiV1+FH/4wdOKll6BPnzodp4gkj06y1sS8eaFWza9/DX/4Q73s8sMPwySdcePKTq3MZCdXcR+3cjNuGfxt/z/x9jcvI7tDJq1bQ6+173L+C0NotvVL3vzFOL465gc0b87X2777hvMBZa6VsmFDmNN5881w+OEVd2rGjHDCdcMGeOop+MEP6uVYRaRhKcDX1IcfhhFzRgbcdVc48Tp4MPTuXae5kNu3h0H66tWwbt4X9L75TNp9NpOFB5zKw0f+nY83d6WwMMzBX78eNm6E1ttX8Veu4FfcQwFdyt1vv35hYe45//MV3UecEibpP/EEDBlSeYfy80OQnzMHnn9eM2xEUpACfF2ceWY4+QrQvXsI9EOGhEsA1sW2bWES/aWXhuhcwRfH9u3hOiUbN8LG9SW0uf1aPvvB5RQ1z2HjxrDi9vnn4bPphbzOIHrZAl4472n6/PYMevasRj82bQort26+OfwsEJGUogBfVytWhDLDL7wAb74JF10EDz4YZrm8+CIcfHDIm2dkhK19+xAst28Pk+QzMsLj06eHXM2LL0KLFjXvx6JFcPTRYX///jecckpoX7WK7d8ZiH2+jGsPfJ6/LDwRCFM2zz47bL16VePHx8aNYTL/rbdCmzY175+INDgF+Pq0cWPYOnYMheOPPHL35zzyCFx8Mbz3HhxzTNnHDjkk/CKo1vC6HEuWwFlnhbTKb38Lv/tdmA550UVhvvuAARQUwHPPhZz/lCnhe+jgg0MBzSZNwtTO+Jb490Gfv8nQx05mfXYPpv/uZVr1PYBOncKhNm5cu+4CsGxZWGQlIvVOAX5P2bED/vvfMMIvLg5nUIuL4TvfgYMOgpUrQzCPt7doESqXNW1at/fdsgUuuyysqBozBi68sMKnxrvw3HMh5b59e9lt27ZwG6+aeSxT+A9nUEwmp/EiH3AUEH6U7L8/dOoUbuP3c3JCcc6cnAq+BJ5/Hs4/P8wK+ulPw7eNajqI1BsF+ChyD0to58wJK6rqqKQkfF9t3w5b5nxCq/NOptHq5Uy89Hk+aHsSy5dTZlu1quyMoIwM6NYtBPsDD4QDD3BOXHAvvR79NZ7bn4wXXwhvcO658NBDcOihde6ziCjAS20UFsLPfgb33htOLu+iuDgE+bw8WLy47PbZpzv5/doruYwHeIazuYgx7NetGWce8BF/nD6Ixhk72TJuAq2+37/hj0vK99JLYcbYCy9A69bJ7o3UgAK81E1JSTipe/751aukNnkyPnAgKy+8lrcH/YnFSzNYuDBMvS/+dAmvM4gOrGJEx+fYOmAQ/fpBbm4o2Nay5Z4/HCnHeeeF9RA33xxmVUnKUICXunnllTBj5/TTw/z6ffct/3nbtoWztgBz55a7QnbtWpj7+goOHnky7VYuYFj7l/j36kFASM0fckjI57dqFbaWLUvv79rWrh107gyNGu2Zw047p54KkyeHn2Vt2ya7N1JNCvBSd3/7W6hI2bdvmObZsWPZx2fNCmsG/vlP+P73q97funVw/fVw++0U7mjNjBl8vS1fHh5evz7cbt1a8W6yskpP9CZuBxwQMkt1mv2TDvLy4Kuv4Igjwirub30rTJW97bZk90yqSQFe6seLL4aTpPvtF4rhx0+UxtvjtW16967Zfrdsgccfh5/8pNwZNtu3lwb7+LZ+fThNsHRp2fz/hg2lr0s88ZubG753vvOd0h8ZQvhSfvPNMMWqZcvwObqHdE1dZzu9+mqoYPrUU1pEtwdVFeCTXknS95ZqklK16dPdu3VznzQp/H3ffe5m7v36ua9YUbt9/v3voerlz3/uvnNnrbtWUuK+erX7f//rPmaM+803u59/fuhao0bhLfbZx/3kk93vvdd9/vyyRTbTzsSJ4R/ltttK27Ztq599f/ll2De4jx5dP/uUclFFNcmkB3dXgE8tW7eG2wkTwn8+Z57pvmlT7fdXUuJ+/fVhX2efXbr/erR+vfv48e6XX+5+8MGlsadzZ/dhw9yffDJ8OaSNHTvcv/lN9x493Lds2f3xJUvcCwtrv//hw90zM90feCDNv0X3vKoCvFI0Ujvxn/JDh4Z8SF3dcw9cfTV07Qr/+tcevTjJsmUwcWK49OIbb4Q0NITsUteu4RRD4tahQ+n9li0jsFbrr38N51Sefx7OOKPsY0VF4R9hxAi4++6a73vKFBgwIHyW8dfv3Kmz4XuIcvCSOl55Jax6ffDBEGTefhu++CKUZ9hnnz3ylsXFMHNmCPbTpoWFyatWhS2+wjdR06Yh0LdvH2bytGsXyjZXdD87u+6Ll+vdPffAO++EZc7lfVtdfDE8/XQ4ydGpU832nZcXSm2PGhVmXD3ySPh77tyKZ2BJrdU5wJvZaOBUYLW7997lsauBu4H27l5kZgbcB5wCbAYudvdZVXVSAV7KdcklIUDEyzwMGxYKrjXAELqkJNSKW7kybKtWld5fuTKc5F2zJmxFRWVP8O6qbdtQ3qFz54q37Oz6+SFUbZWVjViyJMxZvfzycPnIunj33XDRmbvuCtdZkHpVHwF+ALARGJMY4M2sK/BPoCdwZCzAnwJcQQjwRwH3uftRVXVSAV7K5R5+8o8eHa5Vu3kznHYajB+f7J7tJl48tKioNOivWRPq/y9fDgUFpduqVbtfcrdx4zC189BDQy26Qw8N2yGH1OMCsLlzQ/AePLjqL8mf/jQscFuyJHwDVeXjj+G668LMmS67XLtg0CCYPRs++0yj+HpWLykaM8sBXtolwI8D/gC8AOTGAvz/AW+7+5Ox53wMDHT3FZXtXwFeqrRhQ7iy+T77hJWXGzeGwJOTEyJjTk7Yvve9sMhqbyhs9vHH4fKP/fuXqai5Y0f4FZAY9AsK4NNPwwXcFy8umx7q3Lls4D/wwFBRoEWLEPxbtAgzESv9BeAOAwfC/Pkh9VLVt0ZeXqgz/fDD4ddTZdzhhBNCbaSFC3dfJxEfxd99d8jNS72pKsDX6syHmQ0GCtx9jpX9n6gz8EXC3/mxtt0CvJkNB4YDdOvWrTbdkHTSokWYKx+3fXu4POFnn4VR5htvhAuYjBoVAvyiRWHie05OSIjvu2/YLr88XLBl2TJ48snS9n33Dc/r37/uQ+aPPw6F+OfNK23LyYHHHoMBA8jKLKFr1wy6di3/5Tt2hENauDAcRvz20UfD91pFmjcvDfjx2+zskEY/vnAcZ06ezPwr/kFxXks6dqwiLZSTE751qlOb5pFHQk7/oYd2D+4QPof/+Z+QprniCq1Aa0A1HsGb2T7AJGCQu68zszxKR/AvAXe4+9TY694ErnP3SofnGsFLnbmHnEhWVqhl8NlnYcSYlxdyJ5s2he2++8Ky/NdfhxNP3H0/48eHNNCiReGi5cccE4bOFUVC9zByHTcurKwaPjws3jrjjHCt2/79w8Ve3n479Kd79xAIb789jKgHDgyj34qi/S5vVVAQDm39+vCjprLb+IKwdSs288HGQ/mKNhzJTEoINYUyM8MMoXgZ6B49wirg+G1OTuwEcV5e+KM8q1eHf58+fWDSpIr/nebNCyc2vvWtKo9Tqm9PjOAPALoD8dF7F2CWmfUHCoDE/1K7xNpE9iyzMCSN6949lFioyPe/Xxr049vKlWHZK4RVuddcE+63bg1HHRWC/ciRYXg8a1ZIGY0bF4bbGRmhAidAs2bw2mul73X00WHkGtetW7go+gsvhNEvhKg6dWqls1bMQnp71xR3lX5/F9zyOY2e+BeTu2WyYkU41MTbvDx4663wz5D4fje2up9b1v2SG876lNaH59CjR9mppM1///vwov/7v8pzRDVd4Sz1otY5+ITH8igdwf8AuJzSk6yj3L3KurAawctexx0++SRcmSu+ffppqJjWpEkovjZhQsj5n312GLG3b1+z9ygpCSc+3347/Pq49dbQ/sYbIa3RrFn9HMuTT4b+jxpV6dPcw4h/yZKQpl+yBL6cW8Cfnz2AZ5tewPlb/rnbazrvu5aTW77LogN+8PUVwDp2DN9T7dqFXwlmYcvcuY0+9wxj3aFHU3DWlV+3Z2SEDFmrVuG7tFWrNMriLF8efj7VUn3MonkSGAhkA6uA37n7wwmP51Ea4A24HziJME1yWFXpGVCAlxSxeXPpfPzFi8O1a9u1q9/3WL48nJDt0CGU7x02LKSdkmnkSLj/frbM/pildkC46MuyrawszGR5YdZuvwjWrat4V2/wPb7JAnqwlK1U/AXWrFnZgB+/7dAB+vULP4oOPLCC8+iFhWEh14knhjn9lSgpKc3sxS9hWZ2q2PVm3brwDVeb6zSjhU4iqeedd0JVx/feC1HsD3+AIUNqPlF+6tSQ/7/88rp9SaxYEVJI555bmlK69tqQhnrvvd0WoW3ZEgL9l1+GAFpSEi8OAc1nTabP5cez5PJ7yT97JO7h8U2bQqxbu7b82/j9goLSE81t24ZAH9/694dWeXPCNNBly0LEXrwYunTBPayZmzcvTCSK3y5YEPqbKDOzNNg3aVJ6v2nTkPnr2zcU4OzbN6TLajxZ6/PP4Y47whqDxo0pLq79l4oCvEgqcg/nAX7zm9K5k1VdvLyoKFRxXLQobFOmhOi0aFHdVwJffXUoIbFkSdhyc8Ovi4ceqvm+vvvdcExLl9Y4DVVcHF46bVrptmBB+Oc6i2cZYxextVkbpox4iq3bMpi46Rjmzw/BPHEx2v77h9MCvXqFoL1zZ9nrFG/btvv9LVtC1m7RotJLVmZnh0CfuPXoURr0t2wJXyzxbfOHH3Puw9+n8bb1XPCNqby1uje//GXtr7OiAC+SykpKQi2Ffv3C3zfeGE7QFhaWzqH8xS/CeYCZM0PgzcwM02B69gx197/97br3Y+3aELWaNw/D5S++CO/dpk3N9/XOO2H20F/+AlddVeeurVsHH3wAfs+9dJ02lrN4joVrw8nq7Gy4ov1TdOixL5x2Gr16haBem27HbdoUljfMmlW6zZtXunahVatwHn3FivCdG3cEs3iNE8EyuKrna2w55HC6dYOTT4aTTqpdXxTgRaKisBAOOyxEDgh52549w+h66NAwzFy6NAT3PXWW8t574Ve/Ciduq1oAVZm//jV8KdW01s2uNm4MQ/j+/cMwfscOPKsxS5eGf5792hWHE9Yffggvvxzm4+8B27aFID9rVnir/PzwK6Fr17D1WTuFw278Ada2DfbGRDj44Hp5XwV4kSjZvDks++/ePUxXacjVuu7hnMB++8F//5v8lcJ5eSHfnp8fFgdUtEDtyy/DWoPFi8N5g2OPbdBuAmGtxKWXhqm1NZ7nWrGqAnxDljcSkbraZ58wH79Tp4YPsGbhxO0779TPe0+fHkbxlV2XsSLvvBPSVp9/Hn5NVLb6uG3bUB+6a9dwfeHp02vfZ9i9kFBlZs8Ot4cdFko21GNwrw4FeBGpvk6d6i/9s3EjPPtszU/UPvBASLW0awfvvx+KmVVlv/3C5Qmzs8Mq5urasiXMHHrhhfD3ypVhH6ecEs6MvvZa6QUFyutn377hkpSQlF88StGISHK4hwu7xGfm7Fo4f/v2kJKKb9nZ4QzmJZeEEglPPBH+rom1a0vr61RWkG7ZshCg//nPMFH+nHNCeuXzz8O01WnTwtScePx85pnwa6SoKKSMJkwIM6BOOy3U1q+vRWu70DVZRWTv9eabYYp89+6l129duLD0QrqJ20MPhce3bq3T9Xvd3X32bPcjjgiXJ9zVjTe6Z2SE7Yc/DNcgLu/Sg+vWhf7fdpt7Xl5oe+ih0v5ecIH79u1162cVqOKSfbqOlogkzwknhEVTn34acuUQ0inXXhvONyRu8emeTZrU/X0zMsIo/XvfC1cSmzQpzERq2xaOPDLUtv/FL8J8x4q0bBnm9H/3u6Vtp54aflns2AEXXNDAV3HZnVI0IpKeZswIAX79+vD3ww+H9E8K2SP14EVEUl5ubjjhOmYMXHhhqBgaMQrwIpK+jjoqkoE9TtMkRUQiSgFeRCSiFOBFRCJKAV5EJKIU4EVEIkoBXkQkohTgRUQiSgFeRCSi9opSBWZWCCyr5cuzgaIqn5VaonZMUTseiN4xRe14IHrHVN7xfMPd21f0gr0iwNeFmc2orBZDKoraMUXteCB6xxS144HoHVNtjkcpGhGRiFKAFxGJqCgE+AeT3YE9IGrHFLXjgegdU9SOB6J3TDU+npTPwYuISPmiMIIXEZFyKMCLiERUSgd4MzvJzD42s8Vmdn2y+1MfzCzPzOaa2WwzS7nrGJrZaDNbbWbzEtramtlEM/s0dtsmmX2sqQqO6RYzK4h9TrPN7JRk9rEmzKyrmU0yswVmNt/Mroq1p+TnVMnxpPJn1NTMPjCzObFj+n2svbuZvR+LeU+bWeNK95OqOXgzywQ+Ab4P5APTgfPcfUFSO1ZHZpYH5Lp7Si7QMLMBwEZgjLv3jrXdCXzp7nfEvojbuPt1yexnTVRwTLcAG9397mT2rTbMrBPQyd1nmVkLYCZwBnAxKfg5VXI8Q0jdz8iAfd19o5llAVOBq4BfAc+5+1Nm9g9gjrs/UNF+UnkE3x9Y7O5L3X078BQwOMl9SnvuPhn4cpfmwcBjsfuPEf7nSxkVHFPKcvcV7j4rdn8DsBDoTIp+TpUcT8ryYGPsz6zY5sB3gXGx9io/o1QO8J2BLxL+zifFP9QYB143s5lmNjzZnaknHdx9Rez+SqBDMjtTjy43s49iKZyUSGfsysxygCOA94nA57TL8UAKf0Zmlmlms4HVwERgCbDW3XfGnlJlzEvlAB9Vx7p7X+BkYEQsPRAZHnKCqZkXLOsB4ADgcGAF8L9J7U0tmFlz4FlgpLuvT3wsFT+nco4npT8jdy9298OBLoSMRc+a7iOVA3wB0DXh7y6xtpTm7gWx29XA84QPNtWtiuVJ4/nS1UnuT525+6rY/4AlwEOk2OcUy+s+Czzu7s/FmlP2cyrveFL9M4pz97XAJODbQGszaxR7qMqYl8oBfjpwUOyscmPgXGB8kvtUJ2a2b+wkEWa2LzAImFf5q1LCeODHsfs/Bl5IYl/qRTwQxpxJCn1OsRN4DwML3f2ehIdS8nOq6HhS/DNqb2atY/ebESaTLCQE+rNjT6vyM0rZWTQAsWlPfwEygdHufltye1Q3ZtaDMGoHaAQ8kWrHZGZPAgMJpU1XAb8D/gOMBboRykIPcfeUOWlZwTENJPz0dyAP+HlC/nqvZmbHAlOAuUBJrPlGQt465T6nSo7nPFL3M/oW4SRqJmEgPtbdb43FiKeAtsCHwAXuvq3C/aRygBcRkYqlcopGREQqoQAvIhJRCvAiIhGlAC8iElEK8CIiEaUAL2nBzIoTqgrOrs/qo2aWk1hpUmRv0ajqp4hEwpbYsm+RtKERvKS1WP39O2M1+D8wswNj7Tlm9lasUNWbZtYt1t7BzJ6P1emeY2bHxHaVaWYPxWp3vx5bfSiSVArwki6a7ZKiGZrw2Dp37wPcT1gZDfBX4DF3/xbwODAq1j4KeMfdDwP6AvNj7QcBf3P3XsBa4Kw9ejQi1aCVrJIWzGyjuzcvpz0P+K67L40VrFrp7u3MrIhwEYkdsfYV7p5tZoVAl8Tl4bEStRPd/aDY39cBWe7+xwY4NJEKaQQvUrYsbm1HPIn1QIrR+S3ZCyjAi8DQhNv3Yvf/S6hQCnA+oZgVwJvApfD1BRlaNVQnRWpKowxJF81iV8eJe9Xd41Ml25jZR4RR+HmxtiuAR8zsGqAQGBZrvwp40Mx+QhipX0q4mITIXkc5eElrqX6Rc5HKKEUjIhJRGsGLiESURvAiIhGlAC8iElEK8CIiEaUALyISUQrwIiIR9f9hT4le7zVuYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], 'b-', label='loss')\n",
    "plt.plot(hist.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "783/820 [===========================>..] - ETA: 0s - loss: 1.4500WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 1.4483 - val_loss: 1.5774\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4007 - val_loss: 1.5916\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3897 - val_loss: 1.5876\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3827 - val_loss: 1.5768\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3955 - val_loss: 1.5852\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3861 - val_loss: 1.5943\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3928 - val_loss: 1.5911\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "790/820 [===========================>..] - ETA: 0s - loss: 2.2656WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 2.2653 - val_loss: 2.5861\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2413 - val_loss: 2.5794\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2416 - val_loss: 2.5821\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2297 - val_loss: 2.5598\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2480 - val_loss: 2.5730\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2415 - val_loss: 2.5461\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2533 - val_loss: 2.5711\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2619 - val_loss: 2.6094\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2419 - val_loss: 2.5618\n",
      "Epoch 00009: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "785/820 [===========================>..] - ETA: 0s - loss: 2.6848WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 2.6842 - val_loss: 3.0570\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6568 - val_loss: 3.0701\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6566 - val_loss: 3.0830\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6403 - val_loss: 3.0327\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6642 - val_loss: 3.0904\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6550 - val_loss: 3.0508\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6795 - val_loss: 3.0299\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6899 - val_loss: 3.0605\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6647 - val_loss: 3.0359\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6957 - val_loss: 3.0107\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6120 - val_loss: 3.0242\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6271 - val_loss: 3.0407\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6516 - val_loss: 3.0984\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "779/820 [===========================>..] - ETA: 0s - loss: 2.7867WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 2.7859 - val_loss: 3.1404\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7428 - val_loss: 3.1617\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7569 - val_loss: 3.1800\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7427 - val_loss: 3.1560\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "806/820 [============================>.] - ETA: 0s - loss: 2.6503WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.6503 - val_loss: 3.0179\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6172 - val_loss: 3.0192\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6241 - val_loss: 2.9968\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6248 - val_loss: 3.0859\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6254 - val_loss: 3.0436\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6226 - val_loss: 2.9981\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "780/820 [===========================>..] - ETA: 0s - loss: 2.3402WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.3403 - val_loss: 2.6802\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3168 - val_loss: 2.6758\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3281 - val_loss: 2.7223\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3261 - val_loss: 2.7081\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3309 - val_loss: 2.6713\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3237 - val_loss: 2.6847\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3566 - val_loss: 2.7002\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3766 - val_loss: 2.6867\n",
      "Epoch 00008: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "807/820 [============================>.] - ETA: 0s - loss: 1.9129WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9130 - val_loss: 2.2169\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8985 - val_loss: 2.2082\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8985 - val_loss: 2.1915\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9067 - val_loss: 2.2184\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9036 - val_loss: 2.1809\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8961 - val_loss: 2.1545\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9259 - val_loss: 2.2083\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9385 - val_loss: 2.2027\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8867 - val_loss: 2.2048\n",
      "Epoch 00009: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "818/820 [============================>.] - ETA: 0s - loss: 1.3878WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.3878 - val_loss: 1.5924\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3854 - val_loss: 1.6155\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3834 - val_loss: 1.5800\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3840 - val_loss: 1.5952\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3817 - val_loss: 1.6248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3809 - val_loss: 1.5889\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "793/820 [============================>.] - ETA: 0s - loss: 0.7781WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 0.7780 - val_loss: 0.8960\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7671 - val_loss: 0.9577\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7748 - val_loss: 0.8861\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7689 - val_loss: 0.9138\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7690 - val_loss: 0.8798\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7647 - val_loss: 0.9059\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7790 - val_loss: 0.9289\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7827 - val_loss: 0.8960\n",
      "Epoch 00008: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    model.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model.fit(Day, Day78, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred = pd.DataFrame(model.predict(df_test))\n",
    "    results = pd.concat([results, pred], axis=1)\n",
    "\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0], results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.34889\n",
      "Early stopping, best iteration is:\n",
      "[418]\tvalid_0's quantile: 1.34812\n",
      "0.2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.14466\n",
      "[1000]\tvalid_0's quantile: 2.13764\n",
      "[1500]\tvalid_0's quantile: 2.13582\n",
      "[2000]\tvalid_0's quantile: 2.1334\n",
      "Early stopping, best iteration is:\n",
      "[1749]\tvalid_0's quantile: 2.13312\n",
      "0.3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.53565\n",
      "[1000]\tvalid_0's quantile: 2.50726\n",
      "[1500]\tvalid_0's quantile: 2.49215\n",
      "Early stopping, best iteration is:\n",
      "[1604]\tvalid_0's quantile: 2.48959\n",
      "0.4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.66191\n",
      "[1000]\tvalid_0's quantile: 2.62846\n",
      "[1500]\tvalid_0's quantile: 2.61266\n",
      "[2000]\tvalid_0's quantile: 2.6059\n",
      "[2500]\tvalid_0's quantile: 2.59923\n",
      "[3000]\tvalid_0's quantile: 2.59644\n",
      "Early stopping, best iteration is:\n",
      "[2707]\tvalid_0's quantile: 2.59598\n",
      "0.5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.55537\n",
      "[1000]\tvalid_0's quantile: 2.54183\n",
      "[1500]\tvalid_0's quantile: 2.52395\n",
      "[2000]\tvalid_0's quantile: 2.5191\n",
      "[2500]\tvalid_0's quantile: 2.51606\n",
      "[3000]\tvalid_0's quantile: 2.51386\n",
      "[3500]\tvalid_0's quantile: 2.5086\n",
      "[4000]\tvalid_0's quantile: 2.50447\n",
      "[4500]\tvalid_0's quantile: 2.50257\n",
      "[5000]\tvalid_0's quantile: 2.50037\n",
      "[5500]\tvalid_0's quantile: 2.49801\n",
      "[6000]\tvalid_0's quantile: 2.49694\n",
      "[6500]\tvalid_0's quantile: 2.49596\n",
      "Early stopping, best iteration is:\n",
      "[6563]\tvalid_0's quantile: 2.49582\n",
      "0.6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.28838\n",
      "[1000]\tvalid_0's quantile: 2.26798\n",
      "[1500]\tvalid_0's quantile: 2.25775\n",
      "[2000]\tvalid_0's quantile: 2.25273\n",
      "[2500]\tvalid_0's quantile: 2.24936\n",
      "[3000]\tvalid_0's quantile: 2.24642\n",
      "[3500]\tvalid_0's quantile: 2.24451\n",
      "[4000]\tvalid_0's quantile: 2.24427\n",
      "Early stopping, best iteration is:\n",
      "[3735]\tvalid_0's quantile: 2.24391\n",
      "0.7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.87856\n",
      "[1000]\tvalid_0's quantile: 1.86236\n",
      "[1500]\tvalid_0's quantile: 1.85737\n",
      "[2000]\tvalid_0's quantile: 1.85491\n",
      "Early stopping, best iteration is:\n",
      "[1840]\tvalid_0's quantile: 1.85404\n",
      "0.8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.34949\n",
      "[1000]\tvalid_0's quantile: 1.34333\n",
      "Early stopping, best iteration is:\n",
      "[898]\tvalid_0's quantile: 1.34271\n",
      "0.9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 0.748569\n",
      "[1000]\tvalid_0's quantile: 0.746233\n",
      "[1500]\tvalid_0's quantile: 0.74548\n",
      "Early stopping, best iteration is:\n",
      "[1284]\tvalid_0's quantile: 0.745153\n",
      "0.1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.39392\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's quantile: 1.3933\n",
      "0.2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.19349\n",
      "Early stopping, best iteration is:\n",
      "[616]\tvalid_0's quantile: 2.18577\n",
      "0.3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.61892\n",
      "[1000]\tvalid_0's quantile: 2.57944\n",
      "[1500]\tvalid_0's quantile: 2.578\n",
      "Early stopping, best iteration is:\n",
      "[1380]\tvalid_0's quantile: 2.57785\n",
      "0.4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.7433\n",
      "[1000]\tvalid_0's quantile: 2.70695\n",
      "[1500]\tvalid_0's quantile: 2.70092\n",
      "[2000]\tvalid_0's quantile: 2.69464\n",
      "[2500]\tvalid_0's quantile: 2.68927\n",
      "[3000]\tvalid_0's quantile: 2.68204\n",
      "[3500]\tvalid_0's quantile: 2.67218\n",
      "[4000]\tvalid_0's quantile: 2.66515\n",
      "[4500]\tvalid_0's quantile: 2.66079\n",
      "Early stopping, best iteration is:\n",
      "[4475]\tvalid_0's quantile: 2.66079\n",
      "0.5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.6458\n",
      "[1000]\tvalid_0's quantile: 2.62814\n",
      "[1500]\tvalid_0's quantile: 2.61626\n",
      "[2000]\tvalid_0's quantile: 2.60023\n",
      "[2500]\tvalid_0's quantile: 2.58706\n",
      "[3000]\tvalid_0's quantile: 2.58403\n",
      "Early stopping, best iteration is:\n",
      "[2807]\tvalid_0's quantile: 2.58403\n",
      "0.6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.36786\n",
      "[1000]\tvalid_0's quantile: 2.35343\n",
      "[1500]\tvalid_0's quantile: 2.33476\n",
      "[2000]\tvalid_0's quantile: 2.32426\n",
      "[2500]\tvalid_0's quantile: 2.31984\n",
      "[3000]\tvalid_0's quantile: 2.31736\n",
      "Early stopping, best iteration is:\n",
      "[2871]\tvalid_0's quantile: 2.31729\n",
      "0.7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.96038\n",
      "[1000]\tvalid_0's quantile: 1.93778\n",
      "[1500]\tvalid_0's quantile: 1.92682\n",
      "[2000]\tvalid_0's quantile: 1.91583\n",
      "[2500]\tvalid_0's quantile: 1.91245\n",
      "Early stopping, best iteration is:\n",
      "[2560]\tvalid_0's quantile: 1.91213\n",
      "0.8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.40785\n",
      "[1000]\tvalid_0's quantile: 1.39944\n",
      "[1500]\tvalid_0's quantile: 1.39438\n",
      "[2000]\tvalid_0's quantile: 1.39224\n",
      "[2500]\tvalid_0's quantile: 1.39124\n",
      "Early stopping, best iteration is:\n",
      "[2308]\tvalid_0's quantile: 1.39107\n",
      "0.9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 0.780444\n",
      "[1000]\tvalid_0's quantile: 0.777171\n",
      "[1500]\tvalid_0's quantile: 0.775623\n",
      "[2000]\tvalid_0's quantile: 0.775235\n",
      "Early stopping, best iteration is:\n",
      "[1831]\tvalid_0's quantile: 0.774894\n"
     ]
    }
   ],
   "source": [
    "def LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "    \n",
    "    # (a) Modeling  \n",
    "    model = LGBMRegressor(objective='quantile', alpha=q,\n",
    "                         n_estimators=10000, bagging_fraction=0.7, learning_rate=0.027, subsample=0.7)                   \n",
    "                         \n",
    "                         \n",
    "    model.fit(X_train, Y_train, eval_metric = ['quantile'], \n",
    "          eval_set=[(X_valid, Y_valid)], early_stopping_rounds=300, verbose=500)\n",
    "\n",
    "    # (b) Predictions\n",
    "    pred = pd.Series(model.predict(X_test).round(2))\n",
    "    return pred, model\n",
    "\n",
    "def train_data(X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "\n",
    "    LGBM_models=[]\n",
    "    LGBM_actual_pred = pd.DataFrame()\n",
    "\n",
    "    for q in q_lst:\n",
    "        print(q)\n",
    "        pred , model = LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test)\n",
    "        LGBM_models.append(model)\n",
    "        LGBM_actual_pred = pd.concat([LGBM_actual_pred,pred],axis=1)\n",
    "\n",
    "    LGBM_actual_pred.columns=q_lst\n",
    "    \n",
    "    return LGBM_models, LGBM_actual_pred\n",
    "\n",
    "models_1, results_1 = train_data(X_train_1, Y_train_1, X_valid_1, Y_valid_1, df_test)\n",
    "models_2, results_2 = train_data(X_train_2, Y_train_2, X_valid_2, Y_valid_2, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_L0 = pd.DataFrame(results_1.sort_index())\n",
    "res_L0.columns = ['L00.1','L00.2','L00.3','L00.4','L00.5','L00.6','L00.7','L00.8','L00.9']\n",
    "res_L1 = pd.DataFrame(results_1.sort_index())\n",
    "res_L1.columns = ['L10.1','L10.2','L10.3','L10.4','L10.5','L10.6','L10.7','L10.8','L10.9']\n",
    "\n",
    "res_D0 = pd.DataFrame(results[0].sort_index())\n",
    "res_D0.columns = ['D00.1','D00.2','D00.3','D00.4','D00.5','D00.6','D00.7','D00.8','D00.9']\n",
    "res_D1 = pd.DataFrame(results[1].sort_index())\n",
    "res_D1.columns = ['D10.1','D10.2','D10.3','D10.4','D10.5','D10.6','D10.7','D10.8','D10.9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_0 = pd.concat([res_L0, res_D0], axis=1)\n",
    "res_1 = pd.concat([res_L1, res_D1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_0.loc[res_0[res_0['L00.1'] == 0].index, ['D00.1','D00.2','D00.3','D00.4','D00.5','D00.6','D00.7','D00.8','D00.9']] = 0\n",
    "res_1.loc[res_1[res_1['L10.1'] == 0].index, ['D10.1','D10.2','D10.3','D10.4','D10.5','D10.6','D10.7','D10.8','D10.9']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    res_0[\"L00.\"+str(i)] = res_0[\"L00.\"+str(i)]*0.15 + res_0[\"D00.\"+str(i)]*0.85\n",
    "    res_1[\"L10.\"+str(i)] = res_1[\"L10.\"+str(i)]*0.15 + res_1[\"D10.\"+str(i)]*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>0.483308</td>\n",
       "      <td>0.679482</td>\n",
       "      <td>1.180930</td>\n",
       "      <td>1.646939</td>\n",
       "      <td>2.438581</td>\n",
       "      <td>3.826559</td>\n",
       "      <td>6.227041</td>\n",
       "      <td>7.803840</td>\n",
       "      <td>9.928485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>1.222704</td>\n",
       "      <td>3.076825</td>\n",
       "      <td>3.818672</td>\n",
       "      <td>4.447571</td>\n",
       "      <td>6.074837</td>\n",
       "      <td>8.993718</td>\n",
       "      <td>11.328458</td>\n",
       "      <td>14.013577</td>\n",
       "      <td>18.550534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>1.949298</td>\n",
       "      <td>5.297096</td>\n",
       "      <td>5.684612</td>\n",
       "      <td>6.270007</td>\n",
       "      <td>9.326760</td>\n",
       "      <td>13.082036</td>\n",
       "      <td>16.487246</td>\n",
       "      <td>19.468775</td>\n",
       "      <td>23.360148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>5.454330</td>\n",
       "      <td>12.331914</td>\n",
       "      <td>14.585219</td>\n",
       "      <td>13.988752</td>\n",
       "      <td>19.236589</td>\n",
       "      <td>22.784333</td>\n",
       "      <td>24.617011</td>\n",
       "      <td>28.913754</td>\n",
       "      <td>30.697884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>7.297699</td>\n",
       "      <td>14.755270</td>\n",
       "      <td>15.981396</td>\n",
       "      <td>16.702547</td>\n",
       "      <td>22.557694</td>\n",
       "      <td>23.955464</td>\n",
       "      <td>26.565552</td>\n",
       "      <td>29.405802</td>\n",
       "      <td>31.752696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>11.870131</td>\n",
       "      <td>22.629430</td>\n",
       "      <td>24.198139</td>\n",
       "      <td>24.729697</td>\n",
       "      <td>32.303345</td>\n",
       "      <td>35.619208</td>\n",
       "      <td>37.181924</td>\n",
       "      <td>37.368963</td>\n",
       "      <td>37.684343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>12.380250</td>\n",
       "      <td>21.236209</td>\n",
       "      <td>25.879990</td>\n",
       "      <td>26.431305</td>\n",
       "      <td>34.012219</td>\n",
       "      <td>36.331810</td>\n",
       "      <td>37.961073</td>\n",
       "      <td>37.579726</td>\n",
       "      <td>37.315308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>15.295279</td>\n",
       "      <td>28.064555</td>\n",
       "      <td>34.432055</td>\n",
       "      <td>32.670461</td>\n",
       "      <td>41.228280</td>\n",
       "      <td>44.527320</td>\n",
       "      <td>47.152124</td>\n",
       "      <td>46.143171</td>\n",
       "      <td>49.914619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>14.135247</td>\n",
       "      <td>26.301475</td>\n",
       "      <td>31.618305</td>\n",
       "      <td>30.131145</td>\n",
       "      <td>37.574912</td>\n",
       "      <td>40.150545</td>\n",
       "      <td>44.558213</td>\n",
       "      <td>41.805125</td>\n",
       "      <td>47.361309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>13.420705</td>\n",
       "      <td>24.794284</td>\n",
       "      <td>33.169579</td>\n",
       "      <td>31.629500</td>\n",
       "      <td>38.684753</td>\n",
       "      <td>40.796549</td>\n",
       "      <td>44.114309</td>\n",
       "      <td>42.390917</td>\n",
       "      <td>46.787138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>13.308580</td>\n",
       "      <td>24.183834</td>\n",
       "      <td>33.854503</td>\n",
       "      <td>31.962955</td>\n",
       "      <td>38.810801</td>\n",
       "      <td>43.512472</td>\n",
       "      <td>45.597074</td>\n",
       "      <td>43.982412</td>\n",
       "      <td>47.724013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>11.537354</td>\n",
       "      <td>20.848399</td>\n",
       "      <td>30.413905</td>\n",
       "      <td>30.028877</td>\n",
       "      <td>36.714348</td>\n",
       "      <td>39.613817</td>\n",
       "      <td>43.432857</td>\n",
       "      <td>41.496153</td>\n",
       "      <td>46.218378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>11.454076</td>\n",
       "      <td>20.578431</td>\n",
       "      <td>28.849471</td>\n",
       "      <td>28.418233</td>\n",
       "      <td>32.803322</td>\n",
       "      <td>35.406038</td>\n",
       "      <td>42.958357</td>\n",
       "      <td>39.361730</td>\n",
       "      <td>48.390779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>7.863847</td>\n",
       "      <td>17.137177</td>\n",
       "      <td>24.519193</td>\n",
       "      <td>25.047578</td>\n",
       "      <td>29.673107</td>\n",
       "      <td>32.919451</td>\n",
       "      <td>37.757429</td>\n",
       "      <td>35.280643</td>\n",
       "      <td>40.782656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>7.810396</td>\n",
       "      <td>17.176506</td>\n",
       "      <td>24.945319</td>\n",
       "      <td>25.206410</td>\n",
       "      <td>30.061115</td>\n",
       "      <td>33.021963</td>\n",
       "      <td>38.315688</td>\n",
       "      <td>35.731320</td>\n",
       "      <td>40.535110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>4.667605</td>\n",
       "      <td>12.558884</td>\n",
       "      <td>19.597779</td>\n",
       "      <td>20.260223</td>\n",
       "      <td>25.159379</td>\n",
       "      <td>28.176653</td>\n",
       "      <td>31.809275</td>\n",
       "      <td>30.029880</td>\n",
       "      <td>34.081065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>4.205030</td>\n",
       "      <td>12.095882</td>\n",
       "      <td>16.478287</td>\n",
       "      <td>17.120333</td>\n",
       "      <td>20.895593</td>\n",
       "      <td>23.606591</td>\n",
       "      <td>27.780951</td>\n",
       "      <td>25.766081</td>\n",
       "      <td>30.834152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>2.004883</td>\n",
       "      <td>5.330774</td>\n",
       "      <td>9.744336</td>\n",
       "      <td>9.532683</td>\n",
       "      <td>12.073254</td>\n",
       "      <td>14.413462</td>\n",
       "      <td>16.455494</td>\n",
       "      <td>15.855799</td>\n",
       "      <td>18.805100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>1.366910</td>\n",
       "      <td>2.444565</td>\n",
       "      <td>5.806896</td>\n",
       "      <td>4.303989</td>\n",
       "      <td>4.854649</td>\n",
       "      <td>9.141440</td>\n",
       "      <td>11.806860</td>\n",
       "      <td>12.169070</td>\n",
       "      <td>14.979691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1    0.csv_Day7_0h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2    0.csv_Day7_1h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3    0.csv_Day7_1h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4    0.csv_Day7_2h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5    0.csv_Day7_2h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "6    0.csv_Day7_3h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "7    0.csv_Day7_3h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "8    0.csv_Day7_4h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "9    0.csv_Day7_4h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "10   0.csv_Day7_5h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "11   0.csv_Day7_5h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12   0.csv_Day7_6h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "13   0.csv_Day7_6h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "14   0.csv_Day7_7h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "15   0.csv_Day7_7h30m   0.483308   0.679482   1.180930   1.646939   2.438581   \n",
       "16   0.csv_Day7_8h00m   1.222704   3.076825   3.818672   4.447571   6.074837   \n",
       "17   0.csv_Day7_8h30m   1.949298   5.297096   5.684612   6.270007   9.326760   \n",
       "18   0.csv_Day7_9h00m   5.454330  12.331914  14.585219  13.988752  19.236589   \n",
       "19   0.csv_Day7_9h30m   7.297699  14.755270  15.981396  16.702547  22.557694   \n",
       "20  0.csv_Day7_10h00m  11.870131  22.629430  24.198139  24.729697  32.303345   \n",
       "21  0.csv_Day7_10h30m  12.380250  21.236209  25.879990  26.431305  34.012219   \n",
       "22  0.csv_Day7_11h00m  15.295279  28.064555  34.432055  32.670461  41.228280   \n",
       "23  0.csv_Day7_11h30m  14.135247  26.301475  31.618305  30.131145  37.574912   \n",
       "24  0.csv_Day7_12h00m  13.420705  24.794284  33.169579  31.629500  38.684753   \n",
       "25  0.csv_Day7_12h30m  13.308580  24.183834  33.854503  31.962955  38.810801   \n",
       "26  0.csv_Day7_13h00m  11.537354  20.848399  30.413905  30.028877  36.714348   \n",
       "27  0.csv_Day7_13h30m  11.454076  20.578431  28.849471  28.418233  32.803322   \n",
       "28  0.csv_Day7_14h00m   7.863847  17.137177  24.519193  25.047578  29.673107   \n",
       "29  0.csv_Day7_14h30m   7.810396  17.176506  24.945319  25.206410  30.061115   \n",
       "30  0.csv_Day7_15h00m   4.667605  12.558884  19.597779  20.260223  25.159379   \n",
       "31  0.csv_Day7_15h30m   4.205030  12.095882  16.478287  17.120333  20.895593   \n",
       "32  0.csv_Day7_16h00m   2.004883   5.330774   9.744336   9.532683  12.073254   \n",
       "33  0.csv_Day7_16h30m   1.366910   2.444565   5.806896   4.303989   4.854649   \n",
       "34  0.csv_Day7_17h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "35  0.csv_Day7_17h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "36  0.csv_Day7_18h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "37  0.csv_Day7_18h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "38  0.csv_Day7_19h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "39  0.csv_Day7_19h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "40  0.csv_Day7_20h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "41  0.csv_Day7_20h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "42  0.csv_Day7_21h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "43  0.csv_Day7_21h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "44  0.csv_Day7_22h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "45  0.csv_Day7_22h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "46  0.csv_Day7_23h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "47  0.csv_Day7_23h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.000000   0.000000   0.000000   0.000000  \n",
       "1    0.000000   0.000000   0.000000   0.000000  \n",
       "2    0.000000   0.000000   0.000000   0.000000  \n",
       "3    0.000000   0.000000   0.000000   0.000000  \n",
       "4    0.000000   0.000000   0.000000   0.000000  \n",
       "5    0.000000   0.000000   0.000000   0.000000  \n",
       "6    0.000000   0.000000   0.000000   0.000000  \n",
       "7    0.000000   0.000000   0.000000   0.000000  \n",
       "8    0.000000   0.000000   0.000000   0.000000  \n",
       "9    0.000000   0.000000   0.000000   0.000000  \n",
       "10   0.000000   0.000000   0.000000   0.000000  \n",
       "11   0.000000   0.000000   0.000000   0.000000  \n",
       "12   0.000000   0.000000   0.000000   0.000000  \n",
       "13   0.000000   0.000000   0.000000   0.000000  \n",
       "14   0.000000   0.000000   0.000000   0.000000  \n",
       "15   3.826559   6.227041   7.803840   9.928485  \n",
       "16   8.993718  11.328458  14.013577  18.550534  \n",
       "17  13.082036  16.487246  19.468775  23.360148  \n",
       "18  22.784333  24.617011  28.913754  30.697884  \n",
       "19  23.955464  26.565552  29.405802  31.752696  \n",
       "20  35.619208  37.181924  37.368963  37.684343  \n",
       "21  36.331810  37.961073  37.579726  37.315308  \n",
       "22  44.527320  47.152124  46.143171  49.914619  \n",
       "23  40.150545  44.558213  41.805125  47.361309  \n",
       "24  40.796549  44.114309  42.390917  46.787138  \n",
       "25  43.512472  45.597074  43.982412  47.724013  \n",
       "26  39.613817  43.432857  41.496153  46.218378  \n",
       "27  35.406038  42.958357  39.361730  48.390779  \n",
       "28  32.919451  37.757429  35.280643  40.782656  \n",
       "29  33.021963  38.315688  35.731320  40.535110  \n",
       "30  28.176653  31.809275  30.029880  34.081065  \n",
       "31  23.606591  27.780951  25.766081  30.834152  \n",
       "32  14.413462  16.455494  15.855799  18.805100  \n",
       "33   9.141440  11.806860  12.169070  14.979691  \n",
       "34   0.000000   0.000000   0.000000   0.000000  \n",
       "35   0.000000   0.000000   0.000000   0.000000  \n",
       "36   0.000000   0.000000   0.000000   0.000000  \n",
       "37   0.000000   0.000000   0.000000   0.000000  \n",
       "38   0.000000   0.000000   0.000000   0.000000  \n",
       "39   0.000000   0.000000   0.000000   0.000000  \n",
       "40   0.000000   0.000000   0.000000   0.000000  \n",
       "41   0.000000   0.000000   0.000000   0.000000  \n",
       "42   0.000000   0.000000   0.000000   0.000000  \n",
       "43   0.000000   0.000000   0.000000   0.000000  \n",
       "44   0.000000   0.000000   0.000000   0.000000  \n",
       "45   0.000000   0.000000   0.000000   0.000000  \n",
       "46   0.000000   0.000000   0.000000   0.000000  \n",
       "47   0.000000   0.000000   0.000000   0.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.loc[submission.id.str.contains(\"Day7\"), \"q_0.1\":] = res_0[['L00.1','L00.2','L00.3','L00.4','L00.5','L00.6','L00.7','L00.8','L00.9']].values\n",
    "submission.loc[submission.id.str.contains(\"Day8\"), \"q_0.1\":] = res_1[['L10.1','L10.2','L10.3','L10.4','L10.5','L10.6','L10.7','L10.8','L10.9']].values\n",
    "submission[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission/submission_20210118-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1.sort_index()[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].sort_index()[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.94+0.480766)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(9.45 + 9.181172)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[:48]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
