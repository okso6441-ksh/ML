{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, is_train=True):\n",
    "    \n",
    "    temp = data.copy()\n",
    "    temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "\n",
    "    if is_train==True:          \n",
    "    \n",
    "        temp['Target1'] = temp['TARGET'].shift(-48).fillna(method='ffill')\n",
    "        temp['Target2'] = temp['TARGET'].shift(-48*2).fillna(method='ffill')\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        return temp.iloc[:-96]\n",
    "\n",
    "    elif is_train==False:\n",
    "        \n",
    "        temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "                              \n",
    "        return temp.iloc[-48:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train/train.csv')\n",
    "\n",
    "test = []\n",
    "\n",
    "for i in range(81):\n",
    "    file_path = './data/test/' + str(i) + '.csv'\n",
    "    temp = pd.read_csv(file_path)\n",
    "    temp = preprocess_data(temp, is_train=False)\n",
    "    test.append(temp)\n",
    "\n",
    "df_test = pd.concat(test)\n",
    "\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52464, 9), (3888, 7))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess_data(train)\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = df_train[['Hour','DHI','DNI','WS','RH','T']].min()\n",
    "max  = df_train[['Hour','DHI','DNI','WS','RH','T']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Hour','DHI','DNI','WS','RH','T']):\n",
    "    df_train[col] = (df_train[col] - min[i]) / (max[i] - min[i])\n",
    "    df_test[col] = (df_test[col] - min[i]) / (max[i] - min[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day  = df_train.iloc[:, :-2]\n",
    "Day7 = df_train.iloc[:, -2]\n",
    "Day8 = df_train.iloc[:, -1]\n",
    "Day78 = df_train.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(q, y, pred):\n",
    "    err = (y-pred)\n",
    "    return mean(maximum(q*err, (q-1)*err), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lst = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39348, 7), (13116, 7), (39348, 2), (13116, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(Day, Day78, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train_1, X_valid_1, Y_train_1, Y_valid_1 = train_test_split(Day, Day7, test_size=0.25, random_state=42)\n",
    "X_train_2, X_valid_2, Y_train_2, Y_valid_2 = train_test_split(Day, Day8, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import mean, maximum\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(Day.shape)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "hist = model.fit(X_train, Y_train, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], 'b-', label='loss')\n",
    "plt.plot(hist.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    model.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model.fit(Day, Day78, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred = pd.DataFrame(model.predict(df_test))\n",
    "    results = pd.concat([results, pred], axis=1)\n",
    "\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.34889\n",
      "Early stopping, best iteration is:\n",
      "[418]\tvalid_0's quantile: 1.34812\n",
      "0.2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.14466\n",
      "[1000]\tvalid_0's quantile: 2.13764\n",
      "[1500]\tvalid_0's quantile: 2.13582\n",
      "[2000]\tvalid_0's quantile: 2.1334\n",
      "Early stopping, best iteration is:\n",
      "[1749]\tvalid_0's quantile: 2.13312\n",
      "0.3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.53565\n",
      "[1000]\tvalid_0's quantile: 2.50726\n",
      "[1500]\tvalid_0's quantile: 2.49215\n",
      "Early stopping, best iteration is:\n",
      "[1604]\tvalid_0's quantile: 2.48959\n",
      "0.4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.66191\n",
      "[1000]\tvalid_0's quantile: 2.62846\n",
      "[1500]\tvalid_0's quantile: 2.61266\n",
      "[2000]\tvalid_0's quantile: 2.6059\n",
      "[2500]\tvalid_0's quantile: 2.59923\n",
      "[3000]\tvalid_0's quantile: 2.59644\n",
      "Early stopping, best iteration is:\n",
      "[2707]\tvalid_0's quantile: 2.59598\n",
      "0.5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.55537\n",
      "[1000]\tvalid_0's quantile: 2.54183\n",
      "[1500]\tvalid_0's quantile: 2.52395\n",
      "[2000]\tvalid_0's quantile: 2.5191\n",
      "[2500]\tvalid_0's quantile: 2.51606\n",
      "[3000]\tvalid_0's quantile: 2.51386\n",
      "[3500]\tvalid_0's quantile: 2.5086\n",
      "[4000]\tvalid_0's quantile: 2.50447\n",
      "[4500]\tvalid_0's quantile: 2.50257\n",
      "[5000]\tvalid_0's quantile: 2.50037\n",
      "[5500]\tvalid_0's quantile: 2.49801\n",
      "[6000]\tvalid_0's quantile: 2.49694\n",
      "[6500]\tvalid_0's quantile: 2.49596\n",
      "Early stopping, best iteration is:\n",
      "[6563]\tvalid_0's quantile: 2.49582\n",
      "0.6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.28838\n",
      "[1000]\tvalid_0's quantile: 2.26798\n",
      "[1500]\tvalid_0's quantile: 2.25775\n",
      "[2000]\tvalid_0's quantile: 2.25273\n",
      "[2500]\tvalid_0's quantile: 2.24936\n",
      "[3000]\tvalid_0's quantile: 2.24642\n",
      "[3500]\tvalid_0's quantile: 2.24451\n",
      "[4000]\tvalid_0's quantile: 2.24427\n",
      "Early stopping, best iteration is:\n",
      "[3735]\tvalid_0's quantile: 2.24391\n",
      "0.7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.87856\n",
      "[1000]\tvalid_0's quantile: 1.86236\n",
      "[1500]\tvalid_0's quantile: 1.85737\n",
      "[2000]\tvalid_0's quantile: 1.85491\n",
      "Early stopping, best iteration is:\n",
      "[1840]\tvalid_0's quantile: 1.85404\n",
      "0.8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.34949\n",
      "[1000]\tvalid_0's quantile: 1.34333\n",
      "Early stopping, best iteration is:\n",
      "[898]\tvalid_0's quantile: 1.34271\n",
      "0.9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 0.748569\n",
      "[1000]\tvalid_0's quantile: 0.746233\n",
      "[1500]\tvalid_0's quantile: 0.74548\n",
      "Early stopping, best iteration is:\n",
      "[1284]\tvalid_0's quantile: 0.745153\n",
      "0.1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.39392\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's quantile: 1.3933\n",
      "0.2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.19349\n",
      "Early stopping, best iteration is:\n",
      "[616]\tvalid_0's quantile: 2.18577\n",
      "0.3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.61892\n",
      "[1000]\tvalid_0's quantile: 2.57944\n",
      "[1500]\tvalid_0's quantile: 2.578\n",
      "Early stopping, best iteration is:\n",
      "[1380]\tvalid_0's quantile: 2.57785\n",
      "0.4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.7433\n",
      "[1000]\tvalid_0's quantile: 2.70695\n",
      "[1500]\tvalid_0's quantile: 2.70092\n",
      "[2000]\tvalid_0's quantile: 2.69464\n",
      "[2500]\tvalid_0's quantile: 2.68927\n",
      "[3000]\tvalid_0's quantile: 2.68204\n",
      "[3500]\tvalid_0's quantile: 2.67218\n",
      "[4000]\tvalid_0's quantile: 2.66515\n",
      "[4500]\tvalid_0's quantile: 2.66079\n",
      "Early stopping, best iteration is:\n",
      "[4475]\tvalid_0's quantile: 2.66079\n",
      "0.5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.6458\n",
      "[1000]\tvalid_0's quantile: 2.62814\n",
      "[1500]\tvalid_0's quantile: 2.61626\n",
      "[2000]\tvalid_0's quantile: 2.60023\n",
      "[2500]\tvalid_0's quantile: 2.58706\n",
      "[3000]\tvalid_0's quantile: 2.58403\n",
      "Early stopping, best iteration is:\n",
      "[2807]\tvalid_0's quantile: 2.58403\n",
      "0.6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.36786\n",
      "[1000]\tvalid_0's quantile: 2.35343\n",
      "[1500]\tvalid_0's quantile: 2.33476\n",
      "[2000]\tvalid_0's quantile: 2.32426\n",
      "[2500]\tvalid_0's quantile: 2.31984\n",
      "[3000]\tvalid_0's quantile: 2.31736\n",
      "Early stopping, best iteration is:\n",
      "[2871]\tvalid_0's quantile: 2.31729\n",
      "0.7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.96038\n",
      "[1000]\tvalid_0's quantile: 1.93778\n",
      "[1500]\tvalid_0's quantile: 1.92682\n",
      "[2000]\tvalid_0's quantile: 1.91583\n",
      "[2500]\tvalid_0's quantile: 1.91245\n",
      "Early stopping, best iteration is:\n",
      "[2560]\tvalid_0's quantile: 1.91213\n",
      "0.8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.40785\n",
      "[1000]\tvalid_0's quantile: 1.39944\n",
      "[1500]\tvalid_0's quantile: 1.39438\n",
      "[2000]\tvalid_0's quantile: 1.39224\n",
      "[2500]\tvalid_0's quantile: 1.39124\n",
      "Early stopping, best iteration is:\n",
      "[2308]\tvalid_0's quantile: 1.39107\n",
      "0.9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 0.780444\n",
      "[1000]\tvalid_0's quantile: 0.777171\n",
      "[1500]\tvalid_0's quantile: 0.775623\n",
      "[2000]\tvalid_0's quantile: 0.775235\n",
      "Early stopping, best iteration is:\n",
      "[1831]\tvalid_0's quantile: 0.774894\n"
     ]
    }
   ],
   "source": [
    "def LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "    \n",
    "    # (a) Modeling  \n",
    "    model = LGBMRegressor(objective='quantile', alpha=q,\n",
    "                         n_estimators=10000, bagging_fraction=0.7, learning_rate=0.027, subsample=0.7)                   \n",
    "                         \n",
    "                         \n",
    "    model.fit(X_train, Y_train, eval_metric = ['quantile'], \n",
    "          eval_set=[(X_valid, Y_valid)], early_stopping_rounds=300, verbose=500)\n",
    "\n",
    "    # (b) Predictions\n",
    "    pred = pd.Series(model.predict(X_test).round(2))\n",
    "    return pred, model\n",
    "\n",
    "def train_data(X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "\n",
    "    LGBM_models=[]\n",
    "    LGBM_actual_pred = pd.DataFrame()\n",
    "\n",
    "    for q in q_lst:\n",
    "        print(q)\n",
    "        pred , model = LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test)\n",
    "        LGBM_models.append(model)\n",
    "        LGBM_actual_pred = pd.concat([LGBM_actual_pred,pred],axis=1)\n",
    "\n",
    "    LGBM_actual_pred.columns=q_lst\n",
    "    \n",
    "    return LGBM_models, LGBM_actual_pred\n",
    "\n",
    "models_1, results_1 = train_data(X_train_1, Y_train_1, X_valid_1, Y_valid_1, df_test)\n",
    "models_2, results_2 = train_data(X_train_2, Y_train_2, X_valid_2, Y_valid_2, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4368 - val_loss: 1.6004\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4206 - val_loss: 1.6005\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4132 - val_loss: 1.5981\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4163 - val_loss: 1.5975\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4244 - val_loss: 1.6029\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4151 - val_loss: 1.6123\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4173 - val_loss: 1.6122\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4324 - val_loss: 1.5967\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4206 - val_loss: 1.6000\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4341 - val_loss: 1.5966\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4033 - val_loss: 1.5973\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4038 - val_loss: 1.6072\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4105 - val_loss: 1.5904\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.3883 - val_loss: 1.5898\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4209 - val_loss: 1.5881\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4143 - val_loss: 1.5925\n",
      "Epoch 17/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4104 - val_loss: 1.5910\n",
      "Epoch 18/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4069 - val_loss: 1.5939\n",
      "Epoch 19/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4059 - val_loss: 1.5850\n",
      "Epoch 20/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4030 - val_loss: 1.5786\n",
      "Epoch 21/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4102 - val_loss: 1.6088\n",
      "Epoch 22/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3798 - val_loss: 1.5810\n",
      "Epoch 23/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.3789 - val_loss: 1.6017\n",
      "Epoch 24/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3977 - val_loss: 1.6079\n",
      "Epoch 25/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3823 - val_loss: 1.5761\n",
      "Epoch 26/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3759 - val_loss: 1.5785\n",
      "Epoch 27/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3888 - val_loss: 1.5909\n",
      "Epoch 28/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3826 - val_loss: 1.6020\n",
      "Epoch 29/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3687 - val_loss: 1.5811\n",
      "Epoch 30/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3788 - val_loss: 1.5878\n",
      "Epoch 00030: early stopping\n",
      "0.2\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.2133 - val_loss: 2.5432\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.1975 - val_loss: 2.5383\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.1942 - val_loss: 2.5360\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.1807 - val_loss: 2.5315\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2050 - val_loss: 2.5503\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2030 - val_loss: 2.5523\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.2059 - val_loss: 2.5235\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2227 - val_loss: 2.5457\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.1947 - val_loss: 2.5228\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.2285 - val_loss: 2.5258\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.1599 - val_loss: 2.5339\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.1561 - val_loss: 2.5272\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.1916 - val_loss: 2.5429\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.1964 - val_loss: 2.5378\n",
      "Epoch 00014: early stopping\n",
      "0.3\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.6074 - val_loss: 2.9811\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5850 - val_loss: 2.9755\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5807 - val_loss: 2.9874\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5574 - val_loss: 2.9894\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5968 - val_loss: 2.9827\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5951 - val_loss: 2.9761\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5974 - val_loss: 2.9751\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.6339 - val_loss: 3.0045\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5711 - val_loss: 2.9723\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6414 - val_loss: 2.9543\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5271 - val_loss: 2.9857\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5438 - val_loss: 2.9922\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5728 - val_loss: 3.0033\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.5867 - val_loss: 3.0106\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5752 - val_loss: 3.0082\n",
      "Epoch 00015: early stopping\n",
      "0.4\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.7001 - val_loss: 3.0683\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6652 - val_loss: 3.0619\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.6639 - val_loss: 3.1154\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6497 - val_loss: 3.1116\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6854 - val_loss: 3.1127\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6881 - val_loss: 3.0699\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.7085 - val_loss: 3.0537\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.7414 - val_loss: 3.0939\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.6672 - val_loss: 3.0660\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7381 - val_loss: 3.0456\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6096 - val_loss: 3.0678\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6260 - val_loss: 3.0573\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6700 - val_loss: 3.0782\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6801 - val_loss: 3.1005\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6630 - val_loss: 3.0694\n",
      "Epoch 00015: early stopping\n",
      "0.5\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.5723 - val_loss: 2.9176\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.5361 - val_loss: 2.9364\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5375 - val_loss: 2.9313\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.5229 - val_loss: 2.9477\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5485 - val_loss: 2.9612\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 2ms/step - loss: 2.5606 - val_loss: 2.9755\n",
      "Epoch 00006: early stopping\n",
      "0.6\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.2860 - val_loss: 2.6775\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2630 - val_loss: 2.6043\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2606 - val_loss: 2.6450\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2519 - val_loss: 2.6638\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2612 - val_loss: 2.6483\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2832 - val_loss: 2.6445\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2899 - val_loss: 2.5838\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3174 - val_loss: 2.6377\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2563 - val_loss: 2.5862\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3112 - val_loss: 2.5848\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2121 - val_loss: 2.6267\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2219 - val_loss: 2.6047\n",
      "Epoch 00012: early stopping\n",
      "0.7\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.8704 - val_loss: 2.1495\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8426 - val_loss: 2.1327\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8492 - val_loss: 2.1553\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8504 - val_loss: 2.2276\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8472 - val_loss: 2.1632\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8635 - val_loss: 2.1307\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8738 - val_loss: 2.1124\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9018 - val_loss: 2.1724\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8480 - val_loss: 2.2089\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8952 - val_loss: 2.1034\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8137 - val_loss: 2.1350\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8307 - val_loss: 2.1661\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8545 - val_loss: 2.1794\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8478 - val_loss: 2.1248\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.8467 - val_loss: 2.1309\n",
      "Epoch 00015: early stopping\n",
      "0.8\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.3619 - val_loss: 1.5563\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3441 - val_loss: 1.5621\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3510 - val_loss: 1.5555\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3465 - val_loss: 1.5979\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3475 - val_loss: 1.6064\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3584 - val_loss: 1.5528\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3641 - val_loss: 1.6164\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3859 - val_loss: 1.5551\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3407 - val_loss: 1.5476\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3744 - val_loss: 1.5355\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3183 - val_loss: 1.5397\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3345 - val_loss: 1.5579\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3444 - val_loss: 1.5980\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3420 - val_loss: 1.5625\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3412 - val_loss: 1.5441\n",
      "Epoch 00015: early stopping\n",
      "0.9\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 0.7635 - val_loss: 0.8814\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7492 - val_loss: 0.8731\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7562 - val_loss: 0.8721\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7516 - val_loss: 0.8986\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7507 - val_loss: 0.9245\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7527 - val_loss: 0.8628\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7622 - val_loss: 0.8733\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7715 - val_loss: 0.8631\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7405 - val_loss: 0.8503\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7671 - val_loss: 0.8469\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7344 - val_loss: 0.8549\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7456 - val_loss: 0.8607\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7548 - val_loss: 0.8662\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7474 - val_loss: 0.8536\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7390 - val_loss: 0.8544\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7 = tf.keras.Sequential([\n",
    "    layers.Conv1D(filters=128, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result7 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model7.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model7.fit(np.array(Day).reshape(52464, 1, 7), np.array(Day7).reshape(52464, 1), epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred7 = np.squeeze(model7.predict(np.array(df_test).reshape(3888, 1, 7)))\n",
    "    pred7 = pd.DataFrame(pred7)\n",
    "    result7 = pd.concat([result7, pred7], axis=1)\n",
    "    \n",
    "result7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4613 - val_loss: 1.6453\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4441 - val_loss: 1.6420\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4337 - val_loss: 1.6405\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4254 - val_loss: 1.6399\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4427 - val_loss: 1.6395\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4349 - val_loss: 1.6458\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4439 - val_loss: 1.6457\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4508 - val_loss: 1.6383\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4504 - val_loss: 1.6413\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4592 - val_loss: 1.6356\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4259 - val_loss: 1.6470\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4368 - val_loss: 1.6369\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4409 - val_loss: 1.6303\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4211 - val_loss: 1.6452\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4471 - val_loss: 1.6329\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4351 - val_loss: 1.6243\n",
      "Epoch 17/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4252 - val_loss: 1.6304\n",
      "Epoch 18/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4371 - val_loss: 1.6290\n",
      "Epoch 19/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4292 - val_loss: 1.6189\n",
      "Epoch 20/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4301 - val_loss: 1.6257\n",
      "Epoch 21/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4253 - val_loss: 1.6139\n",
      "Epoch 22/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4147 - val_loss: 1.6209\n",
      "Epoch 23/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4097 - val_loss: 1.6292\n",
      "Epoch 24/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4129 - val_loss: 1.6095\n",
      "Epoch 25/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4241 - val_loss: 1.6124\n",
      "Epoch 26/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4133 - val_loss: 1.6069\n",
      "Epoch 27/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4204 - val_loss: 1.6247\n",
      "Epoch 28/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4083 - val_loss: 1.6259\n",
      "Epoch 29/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3979 - val_loss: 1.6121\n",
      "Epoch 30/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4227 - val_loss: 1.6175\n",
      "Epoch 31/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4248 - val_loss: 1.6083\n",
      "Epoch 00031: early stopping\n",
      "0.2\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.3598 - val_loss: 2.6480\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3304 - val_loss: 2.6605\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3142 - val_loss: 2.6489\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3042 - val_loss: 2.6316\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3182 - val_loss: 2.6477\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.3187 - val_loss: 2.6303\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3314 - val_loss: 2.6676\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3295 - val_loss: 2.6605\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3289 - val_loss: 2.6511\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3430 - val_loss: 2.6291\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2904 - val_loss: 2.6390\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3084 - val_loss: 2.6344\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3141 - val_loss: 2.6239\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2832 - val_loss: 2.6658\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3115 - val_loss: 2.6468\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2966 - val_loss: 2.6207\n",
      "Epoch 17/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3038 - val_loss: 2.6176\n",
      "Epoch 18/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3123 - val_loss: 2.6124\n",
      "Epoch 19/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2825 - val_loss: 2.6253\n",
      "Epoch 20/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.3025 - val_loss: 2.6389\n",
      "Epoch 21/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2915 - val_loss: 2.6553\n",
      "Epoch 22/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2832 - val_loss: 2.6207\n",
      "Epoch 23/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.2625 - val_loss: 2.6344\n",
      "Epoch 00023: early stopping\n",
      "0.3\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.7729 - val_loss: 3.0795\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7547 - val_loss: 3.1207\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7500 - val_loss: 3.1547\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7330 - val_loss: 3.1098\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7481 - val_loss: 3.2825\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7504 - val_loss: 3.0907\n",
      "Epoch 00006: early stopping\n",
      "0.4\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.8879 - val_loss: 3.2040\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.8808 - val_loss: 3.3055\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.8767 - val_loss: 3.2398\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.8663 - val_loss: 3.2217\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.8775 - val_loss: 3.3019\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.8518 - val_loss: 3.2093\n",
      "Epoch 00006: early stopping\n",
      "0.5\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.7432 - val_loss: 3.0752\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7310 - val_loss: 3.1371\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7303 - val_loss: 3.0733\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7356 - val_loss: 3.2147\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7458 - val_loss: 3.1811\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7120 - val_loss: 3.0697\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7556 - val_loss: 3.1065\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.7491 - val_loss: 3.1017\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.7251 - val_loss: 3.0758\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.7601 - val_loss: 3.0641\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6977 - val_loss: 3.0627\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.7146 - val_loss: 3.1142\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7303 - val_loss: 3.1212\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7108 - val_loss: 3.1447\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.7211 - val_loss: 3.0860\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.6999 - val_loss: 3.1529\n",
      "Epoch 00016: early stopping\n",
      "0.6\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.4109 - val_loss: 2.7284\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.4089 - val_loss: 2.7437\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.4057 - val_loss: 2.7380\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.4119 - val_loss: 2.9114\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.4262 - val_loss: 2.7387\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.3834 - val_loss: 2.7407\n",
      "Epoch 00006: early stopping\n",
      "0.7\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.9815 - val_loss: 2.2413\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9743 - val_loss: 2.2453\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9681 - val_loss: 2.2736\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9729 - val_loss: 2.2352\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.9730 - val_loss: 2.2382\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9505 - val_loss: 2.2592\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9779 - val_loss: 2.2561\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9775 - val_loss: 2.2542\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9452 - val_loss: 2.2215\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.9780 - val_loss: 2.2399\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9292 - val_loss: 2.2167\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9579 - val_loss: 2.2497\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9642 - val_loss: 2.2752\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9683 - val_loss: 2.2430\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9475 - val_loss: 2.2133\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9402 - val_loss: 2.2174\n",
      "Epoch 17/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.9749 - val_loss: 2.3688\n",
      "Epoch 18/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9480 - val_loss: 2.2791\n",
      "Epoch 19/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9576 - val_loss: 2.2272\n",
      "Epoch 20/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9412 - val_loss: 2.2098\n",
      "Epoch 21/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9705 - val_loss: 2.2250\n",
      "Epoch 22/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9526 - val_loss: 2.2349\n",
      "Epoch 23/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9328 - val_loss: 2.2608\n",
      "Epoch 24/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9613 - val_loss: 2.2363\n",
      "Epoch 25/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.9268 - val_loss: 2.2880\n",
      "Epoch 00025: early stopping\n",
      "0.8\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4255 - val_loss: 1.6215\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4256 - val_loss: 1.6583\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4236 - val_loss: 1.6381\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4283 - val_loss: 1.6109\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4255 - val_loss: 1.6069\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4037 - val_loss: 1.6081\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4312 - val_loss: 1.6733\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4345 - val_loss: 1.6204\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4109 - val_loss: 1.6294\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.4282 - val_loss: 1.6294\n",
      "Epoch 00010: early stopping\n",
      "0.9\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 0.8072 - val_loss: 0.8939\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7929 - val_loss: 0.9113\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7943 - val_loss: 0.9291\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7958 - val_loss: 0.8901\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7930 - val_loss: 0.8813\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7835 - val_loss: 0.9041\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.8043 - val_loss: 0.9076\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7989 - val_loss: 0.9292\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7886 - val_loss: 0.9017\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 0.7955 - val_loss: 0.9013\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = tf.keras.Sequential([\n",
    "    layers.Conv1D(filters=128, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result8 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model8.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model8.fit(np.array(Day).reshape(52464, 1, 7), np.array(Day8).reshape(52464, 1), epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred8 = np.squeeze(model8.predict(np.array(df_test).reshape(3888, 1, 7)))\n",
    "    pred8 = pd.DataFrame(pred8)\n",
    "    result8 = pd.concat([result8, pred8], axis=1)\n",
    "    \n",
    "result8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_L0 = pd.DataFrame(results_1.sort_index())\n",
    "res_L0.columns = ['L00.1','L00.2','L00.3','L00.4','L00.5','L00.6','L00.7','L00.8','L00.9']\n",
    "res_L1 = pd.DataFrame(results_1.sort_index())\n",
    "res_L1.columns = ['L10.1','L10.2','L10.3','L10.4','L10.5','L10.6','L10.7','L10.8','L10.9']\n",
    "\n",
    "\"\"\"\n",
    "res_D0 = pd.DataFrame(results[0].sort_index())\n",
    "res_D0.columns = ['D00.1','D00.2','D00.3','D00.4','D00.5','D00.6','D00.7','D00.8','D00.9']\n",
    "res_D1 = pd.DataFrame(results[1].sort_index())\n",
    "res_D1.columns = ['D10.1','D10.2','D10.3','D10.4','D10.5','D10.6','D10.7','D10.8','D10.9']\n",
    "\"\"\"\n",
    "\n",
    "res_C0 = pd.DataFrame(result7.sort_index())\n",
    "res_C0.columns = ['C00.1','C00.2','C00.3','C00.4','C00.5','C00.6','C00.7','C00.8','C00.9']\n",
    "res_C1 = pd.DataFrame(result8.sort_index())\n",
    "res_C1.columns = ['C10.1','C10.2','C10.3','C10.4','C10.5','C10.6','C10.7','C10.8','C10.9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_0 = pd.concat([res_L0, res_C0], axis=1)\n",
    "res_1 = pd.concat([res_L1, res_C1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_0.loc[res_0[res_0['L00.1'] == 0].index, ['C00.1','C00.2','C00.3','C00.4','C00.5','C00.6','C00.7','C00.8','C00.9']] = 0\n",
    "res_1.loc[res_1[res_1['L10.1'] == 0].index, ['C10.1','C10.2','C10.3','C10.4','C10.5','C10.6','C10.7','C10.8','C10.9']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    res_0[\"L00.\"+str(i)] = (res_0[\"L00.\"+str(i)] + res_0[\"D00.\"+str(i)] + res_0[\"C00.\"+str(i)])/3\n",
    "    res_1[\"L10.\"+str(i)] = (res_1[\"L10.\"+str(i)] + res_1[\"D10.\"+str(i)] + res_1[\"C10.\"+str(i)])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>0.391853</td>\n",
       "      <td>1.390559</td>\n",
       "      <td>0.865388</td>\n",
       "      <td>1.200997</td>\n",
       "      <td>2.598433</td>\n",
       "      <td>3.362015</td>\n",
       "      <td>3.922489</td>\n",
       "      <td>5.183811</td>\n",
       "      <td>7.460527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>1.069037</td>\n",
       "      <td>3.232037</td>\n",
       "      <td>3.471438</td>\n",
       "      <td>4.112672</td>\n",
       "      <td>6.875989</td>\n",
       "      <td>8.038964</td>\n",
       "      <td>6.051414</td>\n",
       "      <td>11.198219</td>\n",
       "      <td>18.118141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>3.291354</td>\n",
       "      <td>6.110229</td>\n",
       "      <td>5.833608</td>\n",
       "      <td>6.481433</td>\n",
       "      <td>10.906905</td>\n",
       "      <td>11.786663</td>\n",
       "      <td>9.845729</td>\n",
       "      <td>13.890740</td>\n",
       "      <td>22.172045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>7.032102</td>\n",
       "      <td>13.248648</td>\n",
       "      <td>14.299737</td>\n",
       "      <td>16.824150</td>\n",
       "      <td>23.874655</td>\n",
       "      <td>24.841913</td>\n",
       "      <td>20.142717</td>\n",
       "      <td>26.531397</td>\n",
       "      <td>33.652420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>9.116729</td>\n",
       "      <td>16.883993</td>\n",
       "      <td>15.660697</td>\n",
       "      <td>17.664915</td>\n",
       "      <td>24.723963</td>\n",
       "      <td>24.327513</td>\n",
       "      <td>22.163662</td>\n",
       "      <td>25.527582</td>\n",
       "      <td>31.717117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>13.668143</td>\n",
       "      <td>24.065367</td>\n",
       "      <td>20.583532</td>\n",
       "      <td>22.550396</td>\n",
       "      <td>34.388226</td>\n",
       "      <td>33.444588</td>\n",
       "      <td>32.022144</td>\n",
       "      <td>33.051109</td>\n",
       "      <td>34.920227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>14.366848</td>\n",
       "      <td>25.228937</td>\n",
       "      <td>20.903231</td>\n",
       "      <td>24.408142</td>\n",
       "      <td>35.113747</td>\n",
       "      <td>36.264400</td>\n",
       "      <td>36.544781</td>\n",
       "      <td>36.814663</td>\n",
       "      <td>37.378590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>15.007898</td>\n",
       "      <td>27.723040</td>\n",
       "      <td>28.533401</td>\n",
       "      <td>33.353374</td>\n",
       "      <td>45.023636</td>\n",
       "      <td>39.373306</td>\n",
       "      <td>40.855106</td>\n",
       "      <td>43.226074</td>\n",
       "      <td>48.213322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>14.085758</td>\n",
       "      <td>25.166649</td>\n",
       "      <td>25.860117</td>\n",
       "      <td>30.830658</td>\n",
       "      <td>43.046181</td>\n",
       "      <td>36.584965</td>\n",
       "      <td>37.397205</td>\n",
       "      <td>39.086811</td>\n",
       "      <td>45.639366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>13.900424</td>\n",
       "      <td>25.796186</td>\n",
       "      <td>28.733212</td>\n",
       "      <td>32.189827</td>\n",
       "      <td>43.888485</td>\n",
       "      <td>36.594166</td>\n",
       "      <td>37.738125</td>\n",
       "      <td>37.402012</td>\n",
       "      <td>42.269630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>14.611881</td>\n",
       "      <td>27.689064</td>\n",
       "      <td>29.990103</td>\n",
       "      <td>33.058350</td>\n",
       "      <td>44.518223</td>\n",
       "      <td>37.771049</td>\n",
       "      <td>39.603130</td>\n",
       "      <td>41.066338</td>\n",
       "      <td>42.725872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>13.898856</td>\n",
       "      <td>26.428692</td>\n",
       "      <td>26.832432</td>\n",
       "      <td>31.799921</td>\n",
       "      <td>38.954269</td>\n",
       "      <td>36.287258</td>\n",
       "      <td>36.990299</td>\n",
       "      <td>36.143532</td>\n",
       "      <td>38.496750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>10.908395</td>\n",
       "      <td>22.525305</td>\n",
       "      <td>26.288004</td>\n",
       "      <td>29.361454</td>\n",
       "      <td>37.189552</td>\n",
       "      <td>34.969730</td>\n",
       "      <td>35.716835</td>\n",
       "      <td>36.385918</td>\n",
       "      <td>41.435673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>12.527972</td>\n",
       "      <td>23.323606</td>\n",
       "      <td>22.114260</td>\n",
       "      <td>25.182472</td>\n",
       "      <td>31.908772</td>\n",
       "      <td>33.058678</td>\n",
       "      <td>32.422935</td>\n",
       "      <td>30.525671</td>\n",
       "      <td>31.720663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>12.902238</td>\n",
       "      <td>23.575750</td>\n",
       "      <td>21.952230</td>\n",
       "      <td>25.138441</td>\n",
       "      <td>31.750828</td>\n",
       "      <td>32.573463</td>\n",
       "      <td>32.441181</td>\n",
       "      <td>30.682074</td>\n",
       "      <td>32.094532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>12.216475</td>\n",
       "      <td>21.124254</td>\n",
       "      <td>17.574217</td>\n",
       "      <td>19.373701</td>\n",
       "      <td>25.819300</td>\n",
       "      <td>27.758289</td>\n",
       "      <td>28.872738</td>\n",
       "      <td>26.317612</td>\n",
       "      <td>27.861862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>8.639415</td>\n",
       "      <td>17.455603</td>\n",
       "      <td>16.045116</td>\n",
       "      <td>17.359949</td>\n",
       "      <td>22.016167</td>\n",
       "      <td>25.021576</td>\n",
       "      <td>26.492762</td>\n",
       "      <td>26.199154</td>\n",
       "      <td>24.811480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>5.389178</td>\n",
       "      <td>9.714955</td>\n",
       "      <td>7.752239</td>\n",
       "      <td>7.645441</td>\n",
       "      <td>9.560823</td>\n",
       "      <td>12.334411</td>\n",
       "      <td>17.715446</td>\n",
       "      <td>19.542042</td>\n",
       "      <td>19.056654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>1.053098</td>\n",
       "      <td>4.271366</td>\n",
       "      <td>5.198122</td>\n",
       "      <td>3.606810</td>\n",
       "      <td>4.149300</td>\n",
       "      <td>5.182670</td>\n",
       "      <td>9.219347</td>\n",
       "      <td>12.934913</td>\n",
       "      <td>9.231359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1    0.csv_Day7_0h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2    0.csv_Day7_1h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3    0.csv_Day7_1h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4    0.csv_Day7_2h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5    0.csv_Day7_2h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "6    0.csv_Day7_3h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "7    0.csv_Day7_3h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "8    0.csv_Day7_4h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "9    0.csv_Day7_4h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "10   0.csv_Day7_5h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "11   0.csv_Day7_5h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12   0.csv_Day7_6h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "13   0.csv_Day7_6h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "14   0.csv_Day7_7h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "15   0.csv_Day7_7h30m   0.391853   1.390559   0.865388   1.200997   2.598433   \n",
       "16   0.csv_Day7_8h00m   1.069037   3.232037   3.471438   4.112672   6.875989   \n",
       "17   0.csv_Day7_8h30m   3.291354   6.110229   5.833608   6.481433  10.906905   \n",
       "18   0.csv_Day7_9h00m   7.032102  13.248648  14.299737  16.824150  23.874655   \n",
       "19   0.csv_Day7_9h30m   9.116729  16.883993  15.660697  17.664915  24.723963   \n",
       "20  0.csv_Day7_10h00m  13.668143  24.065367  20.583532  22.550396  34.388226   \n",
       "21  0.csv_Day7_10h30m  14.366848  25.228937  20.903231  24.408142  35.113747   \n",
       "22  0.csv_Day7_11h00m  15.007898  27.723040  28.533401  33.353374  45.023636   \n",
       "23  0.csv_Day7_11h30m  14.085758  25.166649  25.860117  30.830658  43.046181   \n",
       "24  0.csv_Day7_12h00m  13.900424  25.796186  28.733212  32.189827  43.888485   \n",
       "25  0.csv_Day7_12h30m  14.611881  27.689064  29.990103  33.058350  44.518223   \n",
       "26  0.csv_Day7_13h00m  13.898856  26.428692  26.832432  31.799921  38.954269   \n",
       "27  0.csv_Day7_13h30m  10.908395  22.525305  26.288004  29.361454  37.189552   \n",
       "28  0.csv_Day7_14h00m  12.527972  23.323606  22.114260  25.182472  31.908772   \n",
       "29  0.csv_Day7_14h30m  12.902238  23.575750  21.952230  25.138441  31.750828   \n",
       "30  0.csv_Day7_15h00m  12.216475  21.124254  17.574217  19.373701  25.819300   \n",
       "31  0.csv_Day7_15h30m   8.639415  17.455603  16.045116  17.359949  22.016167   \n",
       "32  0.csv_Day7_16h00m   5.389178   9.714955   7.752239   7.645441   9.560823   \n",
       "33  0.csv_Day7_16h30m   1.053098   4.271366   5.198122   3.606810   4.149300   \n",
       "34  0.csv_Day7_17h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "35  0.csv_Day7_17h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "36  0.csv_Day7_18h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "37  0.csv_Day7_18h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "38  0.csv_Day7_19h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "39  0.csv_Day7_19h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "40  0.csv_Day7_20h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "41  0.csv_Day7_20h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "42  0.csv_Day7_21h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "43  0.csv_Day7_21h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "44  0.csv_Day7_22h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "45  0.csv_Day7_22h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "46  0.csv_Day7_23h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "47  0.csv_Day7_23h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.000000   0.000000   0.000000   0.000000  \n",
       "1    0.000000   0.000000   0.000000   0.000000  \n",
       "2    0.000000   0.000000   0.000000   0.000000  \n",
       "3    0.000000   0.000000   0.000000   0.000000  \n",
       "4    0.000000   0.000000   0.000000   0.000000  \n",
       "5    0.000000   0.000000   0.000000   0.000000  \n",
       "6    0.000000   0.000000   0.000000   0.000000  \n",
       "7    0.000000   0.000000   0.000000   0.000000  \n",
       "8    0.000000   0.000000   0.000000   0.000000  \n",
       "9    0.000000   0.000000   0.000000   0.000000  \n",
       "10   0.000000   0.000000   0.000000   0.000000  \n",
       "11   0.000000   0.000000   0.000000   0.000000  \n",
       "12   0.000000   0.000000   0.000000   0.000000  \n",
       "13   0.000000   0.000000   0.000000   0.000000  \n",
       "14   0.000000   0.000000   0.000000   0.000000  \n",
       "15   3.362015   3.922489   5.183811   7.460527  \n",
       "16   8.038964   6.051414  11.198219  18.118141  \n",
       "17  11.786663   9.845729  13.890740  22.172045  \n",
       "18  24.841913  20.142717  26.531397  33.652420  \n",
       "19  24.327513  22.163662  25.527582  31.717117  \n",
       "20  33.444588  32.022144  33.051109  34.920227  \n",
       "21  36.264400  36.544781  36.814663  37.378590  \n",
       "22  39.373306  40.855106  43.226074  48.213322  \n",
       "23  36.584965  37.397205  39.086811  45.639366  \n",
       "24  36.594166  37.738125  37.402012  42.269630  \n",
       "25  37.771049  39.603130  41.066338  42.725872  \n",
       "26  36.287258  36.990299  36.143532  38.496750  \n",
       "27  34.969730  35.716835  36.385918  41.435673  \n",
       "28  33.058678  32.422935  30.525671  31.720663  \n",
       "29  32.573463  32.441181  30.682074  32.094532  \n",
       "30  27.758289  28.872738  26.317612  27.861862  \n",
       "31  25.021576  26.492762  26.199154  24.811480  \n",
       "32  12.334411  17.715446  19.542042  19.056654  \n",
       "33   5.182670   9.219347  12.934913   9.231359  \n",
       "34   0.000000   0.000000   0.000000   0.000000  \n",
       "35   0.000000   0.000000   0.000000   0.000000  \n",
       "36   0.000000   0.000000   0.000000   0.000000  \n",
       "37   0.000000   0.000000   0.000000   0.000000  \n",
       "38   0.000000   0.000000   0.000000   0.000000  \n",
       "39   0.000000   0.000000   0.000000   0.000000  \n",
       "40   0.000000   0.000000   0.000000   0.000000  \n",
       "41   0.000000   0.000000   0.000000   0.000000  \n",
       "42   0.000000   0.000000   0.000000   0.000000  \n",
       "43   0.000000   0.000000   0.000000   0.000000  \n",
       "44   0.000000   0.000000   0.000000   0.000000  \n",
       "45   0.000000   0.000000   0.000000   0.000000  \n",
       "46   0.000000   0.000000   0.000000   0.000000  \n",
       "47   0.000000   0.000000   0.000000   0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.loc[submission.id.str.contains(\"Day7\"), \"q_0.1\":] = res_0[['C00.1','C00.2','C00.3','C00.4','C00.5','C00.6','C00.7','C00.8','C00.9']].values\n",
    "submission.loc[submission.id.str.contains(\"Day8\"), \"q_0.1\":] = res_1[['C10.1','C10.2','C10.3','C10.4','C10.5','C10.6','C10.7','C10.8','C10.9']].values\n",
    "submission[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission/submission_20210120-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
