{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, is_train=True):\n",
    "    \n",
    "    temp = data.copy()\n",
    "    temp = temp[['Day','Hour','Minute', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "\n",
    "    if is_train==True:          \n",
    "    \n",
    "        temp['Target1'] = temp['TARGET'].shift(-48).fillna(method='ffill')\n",
    "        temp['Target2'] = temp['TARGET'].shift(-48*2).fillna(method='ffill')\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        return temp.iloc[:-96]\n",
    "\n",
    "    elif is_train==False:\n",
    "        \n",
    "        temp = temp[['Day','Hour','Minute', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "                              \n",
    "        return temp.iloc[-48:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train/train.csv')\n",
    "\n",
    "test = []\n",
    "\n",
    "for i in range(81):\n",
    "    file_path = './data/test/' + str(i) + '.csv'\n",
    "    temp = pd.read_csv(file_path)\n",
    "    temp['Day'] = i\n",
    "    temp = preprocess_data(temp, is_train=False)\n",
    "    test.append(temp)\n",
    "\n",
    "df_test = pd.concat(test)\n",
    "\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52464, 10), (3888, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess_data(train)\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2349"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3888 - 1539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(df_train[df_train.TARGET == 0].index, inplace=True)\n",
    "df_test = df_test[df_test.TARGET > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1539, 8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.WS = np.log1p(df_train.WS)\n",
    "df_test.WS = np.log1p(df_test.WS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = df_train[['Day','Hour','DHI','DNI','WS','RH','T']].min()\n",
    "max  = df_train[['Day','Hour','DHI','DNI','WS','RH','T']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Day','Hour','DHI','DNI','WS','RH','T']):\n",
    "    df_train[col] = (df_train[col] - min[i]) / (max[i] - min[i])\n",
    "    df_test[col] = (df_test[col] - min[i]) / (max[i] - min[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day0 = df_train.iloc[:, :-2]\n",
    "Day  = df_train.iloc[:, 1:-2]\n",
    "Day7 = df_train.iloc[:, -2]\n",
    "Day8 = df_train.iloc[:, -1]\n",
    "Day78 = df_train.iloc[:, -2:]\n",
    "\n",
    "df_test0 = df_test.copy()\n",
    "df_test = df_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(q, y, pred):\n",
    "    err = (y-pred)\n",
    "    return mean(maximum(q*err, (q-1)*err), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lst = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19398, 7), (6466, 7), (19398, 2), (6466, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(Day, Day78, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train_1, X_valid_1, Y_train_1, Y_valid_1 = train_test_split(Day, Day7, test_size=0.25, random_state=42)\n",
    "X_train_2, X_valid_2, Y_train_2, Y_valid_2 = train_test_split(Day, Day8, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import mean, maximum\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "275/304 [==========================>...] - ETA: 0s - loss: 980.2335 WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "304/304 [==============================] - 1s 3ms/step - loss: 941.2344 - val_loss: 367.3524\n",
      "Epoch 2/100\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 349.7363 - val_loss: 334.3879\n",
      "Epoch 3/100\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 314.5597 - val_loss: 320.5747\n",
      "Epoch 4/100\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 301.6375 - val_loss: 321.5102\n",
      "Epoch 5/100\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 306.0343 - val_loss: 321.7969\n",
      "Epoch 6/100\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 303.3723 - val_loss: 307.7873\n",
      "Epoch 7/100\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 293.2667 - val_loss: 302.8510\n",
      "Epoch 8/100\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 290.2975 - val_loss: 317.6829\n",
      "Epoch 9/100\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 292.9631 - val_loss: 308.8308\n",
      "Epoch 10/100\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 293.2433 - val_loss: 303.7164\n",
      "Epoch 00010: early stopping\n",
      "203/203 [==============================] - 0s 597us/step - loss: 282.6981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "282.6980895996094"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(Day.shape)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "hist = model.fit(X_train, Y_train, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], 'b-', label='loss')\n",
    "plt.plot(hist.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "366/405 [==========================>...] - ETA: 0s - loss: 3.1687WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 3.1493 - val_loss: 3.1345\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 0s 1ms/step - loss: 2.9215 - val_loss: 3.1505\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 0s 1ms/step - loss: 2.8893 - val_loss: 3.1224\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 0s 1ms/step - loss: 2.9227 - val_loss: 3.1040\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 0s 1ms/step - loss: 2.8923 - val_loss: 3.1515\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 0s 1ms/step - loss: 2.8672 - val_loss: 3.1290\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 0s 1ms/step - loss: 2.8983 - val_loss: 3.1051\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "400/405 [============================>.] - ETA: 0s - loss: 4.7187WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 4.7178 - val_loss: 5.0708\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 0s 1ms/step - loss: 4.6516 - val_loss: 5.0458\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 4.5969 - val_loss: 5.0977\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 4.6958 - val_loss: 5.0530\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 4.5972 - val_loss: 5.0590\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "361/405 [=========================>....] - ETA: 0s - loss: 5.5875WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5792 - val_loss: 5.9924\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.4851 - val_loss: 6.0137\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.4483 - val_loss: 6.0226\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.5689 - val_loss: 5.9845\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.4426 - val_loss: 5.9571\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.4448 - val_loss: 5.9696\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.5157 - val_loss: 5.9943\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.4820 - val_loss: 6.0144\n",
      "Epoch 00008: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "390/405 [===========================>..] - ETA: 0s - loss: 5.7952WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.7920 - val_loss: 6.1501\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.6632 - val_loss: 6.1926\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.6729 - val_loss: 6.1476\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.7619 - val_loss: 6.2029\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.6452 - val_loss: 6.1604\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.6546 - val_loss: 6.1739\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "388/405 [===========================>..] - ETA: 0s - loss: 5.5169WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5139 - val_loss: 5.8740\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.3789 - val_loss: 5.8966\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.3967 - val_loss: 5.9175\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.4992 - val_loss: 5.8597\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.3748 - val_loss: 5.8732\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.3766 - val_loss: 5.9986\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 5.4199 - val_loss: 5.9326\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "389/405 [===========================>..] - ETA: 0s - loss: 4.8719WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8697 - val_loss: 5.2390\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 4.7580 - val_loss: 5.2424\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 4.7794 - val_loss: 5.2822\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 4.8548 - val_loss: 5.2730\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "366/405 [==========================>...] - ETA: 0s - loss: 3.9919WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9878 - val_loss: 4.3343\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 3.9034 - val_loss: 4.2838\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 3.9082 - val_loss: 4.3371\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 3.9764 - val_loss: 4.4023\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 3.9061 - val_loss: 4.5171\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "384/405 [===========================>..] - ETA: 0s - loss: 2.894 - ETA: 0s - loss: 2.8923WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8914 - val_loss: 3.1233\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 2.8360 - val_loss: 3.0957\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 2.8382 - val_loss: 3.1812\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 2.9004 - val_loss: 3.2161\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 2.8592 - val_loss: 3.1671\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "387/405 [===========================>..] - ETA: 0s - loss: 1.6176WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.6170 - val_loss: 1.7503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 1.5884 - val_loss: 1.7174\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 1.5848 - val_loss: 1.7823\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 1.6125 - val_loss: 1.7320\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 1.5948 - val_loss: 1.8152\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1539, 18)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    model.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model.fit(Day, Day78, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred = pd.DataFrame(model.predict(df_test))\n",
    "    results = pd.concat([results, pred], axis=1)\n",
    "\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.089914</td>\n",
       "      <td>1.535999</td>\n",
       "      <td>0.251481</td>\n",
       "      <td>2.067167</td>\n",
       "      <td>2.274558</td>\n",
       "      <td>2.980689</td>\n",
       "      <td>5.657227</td>\n",
       "      <td>7.501196</td>\n",
       "      <td>13.620013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.454007</td>\n",
       "      <td>3.661700</td>\n",
       "      <td>3.207733</td>\n",
       "      <td>7.312933</td>\n",
       "      <td>6.125593</td>\n",
       "      <td>7.015919</td>\n",
       "      <td>13.943268</td>\n",
       "      <td>18.824673</td>\n",
       "      <td>28.100439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.152181</td>\n",
       "      <td>5.272353</td>\n",
       "      <td>4.916296</td>\n",
       "      <td>10.437674</td>\n",
       "      <td>9.116087</td>\n",
       "      <td>10.385359</td>\n",
       "      <td>18.414761</td>\n",
       "      <td>23.743040</td>\n",
       "      <td>32.246162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.645403</td>\n",
       "      <td>11.362823</td>\n",
       "      <td>11.982098</td>\n",
       "      <td>22.345695</td>\n",
       "      <td>21.396112</td>\n",
       "      <td>23.175467</td>\n",
       "      <td>32.208233</td>\n",
       "      <td>36.962116</td>\n",
       "      <td>49.590202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.729984</td>\n",
       "      <td>14.176373</td>\n",
       "      <td>14.525365</td>\n",
       "      <td>24.343407</td>\n",
       "      <td>22.575294</td>\n",
       "      <td>25.448076</td>\n",
       "      <td>33.503662</td>\n",
       "      <td>36.404053</td>\n",
       "      <td>47.327972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.925003</td>\n",
       "      <td>21.527153</td>\n",
       "      <td>20.120258</td>\n",
       "      <td>31.171200</td>\n",
       "      <td>29.313362</td>\n",
       "      <td>32.059452</td>\n",
       "      <td>40.228367</td>\n",
       "      <td>39.441025</td>\n",
       "      <td>42.437454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.758869</td>\n",
       "      <td>23.006657</td>\n",
       "      <td>21.763710</td>\n",
       "      <td>32.858318</td>\n",
       "      <td>31.412830</td>\n",
       "      <td>34.656189</td>\n",
       "      <td>40.869354</td>\n",
       "      <td>39.015755</td>\n",
       "      <td>39.964523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.477924</td>\n",
       "      <td>26.686825</td>\n",
       "      <td>24.446363</td>\n",
       "      <td>36.895210</td>\n",
       "      <td>35.948029</td>\n",
       "      <td>38.952061</td>\n",
       "      <td>50.046177</td>\n",
       "      <td>50.770226</td>\n",
       "      <td>59.937820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.677671</td>\n",
       "      <td>24.338600</td>\n",
       "      <td>22.054665</td>\n",
       "      <td>34.716610</td>\n",
       "      <td>33.896721</td>\n",
       "      <td>36.820736</td>\n",
       "      <td>47.722492</td>\n",
       "      <td>48.221161</td>\n",
       "      <td>59.525246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.143011</td>\n",
       "      <td>25.722069</td>\n",
       "      <td>24.011017</td>\n",
       "      <td>36.804966</td>\n",
       "      <td>34.961849</td>\n",
       "      <td>38.097794</td>\n",
       "      <td>45.701633</td>\n",
       "      <td>47.157135</td>\n",
       "      <td>59.947662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.349978</td>\n",
       "      <td>26.656845</td>\n",
       "      <td>25.215502</td>\n",
       "      <td>37.336113</td>\n",
       "      <td>34.994568</td>\n",
       "      <td>38.526760</td>\n",
       "      <td>45.897099</td>\n",
       "      <td>46.569588</td>\n",
       "      <td>55.227093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.351130</td>\n",
       "      <td>23.652269</td>\n",
       "      <td>21.998749</td>\n",
       "      <td>34.265121</td>\n",
       "      <td>32.101601</td>\n",
       "      <td>35.447529</td>\n",
       "      <td>43.461594</td>\n",
       "      <td>43.012669</td>\n",
       "      <td>53.518066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.480780</td>\n",
       "      <td>24.346577</td>\n",
       "      <td>22.024837</td>\n",
       "      <td>33.893494</td>\n",
       "      <td>32.301613</td>\n",
       "      <td>35.719982</td>\n",
       "      <td>43.098785</td>\n",
       "      <td>44.571602</td>\n",
       "      <td>59.441296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.042791</td>\n",
       "      <td>20.210560</td>\n",
       "      <td>17.767374</td>\n",
       "      <td>28.540071</td>\n",
       "      <td>27.497330</td>\n",
       "      <td>30.959517</td>\n",
       "      <td>36.800484</td>\n",
       "      <td>36.437393</td>\n",
       "      <td>45.046467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.698090</td>\n",
       "      <td>20.000715</td>\n",
       "      <td>17.955135</td>\n",
       "      <td>28.473349</td>\n",
       "      <td>27.456823</td>\n",
       "      <td>31.223455</td>\n",
       "      <td>37.644146</td>\n",
       "      <td>36.870018</td>\n",
       "      <td>44.045528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.471292</td>\n",
       "      <td>15.755287</td>\n",
       "      <td>13.809167</td>\n",
       "      <td>22.439745</td>\n",
       "      <td>22.220272</td>\n",
       "      <td>26.391130</td>\n",
       "      <td>30.439184</td>\n",
       "      <td>29.057045</td>\n",
       "      <td>33.145218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.851833</td>\n",
       "      <td>15.990232</td>\n",
       "      <td>13.015645</td>\n",
       "      <td>21.418409</td>\n",
       "      <td>20.147076</td>\n",
       "      <td>23.601444</td>\n",
       "      <td>28.126293</td>\n",
       "      <td>27.430569</td>\n",
       "      <td>33.512337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.846483</td>\n",
       "      <td>8.608600</td>\n",
       "      <td>5.684265</td>\n",
       "      <td>12.796659</td>\n",
       "      <td>9.421673</td>\n",
       "      <td>11.230726</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>15.210463</td>\n",
       "      <td>21.378502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.616631</td>\n",
       "      <td>6.132179</td>\n",
       "      <td>2.303740</td>\n",
       "      <td>7.890198</td>\n",
       "      <td>5.111377</td>\n",
       "      <td>6.585017</td>\n",
       "      <td>9.538690</td>\n",
       "      <td>11.869139</td>\n",
       "      <td>22.719604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.866464</td>\n",
       "      <td>1.829286</td>\n",
       "      <td>1.113161</td>\n",
       "      <td>1.670823</td>\n",
       "      <td>1.913329</td>\n",
       "      <td>1.956258</td>\n",
       "      <td>2.831248</td>\n",
       "      <td>2.761875</td>\n",
       "      <td>3.055362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.013944</td>\n",
       "      <td>5.120073</td>\n",
       "      <td>4.913796</td>\n",
       "      <td>6.703046</td>\n",
       "      <td>6.869369</td>\n",
       "      <td>7.326647</td>\n",
       "      <td>8.296798</td>\n",
       "      <td>8.208632</td>\n",
       "      <td>8.746562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.145498</td>\n",
       "      <td>9.832152</td>\n",
       "      <td>10.329431</td>\n",
       "      <td>14.065063</td>\n",
       "      <td>13.615326</td>\n",
       "      <td>15.084644</td>\n",
       "      <td>16.247154</td>\n",
       "      <td>16.140902</td>\n",
       "      <td>16.513630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.716177</td>\n",
       "      <td>14.788320</td>\n",
       "      <td>14.985394</td>\n",
       "      <td>20.418873</td>\n",
       "      <td>19.450008</td>\n",
       "      <td>21.507978</td>\n",
       "      <td>23.630615</td>\n",
       "      <td>23.313759</td>\n",
       "      <td>24.027779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.321924</td>\n",
       "      <td>20.836136</td>\n",
       "      <td>20.468712</td>\n",
       "      <td>27.460625</td>\n",
       "      <td>26.203033</td>\n",
       "      <td>28.526421</td>\n",
       "      <td>30.870600</td>\n",
       "      <td>30.769531</td>\n",
       "      <td>31.390360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14.460339</td>\n",
       "      <td>25.093189</td>\n",
       "      <td>26.195000</td>\n",
       "      <td>33.643547</td>\n",
       "      <td>32.458740</td>\n",
       "      <td>35.357384</td>\n",
       "      <td>37.735203</td>\n",
       "      <td>37.658012</td>\n",
       "      <td>38.052437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.315401</td>\n",
       "      <td>28.942661</td>\n",
       "      <td>30.713709</td>\n",
       "      <td>39.141647</td>\n",
       "      <td>37.467491</td>\n",
       "      <td>40.470501</td>\n",
       "      <td>43.052464</td>\n",
       "      <td>42.864265</td>\n",
       "      <td>43.189346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17.144218</td>\n",
       "      <td>31.280920</td>\n",
       "      <td>33.499172</td>\n",
       "      <td>42.894604</td>\n",
       "      <td>41.664841</td>\n",
       "      <td>44.697033</td>\n",
       "      <td>47.475311</td>\n",
       "      <td>47.171860</td>\n",
       "      <td>47.488766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.011995</td>\n",
       "      <td>33.112930</td>\n",
       "      <td>35.432873</td>\n",
       "      <td>45.340805</td>\n",
       "      <td>43.968613</td>\n",
       "      <td>47.101658</td>\n",
       "      <td>50.044937</td>\n",
       "      <td>49.727253</td>\n",
       "      <td>49.900177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17.827007</td>\n",
       "      <td>33.140533</td>\n",
       "      <td>35.100704</td>\n",
       "      <td>45.235233</td>\n",
       "      <td>44.120487</td>\n",
       "      <td>48.118053</td>\n",
       "      <td>50.502155</td>\n",
       "      <td>50.924591</td>\n",
       "      <td>51.029945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.671438</td>\n",
       "      <td>32.776085</td>\n",
       "      <td>34.758705</td>\n",
       "      <td>44.741650</td>\n",
       "      <td>43.585106</td>\n",
       "      <td>47.612328</td>\n",
       "      <td>49.968796</td>\n",
       "      <td>50.302055</td>\n",
       "      <td>50.441017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16.460413</td>\n",
       "      <td>30.494377</td>\n",
       "      <td>32.054413</td>\n",
       "      <td>41.680981</td>\n",
       "      <td>40.920441</td>\n",
       "      <td>45.188786</td>\n",
       "      <td>47.405720</td>\n",
       "      <td>48.073883</td>\n",
       "      <td>48.450737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15.189924</td>\n",
       "      <td>28.075066</td>\n",
       "      <td>29.689884</td>\n",
       "      <td>38.337173</td>\n",
       "      <td>37.794254</td>\n",
       "      <td>41.868240</td>\n",
       "      <td>44.008949</td>\n",
       "      <td>44.561951</td>\n",
       "      <td>45.068085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.523960</td>\n",
       "      <td>23.836605</td>\n",
       "      <td>25.750660</td>\n",
       "      <td>32.762756</td>\n",
       "      <td>33.002579</td>\n",
       "      <td>36.842674</td>\n",
       "      <td>38.829479</td>\n",
       "      <td>39.343071</td>\n",
       "      <td>40.105373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10.059118</td>\n",
       "      <td>19.460970</td>\n",
       "      <td>22.516634</td>\n",
       "      <td>28.033865</td>\n",
       "      <td>27.659435</td>\n",
       "      <td>31.117174</td>\n",
       "      <td>32.914089</td>\n",
       "      <td>33.375576</td>\n",
       "      <td>34.156319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6.513051</td>\n",
       "      <td>14.422357</td>\n",
       "      <td>16.522879</td>\n",
       "      <td>22.373310</td>\n",
       "      <td>21.034821</td>\n",
       "      <td>23.780441</td>\n",
       "      <td>25.781328</td>\n",
       "      <td>26.345791</td>\n",
       "      <td>26.619772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.290338</td>\n",
       "      <td>9.925731</td>\n",
       "      <td>11.347129</td>\n",
       "      <td>15.129990</td>\n",
       "      <td>14.436334</td>\n",
       "      <td>16.209265</td>\n",
       "      <td>17.712864</td>\n",
       "      <td>18.191017</td>\n",
       "      <td>18.934624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.914204</td>\n",
       "      <td>6.523449</td>\n",
       "      <td>6.553935</td>\n",
       "      <td>9.726248</td>\n",
       "      <td>8.768323</td>\n",
       "      <td>9.499750</td>\n",
       "      <td>10.433439</td>\n",
       "      <td>10.988625</td>\n",
       "      <td>11.371990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.145520</td>\n",
       "      <td>2.406549</td>\n",
       "      <td>1.896997</td>\n",
       "      <td>2.833803</td>\n",
       "      <td>2.768279</td>\n",
       "      <td>2.862057</td>\n",
       "      <td>3.294897</td>\n",
       "      <td>3.329126</td>\n",
       "      <td>3.674695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.289500</td>\n",
       "      <td>2.497710</td>\n",
       "      <td>1.633605</td>\n",
       "      <td>1.604467</td>\n",
       "      <td>1.617813</td>\n",
       "      <td>1.921162</td>\n",
       "      <td>3.440132</td>\n",
       "      <td>3.118629</td>\n",
       "      <td>3.393059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.512574</td>\n",
       "      <td>4.864541</td>\n",
       "      <td>4.844035</td>\n",
       "      <td>6.814064</td>\n",
       "      <td>6.727995</td>\n",
       "      <td>7.178438</td>\n",
       "      <td>8.741557</td>\n",
       "      <td>8.831665</td>\n",
       "      <td>9.257715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.288871</td>\n",
       "      <td>10.405574</td>\n",
       "      <td>11.137383</td>\n",
       "      <td>15.526767</td>\n",
       "      <td>14.807780</td>\n",
       "      <td>15.889107</td>\n",
       "      <td>17.899857</td>\n",
       "      <td>17.860970</td>\n",
       "      <td>18.350775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.950894</td>\n",
       "      <td>14.163112</td>\n",
       "      <td>15.243681</td>\n",
       "      <td>21.095215</td>\n",
       "      <td>20.096769</td>\n",
       "      <td>22.687944</td>\n",
       "      <td>25.066170</td>\n",
       "      <td>24.813671</td>\n",
       "      <td>25.555208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>12.124215</td>\n",
       "      <td>19.905428</td>\n",
       "      <td>20.627243</td>\n",
       "      <td>28.033966</td>\n",
       "      <td>27.111992</td>\n",
       "      <td>30.006907</td>\n",
       "      <td>32.770481</td>\n",
       "      <td>32.487820</td>\n",
       "      <td>33.554462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>14.166721</td>\n",
       "      <td>24.574501</td>\n",
       "      <td>25.421070</td>\n",
       "      <td>33.382267</td>\n",
       "      <td>32.665657</td>\n",
       "      <td>36.132523</td>\n",
       "      <td>39.231457</td>\n",
       "      <td>38.892418</td>\n",
       "      <td>40.130020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>14.067751</td>\n",
       "      <td>24.885170</td>\n",
       "      <td>27.607849</td>\n",
       "      <td>36.124130</td>\n",
       "      <td>35.570843</td>\n",
       "      <td>39.418720</td>\n",
       "      <td>42.939709</td>\n",
       "      <td>43.168102</td>\n",
       "      <td>44.263138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>13.036249</td>\n",
       "      <td>23.734848</td>\n",
       "      <td>27.384605</td>\n",
       "      <td>38.155712</td>\n",
       "      <td>37.981838</td>\n",
       "      <td>42.523365</td>\n",
       "      <td>46.646046</td>\n",
       "      <td>47.509705</td>\n",
       "      <td>48.385422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>16.994919</td>\n",
       "      <td>31.103714</td>\n",
       "      <td>33.524715</td>\n",
       "      <td>43.779659</td>\n",
       "      <td>42.432640</td>\n",
       "      <td>46.042759</td>\n",
       "      <td>49.895267</td>\n",
       "      <td>49.543472</td>\n",
       "      <td>50.904404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17.576097</td>\n",
       "      <td>32.584976</td>\n",
       "      <td>34.379391</td>\n",
       "      <td>45.326988</td>\n",
       "      <td>44.136169</td>\n",
       "      <td>48.146603</td>\n",
       "      <td>51.324905</td>\n",
       "      <td>51.711529</td>\n",
       "      <td>52.831200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1          1          1          1          1          1  \\\n",
       "0    1.089914   1.535999   0.251481   2.067167   2.274558   2.980689   \n",
       "1    2.454007   3.661700   3.207733   7.312933   6.125593   7.015919   \n",
       "2    4.152181   5.272353   4.916296  10.437674   9.116087  10.385359   \n",
       "3    7.645403  11.362823  11.982098  22.345695  21.396112  23.175467   \n",
       "4    9.729984  14.176373  14.525365  24.343407  22.575294  25.448076   \n",
       "5   13.925003  21.527153  20.120258  31.171200  29.313362  32.059452   \n",
       "6   13.758869  23.006657  21.763710  32.858318  31.412830  34.656189   \n",
       "7   16.477924  26.686825  24.446363  36.895210  35.948029  38.952061   \n",
       "8   15.677671  24.338600  22.054665  34.716610  33.896721  36.820736   \n",
       "9   15.143011  25.722069  24.011017  36.804966  34.961849  38.097794   \n",
       "10  14.349978  26.656845  25.215502  37.336113  34.994568  38.526760   \n",
       "11  13.351130  23.652269  21.998749  34.265121  32.101601  35.447529   \n",
       "12  14.480780  24.346577  22.024837  33.893494  32.301613  35.719982   \n",
       "13  12.042791  20.210560  17.767374  28.540071  27.497330  30.959517   \n",
       "14  11.698090  20.000715  17.955135  28.473349  27.456823  31.223455   \n",
       "15   9.471292  15.755287  13.809167  22.439745  22.220272  26.391130   \n",
       "16   8.851833  15.990232  13.015645  21.418409  20.147076  23.601444   \n",
       "17   4.846483   8.608600   5.684265  12.796659   9.421673  11.230726   \n",
       "18   3.616631   6.132179   2.303740   7.890198   5.111377   6.585017   \n",
       "19   0.866464   1.829286   1.113161   1.670823   1.913329   1.956258   \n",
       "20   3.013944   5.120073   4.913796   6.703046   6.869369   7.326647   \n",
       "21   5.145498   9.832152  10.329431  14.065063  13.615326  15.084644   \n",
       "22   8.716177  14.788320  14.985394  20.418873  19.450008  21.507978   \n",
       "23  12.321924  20.836136  20.468712  27.460625  26.203033  28.526421   \n",
       "24  14.460339  25.093189  26.195000  33.643547  32.458740  35.357384   \n",
       "25  16.315401  28.942661  30.713709  39.141647  37.467491  40.470501   \n",
       "26  17.144218  31.280920  33.499172  42.894604  41.664841  44.697033   \n",
       "27  18.011995  33.112930  35.432873  45.340805  43.968613  47.101658   \n",
       "28  17.827007  33.140533  35.100704  45.235233  44.120487  48.118053   \n",
       "29  17.671438  32.776085  34.758705  44.741650  43.585106  47.612328   \n",
       "30  16.460413  30.494377  32.054413  41.680981  40.920441  45.188786   \n",
       "31  15.189924  28.075066  29.689884  38.337173  37.794254  41.868240   \n",
       "32  12.523960  23.836605  25.750660  32.762756  33.002579  36.842674   \n",
       "33  10.059118  19.460970  22.516634  28.033865  27.659435  31.117174   \n",
       "34   6.513051  14.422357  16.522879  22.373310  21.034821  23.780441   \n",
       "35   4.290338   9.925731  11.347129  15.129990  14.436334  16.209265   \n",
       "36   2.914204   6.523449   6.553935   9.726248   8.768323   9.499750   \n",
       "37   1.145520   2.406549   1.896997   2.833803   2.768279   2.862057   \n",
       "38   1.289500   2.497710   1.633605   1.604467   1.617813   1.921162   \n",
       "39   2.512574   4.864541   4.844035   6.814064   6.727995   7.178438   \n",
       "40   5.288871  10.405574  11.137383  15.526767  14.807780  15.889107   \n",
       "41   7.950894  14.163112  15.243681  21.095215  20.096769  22.687944   \n",
       "42  12.124215  19.905428  20.627243  28.033966  27.111992  30.006907   \n",
       "43  14.166721  24.574501  25.421070  33.382267  32.665657  36.132523   \n",
       "44  14.067751  24.885170  27.607849  36.124130  35.570843  39.418720   \n",
       "45  13.036249  23.734848  27.384605  38.155712  37.981838  42.523365   \n",
       "46  16.994919  31.103714  33.524715  43.779659  42.432640  46.042759   \n",
       "47  17.576097  32.584976  34.379391  45.326988  44.136169  48.146603   \n",
       "\n",
       "            1          1          1  \n",
       "0    5.657227   7.501196  13.620013  \n",
       "1   13.943268  18.824673  28.100439  \n",
       "2   18.414761  23.743040  32.246162  \n",
       "3   32.208233  36.962116  49.590202  \n",
       "4   33.503662  36.404053  47.327972  \n",
       "5   40.228367  39.441025  42.437454  \n",
       "6   40.869354  39.015755  39.964523  \n",
       "7   50.046177  50.770226  59.937820  \n",
       "8   47.722492  48.221161  59.525246  \n",
       "9   45.701633  47.157135  59.947662  \n",
       "10  45.897099  46.569588  55.227093  \n",
       "11  43.461594  43.012669  53.518066  \n",
       "12  43.098785  44.571602  59.441296  \n",
       "13  36.800484  36.437393  45.046467  \n",
       "14  37.644146  36.870018  44.045528  \n",
       "15  30.439184  29.057045  33.145218  \n",
       "16  28.126293  27.430569  33.512337  \n",
       "17  14.970000  15.210463  21.378502  \n",
       "18   9.538690  11.869139  22.719604  \n",
       "19   2.831248   2.761875   3.055362  \n",
       "20   8.296798   8.208632   8.746562  \n",
       "21  16.247154  16.140902  16.513630  \n",
       "22  23.630615  23.313759  24.027779  \n",
       "23  30.870600  30.769531  31.390360  \n",
       "24  37.735203  37.658012  38.052437  \n",
       "25  43.052464  42.864265  43.189346  \n",
       "26  47.475311  47.171860  47.488766  \n",
       "27  50.044937  49.727253  49.900177  \n",
       "28  50.502155  50.924591  51.029945  \n",
       "29  49.968796  50.302055  50.441017  \n",
       "30  47.405720  48.073883  48.450737  \n",
       "31  44.008949  44.561951  45.068085  \n",
       "32  38.829479  39.343071  40.105373  \n",
       "33  32.914089  33.375576  34.156319  \n",
       "34  25.781328  26.345791  26.619772  \n",
       "35  17.712864  18.191017  18.934624  \n",
       "36  10.433439  10.988625  11.371990  \n",
       "37   3.294897   3.329126   3.674695  \n",
       "38   3.440132   3.118629   3.393059  \n",
       "39   8.741557   8.831665   9.257715  \n",
       "40  17.899857  17.860970  18.350775  \n",
       "41  25.066170  24.813671  25.555208  \n",
       "42  32.770481  32.487820  33.554462  \n",
       "43  39.231457  38.892418  40.130020  \n",
       "44  42.939709  43.168102  44.263138  \n",
       "45  46.646046  47.509705  48.385422  \n",
       "46  49.895267  49.543472  50.904404  \n",
       "47  51.324905  51.711529  52.831200  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1][:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.74843\n",
      "Early stopping, best iteration is:\n",
      "[395]\tvalid_0's quantile: 2.74315\n",
      "0.2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 4.32907\n",
      "[1000]\tvalid_0's quantile: 4.29785\n",
      "[1500]\tvalid_0's quantile: 4.29175\n",
      "[2000]\tvalid_0's quantile: 4.28777\n",
      "[2500]\tvalid_0's quantile: 4.28681\n",
      "Early stopping, best iteration is:\n",
      "[2390]\tvalid_0's quantile: 4.28618\n",
      "0.3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 5.11035\n",
      "[1000]\tvalid_0's quantile: 5.06385\n",
      "[1500]\tvalid_0's quantile: 5.03819\n",
      "[2000]\tvalid_0's quantile: 5.03241\n",
      "[2500]\tvalid_0's quantile: 5.02522\n",
      "[3000]\tvalid_0's quantile: 5.01099\n",
      "[3500]\tvalid_0's quantile: 5.00274\n",
      "[4000]\tvalid_0's quantile: 4.99971\n",
      "Early stopping, best iteration is:\n",
      "[3854]\tvalid_0's quantile: 4.99804\n",
      "0.4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 5.3245\n",
      "[1000]\tvalid_0's quantile: 5.26484\n",
      "[1500]\tvalid_0's quantile: 5.24914\n",
      "Early stopping, best iteration is:\n",
      "[1306]\tvalid_0's quantile: 5.24898\n",
      "0.5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 5.13262\n",
      "[1000]\tvalid_0's quantile: 5.08428\n",
      "[1500]\tvalid_0's quantile: 5.05645\n",
      "[2000]\tvalid_0's quantile: 5.0312\n",
      "[2500]\tvalid_0's quantile: 5.01739\n",
      "[3000]\tvalid_0's quantile: 5.00404\n",
      "[3500]\tvalid_0's quantile: 5.00268\n",
      "[4000]\tvalid_0's quantile: 4.99157\n",
      "[4500]\tvalid_0's quantile: 4.98795\n",
      "Early stopping, best iteration is:\n",
      "[4454]\tvalid_0's quantile: 4.98702\n",
      "0.6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 4.57603\n",
      "[1000]\tvalid_0's quantile: 4.54671\n",
      "[1500]\tvalid_0's quantile: 4.52543\n",
      "[2000]\tvalid_0's quantile: 4.50554\n",
      "[2500]\tvalid_0's quantile: 4.49328\n",
      "[3000]\tvalid_0's quantile: 4.48868\n",
      "[3500]\tvalid_0's quantile: 4.48603\n",
      "[4000]\tvalid_0's quantile: 4.48525\n",
      "Early stopping, best iteration is:\n",
      "[3891]\tvalid_0's quantile: 4.48402\n",
      "0.7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 3.7572\n",
      "[1000]\tvalid_0's quantile: 3.7354\n",
      "Early stopping, best iteration is:\n",
      "[1115]\tvalid_0's quantile: 3.73212\n",
      "0.8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.74663\n",
      "[1000]\tvalid_0's quantile: 2.73601\n",
      "Early stopping, best iteration is:\n",
      "[829]\tvalid_0's quantile: 2.73543\n",
      "0.9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.52823\n",
      "[1000]\tvalid_0's quantile: 1.51959\n",
      "[1500]\tvalid_0's quantile: 1.51721\n",
      "Early stopping, best iteration is:\n",
      "[1642]\tvalid_0's quantile: 1.51688\n",
      "0.1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.77726\n",
      "Early stopping, best iteration is:\n",
      "[553]\tvalid_0's quantile: 2.77577\n",
      "0.2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 4.40716\n",
      "[1000]\tvalid_0's quantile: 4.39553\n",
      "Early stopping, best iteration is:\n",
      "[701]\tvalid_0's quantile: 4.38298\n",
      "0.3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 5.23083\n",
      "[1000]\tvalid_0's quantile: 5.19952\n",
      "[1500]\tvalid_0's quantile: 5.16744\n",
      "[2000]\tvalid_0's quantile: 5.14481\n",
      "[2500]\tvalid_0's quantile: 5.13892\n",
      "Early stopping, best iteration is:\n",
      "[2217]\tvalid_0's quantile: 5.13832\n",
      "0.4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 5.51157\n",
      "[1000]\tvalid_0's quantile: 5.44259\n",
      "[1500]\tvalid_0's quantile: 5.42143\n",
      "[2000]\tvalid_0's quantile: 5.40827\n",
      "Early stopping, best iteration is:\n",
      "[1931]\tvalid_0's quantile: 5.40686\n",
      "0.5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 5.34707\n",
      "[1000]\tvalid_0's quantile: 5.28537\n",
      "[1500]\tvalid_0's quantile: 5.25378\n",
      "[2000]\tvalid_0's quantile: 5.22554\n",
      "[2500]\tvalid_0's quantile: 5.21719\n",
      "[3000]\tvalid_0's quantile: 5.21101\n",
      "[3500]\tvalid_0's quantile: 5.20809\n",
      "[4000]\tvalid_0's quantile: 5.20079\n",
      "[4500]\tvalid_0's quantile: 5.19397\n",
      "[5000]\tvalid_0's quantile: 5.19233\n",
      "Early stopping, best iteration is:\n",
      "[5022]\tvalid_0's quantile: 5.1918\n",
      "0.6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 4.79358\n",
      "[1000]\tvalid_0's quantile: 4.75405\n",
      "[1500]\tvalid_0's quantile: 4.73753\n",
      "[2000]\tvalid_0's quantile: 4.72107\n",
      "[2500]\tvalid_0's quantile: 4.70367\n",
      "[3000]\tvalid_0's quantile: 4.69487\n",
      "[3500]\tvalid_0's quantile: 4.68797\n",
      "[4000]\tvalid_0's quantile: 4.68205\n",
      "Early stopping, best iteration is:\n",
      "[3865]\tvalid_0's quantile: 4.67971\n",
      "0.7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 3.93506\n",
      "[1000]\tvalid_0's quantile: 3.90742\n",
      "[1500]\tvalid_0's quantile: 3.89947\n",
      "[2000]\tvalid_0's quantile: 3.88676\n",
      "Early stopping, best iteration is:\n",
      "[2136]\tvalid_0's quantile: 3.8825\n",
      "0.8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.83096\n",
      "[1000]\tvalid_0's quantile: 2.8193\n",
      "[1500]\tvalid_0's quantile: 2.81749\n",
      "Early stopping, best iteration is:\n",
      "[1314]\tvalid_0's quantile: 2.81601\n",
      "0.9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.55916\n",
      "[1000]\tvalid_0's quantile: 1.55243\n",
      "Early stopping, best iteration is:\n",
      "[1142]\tvalid_0's quantile: 1.55219\n"
     ]
    }
   ],
   "source": [
    "def LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "    \n",
    "    # (a) Modeling  \n",
    "    model = LGBMRegressor(objective='quantile', alpha=q,\n",
    "                         n_estimators=10000, bagging_fraction=0.7, learning_rate=0.027, subsample=0.7)                   \n",
    "                         \n",
    "                         \n",
    "    model.fit(X_train, Y_train, eval_metric = ['quantile'], \n",
    "          eval_set=[(X_valid, Y_valid)], early_stopping_rounds=300, verbose=500)\n",
    "\n",
    "    # (b) Predictions\n",
    "    pred = pd.Series(model.predict(X_test).round(2))\n",
    "    return pred, model\n",
    "\n",
    "def train_data(X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "\n",
    "    LGBM_models=[]\n",
    "    LGBM_actual_pred = pd.DataFrame()\n",
    "\n",
    "    for q in q_lst:\n",
    "        print(q)\n",
    "        pred , model = LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test)\n",
    "        LGBM_models.append(model)\n",
    "        LGBM_actual_pred = pd.concat([LGBM_actual_pred,pred],axis=1)\n",
    "\n",
    "    LGBM_actual_pred.columns=q_lst\n",
    "    \n",
    "    return LGBM_models, LGBM_actual_pred\n",
    "\n",
    "models_1, results_1 = train_data(X_train_1, Y_train_1, X_valid_1, Y_valid_1, df_test)\n",
    "models_2, results_2 = train_data(X_train_2, Y_train_2, X_valid_2, Y_valid_2, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.21</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.69</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.82</td>\n",
       "      <td>7.76</td>\n",
       "      <td>13.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.02</td>\n",
       "      <td>5.08</td>\n",
       "      <td>3.72</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.37</td>\n",
       "      <td>11.08</td>\n",
       "      <td>13.85</td>\n",
       "      <td>16.70</td>\n",
       "      <td>24.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.95</td>\n",
       "      <td>7.68</td>\n",
       "      <td>6.93</td>\n",
       "      <td>9.15</td>\n",
       "      <td>11.44</td>\n",
       "      <td>13.54</td>\n",
       "      <td>17.00</td>\n",
       "      <td>22.30</td>\n",
       "      <td>30.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.75</td>\n",
       "      <td>18.21</td>\n",
       "      <td>14.21</td>\n",
       "      <td>12.27</td>\n",
       "      <td>13.04</td>\n",
       "      <td>14.29</td>\n",
       "      <td>24.18</td>\n",
       "      <td>23.67</td>\n",
       "      <td>32.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.46</td>\n",
       "      <td>19.97</td>\n",
       "      <td>19.76</td>\n",
       "      <td>14.46</td>\n",
       "      <td>14.23</td>\n",
       "      <td>17.93</td>\n",
       "      <td>24.89</td>\n",
       "      <td>24.49</td>\n",
       "      <td>33.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.49</td>\n",
       "      <td>33.17</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.79</td>\n",
       "      <td>31.74</td>\n",
       "      <td>29.02</td>\n",
       "      <td>32.47</td>\n",
       "      <td>31.01</td>\n",
       "      <td>35.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.84</td>\n",
       "      <td>30.46</td>\n",
       "      <td>33.34</td>\n",
       "      <td>34.52</td>\n",
       "      <td>33.37</td>\n",
       "      <td>31.68</td>\n",
       "      <td>34.05</td>\n",
       "      <td>34.45</td>\n",
       "      <td>33.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.18</td>\n",
       "      <td>34.47</td>\n",
       "      <td>41.16</td>\n",
       "      <td>42.26</td>\n",
       "      <td>45.32</td>\n",
       "      <td>32.25</td>\n",
       "      <td>36.77</td>\n",
       "      <td>36.94</td>\n",
       "      <td>41.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.98</td>\n",
       "      <td>28.02</td>\n",
       "      <td>33.01</td>\n",
       "      <td>36.39</td>\n",
       "      <td>38.08</td>\n",
       "      <td>30.77</td>\n",
       "      <td>31.88</td>\n",
       "      <td>33.00</td>\n",
       "      <td>40.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.81</td>\n",
       "      <td>28.88</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.41</td>\n",
       "      <td>35.41</td>\n",
       "      <td>29.31</td>\n",
       "      <td>32.04</td>\n",
       "      <td>30.31</td>\n",
       "      <td>34.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.53</td>\n",
       "      <td>33.20</td>\n",
       "      <td>35.54</td>\n",
       "      <td>35.72</td>\n",
       "      <td>38.17</td>\n",
       "      <td>29.63</td>\n",
       "      <td>35.03</td>\n",
       "      <td>35.92</td>\n",
       "      <td>38.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.55</td>\n",
       "      <td>22.72</td>\n",
       "      <td>30.72</td>\n",
       "      <td>34.70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>29.95</td>\n",
       "      <td>31.44</td>\n",
       "      <td>30.88</td>\n",
       "      <td>35.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.80</td>\n",
       "      <td>21.14</td>\n",
       "      <td>26.15</td>\n",
       "      <td>23.59</td>\n",
       "      <td>20.41</td>\n",
       "      <td>23.02</td>\n",
       "      <td>29.91</td>\n",
       "      <td>39.10</td>\n",
       "      <td>42.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.49</td>\n",
       "      <td>19.90</td>\n",
       "      <td>25.77</td>\n",
       "      <td>25.05</td>\n",
       "      <td>22.90</td>\n",
       "      <td>23.45</td>\n",
       "      <td>24.93</td>\n",
       "      <td>24.84</td>\n",
       "      <td>30.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.55</td>\n",
       "      <td>20.48</td>\n",
       "      <td>25.08</td>\n",
       "      <td>27.33</td>\n",
       "      <td>25.55</td>\n",
       "      <td>21.13</td>\n",
       "      <td>24.69</td>\n",
       "      <td>25.98</td>\n",
       "      <td>31.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.74</td>\n",
       "      <td>19.55</td>\n",
       "      <td>21.24</td>\n",
       "      <td>21.84</td>\n",
       "      <td>24.01</td>\n",
       "      <td>22.53</td>\n",
       "      <td>22.90</td>\n",
       "      <td>23.22</td>\n",
       "      <td>30.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.43</td>\n",
       "      <td>15.27</td>\n",
       "      <td>14.78</td>\n",
       "      <td>15.09</td>\n",
       "      <td>15.30</td>\n",
       "      <td>14.56</td>\n",
       "      <td>16.53</td>\n",
       "      <td>16.20</td>\n",
       "      <td>16.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.01</td>\n",
       "      <td>9.46</td>\n",
       "      <td>9.11</td>\n",
       "      <td>6.71</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.98</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.74</td>\n",
       "      <td>14.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.94</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.97</td>\n",
       "      <td>6.43</td>\n",
       "      <td>10.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.61</td>\n",
       "      <td>3.59</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.33</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.56</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.16</td>\n",
       "      <td>8.99</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.06</td>\n",
       "      <td>12.68</td>\n",
       "      <td>13.53</td>\n",
       "      <td>15.22</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.85</td>\n",
       "      <td>19.44</td>\n",
       "      <td>22.57</td>\n",
       "      <td>22.26</td>\n",
       "      <td>20.77</td>\n",
       "      <td>22.25</td>\n",
       "      <td>23.12</td>\n",
       "      <td>23.11</td>\n",
       "      <td>23.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.35</td>\n",
       "      <td>22.78</td>\n",
       "      <td>23.24</td>\n",
       "      <td>22.13</td>\n",
       "      <td>27.21</td>\n",
       "      <td>28.29</td>\n",
       "      <td>28.58</td>\n",
       "      <td>29.19</td>\n",
       "      <td>30.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23.16</td>\n",
       "      <td>25.54</td>\n",
       "      <td>27.38</td>\n",
       "      <td>30.68</td>\n",
       "      <td>32.23</td>\n",
       "      <td>33.56</td>\n",
       "      <td>35.70</td>\n",
       "      <td>35.72</td>\n",
       "      <td>36.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24.20</td>\n",
       "      <td>26.76</td>\n",
       "      <td>34.43</td>\n",
       "      <td>34.61</td>\n",
       "      <td>34.10</td>\n",
       "      <td>37.38</td>\n",
       "      <td>39.56</td>\n",
       "      <td>40.91</td>\n",
       "      <td>40.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>34.63</td>\n",
       "      <td>44.78</td>\n",
       "      <td>39.29</td>\n",
       "      <td>39.37</td>\n",
       "      <td>41.10</td>\n",
       "      <td>42.40</td>\n",
       "      <td>44.60</td>\n",
       "      <td>45.02</td>\n",
       "      <td>45.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>35.95</td>\n",
       "      <td>41.92</td>\n",
       "      <td>40.53</td>\n",
       "      <td>41.40</td>\n",
       "      <td>43.92</td>\n",
       "      <td>44.44</td>\n",
       "      <td>47.38</td>\n",
       "      <td>47.46</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>37.22</td>\n",
       "      <td>46.59</td>\n",
       "      <td>43.20</td>\n",
       "      <td>45.22</td>\n",
       "      <td>45.11</td>\n",
       "      <td>46.75</td>\n",
       "      <td>47.83</td>\n",
       "      <td>49.36</td>\n",
       "      <td>49.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>38.92</td>\n",
       "      <td>47.51</td>\n",
       "      <td>44.49</td>\n",
       "      <td>45.68</td>\n",
       "      <td>44.82</td>\n",
       "      <td>45.24</td>\n",
       "      <td>47.44</td>\n",
       "      <td>47.66</td>\n",
       "      <td>48.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32.31</td>\n",
       "      <td>40.78</td>\n",
       "      <td>41.03</td>\n",
       "      <td>42.77</td>\n",
       "      <td>41.76</td>\n",
       "      <td>43.91</td>\n",
       "      <td>45.65</td>\n",
       "      <td>46.11</td>\n",
       "      <td>45.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>28.41</td>\n",
       "      <td>40.74</td>\n",
       "      <td>34.27</td>\n",
       "      <td>37.77</td>\n",
       "      <td>37.54</td>\n",
       "      <td>39.47</td>\n",
       "      <td>42.69</td>\n",
       "      <td>43.06</td>\n",
       "      <td>43.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20.90</td>\n",
       "      <td>27.69</td>\n",
       "      <td>28.46</td>\n",
       "      <td>33.65</td>\n",
       "      <td>34.02</td>\n",
       "      <td>35.00</td>\n",
       "      <td>37.63</td>\n",
       "      <td>38.57</td>\n",
       "      <td>38.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>18.31</td>\n",
       "      <td>25.77</td>\n",
       "      <td>28.89</td>\n",
       "      <td>26.08</td>\n",
       "      <td>27.76</td>\n",
       "      <td>31.22</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11.08</td>\n",
       "      <td>23.03</td>\n",
       "      <td>24.38</td>\n",
       "      <td>22.38</td>\n",
       "      <td>24.69</td>\n",
       "      <td>26.11</td>\n",
       "      <td>25.42</td>\n",
       "      <td>25.57</td>\n",
       "      <td>25.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.36</td>\n",
       "      <td>13.11</td>\n",
       "      <td>16.95</td>\n",
       "      <td>17.69</td>\n",
       "      <td>17.08</td>\n",
       "      <td>17.72</td>\n",
       "      <td>17.97</td>\n",
       "      <td>18.39</td>\n",
       "      <td>18.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.34</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.84</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.95</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.06</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.17</td>\n",
       "      <td>3.61</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.24</td>\n",
       "      <td>7.03</td>\n",
       "      <td>7.36</td>\n",
       "      <td>7.70</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.82</td>\n",
       "      <td>10.20</td>\n",
       "      <td>13.27</td>\n",
       "      <td>15.31</td>\n",
       "      <td>15.99</td>\n",
       "      <td>16.46</td>\n",
       "      <td>17.05</td>\n",
       "      <td>16.86</td>\n",
       "      <td>16.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>9.21</td>\n",
       "      <td>15.81</td>\n",
       "      <td>19.20</td>\n",
       "      <td>21.31</td>\n",
       "      <td>22.58</td>\n",
       "      <td>22.97</td>\n",
       "      <td>23.40</td>\n",
       "      <td>23.81</td>\n",
       "      <td>25.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>11.98</td>\n",
       "      <td>21.78</td>\n",
       "      <td>27.90</td>\n",
       "      <td>29.88</td>\n",
       "      <td>30.57</td>\n",
       "      <td>31.18</td>\n",
       "      <td>32.07</td>\n",
       "      <td>32.01</td>\n",
       "      <td>33.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16.12</td>\n",
       "      <td>28.55</td>\n",
       "      <td>32.32</td>\n",
       "      <td>34.97</td>\n",
       "      <td>35.93</td>\n",
       "      <td>37.32</td>\n",
       "      <td>38.20</td>\n",
       "      <td>37.77</td>\n",
       "      <td>39.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>16.29</td>\n",
       "      <td>24.97</td>\n",
       "      <td>30.89</td>\n",
       "      <td>35.17</td>\n",
       "      <td>36.30</td>\n",
       "      <td>39.71</td>\n",
       "      <td>42.33</td>\n",
       "      <td>43.93</td>\n",
       "      <td>43.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17.81</td>\n",
       "      <td>25.01</td>\n",
       "      <td>29.68</td>\n",
       "      <td>33.83</td>\n",
       "      <td>37.27</td>\n",
       "      <td>39.81</td>\n",
       "      <td>42.19</td>\n",
       "      <td>43.91</td>\n",
       "      <td>45.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.94</td>\n",
       "      <td>36.12</td>\n",
       "      <td>40.64</td>\n",
       "      <td>42.25</td>\n",
       "      <td>46.52</td>\n",
       "      <td>48.62</td>\n",
       "      <td>47.93</td>\n",
       "      <td>49.41</td>\n",
       "      <td>50.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>21.37</td>\n",
       "      <td>39.09</td>\n",
       "      <td>48.19</td>\n",
       "      <td>45.46</td>\n",
       "      <td>47.59</td>\n",
       "      <td>50.48</td>\n",
       "      <td>50.25</td>\n",
       "      <td>51.04</td>\n",
       "      <td>51.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.1    0.2    0.3    0.4    0.5    0.6    0.7    0.8    0.9\n",
       "0    1.21   2.60   3.21   2.69   5.25   4.98   5.82   7.76  13.55\n",
       "1    5.02   5.08   3.72   8.10   8.37  11.08  13.85  16.70  24.47\n",
       "2    6.95   7.68   6.93   9.15  11.44  13.54  17.00  22.30  30.41\n",
       "3   10.75  18.21  14.21  12.27  13.04  14.29  24.18  23.67  32.19\n",
       "4   14.46  19.97  19.76  14.46  14.23  17.93  24.89  24.49  33.79\n",
       "5   22.49  33.17  31.34  30.79  31.74  29.02  32.47  31.01  35.08\n",
       "6   23.84  30.46  33.34  34.52  33.37  31.68  34.05  34.45  33.44\n",
       "7   24.18  34.47  41.16  42.26  45.32  32.25  36.77  36.94  41.94\n",
       "8   20.98  28.02  33.01  36.39  38.08  30.77  31.88  33.00  40.99\n",
       "9   20.81  28.88  34.68  35.41  35.41  29.31  32.04  30.31  34.51\n",
       "10  21.53  33.20  35.54  35.72  38.17  29.63  35.03  35.92  38.92\n",
       "11  17.55  22.72  30.72  34.70  33.34  29.95  31.44  30.88  35.57\n",
       "12  15.80  21.14  26.15  23.59  20.41  23.02  29.91  39.10  42.60\n",
       "13  15.49  19.90  25.77  25.05  22.90  23.45  24.93  24.84  30.87\n",
       "14  15.55  20.48  25.08  27.33  25.55  21.13  24.69  25.98  31.35\n",
       "15  10.74  19.55  21.24  21.84  24.01  22.53  22.90  23.22  30.14\n",
       "16   8.43  15.27  14.78  15.09  15.30  14.56  16.53  16.20  16.97\n",
       "17   6.01   9.46   9.11   6.71   7.14   7.98   7.98   5.74  14.31\n",
       "18   1.94   2.65   3.48   1.44   1.90   3.32   4.97   6.43  10.87\n",
       "19  -0.80  -0.38  -0.39   0.92  -0.07   1.34   1.44   2.02   1.83\n",
       "20   3.61   3.59   5.40   5.33   6.67   6.56   7.16   7.21   7.57\n",
       "21   6.16   8.99  13.04  13.06  12.68  13.53  15.22  15.38  15.19\n",
       "22   9.85  19.44  22.57  22.26  20.77  22.25  23.12  23.11  23.16\n",
       "23  15.35  22.78  23.24  22.13  27.21  28.29  28.58  29.19  30.69\n",
       "24  23.16  25.54  27.38  30.68  32.23  33.56  35.70  35.72  36.23\n",
       "25  24.20  26.76  34.43  34.61  34.10  37.38  39.56  40.91  40.63\n",
       "26  34.63  44.78  39.29  39.37  41.10  42.40  44.60  45.02  45.32\n",
       "27  35.95  41.92  40.53  41.40  43.92  44.44  47.38  47.46  48.00\n",
       "28  37.22  46.59  43.20  45.22  45.11  46.75  47.83  49.36  49.20\n",
       "29  38.92  47.51  44.49  45.68  44.82  45.24  47.44  47.66  48.24\n",
       "30  32.31  40.78  41.03  42.77  41.76  43.91  45.65  46.11  45.99\n",
       "31  28.41  40.74  34.27  37.77  37.54  39.47  42.69  43.06  43.14\n",
       "32  20.90  27.69  28.46  33.65  34.02  35.00  37.63  38.57  38.50\n",
       "33  18.31  25.77  28.89  26.08  27.76  31.22  32.09  32.93  32.45\n",
       "34  11.08  23.03  24.38  22.38  24.69  26.11  25.42  25.57  25.94\n",
       "35  10.36  13.11  16.95  17.69  17.08  17.72  17.97  18.39  18.84\n",
       "36   4.34   6.68   6.82   6.94   6.84   8.00   8.95   9.36   9.87\n",
       "37   2.06   2.46   2.53   1.37   1.20   2.03   2.71   2.67   2.64\n",
       "38   0.34   0.72   1.28   1.32   1.95   1.63   1.63   1.46   2.08\n",
       "39   2.17   3.61   5.74   6.24   7.03   7.36   7.70   8.05   8.39\n",
       "40   5.82  10.20  13.27  15.31  15.99  16.46  17.05  16.86  16.96\n",
       "41   9.21  15.81  19.20  21.31  22.58  22.97  23.40  23.81  25.24\n",
       "42  11.98  21.78  27.90  29.88  30.57  31.18  32.07  32.01  33.51\n",
       "43  16.12  28.55  32.32  34.97  35.93  37.32  38.20  37.77  39.81\n",
       "44  16.29  24.97  30.89  35.17  36.30  39.71  42.33  43.93  43.55\n",
       "45  17.81  25.01  29.68  33.83  37.27  39.81  42.19  43.91  45.57\n",
       "46  19.94  36.12  40.64  42.25  46.52  48.62  47.93  49.41  50.03\n",
       "47  21.37  39.09  48.19  45.46  47.59  50.48  50.25  51.04  51.74"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.24</td>\n",
       "      <td>7.65</td>\n",
       "      <td>13.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.84</td>\n",
       "      <td>7.56</td>\n",
       "      <td>8.54</td>\n",
       "      <td>11.20</td>\n",
       "      <td>12.59</td>\n",
       "      <td>13.95</td>\n",
       "      <td>15.53</td>\n",
       "      <td>19.48</td>\n",
       "      <td>23.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.70</td>\n",
       "      <td>8.06</td>\n",
       "      <td>12.87</td>\n",
       "      <td>14.03</td>\n",
       "      <td>16.72</td>\n",
       "      <td>16.80</td>\n",
       "      <td>21.77</td>\n",
       "      <td>30.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.70</td>\n",
       "      <td>13.68</td>\n",
       "      <td>14.35</td>\n",
       "      <td>12.42</td>\n",
       "      <td>12.63</td>\n",
       "      <td>17.10</td>\n",
       "      <td>22.92</td>\n",
       "      <td>25.48</td>\n",
       "      <td>32.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.45</td>\n",
       "      <td>17.75</td>\n",
       "      <td>19.00</td>\n",
       "      <td>14.93</td>\n",
       "      <td>17.01</td>\n",
       "      <td>20.71</td>\n",
       "      <td>25.85</td>\n",
       "      <td>28.44</td>\n",
       "      <td>38.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.08</td>\n",
       "      <td>28.80</td>\n",
       "      <td>26.85</td>\n",
       "      <td>30.29</td>\n",
       "      <td>26.01</td>\n",
       "      <td>23.81</td>\n",
       "      <td>26.92</td>\n",
       "      <td>30.55</td>\n",
       "      <td>34.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.33</td>\n",
       "      <td>26.39</td>\n",
       "      <td>22.47</td>\n",
       "      <td>30.44</td>\n",
       "      <td>28.62</td>\n",
       "      <td>28.59</td>\n",
       "      <td>30.50</td>\n",
       "      <td>33.06</td>\n",
       "      <td>34.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.63</td>\n",
       "      <td>32.86</td>\n",
       "      <td>34.60</td>\n",
       "      <td>38.86</td>\n",
       "      <td>35.82</td>\n",
       "      <td>32.05</td>\n",
       "      <td>33.63</td>\n",
       "      <td>36.78</td>\n",
       "      <td>41.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.81</td>\n",
       "      <td>31.80</td>\n",
       "      <td>31.75</td>\n",
       "      <td>34.20</td>\n",
       "      <td>27.53</td>\n",
       "      <td>27.53</td>\n",
       "      <td>28.11</td>\n",
       "      <td>33.86</td>\n",
       "      <td>42.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.39</td>\n",
       "      <td>32.16</td>\n",
       "      <td>33.91</td>\n",
       "      <td>35.44</td>\n",
       "      <td>30.80</td>\n",
       "      <td>29.15</td>\n",
       "      <td>31.71</td>\n",
       "      <td>32.63</td>\n",
       "      <td>36.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.48</td>\n",
       "      <td>32.10</td>\n",
       "      <td>35.97</td>\n",
       "      <td>38.11</td>\n",
       "      <td>35.66</td>\n",
       "      <td>30.07</td>\n",
       "      <td>32.96</td>\n",
       "      <td>35.88</td>\n",
       "      <td>40.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.01</td>\n",
       "      <td>31.16</td>\n",
       "      <td>32.61</td>\n",
       "      <td>32.96</td>\n",
       "      <td>30.08</td>\n",
       "      <td>26.93</td>\n",
       "      <td>29.84</td>\n",
       "      <td>34.73</td>\n",
       "      <td>35.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.13</td>\n",
       "      <td>22.72</td>\n",
       "      <td>31.09</td>\n",
       "      <td>27.32</td>\n",
       "      <td>21.63</td>\n",
       "      <td>31.42</td>\n",
       "      <td>39.63</td>\n",
       "      <td>43.33</td>\n",
       "      <td>50.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.46</td>\n",
       "      <td>25.70</td>\n",
       "      <td>28.06</td>\n",
       "      <td>27.89</td>\n",
       "      <td>21.79</td>\n",
       "      <td>21.67</td>\n",
       "      <td>24.92</td>\n",
       "      <td>26.49</td>\n",
       "      <td>32.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.57</td>\n",
       "      <td>28.26</td>\n",
       "      <td>29.63</td>\n",
       "      <td>29.51</td>\n",
       "      <td>23.79</td>\n",
       "      <td>24.61</td>\n",
       "      <td>26.87</td>\n",
       "      <td>30.76</td>\n",
       "      <td>32.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.89</td>\n",
       "      <td>20.62</td>\n",
       "      <td>26.83</td>\n",
       "      <td>23.85</td>\n",
       "      <td>20.28</td>\n",
       "      <td>20.27</td>\n",
       "      <td>23.67</td>\n",
       "      <td>23.65</td>\n",
       "      <td>30.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.40</td>\n",
       "      <td>13.89</td>\n",
       "      <td>15.98</td>\n",
       "      <td>14.03</td>\n",
       "      <td>13.04</td>\n",
       "      <td>15.75</td>\n",
       "      <td>17.92</td>\n",
       "      <td>18.60</td>\n",
       "      <td>23.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.25</td>\n",
       "      <td>7.79</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.09</td>\n",
       "      <td>5.92</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.74</td>\n",
       "      <td>5.95</td>\n",
       "      <td>19.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.99</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.02</td>\n",
       "      <td>5.89</td>\n",
       "      <td>6.35</td>\n",
       "      <td>7.38</td>\n",
       "      <td>16.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.77</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.21</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.92</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.38</td>\n",
       "      <td>7.75</td>\n",
       "      <td>12.02</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.60</td>\n",
       "      <td>13.55</td>\n",
       "      <td>14.47</td>\n",
       "      <td>14.69</td>\n",
       "      <td>15.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.96</td>\n",
       "      <td>15.24</td>\n",
       "      <td>16.33</td>\n",
       "      <td>19.96</td>\n",
       "      <td>20.44</td>\n",
       "      <td>20.83</td>\n",
       "      <td>21.77</td>\n",
       "      <td>22.90</td>\n",
       "      <td>22.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.91</td>\n",
       "      <td>20.67</td>\n",
       "      <td>21.53</td>\n",
       "      <td>25.54</td>\n",
       "      <td>28.95</td>\n",
       "      <td>28.02</td>\n",
       "      <td>27.94</td>\n",
       "      <td>28.91</td>\n",
       "      <td>30.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17.43</td>\n",
       "      <td>18.60</td>\n",
       "      <td>23.80</td>\n",
       "      <td>25.96</td>\n",
       "      <td>33.75</td>\n",
       "      <td>32.49</td>\n",
       "      <td>34.79</td>\n",
       "      <td>35.18</td>\n",
       "      <td>36.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15.81</td>\n",
       "      <td>22.40</td>\n",
       "      <td>25.83</td>\n",
       "      <td>29.35</td>\n",
       "      <td>36.73</td>\n",
       "      <td>35.60</td>\n",
       "      <td>38.80</td>\n",
       "      <td>40.25</td>\n",
       "      <td>40.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21.26</td>\n",
       "      <td>28.23</td>\n",
       "      <td>24.88</td>\n",
       "      <td>25.67</td>\n",
       "      <td>25.76</td>\n",
       "      <td>30.86</td>\n",
       "      <td>38.04</td>\n",
       "      <td>42.85</td>\n",
       "      <td>43.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22.03</td>\n",
       "      <td>31.71</td>\n",
       "      <td>29.19</td>\n",
       "      <td>30.21</td>\n",
       "      <td>31.31</td>\n",
       "      <td>33.62</td>\n",
       "      <td>38.02</td>\n",
       "      <td>43.82</td>\n",
       "      <td>45.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22.00</td>\n",
       "      <td>32.56</td>\n",
       "      <td>27.35</td>\n",
       "      <td>30.65</td>\n",
       "      <td>33.70</td>\n",
       "      <td>37.12</td>\n",
       "      <td>41.10</td>\n",
       "      <td>46.73</td>\n",
       "      <td>48.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.27</td>\n",
       "      <td>27.40</td>\n",
       "      <td>26.75</td>\n",
       "      <td>30.04</td>\n",
       "      <td>29.45</td>\n",
       "      <td>35.11</td>\n",
       "      <td>39.92</td>\n",
       "      <td>44.32</td>\n",
       "      <td>46.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.36</td>\n",
       "      <td>24.51</td>\n",
       "      <td>28.28</td>\n",
       "      <td>31.83</td>\n",
       "      <td>30.84</td>\n",
       "      <td>36.56</td>\n",
       "      <td>41.49</td>\n",
       "      <td>43.48</td>\n",
       "      <td>44.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13.02</td>\n",
       "      <td>18.89</td>\n",
       "      <td>26.87</td>\n",
       "      <td>29.48</td>\n",
       "      <td>35.25</td>\n",
       "      <td>36.42</td>\n",
       "      <td>40.61</td>\n",
       "      <td>41.84</td>\n",
       "      <td>43.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11.26</td>\n",
       "      <td>15.59</td>\n",
       "      <td>27.57</td>\n",
       "      <td>28.44</td>\n",
       "      <td>31.57</td>\n",
       "      <td>31.63</td>\n",
       "      <td>36.37</td>\n",
       "      <td>37.07</td>\n",
       "      <td>38.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.90</td>\n",
       "      <td>15.70</td>\n",
       "      <td>26.92</td>\n",
       "      <td>21.42</td>\n",
       "      <td>29.22</td>\n",
       "      <td>29.51</td>\n",
       "      <td>31.08</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7.76</td>\n",
       "      <td>13.17</td>\n",
       "      <td>16.99</td>\n",
       "      <td>19.82</td>\n",
       "      <td>22.65</td>\n",
       "      <td>24.78</td>\n",
       "      <td>24.62</td>\n",
       "      <td>25.14</td>\n",
       "      <td>25.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.68</td>\n",
       "      <td>8.31</td>\n",
       "      <td>12.89</td>\n",
       "      <td>14.46</td>\n",
       "      <td>15.21</td>\n",
       "      <td>15.84</td>\n",
       "      <td>17.08</td>\n",
       "      <td>17.28</td>\n",
       "      <td>18.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8.62</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.84</td>\n",
       "      <td>8.84</td>\n",
       "      <td>9.06</td>\n",
       "      <td>8.43</td>\n",
       "      <td>8.23</td>\n",
       "      <td>9.62</td>\n",
       "      <td>9.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.88</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.83</td>\n",
       "      <td>4.24</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.29</td>\n",
       "      <td>3.73</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.83</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.49</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.04</td>\n",
       "      <td>8.84</td>\n",
       "      <td>13.95</td>\n",
       "      <td>14.75</td>\n",
       "      <td>16.22</td>\n",
       "      <td>16.69</td>\n",
       "      <td>17.19</td>\n",
       "      <td>17.47</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.68</td>\n",
       "      <td>13.32</td>\n",
       "      <td>18.85</td>\n",
       "      <td>21.34</td>\n",
       "      <td>22.22</td>\n",
       "      <td>23.12</td>\n",
       "      <td>23.77</td>\n",
       "      <td>24.55</td>\n",
       "      <td>24.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.50</td>\n",
       "      <td>16.62</td>\n",
       "      <td>23.12</td>\n",
       "      <td>27.73</td>\n",
       "      <td>29.46</td>\n",
       "      <td>29.94</td>\n",
       "      <td>31.29</td>\n",
       "      <td>32.87</td>\n",
       "      <td>32.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13.97</td>\n",
       "      <td>23.69</td>\n",
       "      <td>28.18</td>\n",
       "      <td>30.94</td>\n",
       "      <td>34.79</td>\n",
       "      <td>36.23</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.54</td>\n",
       "      <td>37.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>18.60</td>\n",
       "      <td>25.02</td>\n",
       "      <td>32.07</td>\n",
       "      <td>34.73</td>\n",
       "      <td>37.58</td>\n",
       "      <td>42.45</td>\n",
       "      <td>44.85</td>\n",
       "      <td>45.31</td>\n",
       "      <td>44.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>14.39</td>\n",
       "      <td>25.44</td>\n",
       "      <td>32.47</td>\n",
       "      <td>37.51</td>\n",
       "      <td>40.66</td>\n",
       "      <td>43.06</td>\n",
       "      <td>46.19</td>\n",
       "      <td>46.57</td>\n",
       "      <td>46.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.41</td>\n",
       "      <td>29.93</td>\n",
       "      <td>38.53</td>\n",
       "      <td>42.26</td>\n",
       "      <td>45.78</td>\n",
       "      <td>46.49</td>\n",
       "      <td>47.02</td>\n",
       "      <td>48.59</td>\n",
       "      <td>50.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20.72</td>\n",
       "      <td>32.24</td>\n",
       "      <td>39.67</td>\n",
       "      <td>43.87</td>\n",
       "      <td>44.40</td>\n",
       "      <td>47.57</td>\n",
       "      <td>49.76</td>\n",
       "      <td>50.98</td>\n",
       "      <td>51.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.1    0.2    0.3    0.4    0.5    0.6    0.7    0.8    0.9\n",
       "0    0.92   1.35   1.73   2.79   2.96   2.62   3.24   7.65  13.65\n",
       "1    4.84   7.56   8.54  11.20  12.59  13.95  15.53  19.48  23.97\n",
       "2    4.69   7.70   8.06  12.87  14.03  16.72  16.80  21.77  30.12\n",
       "3    8.70  13.68  14.35  12.42  12.63  17.10  22.92  25.48  32.35\n",
       "4    9.45  17.75  19.00  14.93  17.01  20.71  25.85  28.44  38.22\n",
       "5   18.08  28.80  26.85  30.29  26.01  23.81  26.92  30.55  34.15\n",
       "6   19.33  26.39  22.47  30.44  28.62  28.59  30.50  33.06  34.16\n",
       "7   22.63  32.86  34.60  38.86  35.82  32.05  33.63  36.78  41.76\n",
       "8   21.81  31.80  31.75  34.20  27.53  27.53  28.11  33.86  42.06\n",
       "9   22.39  32.16  33.91  35.44  30.80  29.15  31.71  32.63  36.20\n",
       "10  22.48  32.10  35.97  38.11  35.66  30.07  32.96  35.88  40.14\n",
       "11  20.01  31.16  32.61  32.96  30.08  26.93  29.84  34.73  35.22\n",
       "12  13.13  22.72  31.09  27.32  21.63  31.42  39.63  43.33  50.68\n",
       "13  18.46  25.70  28.06  27.89  21.79  21.67  24.92  26.49  32.57\n",
       "14  17.57  28.26  29.63  29.51  23.79  24.61  26.87  30.76  32.48\n",
       "15  13.89  20.62  26.83  23.85  20.28  20.27  23.67  23.65  30.46\n",
       "16   9.40  13.89  15.98  14.03  13.04  15.75  17.92  18.60  23.82\n",
       "17   4.25   7.79   8.49   8.09   5.92   6.12   6.74   5.95  19.56\n",
       "18   1.99   1.69   2.97   3.30   2.02   5.89   6.35   7.38  16.96\n",
       "19   0.34   0.95   0.71   0.49   1.80   2.68   2.51   1.92   2.09\n",
       "20   2.77   3.55   4.95   5.75   5.04   5.21   6.59   6.92   7.31\n",
       "21   6.38   7.75  12.02  12.55  12.60  13.55  14.47  14.69  15.12\n",
       "22  11.96  15.24  16.33  19.96  20.44  20.83  21.77  22.90  22.90\n",
       "23  10.91  20.67  21.53  25.54  28.95  28.02  27.94  28.91  30.66\n",
       "24  17.43  18.60  23.80  25.96  33.75  32.49  34.79  35.18  36.52\n",
       "25  15.81  22.40  25.83  29.35  36.73  35.60  38.80  40.25  40.68\n",
       "26  21.26  28.23  24.88  25.67  25.76  30.86  38.04  42.85  43.80\n",
       "27  22.03  31.71  29.19  30.21  31.31  33.62  38.02  43.82  45.73\n",
       "28  22.00  32.56  27.35  30.65  33.70  37.12  41.10  46.73  48.88\n",
       "29  19.27  27.40  26.75  30.04  29.45  35.11  39.92  44.32  46.44\n",
       "30  15.36  24.51  28.28  31.83  30.84  36.56  41.49  43.48  44.92\n",
       "31  13.02  18.89  26.87  29.48  35.25  36.42  40.61  41.84  43.60\n",
       "32  11.26  15.59  27.57  28.44  31.57  31.63  36.37  37.07  38.11\n",
       "33  12.90  15.70  26.92  21.42  29.22  29.51  31.08  31.76  32.98\n",
       "34   7.76  13.17  16.99  19.82  22.65  24.78  24.62  25.14  25.97\n",
       "35   5.68   8.31  12.89  14.46  15.21  15.84  17.08  17.28  18.61\n",
       "36   8.62   7.44   7.84   8.84   9.06   8.43   8.23   9.62   9.47\n",
       "37   3.88   1.33   2.09   3.83   4.24   3.23   2.57   3.06   2.81\n",
       "38   0.30   0.63   1.03   0.50   1.37   1.19   1.19   1.53   2.29\n",
       "39   2.29   3.73   5.13   5.83   7.20   7.49   8.08   8.44   8.79\n",
       "40   6.04   8.84  13.95  14.75  16.22  16.69  17.19  17.47  17.50\n",
       "41   8.68  13.32  18.85  21.34  22.22  23.12  23.77  24.55  24.52\n",
       "42  10.50  16.62  23.12  27.73  29.46  29.94  31.29  32.87  32.79\n",
       "43  13.97  23.69  28.18  30.94  34.79  36.23  37.51  37.54  37.60\n",
       "44  18.60  25.02  32.07  34.73  37.58  42.45  44.85  45.31  44.62\n",
       "45  14.39  25.44  32.47  37.51  40.66  43.06  46.19  46.57  46.66\n",
       "46  19.41  29.93  38.53  42.26  45.78  46.49  47.02  48.59  50.05\n",
       "47  20.72  32.24  39.67  43.87  44.40  47.57  49.76  50.98  51.73"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1539, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9777 - val_loss: 3.1102\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9190 - val_loss: 3.1094\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8938 - val_loss: 3.1123\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9480 - val_loss: 3.0977\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9174 - val_loss: 3.1428\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9016 - val_loss: 3.1273\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9226 - val_loss: 3.1090\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9014 - val_loss: 3.0722\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9131 - val_loss: 3.1278\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 1ms/step - loss: 2.9181 - val_loss: 3.0746\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8759 - val_loss: 3.0952\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8615 - val_loss: 3.0424\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8765 - val_loss: 3.0400\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8277 - val_loss: 3.1527\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8777 - val_loss: 3.0273\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8435 - val_loss: 3.0457\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8046 - val_loss: 3.0296\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8301 - val_loss: 3.0408\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8383 - val_loss: 3.0352\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8008 - val_loss: 3.0651\n",
      "Epoch 00020: early stopping\n",
      "0.2\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5669 - val_loss: 4.9195\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4764 - val_loss: 4.9441\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4456 - val_loss: 4.9261\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5493 - val_loss: 4.9241\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4396 - val_loss: 4.9109\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4708 - val_loss: 5.0483\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5195 - val_loss: 4.9276\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4853 - val_loss: 4.9047\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4856 - val_loss: 4.9404\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5736 - val_loss: 4.9324\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4571 - val_loss: 4.9711\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5186 - val_loss: 4.9086\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4875 - val_loss: 4.8991\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4495 - val_loss: 5.1180\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5173 - val_loss: 4.8803\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5004 - val_loss: 4.9461\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4206 - val_loss: 4.8696\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4110 - val_loss: 4.8970\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5007 - val_loss: 4.8845\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4673 - val_loss: 4.9140\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4695 - val_loss: 4.8958\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4235 - val_loss: 4.8540\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5027 - val_loss: 4.8609\n",
      "Epoch 24/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4695 - val_loss: 4.9019\n",
      "Epoch 25/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4202 - val_loss: 4.9616\n",
      "Epoch 26/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.4628 - val_loss: 4.8736\n",
      "Epoch 27/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5050 - val_loss: 4.8676\n",
      "Epoch 00027: early stopping\n",
      "0.3\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.3312 - val_loss: 5.7496\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.2287 - val_loss: 5.9268\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.2435 - val_loss: 5.7443\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.3210 - val_loss: 5.8319\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.2002 - val_loss: 5.8200\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.2095 - val_loss: 5.8000\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.2709 - val_loss: 5.7691\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.2752 - val_loss: 5.7635\n",
      "Epoch 00008: early stopping\n",
      "0.4\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5781 - val_loss: 5.9978\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.4247 - val_loss: 6.1072\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.4991 - val_loss: 5.9297\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5325 - val_loss: 6.0964\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.4014 - val_loss: 5.9638\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.3988 - val_loss: 5.9689\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.4656 - val_loss: 5.9597\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5414 - val_loss: 6.0684\n",
      "Epoch 00008: early stopping\n",
      "0.5\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.3457 - val_loss: 5.6664\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.1814 - val_loss: 5.7156\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.2272 - val_loss: 5.7014\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.2905 - val_loss: 5.6764\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.1412 - val_loss: 5.7156\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.1611 - val_loss: 5.7679\n",
      "Epoch 00006: early stopping\n",
      "0.6\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.7607 - val_loss: 5.1077\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6178 - val_loss: 5.0920\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6642 - val_loss: 5.2243\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.7193 - val_loss: 5.0644\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5765 - val_loss: 5.0539\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5953 - val_loss: 5.0967\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6058 - val_loss: 5.1202\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6804 - val_loss: 5.0906\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6045 - val_loss: 5.0584\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.7344 - val_loss: 5.0606\n",
      "Epoch 00010: early stopping\n",
      "0.7\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 1s 2ms/step - loss: 3.8919 - val_loss: 4.2397\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.8002 - val_loss: 4.1551\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.8294 - val_loss: 4.2446\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.8708 - val_loss: 4.1403\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.7546 - val_loss: 4.2036\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.7804 - val_loss: 4.1166\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.7851 - val_loss: 4.1755\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.8498 - val_loss: 4.1266\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.7867 - val_loss: 4.1449\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.8756 - val_loss: 4.2317\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.8427 - val_loss: 4.1854\n",
      "Epoch 00011: early stopping\n",
      "0.8\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8539 - val_loss: 3.0304\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.7523 - val_loss: 3.0647\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8024 - val_loss: 3.1088\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8240 - val_loss: 3.0479\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.7551 - val_loss: 3.2125\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.7648 - val_loss: 3.0498\n",
      "Epoch 00006: early stopping\n",
      "0.9\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5981 - val_loss: 1.6818\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5354 - val_loss: 1.6904\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5602 - val_loss: 1.6851\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5857 - val_loss: 1.7041\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5349 - val_loss: 1.7817\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5405 - val_loss: 1.6764\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5499 - val_loss: 1.6883\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5658 - val_loss: 1.7512\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5415 - val_loss: 1.6566\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5766 - val_loss: 1.6708\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5500 - val_loss: 1.7179\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5338 - val_loss: 1.6733\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5192 - val_loss: 1.6453\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5373 - val_loss: 1.6892\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5447 - val_loss: 1.6810\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5577 - val_loss: 1.6612\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5119 - val_loss: 1.6686\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5365 - val_loss: 1.7434\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.348731</td>\n",
       "      <td>0.554478</td>\n",
       "      <td>0.771052</td>\n",
       "      <td>1.086361</td>\n",
       "      <td>1.878148</td>\n",
       "      <td>2.272291</td>\n",
       "      <td>4.032242</td>\n",
       "      <td>6.260856</td>\n",
       "      <td>10.634353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.027880</td>\n",
       "      <td>1.711945</td>\n",
       "      <td>1.974530</td>\n",
       "      <td>2.487097</td>\n",
       "      <td>5.196687</td>\n",
       "      <td>5.665732</td>\n",
       "      <td>10.685476</td>\n",
       "      <td>16.257795</td>\n",
       "      <td>21.127674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.203550</td>\n",
       "      <td>3.555515</td>\n",
       "      <td>3.431974</td>\n",
       "      <td>4.069526</td>\n",
       "      <td>8.909965</td>\n",
       "      <td>8.742459</td>\n",
       "      <td>13.262949</td>\n",
       "      <td>19.883142</td>\n",
       "      <td>25.723112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.013263</td>\n",
       "      <td>12.216247</td>\n",
       "      <td>10.660323</td>\n",
       "      <td>10.378981</td>\n",
       "      <td>18.625441</td>\n",
       "      <td>17.626141</td>\n",
       "      <td>25.644768</td>\n",
       "      <td>34.888874</td>\n",
       "      <td>38.077370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.103452</td>\n",
       "      <td>15.318599</td>\n",
       "      <td>13.829759</td>\n",
       "      <td>13.627136</td>\n",
       "      <td>21.281992</td>\n",
       "      <td>21.597427</td>\n",
       "      <td>25.956308</td>\n",
       "      <td>35.323227</td>\n",
       "      <td>37.067989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.763417</td>\n",
       "      <td>25.196619</td>\n",
       "      <td>22.763470</td>\n",
       "      <td>22.808643</td>\n",
       "      <td>31.761524</td>\n",
       "      <td>34.103409</td>\n",
       "      <td>34.713825</td>\n",
       "      <td>42.633331</td>\n",
       "      <td>34.986988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.758438</td>\n",
       "      <td>26.458612</td>\n",
       "      <td>23.757744</td>\n",
       "      <td>24.492601</td>\n",
       "      <td>33.554649</td>\n",
       "      <td>35.799686</td>\n",
       "      <td>36.333210</td>\n",
       "      <td>40.169979</td>\n",
       "      <td>33.962479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.610710</td>\n",
       "      <td>30.811193</td>\n",
       "      <td>31.512955</td>\n",
       "      <td>29.265636</td>\n",
       "      <td>38.949345</td>\n",
       "      <td>41.157803</td>\n",
       "      <td>44.349277</td>\n",
       "      <td>50.931015</td>\n",
       "      <td>43.281418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.310388</td>\n",
       "      <td>28.721195</td>\n",
       "      <td>29.501114</td>\n",
       "      <td>26.992758</td>\n",
       "      <td>37.178062</td>\n",
       "      <td>38.634224</td>\n",
       "      <td>42.145905</td>\n",
       "      <td>49.744267</td>\n",
       "      <td>41.529686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.520775</td>\n",
       "      <td>29.376112</td>\n",
       "      <td>31.293385</td>\n",
       "      <td>29.964169</td>\n",
       "      <td>37.493893</td>\n",
       "      <td>38.847698</td>\n",
       "      <td>42.419136</td>\n",
       "      <td>48.186600</td>\n",
       "      <td>39.041752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.357555</td>\n",
       "      <td>30.193003</td>\n",
       "      <td>31.065468</td>\n",
       "      <td>30.603979</td>\n",
       "      <td>37.486874</td>\n",
       "      <td>40.150928</td>\n",
       "      <td>43.182549</td>\n",
       "      <td>47.354980</td>\n",
       "      <td>38.724174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.050957</td>\n",
       "      <td>26.105230</td>\n",
       "      <td>28.677418</td>\n",
       "      <td>30.136717</td>\n",
       "      <td>35.097404</td>\n",
       "      <td>37.833267</td>\n",
       "      <td>40.152794</td>\n",
       "      <td>44.470577</td>\n",
       "      <td>36.853584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.673885</td>\n",
       "      <td>22.570089</td>\n",
       "      <td>25.422626</td>\n",
       "      <td>27.210066</td>\n",
       "      <td>32.905811</td>\n",
       "      <td>36.602295</td>\n",
       "      <td>41.542984</td>\n",
       "      <td>46.363686</td>\n",
       "      <td>42.579437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.129294</td>\n",
       "      <td>19.673513</td>\n",
       "      <td>22.690186</td>\n",
       "      <td>25.322723</td>\n",
       "      <td>29.653063</td>\n",
       "      <td>32.430191</td>\n",
       "      <td>34.577797</td>\n",
       "      <td>37.810883</td>\n",
       "      <td>33.499397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.668872</td>\n",
       "      <td>20.317507</td>\n",
       "      <td>23.575394</td>\n",
       "      <td>25.849300</td>\n",
       "      <td>30.313293</td>\n",
       "      <td>32.825863</td>\n",
       "      <td>34.010109</td>\n",
       "      <td>37.370361</td>\n",
       "      <td>31.951550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.689232</td>\n",
       "      <td>16.249315</td>\n",
       "      <td>18.865978</td>\n",
       "      <td>22.355818</td>\n",
       "      <td>25.903942</td>\n",
       "      <td>27.754879</td>\n",
       "      <td>27.955994</td>\n",
       "      <td>29.638941</td>\n",
       "      <td>27.010740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.127713</td>\n",
       "      <td>13.513766</td>\n",
       "      <td>15.232833</td>\n",
       "      <td>16.609638</td>\n",
       "      <td>20.443596</td>\n",
       "      <td>23.410629</td>\n",
       "      <td>25.413456</td>\n",
       "      <td>27.986534</td>\n",
       "      <td>27.030090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.654276</td>\n",
       "      <td>5.947260</td>\n",
       "      <td>6.311623</td>\n",
       "      <td>7.363977</td>\n",
       "      <td>9.838961</td>\n",
       "      <td>10.898157</td>\n",
       "      <td>13.424358</td>\n",
       "      <td>13.618485</td>\n",
       "      <td>18.603340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.829259</td>\n",
       "      <td>2.185976</td>\n",
       "      <td>1.835973</td>\n",
       "      <td>2.412414</td>\n",
       "      <td>3.961266</td>\n",
       "      <td>5.090342</td>\n",
       "      <td>9.035365</td>\n",
       "      <td>8.801086</td>\n",
       "      <td>22.773506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.735331</td>\n",
       "      <td>0.587074</td>\n",
       "      <td>0.656743</td>\n",
       "      <td>1.033452</td>\n",
       "      <td>1.762184</td>\n",
       "      <td>1.646850</td>\n",
       "      <td>1.900053</td>\n",
       "      <td>1.982569</td>\n",
       "      <td>1.980968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.424727</td>\n",
       "      <td>5.081932</td>\n",
       "      <td>5.479901</td>\n",
       "      <td>6.413879</td>\n",
       "      <td>7.619194</td>\n",
       "      <td>7.470941</td>\n",
       "      <td>7.815268</td>\n",
       "      <td>7.876755</td>\n",
       "      <td>7.918359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.368256</td>\n",
       "      <td>12.314083</td>\n",
       "      <td>12.296295</td>\n",
       "      <td>12.847010</td>\n",
       "      <td>15.565990</td>\n",
       "      <td>14.749401</td>\n",
       "      <td>16.481787</td>\n",
       "      <td>15.970465</td>\n",
       "      <td>16.227993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.969104</td>\n",
       "      <td>16.934774</td>\n",
       "      <td>18.602917</td>\n",
       "      <td>19.097034</td>\n",
       "      <td>22.849777</td>\n",
       "      <td>22.158594</td>\n",
       "      <td>24.200306</td>\n",
       "      <td>23.388254</td>\n",
       "      <td>24.730671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.876843</td>\n",
       "      <td>22.210680</td>\n",
       "      <td>24.931908</td>\n",
       "      <td>25.675293</td>\n",
       "      <td>30.047125</td>\n",
       "      <td>29.318571</td>\n",
       "      <td>30.844282</td>\n",
       "      <td>29.660795</td>\n",
       "      <td>31.277872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.452265</td>\n",
       "      <td>26.656744</td>\n",
       "      <td>30.142975</td>\n",
       "      <td>30.689545</td>\n",
       "      <td>35.813931</td>\n",
       "      <td>35.764645</td>\n",
       "      <td>36.604683</td>\n",
       "      <td>35.762421</td>\n",
       "      <td>37.467487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19.317360</td>\n",
       "      <td>30.841961</td>\n",
       "      <td>35.200893</td>\n",
       "      <td>35.590691</td>\n",
       "      <td>41.253220</td>\n",
       "      <td>40.639317</td>\n",
       "      <td>41.476952</td>\n",
       "      <td>40.409462</td>\n",
       "      <td>42.593483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19.390873</td>\n",
       "      <td>33.718987</td>\n",
       "      <td>39.027248</td>\n",
       "      <td>39.377693</td>\n",
       "      <td>45.364326</td>\n",
       "      <td>44.907394</td>\n",
       "      <td>45.395599</td>\n",
       "      <td>44.497047</td>\n",
       "      <td>46.678108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20.206463</td>\n",
       "      <td>35.538158</td>\n",
       "      <td>41.302853</td>\n",
       "      <td>41.630432</td>\n",
       "      <td>47.860519</td>\n",
       "      <td>47.407890</td>\n",
       "      <td>47.861130</td>\n",
       "      <td>46.945431</td>\n",
       "      <td>48.986122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18.849522</td>\n",
       "      <td>35.850796</td>\n",
       "      <td>42.135296</td>\n",
       "      <td>42.431862</td>\n",
       "      <td>48.719097</td>\n",
       "      <td>48.470715</td>\n",
       "      <td>48.952106</td>\n",
       "      <td>48.012856</td>\n",
       "      <td>49.933044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.850189</td>\n",
       "      <td>35.393311</td>\n",
       "      <td>41.550400</td>\n",
       "      <td>41.916958</td>\n",
       "      <td>48.215446</td>\n",
       "      <td>47.961689</td>\n",
       "      <td>48.405510</td>\n",
       "      <td>47.504948</td>\n",
       "      <td>49.491661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16.691788</td>\n",
       "      <td>33.449764</td>\n",
       "      <td>39.520988</td>\n",
       "      <td>39.981857</td>\n",
       "      <td>46.025658</td>\n",
       "      <td>45.997623</td>\n",
       "      <td>46.368179</td>\n",
       "      <td>45.505753</td>\n",
       "      <td>47.583374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15.788994</td>\n",
       "      <td>30.867052</td>\n",
       "      <td>36.217308</td>\n",
       "      <td>36.842979</td>\n",
       "      <td>42.635494</td>\n",
       "      <td>42.606808</td>\n",
       "      <td>42.946663</td>\n",
       "      <td>42.080696</td>\n",
       "      <td>44.287228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.909652</td>\n",
       "      <td>27.122162</td>\n",
       "      <td>31.735836</td>\n",
       "      <td>32.545250</td>\n",
       "      <td>37.722744</td>\n",
       "      <td>37.908199</td>\n",
       "      <td>38.530106</td>\n",
       "      <td>37.657463</td>\n",
       "      <td>39.620876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>11.237125</td>\n",
       "      <td>22.681383</td>\n",
       "      <td>26.172382</td>\n",
       "      <td>27.222525</td>\n",
       "      <td>31.784025</td>\n",
       "      <td>32.273228</td>\n",
       "      <td>32.718613</td>\n",
       "      <td>32.199459</td>\n",
       "      <td>33.448017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8.221263</td>\n",
       "      <td>17.137440</td>\n",
       "      <td>19.555054</td>\n",
       "      <td>21.138342</td>\n",
       "      <td>24.964853</td>\n",
       "      <td>25.600887</td>\n",
       "      <td>26.161440</td>\n",
       "      <td>26.008331</td>\n",
       "      <td>26.667339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.871815</td>\n",
       "      <td>12.028768</td>\n",
       "      <td>13.322980</td>\n",
       "      <td>15.283957</td>\n",
       "      <td>17.944788</td>\n",
       "      <td>17.992401</td>\n",
       "      <td>18.662718</td>\n",
       "      <td>18.857685</td>\n",
       "      <td>19.106951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.149099</td>\n",
       "      <td>8.496670</td>\n",
       "      <td>8.663188</td>\n",
       "      <td>9.300360</td>\n",
       "      <td>10.623176</td>\n",
       "      <td>10.298076</td>\n",
       "      <td>11.030104</td>\n",
       "      <td>11.468357</td>\n",
       "      <td>10.854310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.271482</td>\n",
       "      <td>2.792402</td>\n",
       "      <td>2.641541</td>\n",
       "      <td>2.620915</td>\n",
       "      <td>3.101978</td>\n",
       "      <td>3.199960</td>\n",
       "      <td>3.465419</td>\n",
       "      <td>3.236400</td>\n",
       "      <td>3.236481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.636380</td>\n",
       "      <td>0.783432</td>\n",
       "      <td>0.883215</td>\n",
       "      <td>1.169443</td>\n",
       "      <td>1.792892</td>\n",
       "      <td>1.688524</td>\n",
       "      <td>2.007983</td>\n",
       "      <td>2.253144</td>\n",
       "      <td>2.478794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.749617</td>\n",
       "      <td>4.812282</td>\n",
       "      <td>5.665816</td>\n",
       "      <td>6.148444</td>\n",
       "      <td>7.382994</td>\n",
       "      <td>6.911043</td>\n",
       "      <td>7.652273</td>\n",
       "      <td>8.332553</td>\n",
       "      <td>8.591023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.923636</td>\n",
       "      <td>11.550400</td>\n",
       "      <td>12.307500</td>\n",
       "      <td>13.369113</td>\n",
       "      <td>16.922773</td>\n",
       "      <td>15.835124</td>\n",
       "      <td>17.451544</td>\n",
       "      <td>17.063091</td>\n",
       "      <td>18.051044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.847495</td>\n",
       "      <td>15.242807</td>\n",
       "      <td>17.657173</td>\n",
       "      <td>19.123346</td>\n",
       "      <td>23.272726</td>\n",
       "      <td>22.845295</td>\n",
       "      <td>24.286438</td>\n",
       "      <td>24.187857</td>\n",
       "      <td>25.202948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>12.037335</td>\n",
       "      <td>20.953495</td>\n",
       "      <td>24.449699</td>\n",
       "      <td>26.181873</td>\n",
       "      <td>30.772566</td>\n",
       "      <td>30.516273</td>\n",
       "      <td>31.792568</td>\n",
       "      <td>31.132120</td>\n",
       "      <td>32.720474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15.259652</td>\n",
       "      <td>24.857025</td>\n",
       "      <td>29.378429</td>\n",
       "      <td>30.803871</td>\n",
       "      <td>36.438572</td>\n",
       "      <td>36.588062</td>\n",
       "      <td>37.770287</td>\n",
       "      <td>37.489319</td>\n",
       "      <td>38.821342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>16.498363</td>\n",
       "      <td>25.610044</td>\n",
       "      <td>30.932796</td>\n",
       "      <td>32.744835</td>\n",
       "      <td>38.678131</td>\n",
       "      <td>39.571228</td>\n",
       "      <td>40.890053</td>\n",
       "      <td>42.368942</td>\n",
       "      <td>43.464977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15.735598</td>\n",
       "      <td>24.190575</td>\n",
       "      <td>31.767017</td>\n",
       "      <td>33.833202</td>\n",
       "      <td>39.710480</td>\n",
       "      <td>41.750309</td>\n",
       "      <td>43.981483</td>\n",
       "      <td>45.756496</td>\n",
       "      <td>47.108753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>17.819504</td>\n",
       "      <td>32.516262</td>\n",
       "      <td>39.403069</td>\n",
       "      <td>40.459164</td>\n",
       "      <td>46.810753</td>\n",
       "      <td>47.021584</td>\n",
       "      <td>47.959106</td>\n",
       "      <td>48.335960</td>\n",
       "      <td>49.542309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>16.983543</td>\n",
       "      <td>34.394714</td>\n",
       "      <td>42.206589</td>\n",
       "      <td>42.763508</td>\n",
       "      <td>49.120594</td>\n",
       "      <td>49.291683</td>\n",
       "      <td>50.179100</td>\n",
       "      <td>49.893715</td>\n",
       "      <td>51.542133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          0          0          0          0          0  \\\n",
       "0    0.348731   0.554478   0.771052   1.086361   1.878148   2.272291   \n",
       "1    1.027880   1.711945   1.974530   2.487097   5.196687   5.665732   \n",
       "2    2.203550   3.555515   3.431974   4.069526   8.909965   8.742459   \n",
       "3    7.013263  12.216247  10.660323  10.378981  18.625441  17.626141   \n",
       "4    9.103452  15.318599  13.829759  13.627136  21.281992  21.597427   \n",
       "5   14.763417  25.196619  22.763470  22.808643  31.761524  34.103409   \n",
       "6   16.758438  26.458612  23.757744  24.492601  33.554649  35.799686   \n",
       "7   17.610710  30.811193  31.512955  29.265636  38.949345  41.157803   \n",
       "8   15.310388  28.721195  29.501114  26.992758  37.178062  38.634224   \n",
       "9   16.520775  29.376112  31.293385  29.964169  37.493893  38.847698   \n",
       "10  18.357555  30.193003  31.065468  30.603979  37.486874  40.150928   \n",
       "11  17.050957  26.105230  28.677418  30.136717  35.097404  37.833267   \n",
       "12  13.673885  22.570089  25.422626  27.210066  32.905811  36.602295   \n",
       "13  14.129294  19.673513  22.690186  25.322723  29.653063  32.430191   \n",
       "14  14.668872  20.317507  23.575394  25.849300  30.313293  32.825863   \n",
       "15  12.689232  16.249315  18.865978  22.355818  25.903942  27.754879   \n",
       "16  10.127713  13.513766  15.232833  16.609638  20.443596  23.410629   \n",
       "17   6.654276   5.947260   6.311623   7.363977   9.838961  10.898157   \n",
       "18   2.829259   2.185976   1.835973   2.412414   3.961266   5.090342   \n",
       "19   0.735331   0.587074   0.656743   1.033452   1.762184   1.646850   \n",
       "20   2.424727   5.081932   5.479901   6.413879   7.619194   7.470941   \n",
       "21   5.368256  12.314083  12.296295  12.847010  15.565990  14.749401   \n",
       "22   8.969104  16.934774  18.602917  19.097034  22.849777  22.158594   \n",
       "23  12.876843  22.210680  24.931908  25.675293  30.047125  29.318571   \n",
       "24  16.452265  26.656744  30.142975  30.689545  35.813931  35.764645   \n",
       "25  19.317360  30.841961  35.200893  35.590691  41.253220  40.639317   \n",
       "26  19.390873  33.718987  39.027248  39.377693  45.364326  44.907394   \n",
       "27  20.206463  35.538158  41.302853  41.630432  47.860519  47.407890   \n",
       "28  18.849522  35.850796  42.135296  42.431862  48.719097  48.470715   \n",
       "29  18.850189  35.393311  41.550400  41.916958  48.215446  47.961689   \n",
       "30  16.691788  33.449764  39.520988  39.981857  46.025658  45.997623   \n",
       "31  15.788994  30.867052  36.217308  36.842979  42.635494  42.606808   \n",
       "32  12.909652  27.122162  31.735836  32.545250  37.722744  37.908199   \n",
       "33  11.237125  22.681383  26.172382  27.222525  31.784025  32.273228   \n",
       "34   8.221263  17.137440  19.555054  21.138342  24.964853  25.600887   \n",
       "35   6.871815  12.028768  13.322980  15.283957  17.944788  17.992401   \n",
       "36   4.149099   8.496670   8.663188   9.300360  10.623176  10.298076   \n",
       "37   1.271482   2.792402   2.641541   2.620915   3.101978   3.199960   \n",
       "38   0.636380   0.783432   0.883215   1.169443   1.792892   1.688524   \n",
       "39   2.749617   4.812282   5.665816   6.148444   7.382994   6.911043   \n",
       "40   4.923636  11.550400  12.307500  13.369113  16.922773  15.835124   \n",
       "41   7.847495  15.242807  17.657173  19.123346  23.272726  22.845295   \n",
       "42  12.037335  20.953495  24.449699  26.181873  30.772566  30.516273   \n",
       "43  15.259652  24.857025  29.378429  30.803871  36.438572  36.588062   \n",
       "44  16.498363  25.610044  30.932796  32.744835  38.678131  39.571228   \n",
       "45  15.735598  24.190575  31.767017  33.833202  39.710480  41.750309   \n",
       "46  17.819504  32.516262  39.403069  40.459164  46.810753  47.021584   \n",
       "47  16.983543  34.394714  42.206589  42.763508  49.120594  49.291683   \n",
       "\n",
       "            0          0          0  \n",
       "0    4.032242   6.260856  10.634353  \n",
       "1   10.685476  16.257795  21.127674  \n",
       "2   13.262949  19.883142  25.723112  \n",
       "3   25.644768  34.888874  38.077370  \n",
       "4   25.956308  35.323227  37.067989  \n",
       "5   34.713825  42.633331  34.986988  \n",
       "6   36.333210  40.169979  33.962479  \n",
       "7   44.349277  50.931015  43.281418  \n",
       "8   42.145905  49.744267  41.529686  \n",
       "9   42.419136  48.186600  39.041752  \n",
       "10  43.182549  47.354980  38.724174  \n",
       "11  40.152794  44.470577  36.853584  \n",
       "12  41.542984  46.363686  42.579437  \n",
       "13  34.577797  37.810883  33.499397  \n",
       "14  34.010109  37.370361  31.951550  \n",
       "15  27.955994  29.638941  27.010740  \n",
       "16  25.413456  27.986534  27.030090  \n",
       "17  13.424358  13.618485  18.603340  \n",
       "18   9.035365   8.801086  22.773506  \n",
       "19   1.900053   1.982569   1.980968  \n",
       "20   7.815268   7.876755   7.918359  \n",
       "21  16.481787  15.970465  16.227993  \n",
       "22  24.200306  23.388254  24.730671  \n",
       "23  30.844282  29.660795  31.277872  \n",
       "24  36.604683  35.762421  37.467487  \n",
       "25  41.476952  40.409462  42.593483  \n",
       "26  45.395599  44.497047  46.678108  \n",
       "27  47.861130  46.945431  48.986122  \n",
       "28  48.952106  48.012856  49.933044  \n",
       "29  48.405510  47.504948  49.491661  \n",
       "30  46.368179  45.505753  47.583374  \n",
       "31  42.946663  42.080696  44.287228  \n",
       "32  38.530106  37.657463  39.620876  \n",
       "33  32.718613  32.199459  33.448017  \n",
       "34  26.161440  26.008331  26.667339  \n",
       "35  18.662718  18.857685  19.106951  \n",
       "36  11.030104  11.468357  10.854310  \n",
       "37   3.465419   3.236400   3.236481  \n",
       "38   2.007983   2.253144   2.478794  \n",
       "39   7.652273   8.332553   8.591023  \n",
       "40  17.451544  17.063091  18.051044  \n",
       "41  24.286438  24.187857  25.202948  \n",
       "42  31.792568  31.132120  32.720474  \n",
       "43  37.770287  37.489319  38.821342  \n",
       "44  40.890053  42.368942  43.464977  \n",
       "45  43.981483  45.756496  47.108753  \n",
       "46  47.959106  48.335960  49.542309  \n",
       "47  50.179100  49.893715  51.542133  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7 = tf.keras.Sequential([\n",
    "    layers.Conv1D(filters=128, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result7 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model7.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model7.fit(np.array(Day).reshape(25864, 1, 7), np.array(Day7).reshape(25864, 1), epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred7 = np.squeeze(model7.predict(np.array(df_test).reshape(1539, 1, 7)))\n",
    "    pred7 = pd.DataFrame(pred7)\n",
    "    result7 = pd.concat([result7, pred7], axis=1)\n",
    "    \n",
    "result7[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.0383 - val_loss: 3.1890\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9896 - val_loss: 3.2023\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9669 - val_loss: 3.1825\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9760 - val_loss: 3.2057\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9567 - val_loss: 3.2585\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9344 - val_loss: 3.1983\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9774 - val_loss: 3.1679\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9488 - val_loss: 3.1572\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9534 - val_loss: 3.1603\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9556 - val_loss: 3.1569\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9482 - val_loss: 3.1394\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9342 - val_loss: 3.1686\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9301 - val_loss: 3.1731\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9030 - val_loss: 3.1280\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9071 - val_loss: 3.1113\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8881 - val_loss: 3.1091\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9000 - val_loss: 3.0982\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9160 - val_loss: 3.0942\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8955 - val_loss: 3.1876\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9001 - val_loss: 3.0791\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8874 - val_loss: 3.1480\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9044 - val_loss: 3.0862\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9029 - val_loss: 3.1059\n",
      "Epoch 24/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9095 - val_loss: 3.0615\n",
      "Epoch 25/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8835 - val_loss: 3.0671\n",
      "Epoch 26/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8802 - val_loss: 3.0590\n",
      "Epoch 27/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8987 - val_loss: 3.0912\n",
      "Epoch 28/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8692 - val_loss: 3.0544\n",
      "Epoch 29/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8869 - val_loss: 3.0671\n",
      "Epoch 30/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8767 - val_loss: 3.1140\n",
      "Epoch 31/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8736 - val_loss: 3.1113\n",
      "Epoch 32/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8880 - val_loss: 3.0423\n",
      "Epoch 33/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8760 - val_loss: 3.0627\n",
      "Epoch 34/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8532 - val_loss: 3.0538\n",
      "Epoch 35/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8913 - val_loss: 3.0519\n",
      "Epoch 36/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8480 - val_loss: 3.0592\n",
      "Epoch 37/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8768 - val_loss: 3.0386\n",
      "Epoch 38/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8807 - val_loss: 3.0626\n",
      "Epoch 39/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8752 - val_loss: 3.0446\n",
      "Epoch 40/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8920 - val_loss: 3.0457\n",
      "Epoch 41/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8157 - val_loss: 3.0419\n",
      "Epoch 42/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8181 - val_loss: 3.1157\n",
      "Epoch 00042: early stopping\n",
      "0.2\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.7987 - val_loss: 5.0668\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.7409 - val_loss: 5.0987\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6699 - val_loss: 5.0514\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.7279 - val_loss: 5.0117\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6797 - val_loss: 5.1174\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6593 - val_loss: 5.0765\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.7640 - val_loss: 5.1053\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6758 - val_loss: 5.0580\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6834 - val_loss: 5.0114\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.7166 - val_loss: 5.0007\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6449 - val_loss: 5.0534\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6252 - val_loss: 5.1537\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6420 - val_loss: 5.0295\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.5930 - val_loss: 5.1761\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.6829 - val_loss: 5.0124\n",
      "Epoch 00015: early stopping\n",
      "0.3\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.6940 - val_loss: 5.9728\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.6225 - val_loss: 6.0764\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5590 - val_loss: 5.9521\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.6559 - val_loss: 5.9558\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5913 - val_loss: 6.0114\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5728 - val_loss: 5.9420\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.6594 - val_loss: 6.0275\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5853 - val_loss: 6.1319\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.6200 - val_loss: 5.9669\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.6540 - val_loss: 5.9962\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5611 - val_loss: 6.0041\n",
      "Epoch 00011: early stopping\n",
      "0.4\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.9209 - val_loss: 6.2358\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.8465 - val_loss: 6.3033\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.7926 - val_loss: 6.2821\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.9311 - val_loss: 6.2524\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.8150 - val_loss: 6.2439\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.8235 - val_loss: 6.3406\n",
      "Epoch 00006: early stopping\n",
      "0.5\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.6190 - val_loss: 6.0114\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5515 - val_loss: 6.0395\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5157 - val_loss: 6.0221\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.6588 - val_loss: 6.0131\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5602 - val_loss: 6.0906\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 1s 2ms/step - loss: 5.5383 - val_loss: 6.0416\n",
      "Epoch 00006: early stopping\n",
      "0.6\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9668 - val_loss: 5.3480\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9097 - val_loss: 5.3825\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8686 - val_loss: 5.3705\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9875 - val_loss: 5.4243\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9253 - val_loss: 5.3472\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8839 - val_loss: 5.3769\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9309 - val_loss: 5.4808\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9588 - val_loss: 5.3431\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9398 - val_loss: 5.4724\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9400 - val_loss: 5.3343\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8610 - val_loss: 5.3819\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8392 - val_loss: 5.3548\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8680 - val_loss: 5.3376\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.7797 - val_loss: 5.5027\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9394 - val_loss: 5.3308\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9205 - val_loss: 5.3354\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8395 - val_loss: 5.3775\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9116 - val_loss: 5.3119\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8687 - val_loss: 5.3553\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8388 - val_loss: 5.3550\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.9648 - val_loss: 5.4720\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8860 - val_loss: 5.3325\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.8886 - val_loss: 5.3298\n",
      "Epoch 00023: early stopping\n",
      "0.7\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.0260 - val_loss: 4.4228\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9658 - val_loss: 4.3407\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9491 - val_loss: 4.3546\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.0325 - val_loss: 4.4756\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9942 - val_loss: 4.3338\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9565 - val_loss: 4.4154\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9907 - val_loss: 4.3485\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.0226 - val_loss: 4.3267\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 4.0101 - val_loss: 4.3810\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9990 - val_loss: 4.3719\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9259 - val_loss: 4.3435\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9264 - val_loss: 4.4076\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 3.9372 - val_loss: 4.3472\n",
      "Epoch 00013: early stopping\n",
      "0.8\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8982 - val_loss: 3.1766\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8678 - val_loss: 3.1237\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8435 - val_loss: 3.1388\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9068 - val_loss: 3.2710\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8822 - val_loss: 3.1723\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8560 - val_loss: 3.1840\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9108 - val_loss: 3.1223\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.9060 - val_loss: 3.1147\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8925 - val_loss: 3.1317\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8844 - val_loss: 3.1629\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8307 - val_loss: 3.1232\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8212 - val_loss: 3.1116\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8285 - val_loss: 3.1205\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.7935 - val_loss: 3.1793\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8828 - val_loss: 3.1018\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8782 - val_loss: 3.2397\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8318 - val_loss: 3.1776\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8667 - val_loss: 3.1354\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8588 - val_loss: 3.1329\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 2.8351 - val_loss: 3.1501\n",
      "Epoch 00020: early stopping\n",
      "0.9\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.6012 - val_loss: 1.7344\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5781 - val_loss: 1.7210\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5552 - val_loss: 1.7044\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.6144 - val_loss: 1.7250\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5792 - val_loss: 1.7581\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5732 - val_loss: 1.7524\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.6003 - val_loss: 1.7209\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 2ms/step - loss: 1.5992 - val_loss: 1.7398\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586329</td>\n",
       "      <td>1.294001</td>\n",
       "      <td>0.729435</td>\n",
       "      <td>1.448856</td>\n",
       "      <td>2.347870</td>\n",
       "      <td>3.072911</td>\n",
       "      <td>4.721885</td>\n",
       "      <td>6.036065</td>\n",
       "      <td>10.198798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.068924</td>\n",
       "      <td>3.241029</td>\n",
       "      <td>1.287906</td>\n",
       "      <td>2.376184</td>\n",
       "      <td>3.148114</td>\n",
       "      <td>5.384584</td>\n",
       "      <td>10.104990</td>\n",
       "      <td>14.507016</td>\n",
       "      <td>18.551170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.272756</td>\n",
       "      <td>6.562529</td>\n",
       "      <td>3.490634</td>\n",
       "      <td>5.614873</td>\n",
       "      <td>7.262458</td>\n",
       "      <td>11.227932</td>\n",
       "      <td>17.644110</td>\n",
       "      <td>21.233719</td>\n",
       "      <td>24.014761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.428158</td>\n",
       "      <td>14.147050</td>\n",
       "      <td>12.573075</td>\n",
       "      <td>16.625309</td>\n",
       "      <td>20.459242</td>\n",
       "      <td>22.823587</td>\n",
       "      <td>30.048111</td>\n",
       "      <td>33.621944</td>\n",
       "      <td>35.424290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.644973</td>\n",
       "      <td>15.683630</td>\n",
       "      <td>13.874595</td>\n",
       "      <td>19.249443</td>\n",
       "      <td>23.257790</td>\n",
       "      <td>23.785917</td>\n",
       "      <td>31.138536</td>\n",
       "      <td>33.246929</td>\n",
       "      <td>35.445709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.078230</td>\n",
       "      <td>23.402231</td>\n",
       "      <td>21.986122</td>\n",
       "      <td>28.087221</td>\n",
       "      <td>32.493725</td>\n",
       "      <td>33.738998</td>\n",
       "      <td>36.425301</td>\n",
       "      <td>35.015198</td>\n",
       "      <td>35.553394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.211073</td>\n",
       "      <td>25.141939</td>\n",
       "      <td>24.833261</td>\n",
       "      <td>30.900679</td>\n",
       "      <td>35.270168</td>\n",
       "      <td>35.799740</td>\n",
       "      <td>37.037495</td>\n",
       "      <td>35.834381</td>\n",
       "      <td>36.955414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.067118</td>\n",
       "      <td>29.602354</td>\n",
       "      <td>30.755152</td>\n",
       "      <td>33.897537</td>\n",
       "      <td>40.410896</td>\n",
       "      <td>41.361565</td>\n",
       "      <td>44.548252</td>\n",
       "      <td>46.724224</td>\n",
       "      <td>49.580566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.376162</td>\n",
       "      <td>26.669256</td>\n",
       "      <td>26.807775</td>\n",
       "      <td>30.494371</td>\n",
       "      <td>36.461365</td>\n",
       "      <td>37.668457</td>\n",
       "      <td>40.887398</td>\n",
       "      <td>42.695232</td>\n",
       "      <td>46.218060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.786476</td>\n",
       "      <td>28.875738</td>\n",
       "      <td>29.869244</td>\n",
       "      <td>32.815174</td>\n",
       "      <td>38.795712</td>\n",
       "      <td>40.083305</td>\n",
       "      <td>42.444992</td>\n",
       "      <td>42.700863</td>\n",
       "      <td>45.866425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.911112</td>\n",
       "      <td>30.738977</td>\n",
       "      <td>31.316473</td>\n",
       "      <td>34.771198</td>\n",
       "      <td>40.845829</td>\n",
       "      <td>42.086349</td>\n",
       "      <td>44.027084</td>\n",
       "      <td>42.978596</td>\n",
       "      <td>45.314491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.016800</td>\n",
       "      <td>26.975502</td>\n",
       "      <td>28.547739</td>\n",
       "      <td>32.392788</td>\n",
       "      <td>36.418331</td>\n",
       "      <td>38.749065</td>\n",
       "      <td>41.948730</td>\n",
       "      <td>40.940372</td>\n",
       "      <td>43.411232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.593702</td>\n",
       "      <td>26.677008</td>\n",
       "      <td>28.835573</td>\n",
       "      <td>34.423058</td>\n",
       "      <td>38.647175</td>\n",
       "      <td>35.778381</td>\n",
       "      <td>44.085930</td>\n",
       "      <td>44.399563</td>\n",
       "      <td>46.623672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.964253</td>\n",
       "      <td>21.600534</td>\n",
       "      <td>22.729557</td>\n",
       "      <td>28.852413</td>\n",
       "      <td>30.699219</td>\n",
       "      <td>31.190069</td>\n",
       "      <td>36.794083</td>\n",
       "      <td>35.112286</td>\n",
       "      <td>37.316002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.977612</td>\n",
       "      <td>21.480961</td>\n",
       "      <td>21.947887</td>\n",
       "      <td>28.637560</td>\n",
       "      <td>30.733307</td>\n",
       "      <td>32.320793</td>\n",
       "      <td>37.003284</td>\n",
       "      <td>35.163448</td>\n",
       "      <td>36.936638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.281479</td>\n",
       "      <td>14.273341</td>\n",
       "      <td>15.138619</td>\n",
       "      <td>21.577694</td>\n",
       "      <td>24.499023</td>\n",
       "      <td>26.869808</td>\n",
       "      <td>31.124178</td>\n",
       "      <td>28.307659</td>\n",
       "      <td>28.849108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.026958</td>\n",
       "      <td>15.223620</td>\n",
       "      <td>15.262870</td>\n",
       "      <td>19.392023</td>\n",
       "      <td>21.988602</td>\n",
       "      <td>22.411596</td>\n",
       "      <td>27.289110</td>\n",
       "      <td>26.061188</td>\n",
       "      <td>26.733780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.916548</td>\n",
       "      <td>8.260080</td>\n",
       "      <td>7.043464</td>\n",
       "      <td>9.608108</td>\n",
       "      <td>10.759098</td>\n",
       "      <td>13.799692</td>\n",
       "      <td>17.750959</td>\n",
       "      <td>16.720861</td>\n",
       "      <td>17.592558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.840262</td>\n",
       "      <td>4.210120</td>\n",
       "      <td>4.003927</td>\n",
       "      <td>5.354518</td>\n",
       "      <td>5.963712</td>\n",
       "      <td>6.346700</td>\n",
       "      <td>11.258275</td>\n",
       "      <td>17.430828</td>\n",
       "      <td>19.706966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.757750</td>\n",
       "      <td>0.703277</td>\n",
       "      <td>1.226403</td>\n",
       "      <td>1.342828</td>\n",
       "      <td>1.526829</td>\n",
       "      <td>1.706576</td>\n",
       "      <td>1.622509</td>\n",
       "      <td>1.865260</td>\n",
       "      <td>2.416020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.326189</td>\n",
       "      <td>3.173213</td>\n",
       "      <td>4.819894</td>\n",
       "      <td>5.630947</td>\n",
       "      <td>6.236478</td>\n",
       "      <td>6.677197</td>\n",
       "      <td>7.267983</td>\n",
       "      <td>7.620594</td>\n",
       "      <td>7.828514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.298869</td>\n",
       "      <td>7.017405</td>\n",
       "      <td>10.300815</td>\n",
       "      <td>12.415505</td>\n",
       "      <td>13.126040</td>\n",
       "      <td>13.008469</td>\n",
       "      <td>14.583956</td>\n",
       "      <td>15.232357</td>\n",
       "      <td>15.779061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.188456</td>\n",
       "      <td>11.314623</td>\n",
       "      <td>15.541911</td>\n",
       "      <td>19.459030</td>\n",
       "      <td>20.975269</td>\n",
       "      <td>20.903021</td>\n",
       "      <td>22.569668</td>\n",
       "      <td>23.215626</td>\n",
       "      <td>23.620272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.833838</td>\n",
       "      <td>16.158611</td>\n",
       "      <td>21.152023</td>\n",
       "      <td>26.035425</td>\n",
       "      <td>27.607182</td>\n",
       "      <td>27.672377</td>\n",
       "      <td>29.408636</td>\n",
       "      <td>30.228176</td>\n",
       "      <td>31.103544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.604498</td>\n",
       "      <td>20.815458</td>\n",
       "      <td>26.221752</td>\n",
       "      <td>31.697289</td>\n",
       "      <td>33.372543</td>\n",
       "      <td>34.086433</td>\n",
       "      <td>35.695885</td>\n",
       "      <td>36.628212</td>\n",
       "      <td>37.656483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19.917692</td>\n",
       "      <td>24.924871</td>\n",
       "      <td>30.849857</td>\n",
       "      <td>36.970665</td>\n",
       "      <td>38.596386</td>\n",
       "      <td>38.934624</td>\n",
       "      <td>40.605331</td>\n",
       "      <td>42.111076</td>\n",
       "      <td>42.707642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21.923208</td>\n",
       "      <td>29.163145</td>\n",
       "      <td>33.655247</td>\n",
       "      <td>40.868004</td>\n",
       "      <td>42.310303</td>\n",
       "      <td>42.534214</td>\n",
       "      <td>44.642708</td>\n",
       "      <td>46.159248</td>\n",
       "      <td>46.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23.010218</td>\n",
       "      <td>31.181641</td>\n",
       "      <td>35.596489</td>\n",
       "      <td>43.316849</td>\n",
       "      <td>44.694324</td>\n",
       "      <td>44.803020</td>\n",
       "      <td>46.920273</td>\n",
       "      <td>48.450985</td>\n",
       "      <td>49.076717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22.782660</td>\n",
       "      <td>31.530386</td>\n",
       "      <td>35.421150</td>\n",
       "      <td>43.750664</td>\n",
       "      <td>44.863285</td>\n",
       "      <td>45.598801</td>\n",
       "      <td>47.575310</td>\n",
       "      <td>49.336861</td>\n",
       "      <td>49.953167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>22.545532</td>\n",
       "      <td>31.171667</td>\n",
       "      <td>35.034325</td>\n",
       "      <td>43.192429</td>\n",
       "      <td>44.352280</td>\n",
       "      <td>45.078217</td>\n",
       "      <td>47.033661</td>\n",
       "      <td>48.778484</td>\n",
       "      <td>49.447266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20.881779</td>\n",
       "      <td>28.398241</td>\n",
       "      <td>32.524193</td>\n",
       "      <td>40.500298</td>\n",
       "      <td>41.650536</td>\n",
       "      <td>42.932274</td>\n",
       "      <td>44.996521</td>\n",
       "      <td>46.787136</td>\n",
       "      <td>47.387188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>19.430773</td>\n",
       "      <td>26.794737</td>\n",
       "      <td>30.328218</td>\n",
       "      <td>37.183029</td>\n",
       "      <td>38.458012</td>\n",
       "      <td>39.661339</td>\n",
       "      <td>41.766670</td>\n",
       "      <td>43.306320</td>\n",
       "      <td>44.155334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15.969060</td>\n",
       "      <td>22.305927</td>\n",
       "      <td>26.650686</td>\n",
       "      <td>31.979155</td>\n",
       "      <td>33.148289</td>\n",
       "      <td>35.011997</td>\n",
       "      <td>37.194530</td>\n",
       "      <td>38.122833</td>\n",
       "      <td>39.301769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13.583893</td>\n",
       "      <td>19.348141</td>\n",
       "      <td>22.889086</td>\n",
       "      <td>26.744802</td>\n",
       "      <td>27.656040</td>\n",
       "      <td>29.702871</td>\n",
       "      <td>31.692385</td>\n",
       "      <td>32.130531</td>\n",
       "      <td>33.343086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9.615687</td>\n",
       "      <td>14.557113</td>\n",
       "      <td>17.864723</td>\n",
       "      <td>20.728451</td>\n",
       "      <td>21.625946</td>\n",
       "      <td>23.148029</td>\n",
       "      <td>25.084288</td>\n",
       "      <td>25.270851</td>\n",
       "      <td>26.309155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.812320</td>\n",
       "      <td>10.388501</td>\n",
       "      <td>12.657641</td>\n",
       "      <td>14.384055</td>\n",
       "      <td>15.722021</td>\n",
       "      <td>15.729008</td>\n",
       "      <td>17.588387</td>\n",
       "      <td>17.907364</td>\n",
       "      <td>18.594843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.708306</td>\n",
       "      <td>6.732769</td>\n",
       "      <td>7.701541</td>\n",
       "      <td>8.492422</td>\n",
       "      <td>8.862773</td>\n",
       "      <td>9.066749</td>\n",
       "      <td>9.681761</td>\n",
       "      <td>9.663363</td>\n",
       "      <td>9.769611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.638556</td>\n",
       "      <td>2.877656</td>\n",
       "      <td>3.170463</td>\n",
       "      <td>3.213958</td>\n",
       "      <td>3.383867</td>\n",
       "      <td>3.606323</td>\n",
       "      <td>3.275060</td>\n",
       "      <td>3.383246</td>\n",
       "      <td>3.623526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.786714</td>\n",
       "      <td>0.536858</td>\n",
       "      <td>0.504970</td>\n",
       "      <td>0.873455</td>\n",
       "      <td>1.350923</td>\n",
       "      <td>1.539912</td>\n",
       "      <td>1.962216</td>\n",
       "      <td>2.042330</td>\n",
       "      <td>2.407746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.042448</td>\n",
       "      <td>4.169839</td>\n",
       "      <td>5.667620</td>\n",
       "      <td>6.804619</td>\n",
       "      <td>7.195557</td>\n",
       "      <td>7.597142</td>\n",
       "      <td>8.421906</td>\n",
       "      <td>9.099982</td>\n",
       "      <td>9.847962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.549746</td>\n",
       "      <td>7.794083</td>\n",
       "      <td>11.858674</td>\n",
       "      <td>14.504044</td>\n",
       "      <td>15.195071</td>\n",
       "      <td>15.275701</td>\n",
       "      <td>17.068441</td>\n",
       "      <td>17.078388</td>\n",
       "      <td>17.794975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.908799</td>\n",
       "      <td>11.173594</td>\n",
       "      <td>16.166664</td>\n",
       "      <td>20.793314</td>\n",
       "      <td>22.282148</td>\n",
       "      <td>22.500118</td>\n",
       "      <td>24.342995</td>\n",
       "      <td>24.655191</td>\n",
       "      <td>25.467381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>11.451097</td>\n",
       "      <td>16.092970</td>\n",
       "      <td>21.648479</td>\n",
       "      <td>27.995142</td>\n",
       "      <td>29.333782</td>\n",
       "      <td>29.394751</td>\n",
       "      <td>31.359436</td>\n",
       "      <td>32.372837</td>\n",
       "      <td>33.063217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15.385585</td>\n",
       "      <td>20.318838</td>\n",
       "      <td>26.143160</td>\n",
       "      <td>33.313583</td>\n",
       "      <td>34.824295</td>\n",
       "      <td>35.399181</td>\n",
       "      <td>37.217781</td>\n",
       "      <td>38.745155</td>\n",
       "      <td>39.833935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>17.801308</td>\n",
       "      <td>22.874115</td>\n",
       "      <td>28.691370</td>\n",
       "      <td>36.637772</td>\n",
       "      <td>38.033218</td>\n",
       "      <td>39.106575</td>\n",
       "      <td>41.596458</td>\n",
       "      <td>43.889370</td>\n",
       "      <td>44.426842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>18.261850</td>\n",
       "      <td>25.428991</td>\n",
       "      <td>29.643919</td>\n",
       "      <td>38.509453</td>\n",
       "      <td>39.905731</td>\n",
       "      <td>42.167984</td>\n",
       "      <td>45.042347</td>\n",
       "      <td>47.370010</td>\n",
       "      <td>48.304550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>22.062460</td>\n",
       "      <td>29.681864</td>\n",
       "      <td>34.376320</td>\n",
       "      <td>43.711693</td>\n",
       "      <td>44.610043</td>\n",
       "      <td>45.236046</td>\n",
       "      <td>47.444103</td>\n",
       "      <td>49.490589</td>\n",
       "      <td>50.036873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>22.720863</td>\n",
       "      <td>31.180479</td>\n",
       "      <td>35.339661</td>\n",
       "      <td>45.061462</td>\n",
       "      <td>45.930347</td>\n",
       "      <td>47.144634</td>\n",
       "      <td>49.027893</td>\n",
       "      <td>51.092640</td>\n",
       "      <td>51.338139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          0          0          0          0          0  \\\n",
       "0    0.586329   1.294001   0.729435   1.448856   2.347870   3.072911   \n",
       "1    1.068924   3.241029   1.287906   2.376184   3.148114   5.384584   \n",
       "2    3.272756   6.562529   3.490634   5.614873   7.262458  11.227932   \n",
       "3    9.428158  14.147050  12.573075  16.625309  20.459242  22.823587   \n",
       "4   11.644973  15.683630  13.874595  19.249443  23.257790  23.785917   \n",
       "5   17.078230  23.402231  21.986122  28.087221  32.493725  33.738998   \n",
       "6   18.211073  25.141939  24.833261  30.900679  35.270168  35.799740   \n",
       "7   20.067118  29.602354  30.755152  33.897537  40.410896  41.361565   \n",
       "8   18.376162  26.669256  26.807775  30.494371  36.461365  37.668457   \n",
       "9   19.786476  28.875738  29.869244  32.815174  38.795712  40.083305   \n",
       "10  20.911112  30.738977  31.316473  34.771198  40.845829  42.086349   \n",
       "11  19.016800  26.975502  28.547739  32.392788  36.418331  38.749065   \n",
       "12  18.593702  26.677008  28.835573  34.423058  38.647175  35.778381   \n",
       "13  15.964253  21.600534  22.729557  28.852413  30.699219  31.190069   \n",
       "14  15.977612  21.480961  21.947887  28.637560  30.733307  32.320793   \n",
       "15  12.281479  14.273341  15.138619  21.577694  24.499023  26.869808   \n",
       "16  12.026958  15.223620  15.262870  19.392023  21.988602  22.411596   \n",
       "17   7.916548   8.260080   7.043464   9.608108  10.759098  13.799692   \n",
       "18   3.840262   4.210120   4.003927   5.354518   5.963712   6.346700   \n",
       "19   0.757750   0.703277   1.226403   1.342828   1.526829   1.706576   \n",
       "20   2.326189   3.173213   4.819894   5.630947   6.236478   6.677197   \n",
       "21   5.298869   7.017405  10.300815  12.415505  13.126040  13.008469   \n",
       "22   8.188456  11.314623  15.541911  19.459030  20.975269  20.903021   \n",
       "23  11.833838  16.158611  21.152023  26.035425  27.607182  27.672377   \n",
       "24  16.604498  20.815458  26.221752  31.697289  33.372543  34.086433   \n",
       "25  19.917692  24.924871  30.849857  36.970665  38.596386  38.934624   \n",
       "26  21.923208  29.163145  33.655247  40.868004  42.310303  42.534214   \n",
       "27  23.010218  31.181641  35.596489  43.316849  44.694324  44.803020   \n",
       "28  22.782660  31.530386  35.421150  43.750664  44.863285  45.598801   \n",
       "29  22.545532  31.171667  35.034325  43.192429  44.352280  45.078217   \n",
       "30  20.881779  28.398241  32.524193  40.500298  41.650536  42.932274   \n",
       "31  19.430773  26.794737  30.328218  37.183029  38.458012  39.661339   \n",
       "32  15.969060  22.305927  26.650686  31.979155  33.148289  35.011997   \n",
       "33  13.583893  19.348141  22.889086  26.744802  27.656040  29.702871   \n",
       "34   9.615687  14.557113  17.864723  20.728451  21.625946  23.148029   \n",
       "35   6.812320  10.388501  12.657641  14.384055  15.722021  15.729008   \n",
       "36   3.708306   6.732769   7.701541   8.492422   8.862773   9.066749   \n",
       "37   1.638556   2.877656   3.170463   3.213958   3.383867   3.606323   \n",
       "38   0.786714   0.536858   0.504970   0.873455   1.350923   1.539912   \n",
       "39   3.042448   4.169839   5.667620   6.804619   7.195557   7.597142   \n",
       "40   5.549746   7.794083  11.858674  14.504044  15.195071  15.275701   \n",
       "41   7.908799  11.173594  16.166664  20.793314  22.282148  22.500118   \n",
       "42  11.451097  16.092970  21.648479  27.995142  29.333782  29.394751   \n",
       "43  15.385585  20.318838  26.143160  33.313583  34.824295  35.399181   \n",
       "44  17.801308  22.874115  28.691370  36.637772  38.033218  39.106575   \n",
       "45  18.261850  25.428991  29.643919  38.509453  39.905731  42.167984   \n",
       "46  22.062460  29.681864  34.376320  43.711693  44.610043  45.236046   \n",
       "47  22.720863  31.180479  35.339661  45.061462  45.930347  47.144634   \n",
       "\n",
       "            0          0          0  \n",
       "0    4.721885   6.036065  10.198798  \n",
       "1   10.104990  14.507016  18.551170  \n",
       "2   17.644110  21.233719  24.014761  \n",
       "3   30.048111  33.621944  35.424290  \n",
       "4   31.138536  33.246929  35.445709  \n",
       "5   36.425301  35.015198  35.553394  \n",
       "6   37.037495  35.834381  36.955414  \n",
       "7   44.548252  46.724224  49.580566  \n",
       "8   40.887398  42.695232  46.218060  \n",
       "9   42.444992  42.700863  45.866425  \n",
       "10  44.027084  42.978596  45.314491  \n",
       "11  41.948730  40.940372  43.411232  \n",
       "12  44.085930  44.399563  46.623672  \n",
       "13  36.794083  35.112286  37.316002  \n",
       "14  37.003284  35.163448  36.936638  \n",
       "15  31.124178  28.307659  28.849108  \n",
       "16  27.289110  26.061188  26.733780  \n",
       "17  17.750959  16.720861  17.592558  \n",
       "18  11.258275  17.430828  19.706966  \n",
       "19   1.622509   1.865260   2.416020  \n",
       "20   7.267983   7.620594   7.828514  \n",
       "21  14.583956  15.232357  15.779061  \n",
       "22  22.569668  23.215626  23.620272  \n",
       "23  29.408636  30.228176  31.103544  \n",
       "24  35.695885  36.628212  37.656483  \n",
       "25  40.605331  42.111076  42.707642  \n",
       "26  44.642708  46.159248  46.792000  \n",
       "27  46.920273  48.450985  49.076717  \n",
       "28  47.575310  49.336861  49.953167  \n",
       "29  47.033661  48.778484  49.447266  \n",
       "30  44.996521  46.787136  47.387188  \n",
       "31  41.766670  43.306320  44.155334  \n",
       "32  37.194530  38.122833  39.301769  \n",
       "33  31.692385  32.130531  33.343086  \n",
       "34  25.084288  25.270851  26.309155  \n",
       "35  17.588387  17.907364  18.594843  \n",
       "36   9.681761   9.663363   9.769611  \n",
       "37   3.275060   3.383246   3.623526  \n",
       "38   1.962216   2.042330   2.407746  \n",
       "39   8.421906   9.099982   9.847962  \n",
       "40  17.068441  17.078388  17.794975  \n",
       "41  24.342995  24.655191  25.467381  \n",
       "42  31.359436  32.372837  33.063217  \n",
       "43  37.217781  38.745155  39.833935  \n",
       "44  41.596458  43.889370  44.426842  \n",
       "45  45.042347  47.370010  48.304550  \n",
       "46  47.444103  49.490589  50.036873  \n",
       "47  49.027893  51.092640  51.338139  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = tf.keras.Sequential([\n",
    "    layers.Conv1D(filters=128, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result8 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model8.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model8.fit(np.array(Day).reshape(25864, 1, 7), np.array(Day8).reshape(25864, 1), epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred8 = np.squeeze(model8.predict(np.array(df_test).reshape(1539, 1, 7)))\n",
    "    pred8 = pd.DataFrame(pred8)\n",
    "    result8 = pd.concat([result8, pred8], axis=1)\n",
    "    \n",
    "result8[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19398, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "403/405 [============================>.] - ETA: 0s - loss: 3.2328WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 4ms/step - loss: 3.2318 - val_loss: 3.1680\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9927 - val_loss: 3.1225\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8983 - val_loss: 3.1044\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9248 - val_loss: 3.0849\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8982 - val_loss: 3.1094\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8805 - val_loss: 3.0775\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8912 - val_loss: 3.0977\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8760 - val_loss: 3.0638\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8942 - val_loss: 3.0689\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8833 - val_loss: 3.0582\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8604 - val_loss: 3.0686\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 2.8475 - val_loss: 3.0429\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 2.8617 - val_loss: 3.0426\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 2.8259 - val_loss: 3.0945\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8666 - val_loss: 3.0406\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8451 - val_loss: 3.0573\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8043 - val_loss: 3.0463\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8280 - val_loss: 3.0417\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8442 - val_loss: 3.0443\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8185 - val_loss: 3.0792\n",
      "Epoch 00020: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.2\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "396/405 [============================>.] - ETA: 0s - loss: 4.7083WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 4.7070 - val_loss: 4.9973\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6111 - val_loss: 4.9608\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5171 - val_loss: 4.9635\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5734 - val_loss: 4.9609\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5105 - val_loss: 4.9345\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4929 - val_loss: 4.9416\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5316 - val_loss: 4.9316\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5197 - val_loss: 4.9160\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4971 - val_loss: 4.9089\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5853 - val_loss: 4.9059\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4812 - val_loss: 4.9571\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5098 - val_loss: 4.8902\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5036 - val_loss: 4.9035\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4455 - val_loss: 4.9975\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5312 - val_loss: 4.8911\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5043 - val_loss: 4.8944\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4146 - val_loss: 4.9000\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.3\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - ETA: 0s - loss: 5.4331WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 5s 5ms/step - loss: 5.4330 - val_loss: 5.8633\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3345 - val_loss: 5.8194\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3003 - val_loss: 5.7571\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3533 - val_loss: 5.7999\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2500 - val_loss: 5.7505\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2435 - val_loss: 5.7643\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3186 - val_loss: 5.7397\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3324 - val_loss: 5.7550\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2515 - val_loss: 5.7583\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3934 - val_loss: 5.7357\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2976 - val_loss: 5.8366\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3184 - val_loss: 5.7649\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2856 - val_loss: 5.7267\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2526 - val_loss: 5.8994\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3334 - val_loss: 5.7117\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 5.3367 - val_loss: 5.7505\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2266 - val_loss: 5.7235\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.1976 - val_loss: 5.7509\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3217 - val_loss: 5.6983\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2612 - val_loss: 5.7939\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2912 - val_loss: 5.7375\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2163 - val_loss: 5.7170\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2888 - val_loss: 5.7240\n",
      "Epoch 24/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2828 - val_loss: 5.7523\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.4\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "390/405 [===========================>..] - ETA: 0s - loss: 5.6105WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 5.6078 - val_loss: 5.9935\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4602 - val_loss: 6.0108\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4850 - val_loss: 5.9202\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.5372 - val_loss: 5.9628\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4017 - val_loss: 5.9245\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4210 - val_loss: 5.9419\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4778 - val_loss: 5.9519\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.5559 - val_loss: 5.9865\n",
      "Epoch 00008: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.5\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "383/405 [===========================>..] - ETA: 0s - loss: 5.3745WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 5.3700 - val_loss: 5.7057\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2195 - val_loss: 5.7620\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2561 - val_loss: 5.6622\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3028 - val_loss: 5.6701\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.1690 - val_loss: 5.6878\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.1791 - val_loss: 5.6655\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2078 - val_loss: 5.6693\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3094 - val_loss: 5.7348\n",
      "Epoch 00008: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.6\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "397/405 [============================>.] - ETA: 0s - loss: 4.7774WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 4.7758 - val_loss: 5.0799\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6336 - val_loss: 5.0643\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 4.6756 - val_loss: 5.0585\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7181 - val_loss: 5.0525\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5993 - val_loss: 5.0372\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6023 - val_loss: 5.0875\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6234 - val_loss: 5.0678\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7050 - val_loss: 5.0647\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6121 - val_loss: 5.0716\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7415 - val_loss: 5.0500\n",
      "Epoch 00010: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.7\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "395/405 [============================>.] - ETA: 0s - loss: 3.8910WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 3.8896 - val_loss: 4.1655\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7880 - val_loss: 4.1622\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.8267 - val_loss: 4.2024\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.8939 - val_loss: 4.1590\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7678 - val_loss: 4.1689\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7814 - val_loss: 4.1833\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7783 - val_loss: 4.1678\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.8621 - val_loss: 4.1666\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7866 - val_loss: 4.1491\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.8763 - val_loss: 4.1689\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.8106 - val_loss: 4.1510\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.8147 - val_loss: 4.1535\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7643 - val_loss: 4.1655\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7617 - val_loss: 4.2266\n",
      "Epoch 00014: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.8\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "391/405 [===========================>..] - ETA: 0s - loss: 2.8027WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 2.8018 - val_loss: 3.0203\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7414 - val_loss: 3.0195\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7915 - val_loss: 3.0404\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8136 - val_loss: 3.0308\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7356 - val_loss: 3.0243\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7465 - val_loss: 3.0345\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7514 - val_loss: 3.0367\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.9\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "393/405 [============================>.] - ETA: 0s - loss: 1.5632WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 1.5625 - val_loss: 1.6896\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5282 - val_loss: 1.6732\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5467 - val_loss: 1.6965\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5662 - val_loss: 1.6868\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5222 - val_loss: 1.6917\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5186 - val_loss: 1.6651\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5276 - val_loss: 1.6831\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5562 - val_loss: 1.6951\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5256 - val_loss: 1.6602\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5459 - val_loss: 1.6858\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5154 - val_loss: 1.6755\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5262 - val_loss: 1.6563\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5131 - val_loss: 1.6584\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5098 - val_loss: 1.6880\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5389 - val_loss: 1.6454\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 1.5372 - val_loss: 1.6602\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5041 - val_loss: 1.6562\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 1.5301 - val_loss: 1.6880\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 1s 4ms/step - loss: 1.5448 - val_loss: 1.6766\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5223 - val_loss: 1.6800\n",
      "Epoch 00020: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_2_input'), name='gru_2_input', description=\"created by layer 'gru_2_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121911</td>\n",
       "      <td>0.226862</td>\n",
       "      <td>0.534474</td>\n",
       "      <td>1.266406</td>\n",
       "      <td>1.198680</td>\n",
       "      <td>2.155460</td>\n",
       "      <td>3.967098</td>\n",
       "      <td>4.866168</td>\n",
       "      <td>9.765275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.569337</td>\n",
       "      <td>3.137635</td>\n",
       "      <td>3.747150</td>\n",
       "      <td>5.324252</td>\n",
       "      <td>5.181961</td>\n",
       "      <td>6.430194</td>\n",
       "      <td>8.956088</td>\n",
       "      <td>11.151604</td>\n",
       "      <td>21.188997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.182567</td>\n",
       "      <td>5.536314</td>\n",
       "      <td>5.541616</td>\n",
       "      <td>7.118532</td>\n",
       "      <td>7.107107</td>\n",
       "      <td>8.560990</td>\n",
       "      <td>12.548880</td>\n",
       "      <td>15.733072</td>\n",
       "      <td>27.756762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.672319</td>\n",
       "      <td>10.510928</td>\n",
       "      <td>12.000305</td>\n",
       "      <td>15.141517</td>\n",
       "      <td>15.697982</td>\n",
       "      <td>18.082352</td>\n",
       "      <td>22.420256</td>\n",
       "      <td>27.264629</td>\n",
       "      <td>42.049759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.302238</td>\n",
       "      <td>13.373036</td>\n",
       "      <td>13.624437</td>\n",
       "      <td>16.564363</td>\n",
       "      <td>17.613810</td>\n",
       "      <td>19.975491</td>\n",
       "      <td>24.753204</td>\n",
       "      <td>28.639999</td>\n",
       "      <td>41.642868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.478213</td>\n",
       "      <td>21.569414</td>\n",
       "      <td>18.941748</td>\n",
       "      <td>22.939217</td>\n",
       "      <td>26.432163</td>\n",
       "      <td>31.043766</td>\n",
       "      <td>35.111755</td>\n",
       "      <td>34.749157</td>\n",
       "      <td>37.664337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.519293</td>\n",
       "      <td>22.535355</td>\n",
       "      <td>19.508646</td>\n",
       "      <td>23.623806</td>\n",
       "      <td>28.605448</td>\n",
       "      <td>34.125328</td>\n",
       "      <td>37.456612</td>\n",
       "      <td>36.800533</td>\n",
       "      <td>38.413773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.922230</td>\n",
       "      <td>26.200846</td>\n",
       "      <td>26.188810</td>\n",
       "      <td>30.728432</td>\n",
       "      <td>32.684372</td>\n",
       "      <td>38.773342</td>\n",
       "      <td>42.374115</td>\n",
       "      <td>41.599808</td>\n",
       "      <td>46.399887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.194141</td>\n",
       "      <td>23.288677</td>\n",
       "      <td>26.246469</td>\n",
       "      <td>30.836456</td>\n",
       "      <td>31.255783</td>\n",
       "      <td>36.242390</td>\n",
       "      <td>39.390411</td>\n",
       "      <td>38.494053</td>\n",
       "      <td>45.065361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.157064</td>\n",
       "      <td>24.299212</td>\n",
       "      <td>28.692219</td>\n",
       "      <td>31.761734</td>\n",
       "      <td>31.676521</td>\n",
       "      <td>37.316566</td>\n",
       "      <td>38.922333</td>\n",
       "      <td>37.411091</td>\n",
       "      <td>42.480476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.393974</td>\n",
       "      <td>26.167618</td>\n",
       "      <td>26.848448</td>\n",
       "      <td>30.062077</td>\n",
       "      <td>31.605545</td>\n",
       "      <td>37.975342</td>\n",
       "      <td>40.853584</td>\n",
       "      <td>39.528065</td>\n",
       "      <td>41.361061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.314877</td>\n",
       "      <td>24.730989</td>\n",
       "      <td>28.147177</td>\n",
       "      <td>29.525522</td>\n",
       "      <td>30.093800</td>\n",
       "      <td>36.267780</td>\n",
       "      <td>37.971558</td>\n",
       "      <td>36.209438</td>\n",
       "      <td>39.996712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.921762</td>\n",
       "      <td>20.252348</td>\n",
       "      <td>27.881838</td>\n",
       "      <td>29.216999</td>\n",
       "      <td>29.863659</td>\n",
       "      <td>38.223576</td>\n",
       "      <td>38.675468</td>\n",
       "      <td>37.359432</td>\n",
       "      <td>49.664555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.436353</td>\n",
       "      <td>21.404657</td>\n",
       "      <td>24.663013</td>\n",
       "      <td>24.237591</td>\n",
       "      <td>25.297379</td>\n",
       "      <td>32.303993</td>\n",
       "      <td>33.941605</td>\n",
       "      <td>32.047531</td>\n",
       "      <td>37.069763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.205865</td>\n",
       "      <td>22.012386</td>\n",
       "      <td>24.526209</td>\n",
       "      <td>24.404978</td>\n",
       "      <td>25.586823</td>\n",
       "      <td>32.116493</td>\n",
       "      <td>33.783577</td>\n",
       "      <td>32.032070</td>\n",
       "      <td>34.808895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.243544</td>\n",
       "      <td>19.842676</td>\n",
       "      <td>20.043743</td>\n",
       "      <td>19.632454</td>\n",
       "      <td>20.839163</td>\n",
       "      <td>27.015785</td>\n",
       "      <td>28.677553</td>\n",
       "      <td>27.397989</td>\n",
       "      <td>27.836548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.796278</td>\n",
       "      <td>15.556635</td>\n",
       "      <td>17.240673</td>\n",
       "      <td>15.963878</td>\n",
       "      <td>16.503349</td>\n",
       "      <td>22.852955</td>\n",
       "      <td>26.531889</td>\n",
       "      <td>25.077524</td>\n",
       "      <td>30.630814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.414473</td>\n",
       "      <td>8.358117</td>\n",
       "      <td>9.143270</td>\n",
       "      <td>7.253511</td>\n",
       "      <td>6.536629</td>\n",
       "      <td>9.757400</td>\n",
       "      <td>15.062081</td>\n",
       "      <td>14.781587</td>\n",
       "      <td>21.702719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.019074</td>\n",
       "      <td>3.761675</td>\n",
       "      <td>5.429780</td>\n",
       "      <td>3.812401</td>\n",
       "      <td>3.107320</td>\n",
       "      <td>4.275603</td>\n",
       "      <td>8.295963</td>\n",
       "      <td>8.134643</td>\n",
       "      <td>15.400671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.247885</td>\n",
       "      <td>-0.319165</td>\n",
       "      <td>0.770526</td>\n",
       "      <td>1.065159</td>\n",
       "      <td>1.354057</td>\n",
       "      <td>1.690412</td>\n",
       "      <td>1.623821</td>\n",
       "      <td>1.989984</td>\n",
       "      <td>1.933169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.621806</td>\n",
       "      <td>4.982972</td>\n",
       "      <td>5.769222</td>\n",
       "      <td>6.104049</td>\n",
       "      <td>6.197420</td>\n",
       "      <td>6.984417</td>\n",
       "      <td>7.177075</td>\n",
       "      <td>7.861549</td>\n",
       "      <td>7.792755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.523142</td>\n",
       "      <td>10.934595</td>\n",
       "      <td>12.071514</td>\n",
       "      <td>12.308875</td>\n",
       "      <td>12.631379</td>\n",
       "      <td>14.570249</td>\n",
       "      <td>14.971581</td>\n",
       "      <td>16.104748</td>\n",
       "      <td>15.665381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.053761</td>\n",
       "      <td>16.136246</td>\n",
       "      <td>19.616751</td>\n",
       "      <td>19.698488</td>\n",
       "      <td>20.138948</td>\n",
       "      <td>22.083744</td>\n",
       "      <td>22.630400</td>\n",
       "      <td>23.437082</td>\n",
       "      <td>23.882532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16.023119</td>\n",
       "      <td>20.881710</td>\n",
       "      <td>26.263472</td>\n",
       "      <td>26.884937</td>\n",
       "      <td>27.013615</td>\n",
       "      <td>29.674286</td>\n",
       "      <td>29.554893</td>\n",
       "      <td>29.736917</td>\n",
       "      <td>31.443598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.808369</td>\n",
       "      <td>26.378338</td>\n",
       "      <td>31.873724</td>\n",
       "      <td>32.015759</td>\n",
       "      <td>32.915684</td>\n",
       "      <td>36.501209</td>\n",
       "      <td>35.583298</td>\n",
       "      <td>35.419842</td>\n",
       "      <td>37.763214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21.968678</td>\n",
       "      <td>31.291170</td>\n",
       "      <td>37.085251</td>\n",
       "      <td>36.377300</td>\n",
       "      <td>38.131863</td>\n",
       "      <td>41.732937</td>\n",
       "      <td>40.430626</td>\n",
       "      <td>40.271893</td>\n",
       "      <td>42.614044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>22.803713</td>\n",
       "      <td>34.651031</td>\n",
       "      <td>40.558849</td>\n",
       "      <td>39.788578</td>\n",
       "      <td>41.985428</td>\n",
       "      <td>45.588062</td>\n",
       "      <td>44.327019</td>\n",
       "      <td>44.331238</td>\n",
       "      <td>46.444283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24.055904</td>\n",
       "      <td>36.681175</td>\n",
       "      <td>42.537769</td>\n",
       "      <td>41.974407</td>\n",
       "      <td>44.476101</td>\n",
       "      <td>47.766636</td>\n",
       "      <td>46.755203</td>\n",
       "      <td>46.672588</td>\n",
       "      <td>48.781582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23.005795</td>\n",
       "      <td>36.411755</td>\n",
       "      <td>42.917736</td>\n",
       "      <td>42.463272</td>\n",
       "      <td>45.387257</td>\n",
       "      <td>48.689884</td>\n",
       "      <td>47.875996</td>\n",
       "      <td>47.775372</td>\n",
       "      <td>49.875072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>22.759426</td>\n",
       "      <td>35.963081</td>\n",
       "      <td>42.439884</td>\n",
       "      <td>41.935337</td>\n",
       "      <td>44.812408</td>\n",
       "      <td>48.245426</td>\n",
       "      <td>47.370770</td>\n",
       "      <td>47.307003</td>\n",
       "      <td>49.417213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20.133827</td>\n",
       "      <td>33.269501</td>\n",
       "      <td>40.221851</td>\n",
       "      <td>39.617840</td>\n",
       "      <td>42.408390</td>\n",
       "      <td>46.453049</td>\n",
       "      <td>45.412987</td>\n",
       "      <td>45.524799</td>\n",
       "      <td>47.576416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>18.286421</td>\n",
       "      <td>30.656595</td>\n",
       "      <td>37.071316</td>\n",
       "      <td>36.582897</td>\n",
       "      <td>38.969475</td>\n",
       "      <td>43.294544</td>\n",
       "      <td>41.937759</td>\n",
       "      <td>42.223377</td>\n",
       "      <td>44.174637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14.429367</td>\n",
       "      <td>25.926832</td>\n",
       "      <td>32.192188</td>\n",
       "      <td>32.284737</td>\n",
       "      <td>34.406620</td>\n",
       "      <td>38.849873</td>\n",
       "      <td>37.307381</td>\n",
       "      <td>37.673859</td>\n",
       "      <td>39.584984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>11.876534</td>\n",
       "      <td>21.912779</td>\n",
       "      <td>27.405752</td>\n",
       "      <td>27.862442</td>\n",
       "      <td>29.028160</td>\n",
       "      <td>32.880108</td>\n",
       "      <td>31.780020</td>\n",
       "      <td>31.929800</td>\n",
       "      <td>33.977402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8.672022</td>\n",
       "      <td>16.510712</td>\n",
       "      <td>21.281858</td>\n",
       "      <td>21.666094</td>\n",
       "      <td>22.483128</td>\n",
       "      <td>25.633274</td>\n",
       "      <td>25.221266</td>\n",
       "      <td>25.435511</td>\n",
       "      <td>26.437605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.630116</td>\n",
       "      <td>12.254563</td>\n",
       "      <td>15.065763</td>\n",
       "      <td>15.016889</td>\n",
       "      <td>15.311061</td>\n",
       "      <td>17.370718</td>\n",
       "      <td>17.992468</td>\n",
       "      <td>18.600275</td>\n",
       "      <td>18.480204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.310253</td>\n",
       "      <td>7.478538</td>\n",
       "      <td>8.921449</td>\n",
       "      <td>8.280861</td>\n",
       "      <td>8.304685</td>\n",
       "      <td>9.623860</td>\n",
       "      <td>10.230453</td>\n",
       "      <td>10.548506</td>\n",
       "      <td>10.304486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.935596</td>\n",
       "      <td>2.385882</td>\n",
       "      <td>2.980807</td>\n",
       "      <td>2.356578</td>\n",
       "      <td>2.338274</td>\n",
       "      <td>2.589768</td>\n",
       "      <td>2.986497</td>\n",
       "      <td>3.098582</td>\n",
       "      <td>3.157816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.603994</td>\n",
       "      <td>0.663951</td>\n",
       "      <td>0.661553</td>\n",
       "      <td>0.990961</td>\n",
       "      <td>1.141060</td>\n",
       "      <td>1.634629</td>\n",
       "      <td>2.328205</td>\n",
       "      <td>2.493169</td>\n",
       "      <td>2.481506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.544197</td>\n",
       "      <td>5.282506</td>\n",
       "      <td>5.985143</td>\n",
       "      <td>5.945423</td>\n",
       "      <td>6.106964</td>\n",
       "      <td>7.285741</td>\n",
       "      <td>7.744471</td>\n",
       "      <td>8.622944</td>\n",
       "      <td>8.750995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8.270996</td>\n",
       "      <td>11.643580</td>\n",
       "      <td>13.554329</td>\n",
       "      <td>13.685773</td>\n",
       "      <td>14.263503</td>\n",
       "      <td>16.244547</td>\n",
       "      <td>16.794725</td>\n",
       "      <td>17.894476</td>\n",
       "      <td>17.885265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.544451</td>\n",
       "      <td>15.721512</td>\n",
       "      <td>19.678236</td>\n",
       "      <td>19.918026</td>\n",
       "      <td>20.645847</td>\n",
       "      <td>22.759619</td>\n",
       "      <td>23.493448</td>\n",
       "      <td>24.288671</td>\n",
       "      <td>25.205109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>13.813389</td>\n",
       "      <td>20.132185</td>\n",
       "      <td>26.221079</td>\n",
       "      <td>27.177435</td>\n",
       "      <td>27.819090</td>\n",
       "      <td>31.130928</td>\n",
       "      <td>30.900286</td>\n",
       "      <td>31.252874</td>\n",
       "      <td>33.253918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15.491955</td>\n",
       "      <td>24.230431</td>\n",
       "      <td>30.956024</td>\n",
       "      <td>31.748957</td>\n",
       "      <td>33.662613</td>\n",
       "      <td>37.833481</td>\n",
       "      <td>36.859207</td>\n",
       "      <td>37.187359</td>\n",
       "      <td>39.380211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>16.049561</td>\n",
       "      <td>25.992535</td>\n",
       "      <td>33.037937</td>\n",
       "      <td>33.348385</td>\n",
       "      <td>36.310883</td>\n",
       "      <td>40.834885</td>\n",
       "      <td>40.226185</td>\n",
       "      <td>41.383572</td>\n",
       "      <td>43.815002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>14.967532</td>\n",
       "      <td>24.492773</td>\n",
       "      <td>34.105629</td>\n",
       "      <td>34.272217</td>\n",
       "      <td>37.910488</td>\n",
       "      <td>43.078411</td>\n",
       "      <td>42.931160</td>\n",
       "      <td>44.545277</td>\n",
       "      <td>47.527428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.129889</td>\n",
       "      <td>31.600901</td>\n",
       "      <td>41.096424</td>\n",
       "      <td>40.940048</td>\n",
       "      <td>44.487560</td>\n",
       "      <td>48.364273</td>\n",
       "      <td>47.748718</td>\n",
       "      <td>48.246861</td>\n",
       "      <td>50.767487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>19.347311</td>\n",
       "      <td>32.535366</td>\n",
       "      <td>42.816219</td>\n",
       "      <td>42.942509</td>\n",
       "      <td>46.911076</td>\n",
       "      <td>50.318043</td>\n",
       "      <td>49.804218</td>\n",
       "      <td>49.885921</td>\n",
       "      <td>52.336914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          0          0          0          0          0  \\\n",
       "0    0.121911   0.226862   0.534474   1.266406   1.198680   2.155460   \n",
       "1    1.569337   3.137635   3.747150   5.324252   5.181961   6.430194   \n",
       "2    3.182567   5.536314   5.541616   7.118532   7.107107   8.560990   \n",
       "3    5.672319  10.510928  12.000305  15.141517  15.697982  18.082352   \n",
       "4    8.302238  13.373036  13.624437  16.564363  17.613810  19.975491   \n",
       "5   15.478213  21.569414  18.941748  22.939217  26.432163  31.043766   \n",
       "6   17.519293  22.535355  19.508646  23.623806  28.605448  34.125328   \n",
       "7   16.922230  26.200846  26.188810  30.728432  32.684372  38.773342   \n",
       "8   14.194141  23.288677  26.246469  30.836456  31.255783  36.242390   \n",
       "9   14.157064  24.299212  28.692219  31.761734  31.676521  37.316566   \n",
       "10  16.393974  26.167618  26.848448  30.062077  31.605545  37.975342   \n",
       "11  14.314877  24.730989  28.147177  29.525522  30.093800  36.267780   \n",
       "12   9.921762  20.252348  27.881838  29.216999  29.863659  38.223576   \n",
       "13  11.436353  21.404657  24.663013  24.237591  25.297379  32.303993   \n",
       "14  12.205865  22.012386  24.526209  24.404978  25.586823  32.116493   \n",
       "15  11.243544  19.842676  20.043743  19.632454  20.839163  27.015785   \n",
       "16   7.796278  15.556635  17.240673  15.963878  16.503349  22.852955   \n",
       "17   4.414473   8.358117   9.143270   7.253511   6.536629   9.757400   \n",
       "18   2.019074   3.761675   5.429780   3.812401   3.107320   4.275603   \n",
       "19   0.247885  -0.319165   0.770526   1.065159   1.354057   1.690412   \n",
       "20   3.621806   4.982972   5.769222   6.104049   6.197420   6.984417   \n",
       "21   8.523142  10.934595  12.071514  12.308875  12.631379  14.570249   \n",
       "22  12.053761  16.136246  19.616751  19.698488  20.138948  22.083744   \n",
       "23  16.023119  20.881710  26.263472  26.884937  27.013615  29.674286   \n",
       "24  18.808369  26.378338  31.873724  32.015759  32.915684  36.501209   \n",
       "25  21.968678  31.291170  37.085251  36.377300  38.131863  41.732937   \n",
       "26  22.803713  34.651031  40.558849  39.788578  41.985428  45.588062   \n",
       "27  24.055904  36.681175  42.537769  41.974407  44.476101  47.766636   \n",
       "28  23.005795  36.411755  42.917736  42.463272  45.387257  48.689884   \n",
       "29  22.759426  35.963081  42.439884  41.935337  44.812408  48.245426   \n",
       "30  20.133827  33.269501  40.221851  39.617840  42.408390  46.453049   \n",
       "31  18.286421  30.656595  37.071316  36.582897  38.969475  43.294544   \n",
       "32  14.429367  25.926832  32.192188  32.284737  34.406620  38.849873   \n",
       "33  11.876534  21.912779  27.405752  27.862442  29.028160  32.880108   \n",
       "34   8.672022  16.510712  21.281858  21.666094  22.483128  25.633274   \n",
       "35   6.630116  12.254563  15.065763  15.016889  15.311061  17.370718   \n",
       "36   4.310253   7.478538   8.921449   8.280861   8.304685   9.623860   \n",
       "37   1.935596   2.385882   2.980807   2.356578   2.338274   2.589768   \n",
       "38   0.603994   0.663951   0.661553   0.990961   1.141060   1.634629   \n",
       "39   3.544197   5.282506   5.985143   5.945423   6.106964   7.285741   \n",
       "40   8.270996  11.643580  13.554329  13.685773  14.263503  16.244547   \n",
       "41  10.544451  15.721512  19.678236  19.918026  20.645847  22.759619   \n",
       "42  13.813389  20.132185  26.221079  27.177435  27.819090  31.130928   \n",
       "43  15.491955  24.230431  30.956024  31.748957  33.662613  37.833481   \n",
       "44  16.049561  25.992535  33.037937  33.348385  36.310883  40.834885   \n",
       "45  14.967532  24.492773  34.105629  34.272217  37.910488  43.078411   \n",
       "46  19.129889  31.600901  41.096424  40.940048  44.487560  48.364273   \n",
       "47  19.347311  32.535366  42.816219  42.942509  46.911076  50.318043   \n",
       "\n",
       "            0          0          0  \n",
       "0    3.967098   4.866168   9.765275  \n",
       "1    8.956088  11.151604  21.188997  \n",
       "2   12.548880  15.733072  27.756762  \n",
       "3   22.420256  27.264629  42.049759  \n",
       "4   24.753204  28.639999  41.642868  \n",
       "5   35.111755  34.749157  37.664337  \n",
       "6   37.456612  36.800533  38.413773  \n",
       "7   42.374115  41.599808  46.399887  \n",
       "8   39.390411  38.494053  45.065361  \n",
       "9   38.922333  37.411091  42.480476  \n",
       "10  40.853584  39.528065  41.361061  \n",
       "11  37.971558  36.209438  39.996712  \n",
       "12  38.675468  37.359432  49.664555  \n",
       "13  33.941605  32.047531  37.069763  \n",
       "14  33.783577  32.032070  34.808895  \n",
       "15  28.677553  27.397989  27.836548  \n",
       "16  26.531889  25.077524  30.630814  \n",
       "17  15.062081  14.781587  21.702719  \n",
       "18   8.295963   8.134643  15.400671  \n",
       "19   1.623821   1.989984   1.933169  \n",
       "20   7.177075   7.861549   7.792755  \n",
       "21  14.971581  16.104748  15.665381  \n",
       "22  22.630400  23.437082  23.882532  \n",
       "23  29.554893  29.736917  31.443598  \n",
       "24  35.583298  35.419842  37.763214  \n",
       "25  40.430626  40.271893  42.614044  \n",
       "26  44.327019  44.331238  46.444283  \n",
       "27  46.755203  46.672588  48.781582  \n",
       "28  47.875996  47.775372  49.875072  \n",
       "29  47.370770  47.307003  49.417213  \n",
       "30  45.412987  45.524799  47.576416  \n",
       "31  41.937759  42.223377  44.174637  \n",
       "32  37.307381  37.673859  39.584984  \n",
       "33  31.780020  31.929800  33.977402  \n",
       "34  25.221266  25.435511  26.437605  \n",
       "35  17.992468  18.600275  18.480204  \n",
       "36  10.230453  10.548506  10.304486  \n",
       "37   2.986497   3.098582   3.157816  \n",
       "38   2.328205   2.493169   2.481506  \n",
       "39   7.744471   8.622944   8.750995  \n",
       "40  16.794725  17.894476  17.885265  \n",
       "41  23.493448  24.288671  25.205109  \n",
       "42  30.900286  31.252874  33.253918  \n",
       "43  36.859207  37.187359  39.380211  \n",
       "44  40.226185  41.383572  43.815002  \n",
       "45  42.931160  44.545277  47.527428  \n",
       "46  47.748718  48.246861  50.767487  \n",
       "47  49.804218  49.885921  52.336914  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_G7 = tf.keras.Sequential([\n",
    "    layers.GRU(units=64, return_sequences=True, input_shape=[25864, 7]),\n",
    "    layers.GRU(units=32),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result_G7 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model_G7.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model_G7.fit(np.array(Day).reshape(25864, 1, 7), np.array(Day7).reshape(25864, 1)\n",
    "                 , epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred_G7 = np.squeeze(model_G7.predict(np.array(df_test).reshape(1539, 1, 7)))\n",
    "    pred_G7 = pd.DataFrame(pred_G7)\n",
    "    result_G7 = pd.concat([result_G7, pred_G7], axis=1)\n",
    "    \n",
    "result_G7[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "393/405 [============================>.] - ETA: 0s - loss: 3.2477WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 3.2432 - val_loss: 3.1679\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9946 - val_loss: 3.1242\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8993 - val_loss: 3.1079\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9253 - val_loss: 3.0849\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8981 - val_loss: 3.1015\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8797 - val_loss: 3.0725\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8900 - val_loss: 3.0933\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8754 - val_loss: 3.0638\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8933 - val_loss: 3.0674\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8798 - val_loss: 3.0508\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8590 - val_loss: 3.0653\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8434 - val_loss: 3.0419\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8589 - val_loss: 3.0443\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8242 - val_loss: 3.1109\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8663 - val_loss: 3.0412\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8446 - val_loss: 3.0462\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8056 - val_loss: 3.0325\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8283 - val_loss: 3.0435\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8460 - val_loss: 3.0471\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8205 - val_loss: 3.0747\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8333 - val_loss: 3.0297\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8217 - val_loss: 3.0422\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8538 - val_loss: 3.0156\n",
      "Epoch 24/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8465 - val_loss: 3.0219\n",
      "Epoch 25/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8170 - val_loss: 3.0671\n",
      "Epoch 26/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 2.8323 - val_loss: 3.0283\n",
      "Epoch 27/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 2.8473 - val_loss: 3.0420\n",
      "Epoch 28/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 2.8122 - val_loss: 3.0328\n",
      "Epoch 00028: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.2\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "396/405 [============================>.] - ETA: 0s - loss: 4.6831WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 4.6818 - val_loss: 4.9788\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5874 - val_loss: 4.9440\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4999 - val_loss: 4.9449\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5603 - val_loss: 4.9507\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4977 - val_loss: 4.9259\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4748 - val_loss: 4.9381\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5229 - val_loss: 4.9233\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5167 - val_loss: 4.9065\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4857 - val_loss: 4.8994\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5780 - val_loss: 4.9037\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4776 - val_loss: 4.9627\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5071 - val_loss: 4.8927\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4996 - val_loss: 4.9028\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4431 - val_loss: 4.9775\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5252 - val_loss: 4.8822\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5029 - val_loss: 4.9004\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4183 - val_loss: 4.8935\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4291 - val_loss: 4.9072\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5102 - val_loss: 4.8744\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 4.4659 - val_loss: 4.9284\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 4.4717 - val_loss: 4.8849\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4394 - val_loss: 4.8758\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4981 - val_loss: 4.8692\n",
      "Epoch 24/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4762 - val_loss: 4.8901\n",
      "Epoch 25/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4295 - val_loss: 4.9487\n",
      "Epoch 26/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4649 - val_loss: 4.8773\n",
      "Epoch 27/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5135 - val_loss: 4.8988\n",
      "Epoch 28/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4277 - val_loss: 4.8640\n",
      "Epoch 29/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4589 - val_loss: 4.8765\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4831 - val_loss: 4.9005\n",
      "Epoch 31/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4706 - val_loss: 4.8641\n",
      "Epoch 32/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4718 - val_loss: 4.8887\n",
      "Epoch 33/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.4338 - val_loss: 4.8873\n",
      "Epoch 00033: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.3\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "386/405 [===========================>..] - ETA: 0s - loss: 5.3802WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 5.3780 - val_loss: 5.7894\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2790 - val_loss: 5.7942\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2549 - val_loss: 5.7440\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3223 - val_loss: 5.7567\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2190 - val_loss: 5.7193\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 5.2136 - val_loss: 5.7471\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 5.2914 - val_loss: 5.7369\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3103 - val_loss: 5.7546\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2202 - val_loss: 5.7334\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3752 - val_loss: 5.7316\n",
      "Epoch 00010: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.4\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "385/405 [===========================>..] - ETA: 0s - loss: 5.6162WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 5.6129 - val_loss: 6.0044\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4738 - val_loss: 6.0280\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 5.4922 - val_loss: 5.9480\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.5377 - val_loss: 5.9582\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4095 - val_loss: 5.9422\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4246 - val_loss: 5.9352\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4829 - val_loss: 5.9547\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.5610 - val_loss: 5.9989\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 5.4370 - val_loss: 5.9810\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.5997 - val_loss: 5.9563\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4924 - val_loss: 5.9682\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.5\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "389/405 [===========================>..] - ETA: 0s - loss: 5.3415WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 4ms/step - loss: 5.3387 - val_loss: 5.7027\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2016 - val_loss: 5.7167\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2315 - val_loss: 5.6706\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.2925 - val_loss: 5.6553\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.1586 - val_loss: 5.7034\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.1623 - val_loss: 5.6895\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.1959 - val_loss: 5.6997\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3004 - val_loss: 5.7340\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.1807 - val_loss: 5.6900\n",
      "Epoch 00009: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.6\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/405 [============================>.] - ETA: 0s - loss: 4.7387WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 4.7372 - val_loss: 5.0468\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6068 - val_loss: 5.0652\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6567 - val_loss: 5.0926\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7156 - val_loss: 5.0579\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5778 - val_loss: 5.0322\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5940 - val_loss: 5.0792\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6078 - val_loss: 5.0900\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6953 - val_loss: 5.1087\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6006 - val_loss: 5.0633\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7204 - val_loss: 5.0593\n",
      "Epoch 00010: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.7\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "400/405 [============================>.] - ETA: 0s - loss: 3.8819WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 3.8812 - val_loss: 4.1661\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7818 - val_loss: 4.1727\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.8212 - val_loss: 4.2351\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.8851 - val_loss: 4.1967\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7569 - val_loss: 4.1990\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.7728 - val_loss: 4.1734\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.8\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "394/405 [============================>.] - ETA: 0s - loss: 2.8148WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 5s 5ms/step - loss: 2.8140 - val_loss: 3.0479\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7542 - val_loss: 3.0492\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7929 - val_loss: 3.0876\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 2.8249 - val_loss: 3.0706\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7308 - val_loss: 3.0155\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7504 - val_loss: 3.0375\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7574 - val_loss: 3.0325\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8000 - val_loss: 3.0292\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7489 - val_loss: 3.0357\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8062 - val_loss: 3.0500\n",
      "Epoch 00010: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "0.9\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "404/405 [============================>.] - ETA: 0s - loss: 1.5691WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 1.5690 - val_loss: 1.6799\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5280 - val_loss: 1.6983\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5548 - val_loss: 1.6955\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5636 - val_loss: 1.6888\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5267 - val_loss: 1.6750\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5252 - val_loss: 1.6619\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5318 - val_loss: 1.6819\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5560 - val_loss: 1.7128\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5295 - val_loss: 1.6678\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5541 - val_loss: 1.6876\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5270 - val_loss: 1.6818\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 7), dtype=tf.float32, name='gru_4_input'), name='gru_4_input', description=\"created by layer 'gru_4_input'\"), but it was called on an input with incompatible shape (None, 1, 7).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.118148</td>\n",
       "      <td>0.728983</td>\n",
       "      <td>0.971046</td>\n",
       "      <td>1.047962</td>\n",
       "      <td>1.551056</td>\n",
       "      <td>1.912070</td>\n",
       "      <td>3.364514</td>\n",
       "      <td>3.760700</td>\n",
       "      <td>9.617659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.108285</td>\n",
       "      <td>3.865702</td>\n",
       "      <td>5.232843</td>\n",
       "      <td>4.985348</td>\n",
       "      <td>5.321519</td>\n",
       "      <td>5.507869</td>\n",
       "      <td>8.577897</td>\n",
       "      <td>9.602978</td>\n",
       "      <td>20.866327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.490887</td>\n",
       "      <td>5.952147</td>\n",
       "      <td>7.677533</td>\n",
       "      <td>7.011625</td>\n",
       "      <td>8.140335</td>\n",
       "      <td>7.945873</td>\n",
       "      <td>12.429950</td>\n",
       "      <td>13.378427</td>\n",
       "      <td>25.929480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.716012</td>\n",
       "      <td>11.917788</td>\n",
       "      <td>16.408276</td>\n",
       "      <td>14.359765</td>\n",
       "      <td>15.824986</td>\n",
       "      <td>16.535480</td>\n",
       "      <td>23.286322</td>\n",
       "      <td>24.471409</td>\n",
       "      <td>38.971222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.901226</td>\n",
       "      <td>13.708292</td>\n",
       "      <td>18.273079</td>\n",
       "      <td>15.512778</td>\n",
       "      <td>18.995520</td>\n",
       "      <td>19.388699</td>\n",
       "      <td>25.850063</td>\n",
       "      <td>25.775200</td>\n",
       "      <td>38.998653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.192307</td>\n",
       "      <td>18.357838</td>\n",
       "      <td>26.428158</td>\n",
       "      <td>23.099239</td>\n",
       "      <td>30.649914</td>\n",
       "      <td>31.986101</td>\n",
       "      <td>36.528770</td>\n",
       "      <td>33.668385</td>\n",
       "      <td>36.662949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.504175</td>\n",
       "      <td>17.855955</td>\n",
       "      <td>25.263275</td>\n",
       "      <td>25.149977</td>\n",
       "      <td>33.660610</td>\n",
       "      <td>35.402031</td>\n",
       "      <td>39.250977</td>\n",
       "      <td>36.593620</td>\n",
       "      <td>37.442463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.584247</td>\n",
       "      <td>25.247437</td>\n",
       "      <td>36.553349</td>\n",
       "      <td>31.754292</td>\n",
       "      <td>35.200638</td>\n",
       "      <td>37.874706</td>\n",
       "      <td>42.947632</td>\n",
       "      <td>40.218739</td>\n",
       "      <td>46.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.491407</td>\n",
       "      <td>24.585892</td>\n",
       "      <td>35.093590</td>\n",
       "      <td>30.945068</td>\n",
       "      <td>31.756310</td>\n",
       "      <td>33.964745</td>\n",
       "      <td>39.470657</td>\n",
       "      <td>36.203442</td>\n",
       "      <td>46.159149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.213213</td>\n",
       "      <td>25.946133</td>\n",
       "      <td>34.889347</td>\n",
       "      <td>33.798912</td>\n",
       "      <td>32.327847</td>\n",
       "      <td>33.640877</td>\n",
       "      <td>38.528469</td>\n",
       "      <td>35.700878</td>\n",
       "      <td>43.475784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.653651</td>\n",
       "      <td>25.288235</td>\n",
       "      <td>34.258511</td>\n",
       "      <td>31.747885</td>\n",
       "      <td>33.689880</td>\n",
       "      <td>35.704689</td>\n",
       "      <td>40.495731</td>\n",
       "      <td>38.118679</td>\n",
       "      <td>40.346756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.995983</td>\n",
       "      <td>25.167841</td>\n",
       "      <td>31.201279</td>\n",
       "      <td>31.304253</td>\n",
       "      <td>32.240818</td>\n",
       "      <td>33.005428</td>\n",
       "      <td>37.293976</td>\n",
       "      <td>35.941689</td>\n",
       "      <td>39.820618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.147939</td>\n",
       "      <td>22.847931</td>\n",
       "      <td>29.166267</td>\n",
       "      <td>33.591274</td>\n",
       "      <td>32.366276</td>\n",
       "      <td>32.607708</td>\n",
       "      <td>35.934525</td>\n",
       "      <td>36.093193</td>\n",
       "      <td>49.869949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.871251</td>\n",
       "      <td>21.459288</td>\n",
       "      <td>24.396729</td>\n",
       "      <td>27.219257</td>\n",
       "      <td>29.113548</td>\n",
       "      <td>29.302160</td>\n",
       "      <td>32.285400</td>\n",
       "      <td>31.841759</td>\n",
       "      <td>38.038448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.251461</td>\n",
       "      <td>21.610632</td>\n",
       "      <td>24.343098</td>\n",
       "      <td>26.688944</td>\n",
       "      <td>29.035404</td>\n",
       "      <td>29.571482</td>\n",
       "      <td>32.770668</td>\n",
       "      <td>32.056496</td>\n",
       "      <td>35.596138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.248714</td>\n",
       "      <td>17.731270</td>\n",
       "      <td>18.628990</td>\n",
       "      <td>22.220953</td>\n",
       "      <td>24.908581</td>\n",
       "      <td>24.434416</td>\n",
       "      <td>27.185747</td>\n",
       "      <td>26.693436</td>\n",
       "      <td>28.813011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.125795</td>\n",
       "      <td>14.446035</td>\n",
       "      <td>15.561917</td>\n",
       "      <td>19.416719</td>\n",
       "      <td>20.513231</td>\n",
       "      <td>20.329649</td>\n",
       "      <td>22.628340</td>\n",
       "      <td>24.453613</td>\n",
       "      <td>31.159916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.449242</td>\n",
       "      <td>6.874859</td>\n",
       "      <td>7.049603</td>\n",
       "      <td>10.438907</td>\n",
       "      <td>8.920302</td>\n",
       "      <td>9.600754</td>\n",
       "      <td>10.877909</td>\n",
       "      <td>13.955951</td>\n",
       "      <td>21.074026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.541727</td>\n",
       "      <td>3.514381</td>\n",
       "      <td>3.697778</td>\n",
       "      <td>6.493600</td>\n",
       "      <td>3.661866</td>\n",
       "      <td>3.979152</td>\n",
       "      <td>4.166843</td>\n",
       "      <td>7.349956</td>\n",
       "      <td>14.644279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.045479</td>\n",
       "      <td>0.876639</td>\n",
       "      <td>1.262984</td>\n",
       "      <td>1.602087</td>\n",
       "      <td>1.709978</td>\n",
       "      <td>1.830191</td>\n",
       "      <td>2.097223</td>\n",
       "      <td>1.997328</td>\n",
       "      <td>2.143718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.769847</td>\n",
       "      <td>4.574948</td>\n",
       "      <td>5.847854</td>\n",
       "      <td>6.617944</td>\n",
       "      <td>7.038013</td>\n",
       "      <td>6.682114</td>\n",
       "      <td>7.212112</td>\n",
       "      <td>7.147394</td>\n",
       "      <td>7.538638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.806479</td>\n",
       "      <td>10.361631</td>\n",
       "      <td>12.116336</td>\n",
       "      <td>12.494832</td>\n",
       "      <td>14.208639</td>\n",
       "      <td>14.250778</td>\n",
       "      <td>15.382014</td>\n",
       "      <td>14.506259</td>\n",
       "      <td>15.569941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.548781</td>\n",
       "      <td>16.036556</td>\n",
       "      <td>20.650139</td>\n",
       "      <td>20.052238</td>\n",
       "      <td>21.813889</td>\n",
       "      <td>22.255146</td>\n",
       "      <td>24.010988</td>\n",
       "      <td>22.686218</td>\n",
       "      <td>23.685423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.070220</td>\n",
       "      <td>20.371239</td>\n",
       "      <td>27.370384</td>\n",
       "      <td>27.402838</td>\n",
       "      <td>28.507050</td>\n",
       "      <td>29.993608</td>\n",
       "      <td>31.337177</td>\n",
       "      <td>30.285973</td>\n",
       "      <td>30.588705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.616720</td>\n",
       "      <td>24.945599</td>\n",
       "      <td>33.344814</td>\n",
       "      <td>34.035347</td>\n",
       "      <td>34.357018</td>\n",
       "      <td>37.329639</td>\n",
       "      <td>37.599125</td>\n",
       "      <td>37.349159</td>\n",
       "      <td>36.885361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22.640327</td>\n",
       "      <td>29.226337</td>\n",
       "      <td>38.454113</td>\n",
       "      <td>39.210056</td>\n",
       "      <td>39.435986</td>\n",
       "      <td>42.380341</td>\n",
       "      <td>42.563175</td>\n",
       "      <td>42.895584</td>\n",
       "      <td>42.073997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23.911995</td>\n",
       "      <td>32.590679</td>\n",
       "      <td>42.459911</td>\n",
       "      <td>42.915775</td>\n",
       "      <td>43.036129</td>\n",
       "      <td>46.005322</td>\n",
       "      <td>46.366795</td>\n",
       "      <td>46.781593</td>\n",
       "      <td>46.211315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>25.346338</td>\n",
       "      <td>34.693542</td>\n",
       "      <td>44.620052</td>\n",
       "      <td>45.540775</td>\n",
       "      <td>45.060371</td>\n",
       "      <td>48.170006</td>\n",
       "      <td>48.555737</td>\n",
       "      <td>48.944977</td>\n",
       "      <td>48.538223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24.129955</td>\n",
       "      <td>35.261951</td>\n",
       "      <td>44.968472</td>\n",
       "      <td>46.286942</td>\n",
       "      <td>45.781029</td>\n",
       "      <td>49.292252</td>\n",
       "      <td>49.591694</td>\n",
       "      <td>49.945534</td>\n",
       "      <td>49.593658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>23.745743</td>\n",
       "      <td>34.728085</td>\n",
       "      <td>44.484711</td>\n",
       "      <td>45.630314</td>\n",
       "      <td>45.324440</td>\n",
       "      <td>48.803513</td>\n",
       "      <td>49.121792</td>\n",
       "      <td>49.495865</td>\n",
       "      <td>49.133965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20.631109</td>\n",
       "      <td>32.653591</td>\n",
       "      <td>42.234180</td>\n",
       "      <td>42.630512</td>\n",
       "      <td>43.267357</td>\n",
       "      <td>47.107647</td>\n",
       "      <td>47.350262</td>\n",
       "      <td>47.668644</td>\n",
       "      <td>47.229134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>18.405050</td>\n",
       "      <td>29.675568</td>\n",
       "      <td>38.838181</td>\n",
       "      <td>38.667683</td>\n",
       "      <td>40.257950</td>\n",
       "      <td>43.860870</td>\n",
       "      <td>44.237392</td>\n",
       "      <td>44.412903</td>\n",
       "      <td>43.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.901345</td>\n",
       "      <td>25.317272</td>\n",
       "      <td>33.317081</td>\n",
       "      <td>33.563213</td>\n",
       "      <td>35.813904</td>\n",
       "      <td>39.248039</td>\n",
       "      <td>39.643093</td>\n",
       "      <td>39.713306</td>\n",
       "      <td>39.200451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10.990327</td>\n",
       "      <td>20.888863</td>\n",
       "      <td>27.972134</td>\n",
       "      <td>28.984272</td>\n",
       "      <td>30.783466</td>\n",
       "      <td>33.355083</td>\n",
       "      <td>33.613739</td>\n",
       "      <td>33.664734</td>\n",
       "      <td>33.135654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7.710686</td>\n",
       "      <td>15.790022</td>\n",
       "      <td>21.290310</td>\n",
       "      <td>22.721395</td>\n",
       "      <td>24.527271</td>\n",
       "      <td>25.895350</td>\n",
       "      <td>26.663166</td>\n",
       "      <td>26.193096</td>\n",
       "      <td>26.168776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.940503</td>\n",
       "      <td>11.565914</td>\n",
       "      <td>15.228271</td>\n",
       "      <td>16.032791</td>\n",
       "      <td>17.228195</td>\n",
       "      <td>17.048195</td>\n",
       "      <td>18.691668</td>\n",
       "      <td>17.945114</td>\n",
       "      <td>18.929718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.065277</td>\n",
       "      <td>7.469175</td>\n",
       "      <td>8.629469</td>\n",
       "      <td>9.183166</td>\n",
       "      <td>9.321412</td>\n",
       "      <td>9.004402</td>\n",
       "      <td>9.808754</td>\n",
       "      <td>9.929041</td>\n",
       "      <td>10.889780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.744316</td>\n",
       "      <td>2.740130</td>\n",
       "      <td>2.850317</td>\n",
       "      <td>3.036875</td>\n",
       "      <td>2.757935</td>\n",
       "      <td>2.850880</td>\n",
       "      <td>3.010959</td>\n",
       "      <td>3.164839</td>\n",
       "      <td>3.699688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.366479</td>\n",
       "      <td>0.950481</td>\n",
       "      <td>0.903350</td>\n",
       "      <td>1.160789</td>\n",
       "      <td>1.595469</td>\n",
       "      <td>1.886275</td>\n",
       "      <td>2.561604</td>\n",
       "      <td>2.437338</td>\n",
       "      <td>3.049698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.731476</td>\n",
       "      <td>5.165722</td>\n",
       "      <td>5.955185</td>\n",
       "      <td>6.262476</td>\n",
       "      <td>7.020463</td>\n",
       "      <td>6.916885</td>\n",
       "      <td>7.702295</td>\n",
       "      <td>7.786439</td>\n",
       "      <td>8.502715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.605548</td>\n",
       "      <td>11.421385</td>\n",
       "      <td>13.893218</td>\n",
       "      <td>14.140720</td>\n",
       "      <td>15.820093</td>\n",
       "      <td>15.905630</td>\n",
       "      <td>17.339382</td>\n",
       "      <td>16.347214</td>\n",
       "      <td>17.503077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.863160</td>\n",
       "      <td>14.947759</td>\n",
       "      <td>19.997902</td>\n",
       "      <td>20.255486</td>\n",
       "      <td>22.063341</td>\n",
       "      <td>22.572723</td>\n",
       "      <td>24.508705</td>\n",
       "      <td>23.808960</td>\n",
       "      <td>24.808882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>12.589677</td>\n",
       "      <td>18.845951</td>\n",
       "      <td>26.671146</td>\n",
       "      <td>28.017813</td>\n",
       "      <td>29.373623</td>\n",
       "      <td>31.502024</td>\n",
       "      <td>32.746315</td>\n",
       "      <td>32.186813</td>\n",
       "      <td>32.502899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>14.711265</td>\n",
       "      <td>22.262383</td>\n",
       "      <td>31.449455</td>\n",
       "      <td>33.303101</td>\n",
       "      <td>35.059391</td>\n",
       "      <td>38.481514</td>\n",
       "      <td>38.986115</td>\n",
       "      <td>38.989021</td>\n",
       "      <td>38.818054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>14.961766</td>\n",
       "      <td>24.144142</td>\n",
       "      <td>33.597118</td>\n",
       "      <td>35.201542</td>\n",
       "      <td>37.911522</td>\n",
       "      <td>41.422741</td>\n",
       "      <td>42.495026</td>\n",
       "      <td>43.449318</td>\n",
       "      <td>43.381569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>13.471038</td>\n",
       "      <td>25.273088</td>\n",
       "      <td>33.971962</td>\n",
       "      <td>36.044605</td>\n",
       "      <td>39.437965</td>\n",
       "      <td>43.277847</td>\n",
       "      <td>45.076954</td>\n",
       "      <td>46.898155</td>\n",
       "      <td>46.934570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.267738</td>\n",
       "      <td>30.926502</td>\n",
       "      <td>41.973278</td>\n",
       "      <td>44.019806</td>\n",
       "      <td>44.872478</td>\n",
       "      <td>48.851570</td>\n",
       "      <td>49.482769</td>\n",
       "      <td>50.132359</td>\n",
       "      <td>50.315735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>19.841455</td>\n",
       "      <td>32.945133</td>\n",
       "      <td>43.618282</td>\n",
       "      <td>46.282955</td>\n",
       "      <td>46.825306</td>\n",
       "      <td>50.740433</td>\n",
       "      <td>51.475594</td>\n",
       "      <td>51.755272</td>\n",
       "      <td>51.923138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          0          0          0          0          0  \\\n",
       "0   -0.118148   0.728983   0.971046   1.047962   1.551056   1.912070   \n",
       "1    1.108285   3.865702   5.232843   4.985348   5.321519   5.507869   \n",
       "2    2.490887   5.952147   7.677533   7.011625   8.140335   7.945873   \n",
       "3    4.716012  11.917788  16.408276  14.359765  15.824986  16.535480   \n",
       "4    6.901226  13.708292  18.273079  15.512778  18.995520  19.388699   \n",
       "5   12.192307  18.357838  26.428158  23.099239  30.649914  31.986101   \n",
       "6   13.504175  17.855955  25.263275  25.149977  33.660610  35.402031   \n",
       "7   13.584247  25.247437  36.553349  31.754292  35.200638  37.874706   \n",
       "8   11.491407  24.585892  35.093590  30.945068  31.756310  33.964745   \n",
       "9   11.213213  25.946133  34.889347  33.798912  32.327847  33.640877   \n",
       "10  12.653651  25.288235  34.258511  31.747885  33.689880  35.704689   \n",
       "11  10.995983  25.167841  31.201279  31.304253  32.240818  33.005428   \n",
       "12   8.147939  22.847931  29.166267  33.591274  32.366276  32.607708   \n",
       "13   8.871251  21.459288  24.396729  27.219257  29.113548  29.302160   \n",
       "14   9.251461  21.610632  24.343098  26.688944  29.035404  29.571482   \n",
       "15   8.248714  17.731270  18.628990  22.220953  24.908581  24.434416   \n",
       "16   6.125795  14.446035  15.561917  19.416719  20.513231  20.329649   \n",
       "17   3.449242   6.874859   7.049603  10.438907   8.920302   9.600754   \n",
       "18   1.541727   3.514381   3.697778   6.493600   3.661866   3.979152   \n",
       "19  -0.045479   0.876639   1.262984   1.602087   1.709978   1.830191   \n",
       "20   2.769847   4.574948   5.847854   6.617944   7.038013   6.682114   \n",
       "21   6.806479  10.361631  12.116336  12.494832  14.208639  14.250778   \n",
       "22  10.548781  16.036556  20.650139  20.052238  21.813889  22.255146   \n",
       "23  15.070220  20.371239  27.370384  27.402838  28.507050  29.993608   \n",
       "24  18.616720  24.945599  33.344814  34.035347  34.357018  37.329639   \n",
       "25  22.640327  29.226337  38.454113  39.210056  39.435986  42.380341   \n",
       "26  23.911995  32.590679  42.459911  42.915775  43.036129  46.005322   \n",
       "27  25.346338  34.693542  44.620052  45.540775  45.060371  48.170006   \n",
       "28  24.129955  35.261951  44.968472  46.286942  45.781029  49.292252   \n",
       "29  23.745743  34.728085  44.484711  45.630314  45.324440  48.803513   \n",
       "30  20.631109  32.653591  42.234180  42.630512  43.267357  47.107647   \n",
       "31  18.405050  29.675568  38.838181  38.667683  40.257950  43.860870   \n",
       "32  13.901345  25.317272  33.317081  33.563213  35.813904  39.248039   \n",
       "33  10.990327  20.888863  27.972134  28.984272  30.783466  33.355083   \n",
       "34   7.710686  15.790022  21.290310  22.721395  24.527271  25.895350   \n",
       "35   5.940503  11.565914  15.228271  16.032791  17.228195  17.048195   \n",
       "36   4.065277   7.469175   8.629469   9.183166   9.321412   9.004402   \n",
       "37   1.744316   2.740130   2.850317   3.036875   2.757935   2.850880   \n",
       "38   0.366479   0.950481   0.903350   1.160789   1.595469   1.886275   \n",
       "39   2.731476   5.165722   5.955185   6.262476   7.020463   6.916885   \n",
       "40   6.605548  11.421385  13.893218  14.140720  15.820093  15.905630   \n",
       "41   8.863160  14.947759  19.997902  20.255486  22.063341  22.572723   \n",
       "42  12.589677  18.845951  26.671146  28.017813  29.373623  31.502024   \n",
       "43  14.711265  22.262383  31.449455  33.303101  35.059391  38.481514   \n",
       "44  14.961766  24.144142  33.597118  35.201542  37.911522  41.422741   \n",
       "45  13.471038  25.273088  33.971962  36.044605  39.437965  43.277847   \n",
       "46  19.267738  30.926502  41.973278  44.019806  44.872478  48.851570   \n",
       "47  19.841455  32.945133  43.618282  46.282955  46.825306  50.740433   \n",
       "\n",
       "            0          0          0  \n",
       "0    3.364514   3.760700   9.617659  \n",
       "1    8.577897   9.602978  20.866327  \n",
       "2   12.429950  13.378427  25.929480  \n",
       "3   23.286322  24.471409  38.971222  \n",
       "4   25.850063  25.775200  38.998653  \n",
       "5   36.528770  33.668385  36.662949  \n",
       "6   39.250977  36.593620  37.442463  \n",
       "7   42.947632  40.218739  46.160000  \n",
       "8   39.470657  36.203442  46.159149  \n",
       "9   38.528469  35.700878  43.475784  \n",
       "10  40.495731  38.118679  40.346756  \n",
       "11  37.293976  35.941689  39.820618  \n",
       "12  35.934525  36.093193  49.869949  \n",
       "13  32.285400  31.841759  38.038448  \n",
       "14  32.770668  32.056496  35.596138  \n",
       "15  27.185747  26.693436  28.813011  \n",
       "16  22.628340  24.453613  31.159916  \n",
       "17  10.877909  13.955951  21.074026  \n",
       "18   4.166843   7.349956  14.644279  \n",
       "19   2.097223   1.997328   2.143718  \n",
       "20   7.212112   7.147394   7.538638  \n",
       "21  15.382014  14.506259  15.569941  \n",
       "22  24.010988  22.686218  23.685423  \n",
       "23  31.337177  30.285973  30.588705  \n",
       "24  37.599125  37.349159  36.885361  \n",
       "25  42.563175  42.895584  42.073997  \n",
       "26  46.366795  46.781593  46.211315  \n",
       "27  48.555737  48.944977  48.538223  \n",
       "28  49.591694  49.945534  49.593658  \n",
       "29  49.121792  49.495865  49.133965  \n",
       "30  47.350262  47.668644  47.229134  \n",
       "31  44.237392  44.412903  43.945312  \n",
       "32  39.643093  39.713306  39.200451  \n",
       "33  33.613739  33.664734  33.135654  \n",
       "34  26.663166  26.193096  26.168776  \n",
       "35  18.691668  17.945114  18.929718  \n",
       "36   9.808754   9.929041  10.889780  \n",
       "37   3.010959   3.164839   3.699688  \n",
       "38   2.561604   2.437338   3.049698  \n",
       "39   7.702295   7.786439   8.502715  \n",
       "40  17.339382  16.347214  17.503077  \n",
       "41  24.508705  23.808960  24.808882  \n",
       "42  32.746315  32.186813  32.502899  \n",
       "43  38.986115  38.989021  38.818054  \n",
       "44  42.495026  43.449318  43.381569  \n",
       "45  45.076954  46.898155  46.934570  \n",
       "46  49.482769  50.132359  50.315735  \n",
       "47  51.475594  51.755272  51.923138  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_G8 = tf.keras.Sequential([\n",
    "    layers.GRU(units=64, return_sequences=True, input_shape=[25864, 7]),\n",
    "    layers.GRU(units=32),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result_G8 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model_G8.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model_G8.fit(np.array(Day).reshape(25864, 1, 7), np.array(Day7).reshape(25864, 1)\n",
    "                 , epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred_G8 = np.squeeze(model_G8.predict(np.array(df_test).reshape(1539, 1, 7)))\n",
    "    pred_G8 = pd.DataFrame(pred_G8)\n",
    "    result_G8 = pd.concat([result_G8, pred_G8], axis=1)\n",
    "    \n",
    "result_G8[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "390/405 [===========================>..] - ETA: 0s - loss: 3.3010WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 3.2950 - val_loss: 3.1870\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.0158 - val_loss: 3.1502\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9102 - val_loss: 3.1094\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9287 - val_loss: 3.1227\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8959 - val_loss: 3.1331\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8752 - val_loss: 3.1164\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.2\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "391/405 [===========================>..] - ETA: 0s - loss: 4.9290WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 4.9269 - val_loss: 5.1491\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7902 - val_loss: 5.0797\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6387 - val_loss: 5.0624\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.6652 - val_loss: 5.0231\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5934 - val_loss: 5.0473\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5680 - val_loss: 5.0402\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.5899 - val_loss: 5.0372\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.3\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "394/405 [============================>.] - ETA: 0s - loss: 5.6717WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 5.6701 - val_loss: 6.0208\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.5350 - val_loss: 5.9805\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 5.4597 - val_loss: 5.9790\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4744 - val_loss: 5.9097\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3521 - val_loss: 5.9256\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3512 - val_loss: 5.9156\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3843 - val_loss: 5.8964\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4186 - val_loss: 5.8692\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3314 - val_loss: 5.8894\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4464 - val_loss: 5.9853\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3697 - val_loss: 5.9024\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.4\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "404/405 [============================>.] - ETA: 0s - loss: 5.7383WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 5.7381 - val_loss: 6.1681\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.6113 - val_loss: 6.1309\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.6101 - val_loss: 6.0698\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.6595 - val_loss: 6.1027\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.5369 - val_loss: 6.1169\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.5288 - val_loss: 6.1246\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "401/405 [============================>.] - ETA: 0s - loss: 5.5345WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 5.5338 - val_loss: 5.8779\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3943 - val_loss: 5.9334\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4051 - val_loss: 5.8108\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.4599 - val_loss: 5.8253\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3314 - val_loss: 5.8428\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.3258 - val_loss: 5.8512\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.6\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "403/405 [============================>.] - ETA: 0s - loss: 4.9581WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 4.9576 - val_loss: 5.2184\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.8103 - val_loss: 5.1900\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.8532 - val_loss: 5.1591\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.8676 - val_loss: 5.1851\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7477 - val_loss: 5.2559\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7788 - val_loss: 5.1199\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7599 - val_loss: 5.1550\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.8419 - val_loss: 5.1596\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7330 - val_loss: 5.1952\n",
      "Epoch 00009: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.7\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "397/405 [============================>.] - ETA: 0s - loss: 4.0294WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 4.0285 - val_loss: 4.2356\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.9154 - val_loss: 4.2431\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.9551 - val_loss: 4.1785\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.9992 - val_loss: 4.2257\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.8772 - val_loss: 4.4588\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.9100 - val_loss: 4.2420\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.8\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "389/405 [===========================>..] - ETA: 0s - loss: 2.9153WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 2.9141 - val_loss: 3.0728\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8333 - val_loss: 3.0467\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8732 - val_loss: 3.1091\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.8913 - val_loss: 3.0890\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.7855 - val_loss: 3.0980\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.9\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "394/405 [============================>.] - ETA: 0s - loss: 1.6108WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 5s 5ms/step - loss: 1.6102 - val_loss: 1.7036\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.5662 - val_loss: 1.7397\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.6314 - val_loss: 1.7435\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.6011 - val_loss: 1.8301\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.651626</td>\n",
       "      <td>1.412930</td>\n",
       "      <td>1.663878</td>\n",
       "      <td>2.391623</td>\n",
       "      <td>3.620630</td>\n",
       "      <td>3.022576</td>\n",
       "      <td>5.746896</td>\n",
       "      <td>6.427562</td>\n",
       "      <td>10.876079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.516569</td>\n",
       "      <td>3.200346</td>\n",
       "      <td>5.007691</td>\n",
       "      <td>7.612739</td>\n",
       "      <td>10.807425</td>\n",
       "      <td>10.988094</td>\n",
       "      <td>16.742872</td>\n",
       "      <td>18.460148</td>\n",
       "      <td>25.416058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.490597</td>\n",
       "      <td>5.195635</td>\n",
       "      <td>8.690712</td>\n",
       "      <td>12.623331</td>\n",
       "      <td>16.221693</td>\n",
       "      <td>14.467131</td>\n",
       "      <td>20.739613</td>\n",
       "      <td>22.330959</td>\n",
       "      <td>30.209188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.558703</td>\n",
       "      <td>7.637560</td>\n",
       "      <td>13.491122</td>\n",
       "      <td>18.699293</td>\n",
       "      <td>23.502199</td>\n",
       "      <td>22.880861</td>\n",
       "      <td>31.975574</td>\n",
       "      <td>36.150452</td>\n",
       "      <td>46.415920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.839878</td>\n",
       "      <td>10.198141</td>\n",
       "      <td>17.454243</td>\n",
       "      <td>22.693516</td>\n",
       "      <td>27.092474</td>\n",
       "      <td>24.169703</td>\n",
       "      <td>32.847008</td>\n",
       "      <td>36.482132</td>\n",
       "      <td>46.895279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.798664</td>\n",
       "      <td>15.330933</td>\n",
       "      <td>24.164576</td>\n",
       "      <td>27.350012</td>\n",
       "      <td>31.454496</td>\n",
       "      <td>30.598495</td>\n",
       "      <td>36.305202</td>\n",
       "      <td>37.333523</td>\n",
       "      <td>40.848919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.042477</td>\n",
       "      <td>16.690411</td>\n",
       "      <td>24.624172</td>\n",
       "      <td>27.018827</td>\n",
       "      <td>31.540594</td>\n",
       "      <td>32.735386</td>\n",
       "      <td>37.522675</td>\n",
       "      <td>38.003830</td>\n",
       "      <td>39.672966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.000772</td>\n",
       "      <td>16.136662</td>\n",
       "      <td>27.386908</td>\n",
       "      <td>31.172380</td>\n",
       "      <td>36.419567</td>\n",
       "      <td>36.419098</td>\n",
       "      <td>43.420963</td>\n",
       "      <td>46.874535</td>\n",
       "      <td>51.689362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.773403</td>\n",
       "      <td>14.348423</td>\n",
       "      <td>24.432497</td>\n",
       "      <td>28.812801</td>\n",
       "      <td>33.840446</td>\n",
       "      <td>33.451294</td>\n",
       "      <td>41.137058</td>\n",
       "      <td>45.712769</td>\n",
       "      <td>52.616653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.526613</td>\n",
       "      <td>14.123219</td>\n",
       "      <td>23.619312</td>\n",
       "      <td>27.363253</td>\n",
       "      <td>32.228859</td>\n",
       "      <td>32.443634</td>\n",
       "      <td>38.739780</td>\n",
       "      <td>43.119469</td>\n",
       "      <td>48.208645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.603545</td>\n",
       "      <td>15.554159</td>\n",
       "      <td>25.120960</td>\n",
       "      <td>27.971552</td>\n",
       "      <td>32.967682</td>\n",
       "      <td>34.105930</td>\n",
       "      <td>39.612999</td>\n",
       "      <td>42.696678</td>\n",
       "      <td>45.417057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.406276</td>\n",
       "      <td>14.052549</td>\n",
       "      <td>22.800934</td>\n",
       "      <td>25.745050</td>\n",
       "      <td>30.354742</td>\n",
       "      <td>30.901155</td>\n",
       "      <td>35.742340</td>\n",
       "      <td>39.410156</td>\n",
       "      <td>42.511856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.629732</td>\n",
       "      <td>10.896416</td>\n",
       "      <td>19.137058</td>\n",
       "      <td>23.736738</td>\n",
       "      <td>28.941547</td>\n",
       "      <td>29.564463</td>\n",
       "      <td>36.140732</td>\n",
       "      <td>42.907837</td>\n",
       "      <td>50.200787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.115972</td>\n",
       "      <td>11.971090</td>\n",
       "      <td>19.373894</td>\n",
       "      <td>22.384325</td>\n",
       "      <td>26.411833</td>\n",
       "      <td>26.014959</td>\n",
       "      <td>29.550989</td>\n",
       "      <td>32.987003</td>\n",
       "      <td>35.909557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.443573</td>\n",
       "      <td>12.486110</td>\n",
       "      <td>19.612082</td>\n",
       "      <td>22.179161</td>\n",
       "      <td>26.143351</td>\n",
       "      <td>26.252958</td>\n",
       "      <td>29.690475</td>\n",
       "      <td>32.779518</td>\n",
       "      <td>35.155376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.974761</td>\n",
       "      <td>11.723354</td>\n",
       "      <td>17.318130</td>\n",
       "      <td>19.118971</td>\n",
       "      <td>22.304539</td>\n",
       "      <td>22.179451</td>\n",
       "      <td>24.334892</td>\n",
       "      <td>26.449394</td>\n",
       "      <td>27.809347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.637974</td>\n",
       "      <td>8.903531</td>\n",
       "      <td>14.418842</td>\n",
       "      <td>17.392981</td>\n",
       "      <td>20.881630</td>\n",
       "      <td>19.549978</td>\n",
       "      <td>21.511440</td>\n",
       "      <td>24.072803</td>\n",
       "      <td>26.282967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.095726</td>\n",
       "      <td>5.311701</td>\n",
       "      <td>9.121095</td>\n",
       "      <td>11.956009</td>\n",
       "      <td>15.396475</td>\n",
       "      <td>13.270828</td>\n",
       "      <td>13.999071</td>\n",
       "      <td>15.685595</td>\n",
       "      <td>17.190290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.881682</td>\n",
       "      <td>2.370034</td>\n",
       "      <td>4.221588</td>\n",
       "      <td>6.204017</td>\n",
       "      <td>9.654202</td>\n",
       "      <td>9.231308</td>\n",
       "      <td>10.874598</td>\n",
       "      <td>13.524657</td>\n",
       "      <td>16.031055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.658838</td>\n",
       "      <td>1.330434</td>\n",
       "      <td>1.154504</td>\n",
       "      <td>1.063127</td>\n",
       "      <td>1.130794</td>\n",
       "      <td>1.519910</td>\n",
       "      <td>1.990139</td>\n",
       "      <td>2.151956</td>\n",
       "      <td>2.062776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.194237</td>\n",
       "      <td>4.143533</td>\n",
       "      <td>6.064661</td>\n",
       "      <td>6.699108</td>\n",
       "      <td>7.300083</td>\n",
       "      <td>6.369847</td>\n",
       "      <td>7.500924</td>\n",
       "      <td>8.008971</td>\n",
       "      <td>8.124584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.194424</td>\n",
       "      <td>9.521467</td>\n",
       "      <td>12.363936</td>\n",
       "      <td>14.115209</td>\n",
       "      <td>16.184280</td>\n",
       "      <td>14.823651</td>\n",
       "      <td>16.502480</td>\n",
       "      <td>16.413942</td>\n",
       "      <td>17.070805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.201926</td>\n",
       "      <td>13.911270</td>\n",
       "      <td>18.494589</td>\n",
       "      <td>21.497286</td>\n",
       "      <td>24.298449</td>\n",
       "      <td>22.940239</td>\n",
       "      <td>25.367527</td>\n",
       "      <td>24.350090</td>\n",
       "      <td>25.905735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.162374</td>\n",
       "      <td>19.149075</td>\n",
       "      <td>24.062498</td>\n",
       "      <td>28.397135</td>\n",
       "      <td>31.457529</td>\n",
       "      <td>29.828190</td>\n",
       "      <td>32.615334</td>\n",
       "      <td>31.043741</td>\n",
       "      <td>33.637703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.351465</td>\n",
       "      <td>23.467091</td>\n",
       "      <td>28.608976</td>\n",
       "      <td>33.889027</td>\n",
       "      <td>37.274853</td>\n",
       "      <td>35.951912</td>\n",
       "      <td>38.707848</td>\n",
       "      <td>37.523529</td>\n",
       "      <td>40.748180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14.922377</td>\n",
       "      <td>28.431149</td>\n",
       "      <td>33.837650</td>\n",
       "      <td>39.051540</td>\n",
       "      <td>42.399414</td>\n",
       "      <td>40.622681</td>\n",
       "      <td>43.320438</td>\n",
       "      <td>42.592911</td>\n",
       "      <td>45.904675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15.803480</td>\n",
       "      <td>30.593998</td>\n",
       "      <td>36.715950</td>\n",
       "      <td>42.036961</td>\n",
       "      <td>45.731613</td>\n",
       "      <td>44.404572</td>\n",
       "      <td>46.926956</td>\n",
       "      <td>46.717934</td>\n",
       "      <td>49.881439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>17.070126</td>\n",
       "      <td>33.137630</td>\n",
       "      <td>39.420242</td>\n",
       "      <td>44.573887</td>\n",
       "      <td>48.342800</td>\n",
       "      <td>46.763161</td>\n",
       "      <td>49.361698</td>\n",
       "      <td>49.220634</td>\n",
       "      <td>52.356319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>16.520857</td>\n",
       "      <td>32.114845</td>\n",
       "      <td>38.556282</td>\n",
       "      <td>44.032230</td>\n",
       "      <td>48.172718</td>\n",
       "      <td>47.504570</td>\n",
       "      <td>50.051456</td>\n",
       "      <td>50.204514</td>\n",
       "      <td>53.180050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16.402988</td>\n",
       "      <td>31.783100</td>\n",
       "      <td>38.033119</td>\n",
       "      <td>43.522022</td>\n",
       "      <td>47.672394</td>\n",
       "      <td>47.026474</td>\n",
       "      <td>49.578156</td>\n",
       "      <td>49.716343</td>\n",
       "      <td>52.688320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14.388479</td>\n",
       "      <td>27.978525</td>\n",
       "      <td>34.172054</td>\n",
       "      <td>40.071667</td>\n",
       "      <td>44.455048</td>\n",
       "      <td>44.775650</td>\n",
       "      <td>47.179844</td>\n",
       "      <td>47.505325</td>\n",
       "      <td>50.336075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.645197</td>\n",
       "      <td>24.863316</td>\n",
       "      <td>30.909405</td>\n",
       "      <td>36.927879</td>\n",
       "      <td>41.220608</td>\n",
       "      <td>41.614090</td>\n",
       "      <td>44.006359</td>\n",
       "      <td>44.118290</td>\n",
       "      <td>46.976162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9.272047</td>\n",
       "      <td>19.500896</td>\n",
       "      <td>25.967335</td>\n",
       "      <td>31.911280</td>\n",
       "      <td>36.102921</td>\n",
       "      <td>37.063538</td>\n",
       "      <td>39.377338</td>\n",
       "      <td>39.243500</td>\n",
       "      <td>42.055561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.735143</td>\n",
       "      <td>15.393017</td>\n",
       "      <td>22.137846</td>\n",
       "      <td>27.239832</td>\n",
       "      <td>30.955410</td>\n",
       "      <td>31.844326</td>\n",
       "      <td>34.124058</td>\n",
       "      <td>33.557854</td>\n",
       "      <td>35.941757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.017846</td>\n",
       "      <td>10.450139</td>\n",
       "      <td>16.765533</td>\n",
       "      <td>20.526527</td>\n",
       "      <td>23.926764</td>\n",
       "      <td>24.945961</td>\n",
       "      <td>27.202299</td>\n",
       "      <td>26.751408</td>\n",
       "      <td>28.041607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.785563</td>\n",
       "      <td>7.429151</td>\n",
       "      <td>12.208894</td>\n",
       "      <td>14.666439</td>\n",
       "      <td>17.456865</td>\n",
       "      <td>17.924042</td>\n",
       "      <td>19.670921</td>\n",
       "      <td>19.398064</td>\n",
       "      <td>19.790562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.692700</td>\n",
       "      <td>4.617312</td>\n",
       "      <td>7.607981</td>\n",
       "      <td>8.773732</td>\n",
       "      <td>10.247350</td>\n",
       "      <td>10.136093</td>\n",
       "      <td>11.172242</td>\n",
       "      <td>11.213359</td>\n",
       "      <td>11.001766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.575418</td>\n",
       "      <td>1.738009</td>\n",
       "      <td>2.904547</td>\n",
       "      <td>2.923477</td>\n",
       "      <td>3.138932</td>\n",
       "      <td>3.046759</td>\n",
       "      <td>3.384630</td>\n",
       "      <td>3.494174</td>\n",
       "      <td>3.226869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.802291</td>\n",
       "      <td>1.708197</td>\n",
       "      <td>1.521986</td>\n",
       "      <td>1.702527</td>\n",
       "      <td>1.867783</td>\n",
       "      <td>1.149644</td>\n",
       "      <td>1.899064</td>\n",
       "      <td>1.940590</td>\n",
       "      <td>2.484862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.696599</td>\n",
       "      <td>4.853239</td>\n",
       "      <td>5.843548</td>\n",
       "      <td>7.078466</td>\n",
       "      <td>8.430592</td>\n",
       "      <td>8.103583</td>\n",
       "      <td>8.848512</td>\n",
       "      <td>8.873066</td>\n",
       "      <td>8.871959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.312920</td>\n",
       "      <td>9.667276</td>\n",
       "      <td>12.834445</td>\n",
       "      <td>14.787426</td>\n",
       "      <td>17.129389</td>\n",
       "      <td>16.120167</td>\n",
       "      <td>17.920708</td>\n",
       "      <td>17.645054</td>\n",
       "      <td>18.492777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6.630163</td>\n",
       "      <td>12.487499</td>\n",
       "      <td>17.367464</td>\n",
       "      <td>20.572191</td>\n",
       "      <td>23.661013</td>\n",
       "      <td>23.134224</td>\n",
       "      <td>25.733986</td>\n",
       "      <td>24.849573</td>\n",
       "      <td>26.609905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9.422367</td>\n",
       "      <td>17.129654</td>\n",
       "      <td>22.938807</td>\n",
       "      <td>27.674749</td>\n",
       "      <td>31.207392</td>\n",
       "      <td>30.465097</td>\n",
       "      <td>33.467827</td>\n",
       "      <td>32.167419</td>\n",
       "      <td>35.105759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>11.225794</td>\n",
       "      <td>20.144056</td>\n",
       "      <td>26.246883</td>\n",
       "      <td>32.131622</td>\n",
       "      <td>36.278439</td>\n",
       "      <td>36.225739</td>\n",
       "      <td>39.316746</td>\n",
       "      <td>38.710838</td>\n",
       "      <td>42.183563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>12.583164</td>\n",
       "      <td>21.162590</td>\n",
       "      <td>26.808037</td>\n",
       "      <td>33.058434</td>\n",
       "      <td>37.942703</td>\n",
       "      <td>39.327881</td>\n",
       "      <td>42.588108</td>\n",
       "      <td>42.918091</td>\n",
       "      <td>46.439999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12.252638</td>\n",
       "      <td>20.123070</td>\n",
       "      <td>25.582579</td>\n",
       "      <td>32.008797</td>\n",
       "      <td>37.813282</td>\n",
       "      <td>41.512123</td>\n",
       "      <td>45.134731</td>\n",
       "      <td>46.614975</td>\n",
       "      <td>49.793106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15.219469</td>\n",
       "      <td>26.853905</td>\n",
       "      <td>33.604534</td>\n",
       "      <td>40.203236</td>\n",
       "      <td>45.115681</td>\n",
       "      <td>46.274261</td>\n",
       "      <td>49.490059</td>\n",
       "      <td>50.328728</td>\n",
       "      <td>53.756237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15.201172</td>\n",
       "      <td>27.664463</td>\n",
       "      <td>34.931221</td>\n",
       "      <td>41.543274</td>\n",
       "      <td>46.576904</td>\n",
       "      <td>48.014565</td>\n",
       "      <td>51.141140</td>\n",
       "      <td>52.160442</td>\n",
       "      <td>55.384090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          0          0          0          0          0  \\\n",
       "0    0.651626   1.412930   1.663878   2.391623   3.620630   3.022576   \n",
       "1    1.516569   3.200346   5.007691   7.612739  10.807425  10.988094   \n",
       "2    2.490597   5.195635   8.690712  12.623331  16.221693  14.467131   \n",
       "3    3.558703   7.637560  13.491122  18.699293  23.502199  22.880861   \n",
       "4    4.839878  10.198141  17.454243  22.693516  27.092474  24.169703   \n",
       "5    7.798664  15.330933  24.164576  27.350012  31.454496  30.598495   \n",
       "6    9.042477  16.690411  24.624172  27.018827  31.540594  32.735386   \n",
       "7    8.000772  16.136662  27.386908  31.172380  36.419567  36.419098   \n",
       "8    6.773403  14.348423  24.432497  28.812801  33.840446  33.451294   \n",
       "9    6.526613  14.123219  23.619312  27.363253  32.228859  32.443634   \n",
       "10   7.603545  15.554159  25.120960  27.971552  32.967682  34.105930   \n",
       "11   6.406276  14.052549  22.800934  25.745050  30.354742  30.901155   \n",
       "12   4.629732  10.896416  19.137058  23.736738  28.941547  29.564463   \n",
       "13   5.115972  11.971090  19.373894  22.384325  26.411833  26.014959   \n",
       "14   5.443573  12.486110  19.612082  22.179161  26.143351  26.252958   \n",
       "15   4.974761  11.723354  17.318130  19.118971  22.304539  22.179451   \n",
       "16   3.637974   8.903531  14.418842  17.392981  20.881630  19.549978   \n",
       "17   2.095726   5.311701   9.121095  11.956009  15.396475  13.270828   \n",
       "18   0.881682   2.370034   4.221588   6.204017   9.654202   9.231308   \n",
       "19   0.658838   1.330434   1.154504   1.063127   1.130794   1.519910   \n",
       "20   2.194237   4.143533   6.064661   6.699108   7.300083   6.369847   \n",
       "21   5.194424   9.521467  12.363936  14.115209  16.184280  14.823651   \n",
       "22   7.201926  13.911270  18.494589  21.497286  24.298449  22.940239   \n",
       "23  10.162374  19.149075  24.062498  28.397135  31.457529  29.828190   \n",
       "24  12.351465  23.467091  28.608976  33.889027  37.274853  35.951912   \n",
       "25  14.922377  28.431149  33.837650  39.051540  42.399414  40.622681   \n",
       "26  15.803480  30.593998  36.715950  42.036961  45.731613  44.404572   \n",
       "27  17.070126  33.137630  39.420242  44.573887  48.342800  46.763161   \n",
       "28  16.520857  32.114845  38.556282  44.032230  48.172718  47.504570   \n",
       "29  16.402988  31.783100  38.033119  43.522022  47.672394  47.026474   \n",
       "30  14.388479  27.978525  34.172054  40.071667  44.455048  44.775650   \n",
       "31  12.645197  24.863316  30.909405  36.927879  41.220608  41.614090   \n",
       "32   9.272047  19.500896  25.967335  31.911280  36.102921  37.063538   \n",
       "33   6.735143  15.393017  22.137846  27.239832  30.955410  31.844326   \n",
       "34   4.017846  10.450139  16.765533  20.526527  23.926764  24.945961   \n",
       "35   2.785563   7.429151  12.208894  14.666439  17.456865  17.924042   \n",
       "36   1.692700   4.617312   7.607981   8.773732  10.247350  10.136093   \n",
       "37   0.575418   1.738009   2.904547   2.923477   3.138932   3.046759   \n",
       "38   0.802291   1.708197   1.521986   1.702527   1.867783   1.149644   \n",
       "39   2.696599   4.853239   5.843548   7.078466   8.430592   8.103583   \n",
       "40   5.312920   9.667276  12.834445  14.787426  17.129389  16.120167   \n",
       "41   6.630163  12.487499  17.367464  20.572191  23.661013  23.134224   \n",
       "42   9.422367  17.129654  22.938807  27.674749  31.207392  30.465097   \n",
       "43  11.225794  20.144056  26.246883  32.131622  36.278439  36.225739   \n",
       "44  12.583164  21.162590  26.808037  33.058434  37.942703  39.327881   \n",
       "45  12.252638  20.123070  25.582579  32.008797  37.813282  41.512123   \n",
       "46  15.219469  26.853905  33.604534  40.203236  45.115681  46.274261   \n",
       "47  15.201172  27.664463  34.931221  41.543274  46.576904  48.014565   \n",
       "\n",
       "            0          0          0  \n",
       "0    5.746896   6.427562  10.876079  \n",
       "1   16.742872  18.460148  25.416058  \n",
       "2   20.739613  22.330959  30.209188  \n",
       "3   31.975574  36.150452  46.415920  \n",
       "4   32.847008  36.482132  46.895279  \n",
       "5   36.305202  37.333523  40.848919  \n",
       "6   37.522675  38.003830  39.672966  \n",
       "7   43.420963  46.874535  51.689362  \n",
       "8   41.137058  45.712769  52.616653  \n",
       "9   38.739780  43.119469  48.208645  \n",
       "10  39.612999  42.696678  45.417057  \n",
       "11  35.742340  39.410156  42.511856  \n",
       "12  36.140732  42.907837  50.200787  \n",
       "13  29.550989  32.987003  35.909557  \n",
       "14  29.690475  32.779518  35.155376  \n",
       "15  24.334892  26.449394  27.809347  \n",
       "16  21.511440  24.072803  26.282967  \n",
       "17  13.999071  15.685595  17.190290  \n",
       "18  10.874598  13.524657  16.031055  \n",
       "19   1.990139   2.151956   2.062776  \n",
       "20   7.500924   8.008971   8.124584  \n",
       "21  16.502480  16.413942  17.070805  \n",
       "22  25.367527  24.350090  25.905735  \n",
       "23  32.615334  31.043741  33.637703  \n",
       "24  38.707848  37.523529  40.748180  \n",
       "25  43.320438  42.592911  45.904675  \n",
       "26  46.926956  46.717934  49.881439  \n",
       "27  49.361698  49.220634  52.356319  \n",
       "28  50.051456  50.204514  53.180050  \n",
       "29  49.578156  49.716343  52.688320  \n",
       "30  47.179844  47.505325  50.336075  \n",
       "31  44.006359  44.118290  46.976162  \n",
       "32  39.377338  39.243500  42.055561  \n",
       "33  34.124058  33.557854  35.941757  \n",
       "34  27.202299  26.751408  28.041607  \n",
       "35  19.670921  19.398064  19.790562  \n",
       "36  11.172242  11.213359  11.001766  \n",
       "37   3.384630   3.494174   3.226869  \n",
       "38   1.899064   1.940590   2.484862  \n",
       "39   8.848512   8.873066   8.871959  \n",
       "40  17.920708  17.645054  18.492777  \n",
       "41  25.733986  24.849573  26.609905  \n",
       "42  33.467827  32.167419  35.105759  \n",
       "43  39.316746  38.710838  42.183563  \n",
       "44  42.588108  42.918091  46.439999  \n",
       "45  45.134731  46.614975  49.793106  \n",
       "46  49.490059  50.328728  53.756237  \n",
       "47  51.141140  52.160442  55.384090  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_M7 = tf.keras.Sequential([\n",
    "    layers.LSTM(units=64, return_sequences=True, input_shape=[25864, 8]),\n",
    "    layers.LSTM(units=32),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result_M7 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model_M7.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model_M7.fit(np.array(Day0).reshape(25864, 1, 8), np.array(Day7).reshape(25864, 1)\n",
    "                 , epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred_M7 = np.squeeze(model_M7.predict(np.array(df_test0).reshape(1539, 1, 8)))\n",
    "    pred_M7 = pd.DataFrame(pred_M7)\n",
    "    result_M7 = pd.concat([result_M7, pred_M7], axis=1)\n",
    "    \n",
    "result_M7[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "396/405 [============================>.] - ETA: 0s - loss: 3.2839WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 3.2806 - val_loss: 3.2004\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 3.0349 - val_loss: 3.2131\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9744 - val_loss: 3.1773\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9478 - val_loss: 3.1986\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9357 - val_loss: 3.1754\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9037 - val_loss: 3.2504\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9439 - val_loss: 3.1595\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9168 - val_loss: 3.0943\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9136 - val_loss: 3.1459\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9130 - val_loss: 3.1520\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9195 - val_loss: 3.1779\n",
      "Epoch 00011: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.2\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "389/405 [===========================>..] - ETA: 0s - loss: 5.0234WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 5.0203 - val_loss: 5.3026\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.9290 - val_loss: 5.2573\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.8147 - val_loss: 5.1961\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.8358 - val_loss: 5.2667\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7869 - val_loss: 5.2376\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.7389 - val_loss: 5.2728\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.3\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "398/405 [============================>.] - ETA: 0s - loss: 6.0038WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 5s 5ms/step - loss: 6.0022 - val_loss: 6.3636\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.8672 - val_loss: 6.2816\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.7472 - val_loss: 6.1836\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.8044 - val_loss: 6.1769\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 5.7358 - val_loss: 6.2280\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.7048 - val_loss: 6.5046\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.7599 - val_loss: 6.1613\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.7356 - val_loss: 6.1618\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.6805 - val_loss: 6.3641\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.7264 - val_loss: 6.2778\n",
      "Epoch 00010: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.4\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "404/405 [============================>.] - ETA: 0s - loss: 6.1245WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 6.1241 - val_loss: 6.4276\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 6.0327 - val_loss: 6.5698\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.8976 - val_loss: 6.4179\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.9934 - val_loss: 6.3783\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 1s 3ms/step - loss: 5.9259 - val_loss: 6.3788\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.9295 - val_loss: 6.6669\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.9660 - val_loss: 6.3785\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.5\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "399/405 [============================>.] - ETA: 0s - loss: 5.8067WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 5.8056 - val_loss: 6.1787\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.6966 - val_loss: 6.2135\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.6183 - val_loss: 6.1928\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.7152 - val_loss: 6.0725\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.6473 - val_loss: 6.1864\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.6345 - val_loss: 6.1753\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.6786 - val_loss: 6.1632\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.6\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "401/405 [============================>.] - ETA: 0s - loss: 5.0977WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 5s 5ms/step - loss: 5.0972 - val_loss: 5.4612\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.0017 - val_loss: 5.4907\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.9480 - val_loss: 5.5550\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 5.0241 - val_loss: 5.4042\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.9883 - val_loss: 5.4249\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.9339 - val_loss: 5.5126\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.9680 - val_loss: 5.4919\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.7\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "400/405 [============================>.] - ETA: 0s - loss: 4.1038WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 4.1033 - val_loss: 4.4120\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.0384 - val_loss: 4.4638\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.0191 - val_loss: 4.4634\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 4.0724 - val_loss: 4.4344\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "0.8\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "402/405 [============================>.] - ETA: 0s - loss: 2.9867WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 2.9865 - val_loss: 3.2101\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9426 - val_loss: 3.1811\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 2.9074 - val_loss: 3.2029\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 2.9534 - val_loss: 3.2172\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 4ms/step - loss: 2.9140 - val_loss: 3.1849\n",
      "Epoch 00005: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "395/405 [============================>.] - ETA: 0s - loss: 1.6562WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n",
      "405/405 [==============================] - 4s 5ms/step - loss: 1.6558 - val_loss: 1.7795\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.6320 - val_loss: 1.7602\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.6004 - val_loss: 1.7725\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.6337 - val_loss: 1.7847\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.6049 - val_loss: 1.7560\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.6030 - val_loss: 1.8209\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.6276 - val_loss: 1.7704\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 1s 3ms/step - loss: 1.6226 - val_loss: 1.7622\n",
      "Epoch 00008: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 25864, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25864, 8), dtype=tf.float32, name='lstm_2_input'), name='lstm_2_input', description=\"created by layer 'lstm_2_input'\"), but it was called on an input with incompatible shape (None, 1, 8).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.329373</td>\n",
       "      <td>1.272975</td>\n",
       "      <td>2.222000</td>\n",
       "      <td>3.875687</td>\n",
       "      <td>5.105513</td>\n",
       "      <td>5.777089</td>\n",
       "      <td>7.476045</td>\n",
       "      <td>10.104208</td>\n",
       "      <td>12.043563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.128118</td>\n",
       "      <td>3.202078</td>\n",
       "      <td>5.518090</td>\n",
       "      <td>9.725550</td>\n",
       "      <td>12.969010</td>\n",
       "      <td>15.099604</td>\n",
       "      <td>18.141224</td>\n",
       "      <td>22.504183</td>\n",
       "      <td>24.998043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.160001</td>\n",
       "      <td>5.547177</td>\n",
       "      <td>8.820875</td>\n",
       "      <td>13.377809</td>\n",
       "      <td>16.289724</td>\n",
       "      <td>18.242142</td>\n",
       "      <td>21.373890</td>\n",
       "      <td>25.896143</td>\n",
       "      <td>28.193527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.460238</td>\n",
       "      <td>8.663424</td>\n",
       "      <td>13.986403</td>\n",
       "      <td>20.827868</td>\n",
       "      <td>26.041220</td>\n",
       "      <td>29.857420</td>\n",
       "      <td>33.051517</td>\n",
       "      <td>39.212105</td>\n",
       "      <td>41.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.107563</td>\n",
       "      <td>11.910898</td>\n",
       "      <td>17.513607</td>\n",
       "      <td>23.314449</td>\n",
       "      <td>27.488192</td>\n",
       "      <td>30.451216</td>\n",
       "      <td>32.408348</td>\n",
       "      <td>37.889675</td>\n",
       "      <td>39.588684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.993871</td>\n",
       "      <td>18.460552</td>\n",
       "      <td>25.109615</td>\n",
       "      <td>26.833054</td>\n",
       "      <td>30.154135</td>\n",
       "      <td>33.465408</td>\n",
       "      <td>32.359592</td>\n",
       "      <td>35.644203</td>\n",
       "      <td>35.074295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.363093</td>\n",
       "      <td>19.981592</td>\n",
       "      <td>25.951077</td>\n",
       "      <td>25.325840</td>\n",
       "      <td>28.332447</td>\n",
       "      <td>33.150784</td>\n",
       "      <td>33.018898</td>\n",
       "      <td>35.123093</td>\n",
       "      <td>34.987961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.228159</td>\n",
       "      <td>19.322693</td>\n",
       "      <td>28.750477</td>\n",
       "      <td>31.273363</td>\n",
       "      <td>37.178356</td>\n",
       "      <td>42.135048</td>\n",
       "      <td>40.336819</td>\n",
       "      <td>47.014378</td>\n",
       "      <td>47.310070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.646490</td>\n",
       "      <td>16.922636</td>\n",
       "      <td>25.574295</td>\n",
       "      <td>30.638409</td>\n",
       "      <td>37.012051</td>\n",
       "      <td>41.465981</td>\n",
       "      <td>40.056301</td>\n",
       "      <td>47.252983</td>\n",
       "      <td>49.060436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.260803</td>\n",
       "      <td>16.316357</td>\n",
       "      <td>25.232349</td>\n",
       "      <td>29.263187</td>\n",
       "      <td>35.237740</td>\n",
       "      <td>39.583549</td>\n",
       "      <td>37.688423</td>\n",
       "      <td>44.847450</td>\n",
       "      <td>47.182415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.623682</td>\n",
       "      <td>18.128372</td>\n",
       "      <td>26.824112</td>\n",
       "      <td>27.669594</td>\n",
       "      <td>32.842304</td>\n",
       "      <td>38.008026</td>\n",
       "      <td>36.251068</td>\n",
       "      <td>42.364960</td>\n",
       "      <td>42.644188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.055909</td>\n",
       "      <td>15.890283</td>\n",
       "      <td>24.498707</td>\n",
       "      <td>26.466946</td>\n",
       "      <td>31.005896</td>\n",
       "      <td>35.155045</td>\n",
       "      <td>33.784100</td>\n",
       "      <td>40.154060</td>\n",
       "      <td>42.670391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.818467</td>\n",
       "      <td>12.408165</td>\n",
       "      <td>21.442879</td>\n",
       "      <td>28.834698</td>\n",
       "      <td>35.341663</td>\n",
       "      <td>39.490532</td>\n",
       "      <td>39.256622</td>\n",
       "      <td>46.276611</td>\n",
       "      <td>53.348797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.374687</td>\n",
       "      <td>13.255543</td>\n",
       "      <td>21.458710</td>\n",
       "      <td>24.519558</td>\n",
       "      <td>27.360790</td>\n",
       "      <td>29.561419</td>\n",
       "      <td>29.029062</td>\n",
       "      <td>33.716805</td>\n",
       "      <td>37.098377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.834748</td>\n",
       "      <td>13.915159</td>\n",
       "      <td>21.748260</td>\n",
       "      <td>23.525955</td>\n",
       "      <td>26.235214</td>\n",
       "      <td>29.125406</td>\n",
       "      <td>28.764288</td>\n",
       "      <td>33.514393</td>\n",
       "      <td>36.397358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.123885</td>\n",
       "      <td>12.532187</td>\n",
       "      <td>18.985107</td>\n",
       "      <td>19.002716</td>\n",
       "      <td>20.060062</td>\n",
       "      <td>22.753223</td>\n",
       "      <td>23.539127</td>\n",
       "      <td>26.719624</td>\n",
       "      <td>28.793344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.545650</td>\n",
       "      <td>9.831881</td>\n",
       "      <td>17.147171</td>\n",
       "      <td>20.896095</td>\n",
       "      <td>21.645552</td>\n",
       "      <td>21.813242</td>\n",
       "      <td>22.039639</td>\n",
       "      <td>24.562485</td>\n",
       "      <td>27.073961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.775307</td>\n",
       "      <td>5.728541</td>\n",
       "      <td>11.096073</td>\n",
       "      <td>15.348503</td>\n",
       "      <td>14.934682</td>\n",
       "      <td>13.533899</td>\n",
       "      <td>13.992954</td>\n",
       "      <td>14.809423</td>\n",
       "      <td>16.402884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.603167</td>\n",
       "      <td>2.393660</td>\n",
       "      <td>4.965306</td>\n",
       "      <td>9.151805</td>\n",
       "      <td>10.362707</td>\n",
       "      <td>10.109591</td>\n",
       "      <td>11.294207</td>\n",
       "      <td>12.022629</td>\n",
       "      <td>15.502774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.281470</td>\n",
       "      <td>0.823242</td>\n",
       "      <td>1.040104</td>\n",
       "      <td>1.075293</td>\n",
       "      <td>1.254039</td>\n",
       "      <td>1.321184</td>\n",
       "      <td>1.716482</td>\n",
       "      <td>2.186939</td>\n",
       "      <td>2.399323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.152913</td>\n",
       "      <td>3.917951</td>\n",
       "      <td>5.252352</td>\n",
       "      <td>4.937126</td>\n",
       "      <td>4.952584</td>\n",
       "      <td>5.789088</td>\n",
       "      <td>6.475689</td>\n",
       "      <td>7.107688</td>\n",
       "      <td>7.609428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.284234</td>\n",
       "      <td>8.551517</td>\n",
       "      <td>10.521102</td>\n",
       "      <td>10.795098</td>\n",
       "      <td>11.350263</td>\n",
       "      <td>13.735605</td>\n",
       "      <td>14.734819</td>\n",
       "      <td>15.409781</td>\n",
       "      <td>15.983940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.160917</td>\n",
       "      <td>12.510571</td>\n",
       "      <td>16.202187</td>\n",
       "      <td>17.685925</td>\n",
       "      <td>18.315889</td>\n",
       "      <td>21.489733</td>\n",
       "      <td>22.719061</td>\n",
       "      <td>23.122620</td>\n",
       "      <td>23.843927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.674736</td>\n",
       "      <td>16.499916</td>\n",
       "      <td>21.969456</td>\n",
       "      <td>24.284307</td>\n",
       "      <td>24.846094</td>\n",
       "      <td>27.991297</td>\n",
       "      <td>29.579254</td>\n",
       "      <td>29.559549</td>\n",
       "      <td>30.446499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.290116</td>\n",
       "      <td>18.970642</td>\n",
       "      <td>26.583889</td>\n",
       "      <td>29.456167</td>\n",
       "      <td>30.375208</td>\n",
       "      <td>33.649197</td>\n",
       "      <td>35.647919</td>\n",
       "      <td>35.563564</td>\n",
       "      <td>36.364796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11.409750</td>\n",
       "      <td>21.657230</td>\n",
       "      <td>30.451183</td>\n",
       "      <td>34.004562</td>\n",
       "      <td>35.169323</td>\n",
       "      <td>38.207138</td>\n",
       "      <td>40.444073</td>\n",
       "      <td>40.758240</td>\n",
       "      <td>41.143299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.049514</td>\n",
       "      <td>23.038967</td>\n",
       "      <td>32.320526</td>\n",
       "      <td>36.200386</td>\n",
       "      <td>38.802258</td>\n",
       "      <td>41.891666</td>\n",
       "      <td>44.190384</td>\n",
       "      <td>45.158058</td>\n",
       "      <td>45.590725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.091581</td>\n",
       "      <td>24.929039</td>\n",
       "      <td>33.709274</td>\n",
       "      <td>37.873466</td>\n",
       "      <td>41.146801</td>\n",
       "      <td>44.239017</td>\n",
       "      <td>46.758072</td>\n",
       "      <td>47.606224</td>\n",
       "      <td>47.952175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.376309</td>\n",
       "      <td>23.827412</td>\n",
       "      <td>33.132587</td>\n",
       "      <td>37.094582</td>\n",
       "      <td>41.094158</td>\n",
       "      <td>45.106354</td>\n",
       "      <td>47.482559</td>\n",
       "      <td>48.801617</td>\n",
       "      <td>49.283482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.145629</td>\n",
       "      <td>23.385645</td>\n",
       "      <td>32.808437</td>\n",
       "      <td>36.664574</td>\n",
       "      <td>40.496777</td>\n",
       "      <td>44.545433</td>\n",
       "      <td>46.895962</td>\n",
       "      <td>48.306332</td>\n",
       "      <td>48.823807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.337456</td>\n",
       "      <td>20.982071</td>\n",
       "      <td>30.661556</td>\n",
       "      <td>33.958252</td>\n",
       "      <td>37.751331</td>\n",
       "      <td>42.337639</td>\n",
       "      <td>44.389053</td>\n",
       "      <td>46.371582</td>\n",
       "      <td>47.246319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9.023592</td>\n",
       "      <td>19.602280</td>\n",
       "      <td>28.647999</td>\n",
       "      <td>31.638607</td>\n",
       "      <td>34.943623</td>\n",
       "      <td>39.253651</td>\n",
       "      <td>41.278557</td>\n",
       "      <td>42.940140</td>\n",
       "      <td>43.961697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.627160</td>\n",
       "      <td>17.230516</td>\n",
       "      <td>24.512157</td>\n",
       "      <td>27.162472</td>\n",
       "      <td>30.440798</td>\n",
       "      <td>35.004349</td>\n",
       "      <td>36.729576</td>\n",
       "      <td>37.935066</td>\n",
       "      <td>39.221050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.894801</td>\n",
       "      <td>14.552773</td>\n",
       "      <td>20.358345</td>\n",
       "      <td>22.927216</td>\n",
       "      <td>25.654211</td>\n",
       "      <td>29.876604</td>\n",
       "      <td>31.200211</td>\n",
       "      <td>32.052986</td>\n",
       "      <td>33.203243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.989256</td>\n",
       "      <td>10.662262</td>\n",
       "      <td>14.695687</td>\n",
       "      <td>16.920227</td>\n",
       "      <td>19.461119</td>\n",
       "      <td>23.344776</td>\n",
       "      <td>24.467306</td>\n",
       "      <td>25.432434</td>\n",
       "      <td>26.377892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.914944</td>\n",
       "      <td>7.749857</td>\n",
       "      <td>10.220388</td>\n",
       "      <td>11.601554</td>\n",
       "      <td>13.405719</td>\n",
       "      <td>16.385185</td>\n",
       "      <td>17.604626</td>\n",
       "      <td>18.383070</td>\n",
       "      <td>18.935654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.031875</td>\n",
       "      <td>5.036841</td>\n",
       "      <td>6.353527</td>\n",
       "      <td>6.720687</td>\n",
       "      <td>7.563734</td>\n",
       "      <td>8.989182</td>\n",
       "      <td>9.952747</td>\n",
       "      <td>10.423515</td>\n",
       "      <td>10.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.350504</td>\n",
       "      <td>1.992132</td>\n",
       "      <td>2.781004</td>\n",
       "      <td>3.468869</td>\n",
       "      <td>3.374558</td>\n",
       "      <td>3.078406</td>\n",
       "      <td>3.169029</td>\n",
       "      <td>3.317488</td>\n",
       "      <td>3.489783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.406368</td>\n",
       "      <td>1.335016</td>\n",
       "      <td>1.928913</td>\n",
       "      <td>2.318510</td>\n",
       "      <td>2.177904</td>\n",
       "      <td>1.495453</td>\n",
       "      <td>1.872091</td>\n",
       "      <td>2.283284</td>\n",
       "      <td>2.301525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.864749</td>\n",
       "      <td>4.283177</td>\n",
       "      <td>5.349444</td>\n",
       "      <td>6.777020</td>\n",
       "      <td>7.233482</td>\n",
       "      <td>7.760514</td>\n",
       "      <td>8.442198</td>\n",
       "      <td>8.987455</td>\n",
       "      <td>9.143443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3.759428</td>\n",
       "      <td>9.304890</td>\n",
       "      <td>11.806891</td>\n",
       "      <td>12.731577</td>\n",
       "      <td>13.249283</td>\n",
       "      <td>15.654570</td>\n",
       "      <td>16.638840</td>\n",
       "      <td>17.251490</td>\n",
       "      <td>17.565552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.332939</td>\n",
       "      <td>12.702641</td>\n",
       "      <td>16.854210</td>\n",
       "      <td>18.760006</td>\n",
       "      <td>19.594412</td>\n",
       "      <td>22.873831</td>\n",
       "      <td>24.181030</td>\n",
       "      <td>24.577845</td>\n",
       "      <td>25.081758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.741753</td>\n",
       "      <td>16.682230</td>\n",
       "      <td>22.602509</td>\n",
       "      <td>25.337088</td>\n",
       "      <td>26.318483</td>\n",
       "      <td>29.746508</td>\n",
       "      <td>31.490782</td>\n",
       "      <td>31.526134</td>\n",
       "      <td>32.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9.150582</td>\n",
       "      <td>18.826040</td>\n",
       "      <td>26.777004</td>\n",
       "      <td>30.070261</td>\n",
       "      <td>31.563866</td>\n",
       "      <td>35.334244</td>\n",
       "      <td>37.491241</td>\n",
       "      <td>37.945538</td>\n",
       "      <td>38.432404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10.473228</td>\n",
       "      <td>20.132496</td>\n",
       "      <td>29.397827</td>\n",
       "      <td>33.441124</td>\n",
       "      <td>35.708488</td>\n",
       "      <td>39.355759</td>\n",
       "      <td>41.478828</td>\n",
       "      <td>42.847137</td>\n",
       "      <td>43.074329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10.391986</td>\n",
       "      <td>20.190556</td>\n",
       "      <td>29.753010</td>\n",
       "      <td>34.221390</td>\n",
       "      <td>38.250462</td>\n",
       "      <td>42.568192</td>\n",
       "      <td>44.442184</td>\n",
       "      <td>46.704884</td>\n",
       "      <td>47.349155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>12.269210</td>\n",
       "      <td>23.013144</td>\n",
       "      <td>33.011841</td>\n",
       "      <td>37.657852</td>\n",
       "      <td>41.880318</td>\n",
       "      <td>45.931225</td>\n",
       "      <td>48.533688</td>\n",
       "      <td>49.954475</td>\n",
       "      <td>50.238041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>12.090740</td>\n",
       "      <td>23.145559</td>\n",
       "      <td>33.233517</td>\n",
       "      <td>37.714043</td>\n",
       "      <td>42.672626</td>\n",
       "      <td>47.496857</td>\n",
       "      <td>50.094948</td>\n",
       "      <td>51.758480</td>\n",
       "      <td>52.188717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          0          0          0          0          0  \\\n",
       "0    0.329373   1.272975   2.222000   3.875687   5.105513   5.777089   \n",
       "1    1.128118   3.202078   5.518090   9.725550  12.969010  15.099604   \n",
       "2    2.160001   5.547177   8.820875  13.377809  16.289724  18.242142   \n",
       "3    3.460238   8.663424  13.986403  20.827868  26.041220  29.857420   \n",
       "4    5.107563  11.910898  17.513607  23.314449  27.488192  30.451216   \n",
       "5    8.993871  18.460552  25.109615  26.833054  30.154135  33.465408   \n",
       "6   10.363093  19.981592  25.951077  25.325840  28.332447  33.150784   \n",
       "7    9.228159  19.322693  28.750477  31.273363  37.178356  42.135048   \n",
       "8    7.646490  16.922636  25.574295  30.638409  37.012051  41.465981   \n",
       "9    7.260803  16.316357  25.232349  29.263187  35.237740  39.583549   \n",
       "10   8.623682  18.128372  26.824112  27.669594  32.842304  38.008026   \n",
       "11   7.055909  15.890283  24.498707  26.466946  31.005896  35.155045   \n",
       "12   4.818467  12.408165  21.442879  28.834698  35.341663  39.490532   \n",
       "13   5.374687  13.255543  21.458710  24.519558  27.360790  29.561419   \n",
       "14   5.834748  13.915159  21.748260  23.525955  26.235214  29.125406   \n",
       "15   5.123885  12.532187  18.985107  19.002716  20.060062  22.753223   \n",
       "16   3.545650   9.831881  17.147171  20.896095  21.645552  21.813242   \n",
       "17   1.775307   5.728541  11.096073  15.348503  14.934682  13.533899   \n",
       "18   0.603167   2.393660   4.965306   9.151805  10.362707  10.109591   \n",
       "19   0.281470   0.823242   1.040104   1.075293   1.254039   1.321184   \n",
       "20   1.152913   3.917951   5.252352   4.937126   4.952584   5.789088   \n",
       "21   3.284234   8.551517  10.521102  10.795098  11.350263  13.735605   \n",
       "22   5.160917  12.510571  16.202187  17.685925  18.315889  21.489733   \n",
       "23   7.674736  16.499916  21.969456  24.284307  24.846094  27.991297   \n",
       "24   9.290116  18.970642  26.583889  29.456167  30.375208  33.649197   \n",
       "25  11.409750  21.657230  30.451183  34.004562  35.169323  38.207138   \n",
       "26  12.049514  23.038967  32.320526  36.200386  38.802258  41.891666   \n",
       "27  13.091581  24.929039  33.709274  37.873466  41.146801  44.239017   \n",
       "28  12.376309  23.827412  33.132587  37.094582  41.094158  45.106354   \n",
       "29  12.145629  23.385645  32.808437  36.664574  40.496777  44.545433   \n",
       "30  10.337456  20.982071  30.661556  33.958252  37.751331  42.337639   \n",
       "31   9.023592  19.602280  28.647999  31.638607  34.943623  39.253651   \n",
       "32   6.627160  17.230516  24.512157  27.162472  30.440798  35.004349   \n",
       "33   4.894801  14.552773  20.358345  22.927216  25.654211  29.876604   \n",
       "34   2.989256  10.662262  14.695687  16.920227  19.461119  23.344776   \n",
       "35   1.914944   7.749857  10.220388  11.601554  13.405719  16.385185   \n",
       "36   1.031875   5.036841   6.353527   6.720687   7.563734   8.989182   \n",
       "37   0.350504   1.992132   2.781004   3.468869   3.374558   3.078406   \n",
       "38   0.406368   1.335016   1.928913   2.318510   2.177904   1.495453   \n",
       "39   1.864749   4.283177   5.349444   6.777020   7.233482   7.760514   \n",
       "40   3.759428   9.304890  11.806891  12.731577  13.249283  15.654570   \n",
       "41   5.332939  12.702641  16.854210  18.760006  19.594412  22.873831   \n",
       "42   7.741753  16.682230  22.602509  25.337088  26.318483  29.746508   \n",
       "43   9.150582  18.826040  26.777004  30.070261  31.563866  35.334244   \n",
       "44  10.473228  20.132496  29.397827  33.441124  35.708488  39.355759   \n",
       "45  10.391986  20.190556  29.753010  34.221390  38.250462  42.568192   \n",
       "46  12.269210  23.013144  33.011841  37.657852  41.880318  45.931225   \n",
       "47  12.090740  23.145559  33.233517  37.714043  42.672626  47.496857   \n",
       "\n",
       "            0          0          0  \n",
       "0    7.476045  10.104208  12.043563  \n",
       "1   18.141224  22.504183  24.998043  \n",
       "2   21.373890  25.896143  28.193527  \n",
       "3   33.051517  39.212105  41.550571  \n",
       "4   32.408348  37.889675  39.588684  \n",
       "5   32.359592  35.644203  35.074295  \n",
       "6   33.018898  35.123093  34.987961  \n",
       "7   40.336819  47.014378  47.310070  \n",
       "8   40.056301  47.252983  49.060436  \n",
       "9   37.688423  44.847450  47.182415  \n",
       "10  36.251068  42.364960  42.644188  \n",
       "11  33.784100  40.154060  42.670391  \n",
       "12  39.256622  46.276611  53.348797  \n",
       "13  29.029062  33.716805  37.098377  \n",
       "14  28.764288  33.514393  36.397358  \n",
       "15  23.539127  26.719624  28.793344  \n",
       "16  22.039639  24.562485  27.073961  \n",
       "17  13.992954  14.809423  16.402884  \n",
       "18  11.294207  12.022629  15.502774  \n",
       "19   1.716482   2.186939   2.399323  \n",
       "20   6.475689   7.107688   7.609428  \n",
       "21  14.734819  15.409781  15.983940  \n",
       "22  22.719061  23.122620  23.843927  \n",
       "23  29.579254  29.559549  30.446499  \n",
       "24  35.647919  35.563564  36.364796  \n",
       "25  40.444073  40.758240  41.143299  \n",
       "26  44.190384  45.158058  45.590725  \n",
       "27  46.758072  47.606224  47.952175  \n",
       "28  47.482559  48.801617  49.283482  \n",
       "29  46.895962  48.306332  48.823807  \n",
       "30  44.389053  46.371582  47.246319  \n",
       "31  41.278557  42.940140  43.961697  \n",
       "32  36.729576  37.935066  39.221050  \n",
       "33  31.200211  32.052986  33.203243  \n",
       "34  24.467306  25.432434  26.377892  \n",
       "35  17.604626  18.383070  18.935654  \n",
       "36   9.952747  10.423515  10.441300  \n",
       "37   3.169029   3.317488   3.489783  \n",
       "38   1.872091   2.283284   2.301525  \n",
       "39   8.442198   8.987455   9.143443  \n",
       "40  16.638840  17.251490  17.565552  \n",
       "41  24.181030  24.577845  25.081758  \n",
       "42  31.490782  31.526134  32.296700  \n",
       "43  37.491241  37.945538  38.432404  \n",
       "44  41.478828  42.847137  43.074329  \n",
       "45  44.442184  46.704884  47.349155  \n",
       "46  48.533688  49.954475  50.238041  \n",
       "47  50.094948  51.758480  52.188717  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_M8 = tf.keras.Sequential([\n",
    "    layers.LSTM(units=64, return_sequences=True, input_shape=[25864, 8]),\n",
    "    layers.LSTM(units=32),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result_M8 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model_M8.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model_M8.fit(np.array(Day0).reshape(25864, 1, 8), np.array(Day8).reshape(25864, 1)\n",
    "                 , epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred_M8 = np.squeeze(model_M8.predict(np.array(df_test0).reshape(1539, 1, 8)))\n",
    "    pred_M8 = pd.DataFrame(pred_M8)\n",
    "    result_M8 = pd.concat([result_M8, pred_M8], axis=1)\n",
    "    \n",
    "result_M8[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_L0 = pd.DataFrame(results_1.sort_index())\n",
    "res_L0.columns = ['L00.1','L00.2','L00.3','L00.4','L00.5','L00.6','L00.7','L00.8','L00.9']\n",
    "res_L1 = pd.DataFrame(results_2.sort_index())\n",
    "res_L1.columns = ['L10.1','L10.2','L10.3','L10.4','L10.5','L10.6','L10.7','L10.8','L10.9']\n",
    "\n",
    "res_D0 = pd.DataFrame(results[0].sort_index())\n",
    "res_D0.columns = ['D00.1','D00.2','D00.3','D00.4','D00.5','D00.6','D00.7','D00.8','D00.9']\n",
    "res_D1 = pd.DataFrame(results[1].sort_index())\n",
    "res_D1.columns = ['D10.1','D10.2','D10.3','D10.4','D10.5','D10.6','D10.7','D10.8','D10.9']\n",
    "\n",
    "res_C0 = pd.DataFrame(result7.sort_index())\n",
    "res_C0.columns = ['C00.1','C00.2','C00.3','C00.4','C00.5','C00.6','C00.7','C00.8','C00.9']\n",
    "res_C1 = pd.DataFrame(result8.sort_index())\n",
    "res_C1.columns = ['C10.1','C10.2','C10.3','C10.4','C10.5','C10.6','C10.7','C10.8','C10.9']\n",
    "\n",
    "res_G0 = pd.DataFrame(result_G7.sort_index())\n",
    "res_G0.columns = ['G00.1','G00.2','G00.3','G00.4','G00.5','G00.6','G00.7','G00.8','G00.9']\n",
    "res_G1 = pd.DataFrame(result_G8.sort_index())\n",
    "res_G1.columns = ['G10.1','G10.2','G10.3','G10.4','G10.5','G10.6','G10.7','G10.8','G10.9']\n",
    "\n",
    "res_M0 = pd.DataFrame(result_M7.sort_index())\n",
    "res_M0.columns = ['M00.1','M00.2','M00.3','M00.4','M00.5','M00.6','M00.7','M00.8','M00.9']\n",
    "res_M1 = pd.DataFrame(result_M8.sort_index())\n",
    "res_M1.columns = ['M10.1','M10.2','M10.3','M10.4','M10.5','M10.6','M10.7','M10.8','M10.9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_0 = pd.DataFrame()\n",
    "res_1= pd.DataFrame()\n",
    "res_0 = pd.concat([res_L0, res_D0, res_C0, res_G0, res_M0], axis=1)\n",
    "res_1 = pd.concat([res_L1, res_D1, res_C1, res_G1, res_M1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L00.1</th>\n",
       "      <th>L00.2</th>\n",
       "      <th>L00.3</th>\n",
       "      <th>L00.4</th>\n",
       "      <th>L00.5</th>\n",
       "      <th>L00.6</th>\n",
       "      <th>L00.7</th>\n",
       "      <th>L00.8</th>\n",
       "      <th>L00.9</th>\n",
       "      <th>D00.1</th>\n",
       "      <th>...</th>\n",
       "      <th>G00.9</th>\n",
       "      <th>M00.1</th>\n",
       "      <th>M00.2</th>\n",
       "      <th>M00.3</th>\n",
       "      <th>M00.4</th>\n",
       "      <th>M00.5</th>\n",
       "      <th>M00.6</th>\n",
       "      <th>M00.7</th>\n",
       "      <th>M00.8</th>\n",
       "      <th>M00.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.21</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.69</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.82</td>\n",
       "      <td>7.76</td>\n",
       "      <td>13.55</td>\n",
       "      <td>0.907302</td>\n",
       "      <td>...</td>\n",
       "      <td>9.765275</td>\n",
       "      <td>0.651626</td>\n",
       "      <td>1.412930</td>\n",
       "      <td>1.663878</td>\n",
       "      <td>2.391623</td>\n",
       "      <td>3.620630</td>\n",
       "      <td>3.022576</td>\n",
       "      <td>5.746896</td>\n",
       "      <td>6.427562</td>\n",
       "      <td>10.876079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.02</td>\n",
       "      <td>5.08</td>\n",
       "      <td>3.72</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.37</td>\n",
       "      <td>11.08</td>\n",
       "      <td>13.85</td>\n",
       "      <td>16.70</td>\n",
       "      <td>24.47</td>\n",
       "      <td>2.578902</td>\n",
       "      <td>...</td>\n",
       "      <td>21.188997</td>\n",
       "      <td>1.516569</td>\n",
       "      <td>3.200346</td>\n",
       "      <td>5.007691</td>\n",
       "      <td>7.612739</td>\n",
       "      <td>10.807425</td>\n",
       "      <td>10.988094</td>\n",
       "      <td>16.742872</td>\n",
       "      <td>18.460148</td>\n",
       "      <td>25.416058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.95</td>\n",
       "      <td>7.68</td>\n",
       "      <td>6.93</td>\n",
       "      <td>9.15</td>\n",
       "      <td>11.44</td>\n",
       "      <td>13.54</td>\n",
       "      <td>17.00</td>\n",
       "      <td>22.30</td>\n",
       "      <td>30.41</td>\n",
       "      <td>3.995721</td>\n",
       "      <td>...</td>\n",
       "      <td>27.756762</td>\n",
       "      <td>2.490597</td>\n",
       "      <td>5.195635</td>\n",
       "      <td>8.690712</td>\n",
       "      <td>12.623331</td>\n",
       "      <td>16.221693</td>\n",
       "      <td>14.467131</td>\n",
       "      <td>20.739613</td>\n",
       "      <td>22.330959</td>\n",
       "      <td>30.209188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.75</td>\n",
       "      <td>18.21</td>\n",
       "      <td>14.21</td>\n",
       "      <td>12.27</td>\n",
       "      <td>13.04</td>\n",
       "      <td>14.29</td>\n",
       "      <td>24.18</td>\n",
       "      <td>23.67</td>\n",
       "      <td>32.19</td>\n",
       "      <td>7.144335</td>\n",
       "      <td>...</td>\n",
       "      <td>42.049759</td>\n",
       "      <td>3.558703</td>\n",
       "      <td>7.637560</td>\n",
       "      <td>13.491122</td>\n",
       "      <td>18.699293</td>\n",
       "      <td>23.502199</td>\n",
       "      <td>22.880861</td>\n",
       "      <td>31.975574</td>\n",
       "      <td>36.150452</td>\n",
       "      <td>46.415920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.46</td>\n",
       "      <td>19.97</td>\n",
       "      <td>19.76</td>\n",
       "      <td>14.46</td>\n",
       "      <td>14.23</td>\n",
       "      <td>17.93</td>\n",
       "      <td>24.89</td>\n",
       "      <td>24.49</td>\n",
       "      <td>33.79</td>\n",
       "      <td>9.069969</td>\n",
       "      <td>...</td>\n",
       "      <td>41.642868</td>\n",
       "      <td>4.839878</td>\n",
       "      <td>10.198141</td>\n",
       "      <td>17.454243</td>\n",
       "      <td>22.693516</td>\n",
       "      <td>27.092474</td>\n",
       "      <td>24.169703</td>\n",
       "      <td>32.847008</td>\n",
       "      <td>36.482132</td>\n",
       "      <td>46.895279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.49</td>\n",
       "      <td>33.17</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.79</td>\n",
       "      <td>31.74</td>\n",
       "      <td>29.02</td>\n",
       "      <td>32.47</td>\n",
       "      <td>31.01</td>\n",
       "      <td>35.08</td>\n",
       "      <td>13.219215</td>\n",
       "      <td>...</td>\n",
       "      <td>37.664337</td>\n",
       "      <td>7.798664</td>\n",
       "      <td>15.330933</td>\n",
       "      <td>24.164576</td>\n",
       "      <td>27.350012</td>\n",
       "      <td>31.454496</td>\n",
       "      <td>30.598495</td>\n",
       "      <td>36.305202</td>\n",
       "      <td>37.333523</td>\n",
       "      <td>40.848919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.84</td>\n",
       "      <td>30.46</td>\n",
       "      <td>33.34</td>\n",
       "      <td>34.52</td>\n",
       "      <td>33.37</td>\n",
       "      <td>31.68</td>\n",
       "      <td>34.05</td>\n",
       "      <td>34.45</td>\n",
       "      <td>33.44</td>\n",
       "      <td>13.704938</td>\n",
       "      <td>...</td>\n",
       "      <td>38.413773</td>\n",
       "      <td>9.042477</td>\n",
       "      <td>16.690411</td>\n",
       "      <td>24.624172</td>\n",
       "      <td>27.018827</td>\n",
       "      <td>31.540594</td>\n",
       "      <td>32.735386</td>\n",
       "      <td>37.522675</td>\n",
       "      <td>38.003830</td>\n",
       "      <td>39.672966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.18</td>\n",
       "      <td>34.47</td>\n",
       "      <td>41.16</td>\n",
       "      <td>42.26</td>\n",
       "      <td>45.32</td>\n",
       "      <td>32.25</td>\n",
       "      <td>36.77</td>\n",
       "      <td>36.94</td>\n",
       "      <td>41.94</td>\n",
       "      <td>15.420390</td>\n",
       "      <td>...</td>\n",
       "      <td>46.399887</td>\n",
       "      <td>8.000772</td>\n",
       "      <td>16.136662</td>\n",
       "      <td>27.386908</td>\n",
       "      <td>31.172380</td>\n",
       "      <td>36.419567</td>\n",
       "      <td>36.419098</td>\n",
       "      <td>43.420963</td>\n",
       "      <td>46.874535</td>\n",
       "      <td>51.689362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.98</td>\n",
       "      <td>28.02</td>\n",
       "      <td>33.01</td>\n",
       "      <td>36.39</td>\n",
       "      <td>38.08</td>\n",
       "      <td>30.77</td>\n",
       "      <td>31.88</td>\n",
       "      <td>33.00</td>\n",
       "      <td>40.99</td>\n",
       "      <td>14.241913</td>\n",
       "      <td>...</td>\n",
       "      <td>45.065361</td>\n",
       "      <td>6.773403</td>\n",
       "      <td>14.348423</td>\n",
       "      <td>24.432497</td>\n",
       "      <td>28.812801</td>\n",
       "      <td>33.840446</td>\n",
       "      <td>33.451294</td>\n",
       "      <td>41.137058</td>\n",
       "      <td>45.712769</td>\n",
       "      <td>52.616653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.81</td>\n",
       "      <td>28.88</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.41</td>\n",
       "      <td>35.41</td>\n",
       "      <td>29.31</td>\n",
       "      <td>32.04</td>\n",
       "      <td>30.31</td>\n",
       "      <td>34.51</td>\n",
       "      <td>13.757400</td>\n",
       "      <td>...</td>\n",
       "      <td>42.480476</td>\n",
       "      <td>6.526613</td>\n",
       "      <td>14.123219</td>\n",
       "      <td>23.619312</td>\n",
       "      <td>27.363253</td>\n",
       "      <td>32.228859</td>\n",
       "      <td>32.443634</td>\n",
       "      <td>38.739780</td>\n",
       "      <td>43.119469</td>\n",
       "      <td>48.208645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.53</td>\n",
       "      <td>33.20</td>\n",
       "      <td>35.54</td>\n",
       "      <td>35.72</td>\n",
       "      <td>38.17</td>\n",
       "      <td>29.63</td>\n",
       "      <td>35.03</td>\n",
       "      <td>35.92</td>\n",
       "      <td>38.92</td>\n",
       "      <td>13.774226</td>\n",
       "      <td>...</td>\n",
       "      <td>41.361061</td>\n",
       "      <td>7.603545</td>\n",
       "      <td>15.554159</td>\n",
       "      <td>25.120960</td>\n",
       "      <td>27.971552</td>\n",
       "      <td>32.967682</td>\n",
       "      <td>34.105930</td>\n",
       "      <td>39.612999</td>\n",
       "      <td>42.696678</td>\n",
       "      <td>45.417057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.55</td>\n",
       "      <td>22.72</td>\n",
       "      <td>30.72</td>\n",
       "      <td>34.70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>29.95</td>\n",
       "      <td>31.44</td>\n",
       "      <td>30.88</td>\n",
       "      <td>35.57</td>\n",
       "      <td>12.409553</td>\n",
       "      <td>...</td>\n",
       "      <td>39.996712</td>\n",
       "      <td>6.406276</td>\n",
       "      <td>14.052549</td>\n",
       "      <td>22.800934</td>\n",
       "      <td>25.745050</td>\n",
       "      <td>30.354742</td>\n",
       "      <td>30.901155</td>\n",
       "      <td>35.742340</td>\n",
       "      <td>39.410156</td>\n",
       "      <td>42.511856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.80</td>\n",
       "      <td>21.14</td>\n",
       "      <td>26.15</td>\n",
       "      <td>23.59</td>\n",
       "      <td>20.41</td>\n",
       "      <td>23.02</td>\n",
       "      <td>29.91</td>\n",
       "      <td>39.10</td>\n",
       "      <td>42.60</td>\n",
       "      <td>12.684363</td>\n",
       "      <td>...</td>\n",
       "      <td>49.664555</td>\n",
       "      <td>4.629732</td>\n",
       "      <td>10.896416</td>\n",
       "      <td>19.137058</td>\n",
       "      <td>23.736738</td>\n",
       "      <td>28.941547</td>\n",
       "      <td>29.564463</td>\n",
       "      <td>36.140732</td>\n",
       "      <td>42.907837</td>\n",
       "      <td>50.200787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.49</td>\n",
       "      <td>19.90</td>\n",
       "      <td>25.77</td>\n",
       "      <td>25.05</td>\n",
       "      <td>22.90</td>\n",
       "      <td>23.45</td>\n",
       "      <td>24.93</td>\n",
       "      <td>24.84</td>\n",
       "      <td>30.87</td>\n",
       "      <td>10.829406</td>\n",
       "      <td>...</td>\n",
       "      <td>37.069763</td>\n",
       "      <td>5.115972</td>\n",
       "      <td>11.971090</td>\n",
       "      <td>19.373894</td>\n",
       "      <td>22.384325</td>\n",
       "      <td>26.411833</td>\n",
       "      <td>26.014959</td>\n",
       "      <td>29.550989</td>\n",
       "      <td>32.987003</td>\n",
       "      <td>35.909557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.55</td>\n",
       "      <td>20.48</td>\n",
       "      <td>25.08</td>\n",
       "      <td>27.33</td>\n",
       "      <td>25.55</td>\n",
       "      <td>21.13</td>\n",
       "      <td>24.69</td>\n",
       "      <td>25.98</td>\n",
       "      <td>31.35</td>\n",
       "      <td>10.728248</td>\n",
       "      <td>...</td>\n",
       "      <td>34.808895</td>\n",
       "      <td>5.443573</td>\n",
       "      <td>12.486110</td>\n",
       "      <td>19.612082</td>\n",
       "      <td>22.179161</td>\n",
       "      <td>26.143351</td>\n",
       "      <td>26.252958</td>\n",
       "      <td>29.690475</td>\n",
       "      <td>32.779518</td>\n",
       "      <td>35.155376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.74</td>\n",
       "      <td>19.55</td>\n",
       "      <td>21.24</td>\n",
       "      <td>21.84</td>\n",
       "      <td>24.01</td>\n",
       "      <td>22.53</td>\n",
       "      <td>22.90</td>\n",
       "      <td>23.22</td>\n",
       "      <td>30.14</td>\n",
       "      <td>8.744321</td>\n",
       "      <td>...</td>\n",
       "      <td>27.836548</td>\n",
       "      <td>4.974761</td>\n",
       "      <td>11.723354</td>\n",
       "      <td>17.318130</td>\n",
       "      <td>19.118971</td>\n",
       "      <td>22.304539</td>\n",
       "      <td>22.179451</td>\n",
       "      <td>24.334892</td>\n",
       "      <td>26.449394</td>\n",
       "      <td>27.809347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.43</td>\n",
       "      <td>15.27</td>\n",
       "      <td>14.78</td>\n",
       "      <td>15.09</td>\n",
       "      <td>15.30</td>\n",
       "      <td>14.56</td>\n",
       "      <td>16.53</td>\n",
       "      <td>16.20</td>\n",
       "      <td>16.97</td>\n",
       "      <td>7.892495</td>\n",
       "      <td>...</td>\n",
       "      <td>30.630814</td>\n",
       "      <td>3.637974</td>\n",
       "      <td>8.903531</td>\n",
       "      <td>14.418842</td>\n",
       "      <td>17.392981</td>\n",
       "      <td>20.881630</td>\n",
       "      <td>19.549978</td>\n",
       "      <td>21.511440</td>\n",
       "      <td>24.072803</td>\n",
       "      <td>26.282967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.01</td>\n",
       "      <td>9.46</td>\n",
       "      <td>9.11</td>\n",
       "      <td>6.71</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.98</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.74</td>\n",
       "      <td>14.31</td>\n",
       "      <td>4.481168</td>\n",
       "      <td>...</td>\n",
       "      <td>21.702719</td>\n",
       "      <td>2.095726</td>\n",
       "      <td>5.311701</td>\n",
       "      <td>9.121095</td>\n",
       "      <td>11.956009</td>\n",
       "      <td>15.396475</td>\n",
       "      <td>13.270828</td>\n",
       "      <td>13.999071</td>\n",
       "      <td>15.685595</td>\n",
       "      <td>17.190290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.94</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.97</td>\n",
       "      <td>6.43</td>\n",
       "      <td>10.87</td>\n",
       "      <td>3.501750</td>\n",
       "      <td>...</td>\n",
       "      <td>15.400671</td>\n",
       "      <td>0.881682</td>\n",
       "      <td>2.370034</td>\n",
       "      <td>4.221588</td>\n",
       "      <td>6.204017</td>\n",
       "      <td>9.654202</td>\n",
       "      <td>9.231308</td>\n",
       "      <td>10.874598</td>\n",
       "      <td>13.524657</td>\n",
       "      <td>16.031055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.083755</td>\n",
       "      <td>...</td>\n",
       "      <td>1.933169</td>\n",
       "      <td>0.658838</td>\n",
       "      <td>1.330434</td>\n",
       "      <td>1.154504</td>\n",
       "      <td>1.063127</td>\n",
       "      <td>1.130794</td>\n",
       "      <td>1.519910</td>\n",
       "      <td>1.990139</td>\n",
       "      <td>2.151956</td>\n",
       "      <td>2.062776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.61</td>\n",
       "      <td>3.59</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.33</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.56</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.57</td>\n",
       "      <td>3.379551</td>\n",
       "      <td>...</td>\n",
       "      <td>7.792755</td>\n",
       "      <td>2.194237</td>\n",
       "      <td>4.143533</td>\n",
       "      <td>6.064661</td>\n",
       "      <td>6.699108</td>\n",
       "      <td>7.300083</td>\n",
       "      <td>6.369847</td>\n",
       "      <td>7.500924</td>\n",
       "      <td>8.008971</td>\n",
       "      <td>8.124584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.16</td>\n",
       "      <td>8.99</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.06</td>\n",
       "      <td>12.68</td>\n",
       "      <td>13.53</td>\n",
       "      <td>15.22</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.19</td>\n",
       "      <td>6.383345</td>\n",
       "      <td>...</td>\n",
       "      <td>15.665381</td>\n",
       "      <td>5.194424</td>\n",
       "      <td>9.521467</td>\n",
       "      <td>12.363936</td>\n",
       "      <td>14.115209</td>\n",
       "      <td>16.184280</td>\n",
       "      <td>14.823651</td>\n",
       "      <td>16.502480</td>\n",
       "      <td>16.413942</td>\n",
       "      <td>17.070805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.85</td>\n",
       "      <td>19.44</td>\n",
       "      <td>22.57</td>\n",
       "      <td>22.26</td>\n",
       "      <td>20.77</td>\n",
       "      <td>22.25</td>\n",
       "      <td>23.12</td>\n",
       "      <td>23.11</td>\n",
       "      <td>23.16</td>\n",
       "      <td>9.966775</td>\n",
       "      <td>...</td>\n",
       "      <td>23.882532</td>\n",
       "      <td>7.201926</td>\n",
       "      <td>13.911270</td>\n",
       "      <td>18.494589</td>\n",
       "      <td>21.497286</td>\n",
       "      <td>24.298449</td>\n",
       "      <td>22.940239</td>\n",
       "      <td>25.367527</td>\n",
       "      <td>24.350090</td>\n",
       "      <td>25.905735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.35</td>\n",
       "      <td>22.78</td>\n",
       "      <td>23.24</td>\n",
       "      <td>22.13</td>\n",
       "      <td>27.21</td>\n",
       "      <td>28.29</td>\n",
       "      <td>28.58</td>\n",
       "      <td>29.19</td>\n",
       "      <td>30.69</td>\n",
       "      <td>13.693385</td>\n",
       "      <td>...</td>\n",
       "      <td>31.443598</td>\n",
       "      <td>10.162374</td>\n",
       "      <td>19.149075</td>\n",
       "      <td>24.062498</td>\n",
       "      <td>28.397135</td>\n",
       "      <td>31.457529</td>\n",
       "      <td>29.828190</td>\n",
       "      <td>32.615334</td>\n",
       "      <td>31.043741</td>\n",
       "      <td>33.637703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23.16</td>\n",
       "      <td>25.54</td>\n",
       "      <td>27.38</td>\n",
       "      <td>30.68</td>\n",
       "      <td>32.23</td>\n",
       "      <td>33.56</td>\n",
       "      <td>35.70</td>\n",
       "      <td>35.72</td>\n",
       "      <td>36.23</td>\n",
       "      <td>16.060265</td>\n",
       "      <td>...</td>\n",
       "      <td>37.763214</td>\n",
       "      <td>12.351465</td>\n",
       "      <td>23.467091</td>\n",
       "      <td>28.608976</td>\n",
       "      <td>33.889027</td>\n",
       "      <td>37.274853</td>\n",
       "      <td>35.951912</td>\n",
       "      <td>38.707848</td>\n",
       "      <td>37.523529</td>\n",
       "      <td>40.748180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24.20</td>\n",
       "      <td>26.76</td>\n",
       "      <td>34.43</td>\n",
       "      <td>34.61</td>\n",
       "      <td>34.10</td>\n",
       "      <td>37.38</td>\n",
       "      <td>39.56</td>\n",
       "      <td>40.91</td>\n",
       "      <td>40.63</td>\n",
       "      <td>18.122995</td>\n",
       "      <td>...</td>\n",
       "      <td>42.614044</td>\n",
       "      <td>14.922377</td>\n",
       "      <td>28.431149</td>\n",
       "      <td>33.837650</td>\n",
       "      <td>39.051540</td>\n",
       "      <td>42.399414</td>\n",
       "      <td>40.622681</td>\n",
       "      <td>43.320438</td>\n",
       "      <td>42.592911</td>\n",
       "      <td>45.904675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>34.63</td>\n",
       "      <td>44.78</td>\n",
       "      <td>39.29</td>\n",
       "      <td>39.37</td>\n",
       "      <td>41.10</td>\n",
       "      <td>42.40</td>\n",
       "      <td>44.60</td>\n",
       "      <td>45.02</td>\n",
       "      <td>45.32</td>\n",
       "      <td>19.072941</td>\n",
       "      <td>...</td>\n",
       "      <td>46.444283</td>\n",
       "      <td>15.803480</td>\n",
       "      <td>30.593998</td>\n",
       "      <td>36.715950</td>\n",
       "      <td>42.036961</td>\n",
       "      <td>45.731613</td>\n",
       "      <td>44.404572</td>\n",
       "      <td>46.926956</td>\n",
       "      <td>46.717934</td>\n",
       "      <td>49.881439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>35.95</td>\n",
       "      <td>41.92</td>\n",
       "      <td>40.53</td>\n",
       "      <td>41.40</td>\n",
       "      <td>43.92</td>\n",
       "      <td>44.44</td>\n",
       "      <td>47.38</td>\n",
       "      <td>47.46</td>\n",
       "      <td>48.00</td>\n",
       "      <td>20.039961</td>\n",
       "      <td>...</td>\n",
       "      <td>48.781582</td>\n",
       "      <td>17.070126</td>\n",
       "      <td>33.137630</td>\n",
       "      <td>39.420242</td>\n",
       "      <td>44.573887</td>\n",
       "      <td>48.342800</td>\n",
       "      <td>46.763161</td>\n",
       "      <td>49.361698</td>\n",
       "      <td>49.220634</td>\n",
       "      <td>52.356319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>37.22</td>\n",
       "      <td>46.59</td>\n",
       "      <td>43.20</td>\n",
       "      <td>45.22</td>\n",
       "      <td>45.11</td>\n",
       "      <td>46.75</td>\n",
       "      <td>47.83</td>\n",
       "      <td>49.36</td>\n",
       "      <td>49.20</td>\n",
       "      <td>19.868374</td>\n",
       "      <td>...</td>\n",
       "      <td>49.875072</td>\n",
       "      <td>16.520857</td>\n",
       "      <td>32.114845</td>\n",
       "      <td>38.556282</td>\n",
       "      <td>44.032230</td>\n",
       "      <td>48.172718</td>\n",
       "      <td>47.504570</td>\n",
       "      <td>50.051456</td>\n",
       "      <td>50.204514</td>\n",
       "      <td>53.180050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>38.92</td>\n",
       "      <td>47.51</td>\n",
       "      <td>44.49</td>\n",
       "      <td>45.68</td>\n",
       "      <td>44.82</td>\n",
       "      <td>45.24</td>\n",
       "      <td>47.44</td>\n",
       "      <td>47.66</td>\n",
       "      <td>48.24</td>\n",
       "      <td>19.697437</td>\n",
       "      <td>...</td>\n",
       "      <td>49.417213</td>\n",
       "      <td>16.402988</td>\n",
       "      <td>31.783100</td>\n",
       "      <td>38.033119</td>\n",
       "      <td>43.522022</td>\n",
       "      <td>47.672394</td>\n",
       "      <td>47.026474</td>\n",
       "      <td>49.578156</td>\n",
       "      <td>49.716343</td>\n",
       "      <td>52.688320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32.31</td>\n",
       "      <td>40.78</td>\n",
       "      <td>41.03</td>\n",
       "      <td>42.77</td>\n",
       "      <td>41.76</td>\n",
       "      <td>43.91</td>\n",
       "      <td>45.65</td>\n",
       "      <td>46.11</td>\n",
       "      <td>45.99</td>\n",
       "      <td>18.383503</td>\n",
       "      <td>...</td>\n",
       "      <td>47.576416</td>\n",
       "      <td>14.388479</td>\n",
       "      <td>27.978525</td>\n",
       "      <td>34.172054</td>\n",
       "      <td>40.071667</td>\n",
       "      <td>44.455048</td>\n",
       "      <td>44.775650</td>\n",
       "      <td>47.179844</td>\n",
       "      <td>47.505325</td>\n",
       "      <td>50.336075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>28.41</td>\n",
       "      <td>40.74</td>\n",
       "      <td>34.27</td>\n",
       "      <td>37.77</td>\n",
       "      <td>37.54</td>\n",
       "      <td>39.47</td>\n",
       "      <td>42.69</td>\n",
       "      <td>43.06</td>\n",
       "      <td>43.14</td>\n",
       "      <td>16.978943</td>\n",
       "      <td>...</td>\n",
       "      <td>44.174637</td>\n",
       "      <td>12.645197</td>\n",
       "      <td>24.863316</td>\n",
       "      <td>30.909405</td>\n",
       "      <td>36.927879</td>\n",
       "      <td>41.220608</td>\n",
       "      <td>41.614090</td>\n",
       "      <td>44.006359</td>\n",
       "      <td>44.118290</td>\n",
       "      <td>46.976162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20.90</td>\n",
       "      <td>27.69</td>\n",
       "      <td>28.46</td>\n",
       "      <td>33.65</td>\n",
       "      <td>34.02</td>\n",
       "      <td>35.00</td>\n",
       "      <td>37.63</td>\n",
       "      <td>38.57</td>\n",
       "      <td>38.50</td>\n",
       "      <td>14.118104</td>\n",
       "      <td>...</td>\n",
       "      <td>39.584984</td>\n",
       "      <td>9.272047</td>\n",
       "      <td>19.500896</td>\n",
       "      <td>25.967335</td>\n",
       "      <td>31.911280</td>\n",
       "      <td>36.102921</td>\n",
       "      <td>37.063538</td>\n",
       "      <td>39.377338</td>\n",
       "      <td>39.243500</td>\n",
       "      <td>42.055561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>18.31</td>\n",
       "      <td>25.77</td>\n",
       "      <td>28.89</td>\n",
       "      <td>26.08</td>\n",
       "      <td>27.76</td>\n",
       "      <td>31.22</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.45</td>\n",
       "      <td>11.514292</td>\n",
       "      <td>...</td>\n",
       "      <td>33.977402</td>\n",
       "      <td>6.735143</td>\n",
       "      <td>15.393017</td>\n",
       "      <td>22.137846</td>\n",
       "      <td>27.239832</td>\n",
       "      <td>30.955410</td>\n",
       "      <td>31.844326</td>\n",
       "      <td>34.124058</td>\n",
       "      <td>33.557854</td>\n",
       "      <td>35.941757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11.08</td>\n",
       "      <td>23.03</td>\n",
       "      <td>24.38</td>\n",
       "      <td>22.38</td>\n",
       "      <td>24.69</td>\n",
       "      <td>26.11</td>\n",
       "      <td>25.42</td>\n",
       "      <td>25.57</td>\n",
       "      <td>25.94</td>\n",
       "      <td>8.187277</td>\n",
       "      <td>...</td>\n",
       "      <td>26.437605</td>\n",
       "      <td>4.017846</td>\n",
       "      <td>10.450139</td>\n",
       "      <td>16.765533</td>\n",
       "      <td>20.526527</td>\n",
       "      <td>23.926764</td>\n",
       "      <td>24.945961</td>\n",
       "      <td>27.202299</td>\n",
       "      <td>26.751408</td>\n",
       "      <td>28.041607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.36</td>\n",
       "      <td>13.11</td>\n",
       "      <td>16.95</td>\n",
       "      <td>17.69</td>\n",
       "      <td>17.08</td>\n",
       "      <td>17.72</td>\n",
       "      <td>17.97</td>\n",
       "      <td>18.39</td>\n",
       "      <td>18.84</td>\n",
       "      <td>5.701241</td>\n",
       "      <td>...</td>\n",
       "      <td>18.480204</td>\n",
       "      <td>2.785563</td>\n",
       "      <td>7.429151</td>\n",
       "      <td>12.208894</td>\n",
       "      <td>14.666439</td>\n",
       "      <td>17.456865</td>\n",
       "      <td>17.924042</td>\n",
       "      <td>19.670921</td>\n",
       "      <td>19.398064</td>\n",
       "      <td>19.790562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.34</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.84</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.95</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.87</td>\n",
       "      <td>3.956131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.304486</td>\n",
       "      <td>1.692700</td>\n",
       "      <td>4.617312</td>\n",
       "      <td>7.607981</td>\n",
       "      <td>8.773732</td>\n",
       "      <td>10.247350</td>\n",
       "      <td>10.136093</td>\n",
       "      <td>11.172242</td>\n",
       "      <td>11.213359</td>\n",
       "      <td>11.001766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.06</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.767852</td>\n",
       "      <td>...</td>\n",
       "      <td>3.157816</td>\n",
       "      <td>0.575418</td>\n",
       "      <td>1.738009</td>\n",
       "      <td>2.904547</td>\n",
       "      <td>2.923477</td>\n",
       "      <td>3.138932</td>\n",
       "      <td>3.046759</td>\n",
       "      <td>3.384630</td>\n",
       "      <td>3.494174</td>\n",
       "      <td>3.226869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.549785</td>\n",
       "      <td>...</td>\n",
       "      <td>2.481506</td>\n",
       "      <td>0.802291</td>\n",
       "      <td>1.708197</td>\n",
       "      <td>1.521986</td>\n",
       "      <td>1.702527</td>\n",
       "      <td>1.867783</td>\n",
       "      <td>1.149644</td>\n",
       "      <td>1.899064</td>\n",
       "      <td>1.940590</td>\n",
       "      <td>2.484862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.17</td>\n",
       "      <td>3.61</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.24</td>\n",
       "      <td>7.03</td>\n",
       "      <td>7.36</td>\n",
       "      <td>7.70</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.39</td>\n",
       "      <td>2.886923</td>\n",
       "      <td>...</td>\n",
       "      <td>8.750995</td>\n",
       "      <td>2.696599</td>\n",
       "      <td>4.853239</td>\n",
       "      <td>5.843548</td>\n",
       "      <td>7.078466</td>\n",
       "      <td>8.430592</td>\n",
       "      <td>8.103583</td>\n",
       "      <td>8.848512</td>\n",
       "      <td>8.873066</td>\n",
       "      <td>8.871959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.82</td>\n",
       "      <td>10.20</td>\n",
       "      <td>13.27</td>\n",
       "      <td>15.31</td>\n",
       "      <td>15.99</td>\n",
       "      <td>16.46</td>\n",
       "      <td>17.05</td>\n",
       "      <td>16.86</td>\n",
       "      <td>16.96</td>\n",
       "      <td>6.471984</td>\n",
       "      <td>...</td>\n",
       "      <td>17.885265</td>\n",
       "      <td>5.312920</td>\n",
       "      <td>9.667276</td>\n",
       "      <td>12.834445</td>\n",
       "      <td>14.787426</td>\n",
       "      <td>17.129389</td>\n",
       "      <td>16.120167</td>\n",
       "      <td>17.920708</td>\n",
       "      <td>17.645054</td>\n",
       "      <td>18.492777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>9.21</td>\n",
       "      <td>15.81</td>\n",
       "      <td>19.20</td>\n",
       "      <td>21.31</td>\n",
       "      <td>22.58</td>\n",
       "      <td>22.97</td>\n",
       "      <td>23.40</td>\n",
       "      <td>23.81</td>\n",
       "      <td>25.24</td>\n",
       "      <td>9.221293</td>\n",
       "      <td>...</td>\n",
       "      <td>25.205109</td>\n",
       "      <td>6.630163</td>\n",
       "      <td>12.487499</td>\n",
       "      <td>17.367464</td>\n",
       "      <td>20.572191</td>\n",
       "      <td>23.661013</td>\n",
       "      <td>23.134224</td>\n",
       "      <td>25.733986</td>\n",
       "      <td>24.849573</td>\n",
       "      <td>26.609905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>11.98</td>\n",
       "      <td>21.78</td>\n",
       "      <td>27.90</td>\n",
       "      <td>29.88</td>\n",
       "      <td>30.57</td>\n",
       "      <td>31.18</td>\n",
       "      <td>32.07</td>\n",
       "      <td>32.01</td>\n",
       "      <td>33.51</td>\n",
       "      <td>13.516776</td>\n",
       "      <td>...</td>\n",
       "      <td>33.253918</td>\n",
       "      <td>9.422367</td>\n",
       "      <td>17.129654</td>\n",
       "      <td>22.938807</td>\n",
       "      <td>27.674749</td>\n",
       "      <td>31.207392</td>\n",
       "      <td>30.465097</td>\n",
       "      <td>33.467827</td>\n",
       "      <td>32.167419</td>\n",
       "      <td>35.105759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16.12</td>\n",
       "      <td>28.55</td>\n",
       "      <td>32.32</td>\n",
       "      <td>34.97</td>\n",
       "      <td>35.93</td>\n",
       "      <td>37.32</td>\n",
       "      <td>38.20</td>\n",
       "      <td>37.77</td>\n",
       "      <td>39.81</td>\n",
       "      <td>15.740187</td>\n",
       "      <td>...</td>\n",
       "      <td>39.380211</td>\n",
       "      <td>11.225794</td>\n",
       "      <td>20.144056</td>\n",
       "      <td>26.246883</td>\n",
       "      <td>32.131622</td>\n",
       "      <td>36.278439</td>\n",
       "      <td>36.225739</td>\n",
       "      <td>39.316746</td>\n",
       "      <td>38.710838</td>\n",
       "      <td>42.183563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>16.29</td>\n",
       "      <td>24.97</td>\n",
       "      <td>30.89</td>\n",
       "      <td>35.17</td>\n",
       "      <td>36.30</td>\n",
       "      <td>39.71</td>\n",
       "      <td>42.33</td>\n",
       "      <td>43.93</td>\n",
       "      <td>43.55</td>\n",
       "      <td>15.506078</td>\n",
       "      <td>...</td>\n",
       "      <td>43.815002</td>\n",
       "      <td>12.583164</td>\n",
       "      <td>21.162590</td>\n",
       "      <td>26.808037</td>\n",
       "      <td>33.058434</td>\n",
       "      <td>37.942703</td>\n",
       "      <td>39.327881</td>\n",
       "      <td>42.588108</td>\n",
       "      <td>42.918091</td>\n",
       "      <td>46.439999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17.81</td>\n",
       "      <td>25.01</td>\n",
       "      <td>29.68</td>\n",
       "      <td>33.83</td>\n",
       "      <td>37.27</td>\n",
       "      <td>39.81</td>\n",
       "      <td>42.19</td>\n",
       "      <td>43.91</td>\n",
       "      <td>45.57</td>\n",
       "      <td>14.302635</td>\n",
       "      <td>...</td>\n",
       "      <td>47.527428</td>\n",
       "      <td>12.252638</td>\n",
       "      <td>20.123070</td>\n",
       "      <td>25.582579</td>\n",
       "      <td>32.008797</td>\n",
       "      <td>37.813282</td>\n",
       "      <td>41.512123</td>\n",
       "      <td>45.134731</td>\n",
       "      <td>46.614975</td>\n",
       "      <td>49.793106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.94</td>\n",
       "      <td>36.12</td>\n",
       "      <td>40.64</td>\n",
       "      <td>42.25</td>\n",
       "      <td>46.52</td>\n",
       "      <td>48.62</td>\n",
       "      <td>47.93</td>\n",
       "      <td>49.41</td>\n",
       "      <td>50.03</td>\n",
       "      <td>18.861544</td>\n",
       "      <td>...</td>\n",
       "      <td>50.767487</td>\n",
       "      <td>15.219469</td>\n",
       "      <td>26.853905</td>\n",
       "      <td>33.604534</td>\n",
       "      <td>40.203236</td>\n",
       "      <td>45.115681</td>\n",
       "      <td>46.274261</td>\n",
       "      <td>49.490059</td>\n",
       "      <td>50.328728</td>\n",
       "      <td>53.756237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>21.37</td>\n",
       "      <td>39.09</td>\n",
       "      <td>48.19</td>\n",
       "      <td>45.46</td>\n",
       "      <td>47.59</td>\n",
       "      <td>50.48</td>\n",
       "      <td>50.25</td>\n",
       "      <td>51.04</td>\n",
       "      <td>51.74</td>\n",
       "      <td>19.566372</td>\n",
       "      <td>...</td>\n",
       "      <td>52.336914</td>\n",
       "      <td>15.201172</td>\n",
       "      <td>27.664463</td>\n",
       "      <td>34.931221</td>\n",
       "      <td>41.543274</td>\n",
       "      <td>46.576904</td>\n",
       "      <td>48.014565</td>\n",
       "      <td>51.141140</td>\n",
       "      <td>52.160442</td>\n",
       "      <td>55.384090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L00.1  L00.2  L00.3  L00.4  L00.5  L00.6  L00.7  L00.8  L00.9      D00.1  \\\n",
       "0    1.21   2.60   3.21   2.69   5.25   4.98   5.82   7.76  13.55   0.907302   \n",
       "1    5.02   5.08   3.72   8.10   8.37  11.08  13.85  16.70  24.47   2.578902   \n",
       "2    6.95   7.68   6.93   9.15  11.44  13.54  17.00  22.30  30.41   3.995721   \n",
       "3   10.75  18.21  14.21  12.27  13.04  14.29  24.18  23.67  32.19   7.144335   \n",
       "4   14.46  19.97  19.76  14.46  14.23  17.93  24.89  24.49  33.79   9.069969   \n",
       "5   22.49  33.17  31.34  30.79  31.74  29.02  32.47  31.01  35.08  13.219215   \n",
       "6   23.84  30.46  33.34  34.52  33.37  31.68  34.05  34.45  33.44  13.704938   \n",
       "7   24.18  34.47  41.16  42.26  45.32  32.25  36.77  36.94  41.94  15.420390   \n",
       "8   20.98  28.02  33.01  36.39  38.08  30.77  31.88  33.00  40.99  14.241913   \n",
       "9   20.81  28.88  34.68  35.41  35.41  29.31  32.04  30.31  34.51  13.757400   \n",
       "10  21.53  33.20  35.54  35.72  38.17  29.63  35.03  35.92  38.92  13.774226   \n",
       "11  17.55  22.72  30.72  34.70  33.34  29.95  31.44  30.88  35.57  12.409553   \n",
       "12  15.80  21.14  26.15  23.59  20.41  23.02  29.91  39.10  42.60  12.684363   \n",
       "13  15.49  19.90  25.77  25.05  22.90  23.45  24.93  24.84  30.87  10.829406   \n",
       "14  15.55  20.48  25.08  27.33  25.55  21.13  24.69  25.98  31.35  10.728248   \n",
       "15  10.74  19.55  21.24  21.84  24.01  22.53  22.90  23.22  30.14   8.744321   \n",
       "16   8.43  15.27  14.78  15.09  15.30  14.56  16.53  16.20  16.97   7.892495   \n",
       "17   6.01   9.46   9.11   6.71   7.14   7.98   7.98   5.74  14.31   4.481168   \n",
       "18   1.94   2.65   3.48   1.44   1.90   3.32   4.97   6.43  10.87   3.501750   \n",
       "19  -0.80  -0.38  -0.39   0.92  -0.07   1.34   1.44   2.02   1.83   1.083755   \n",
       "20   3.61   3.59   5.40   5.33   6.67   6.56   7.16   7.21   7.57   3.379551   \n",
       "21   6.16   8.99  13.04  13.06  12.68  13.53  15.22  15.38  15.19   6.383345   \n",
       "22   9.85  19.44  22.57  22.26  20.77  22.25  23.12  23.11  23.16   9.966775   \n",
       "23  15.35  22.78  23.24  22.13  27.21  28.29  28.58  29.19  30.69  13.693385   \n",
       "24  23.16  25.54  27.38  30.68  32.23  33.56  35.70  35.72  36.23  16.060265   \n",
       "25  24.20  26.76  34.43  34.61  34.10  37.38  39.56  40.91  40.63  18.122995   \n",
       "26  34.63  44.78  39.29  39.37  41.10  42.40  44.60  45.02  45.32  19.072941   \n",
       "27  35.95  41.92  40.53  41.40  43.92  44.44  47.38  47.46  48.00  20.039961   \n",
       "28  37.22  46.59  43.20  45.22  45.11  46.75  47.83  49.36  49.20  19.868374   \n",
       "29  38.92  47.51  44.49  45.68  44.82  45.24  47.44  47.66  48.24  19.697437   \n",
       "30  32.31  40.78  41.03  42.77  41.76  43.91  45.65  46.11  45.99  18.383503   \n",
       "31  28.41  40.74  34.27  37.77  37.54  39.47  42.69  43.06  43.14  16.978943   \n",
       "32  20.90  27.69  28.46  33.65  34.02  35.00  37.63  38.57  38.50  14.118104   \n",
       "33  18.31  25.77  28.89  26.08  27.76  31.22  32.09  32.93  32.45  11.514292   \n",
       "34  11.08  23.03  24.38  22.38  24.69  26.11  25.42  25.57  25.94   8.187277   \n",
       "35  10.36  13.11  16.95  17.69  17.08  17.72  17.97  18.39  18.84   5.701241   \n",
       "36   4.34   6.68   6.82   6.94   6.84   8.00   8.95   9.36   9.87   3.956131   \n",
       "37   2.06   2.46   2.53   1.37   1.20   2.03   2.71   2.67   2.64   1.767852   \n",
       "38   0.34   0.72   1.28   1.32   1.95   1.63   1.63   1.46   2.08   1.549785   \n",
       "39   2.17   3.61   5.74   6.24   7.03   7.36   7.70   8.05   8.39   2.886923   \n",
       "40   5.82  10.20  13.27  15.31  15.99  16.46  17.05  16.86  16.96   6.471984   \n",
       "41   9.21  15.81  19.20  21.31  22.58  22.97  23.40  23.81  25.24   9.221293   \n",
       "42  11.98  21.78  27.90  29.88  30.57  31.18  32.07  32.01  33.51  13.516776   \n",
       "43  16.12  28.55  32.32  34.97  35.93  37.32  38.20  37.77  39.81  15.740187   \n",
       "44  16.29  24.97  30.89  35.17  36.30  39.71  42.33  43.93  43.55  15.506078   \n",
       "45  17.81  25.01  29.68  33.83  37.27  39.81  42.19  43.91  45.57  14.302635   \n",
       "46  19.94  36.12  40.64  42.25  46.52  48.62  47.93  49.41  50.03  18.861544   \n",
       "47  21.37  39.09  48.19  45.46  47.59  50.48  50.25  51.04  51.74  19.566372   \n",
       "\n",
       "    ...      G00.9      M00.1      M00.2      M00.3      M00.4      M00.5  \\\n",
       "0   ...   9.765275   0.651626   1.412930   1.663878   2.391623   3.620630   \n",
       "1   ...  21.188997   1.516569   3.200346   5.007691   7.612739  10.807425   \n",
       "2   ...  27.756762   2.490597   5.195635   8.690712  12.623331  16.221693   \n",
       "3   ...  42.049759   3.558703   7.637560  13.491122  18.699293  23.502199   \n",
       "4   ...  41.642868   4.839878  10.198141  17.454243  22.693516  27.092474   \n",
       "5   ...  37.664337   7.798664  15.330933  24.164576  27.350012  31.454496   \n",
       "6   ...  38.413773   9.042477  16.690411  24.624172  27.018827  31.540594   \n",
       "7   ...  46.399887   8.000772  16.136662  27.386908  31.172380  36.419567   \n",
       "8   ...  45.065361   6.773403  14.348423  24.432497  28.812801  33.840446   \n",
       "9   ...  42.480476   6.526613  14.123219  23.619312  27.363253  32.228859   \n",
       "10  ...  41.361061   7.603545  15.554159  25.120960  27.971552  32.967682   \n",
       "11  ...  39.996712   6.406276  14.052549  22.800934  25.745050  30.354742   \n",
       "12  ...  49.664555   4.629732  10.896416  19.137058  23.736738  28.941547   \n",
       "13  ...  37.069763   5.115972  11.971090  19.373894  22.384325  26.411833   \n",
       "14  ...  34.808895   5.443573  12.486110  19.612082  22.179161  26.143351   \n",
       "15  ...  27.836548   4.974761  11.723354  17.318130  19.118971  22.304539   \n",
       "16  ...  30.630814   3.637974   8.903531  14.418842  17.392981  20.881630   \n",
       "17  ...  21.702719   2.095726   5.311701   9.121095  11.956009  15.396475   \n",
       "18  ...  15.400671   0.881682   2.370034   4.221588   6.204017   9.654202   \n",
       "19  ...   1.933169   0.658838   1.330434   1.154504   1.063127   1.130794   \n",
       "20  ...   7.792755   2.194237   4.143533   6.064661   6.699108   7.300083   \n",
       "21  ...  15.665381   5.194424   9.521467  12.363936  14.115209  16.184280   \n",
       "22  ...  23.882532   7.201926  13.911270  18.494589  21.497286  24.298449   \n",
       "23  ...  31.443598  10.162374  19.149075  24.062498  28.397135  31.457529   \n",
       "24  ...  37.763214  12.351465  23.467091  28.608976  33.889027  37.274853   \n",
       "25  ...  42.614044  14.922377  28.431149  33.837650  39.051540  42.399414   \n",
       "26  ...  46.444283  15.803480  30.593998  36.715950  42.036961  45.731613   \n",
       "27  ...  48.781582  17.070126  33.137630  39.420242  44.573887  48.342800   \n",
       "28  ...  49.875072  16.520857  32.114845  38.556282  44.032230  48.172718   \n",
       "29  ...  49.417213  16.402988  31.783100  38.033119  43.522022  47.672394   \n",
       "30  ...  47.576416  14.388479  27.978525  34.172054  40.071667  44.455048   \n",
       "31  ...  44.174637  12.645197  24.863316  30.909405  36.927879  41.220608   \n",
       "32  ...  39.584984   9.272047  19.500896  25.967335  31.911280  36.102921   \n",
       "33  ...  33.977402   6.735143  15.393017  22.137846  27.239832  30.955410   \n",
       "34  ...  26.437605   4.017846  10.450139  16.765533  20.526527  23.926764   \n",
       "35  ...  18.480204   2.785563   7.429151  12.208894  14.666439  17.456865   \n",
       "36  ...  10.304486   1.692700   4.617312   7.607981   8.773732  10.247350   \n",
       "37  ...   3.157816   0.575418   1.738009   2.904547   2.923477   3.138932   \n",
       "38  ...   2.481506   0.802291   1.708197   1.521986   1.702527   1.867783   \n",
       "39  ...   8.750995   2.696599   4.853239   5.843548   7.078466   8.430592   \n",
       "40  ...  17.885265   5.312920   9.667276  12.834445  14.787426  17.129389   \n",
       "41  ...  25.205109   6.630163  12.487499  17.367464  20.572191  23.661013   \n",
       "42  ...  33.253918   9.422367  17.129654  22.938807  27.674749  31.207392   \n",
       "43  ...  39.380211  11.225794  20.144056  26.246883  32.131622  36.278439   \n",
       "44  ...  43.815002  12.583164  21.162590  26.808037  33.058434  37.942703   \n",
       "45  ...  47.527428  12.252638  20.123070  25.582579  32.008797  37.813282   \n",
       "46  ...  50.767487  15.219469  26.853905  33.604534  40.203236  45.115681   \n",
       "47  ...  52.336914  15.201172  27.664463  34.931221  41.543274  46.576904   \n",
       "\n",
       "        M00.6      M00.7      M00.8      M00.9  \n",
       "0    3.022576   5.746896   6.427562  10.876079  \n",
       "1   10.988094  16.742872  18.460148  25.416058  \n",
       "2   14.467131  20.739613  22.330959  30.209188  \n",
       "3   22.880861  31.975574  36.150452  46.415920  \n",
       "4   24.169703  32.847008  36.482132  46.895279  \n",
       "5   30.598495  36.305202  37.333523  40.848919  \n",
       "6   32.735386  37.522675  38.003830  39.672966  \n",
       "7   36.419098  43.420963  46.874535  51.689362  \n",
       "8   33.451294  41.137058  45.712769  52.616653  \n",
       "9   32.443634  38.739780  43.119469  48.208645  \n",
       "10  34.105930  39.612999  42.696678  45.417057  \n",
       "11  30.901155  35.742340  39.410156  42.511856  \n",
       "12  29.564463  36.140732  42.907837  50.200787  \n",
       "13  26.014959  29.550989  32.987003  35.909557  \n",
       "14  26.252958  29.690475  32.779518  35.155376  \n",
       "15  22.179451  24.334892  26.449394  27.809347  \n",
       "16  19.549978  21.511440  24.072803  26.282967  \n",
       "17  13.270828  13.999071  15.685595  17.190290  \n",
       "18   9.231308  10.874598  13.524657  16.031055  \n",
       "19   1.519910   1.990139   2.151956   2.062776  \n",
       "20   6.369847   7.500924   8.008971   8.124584  \n",
       "21  14.823651  16.502480  16.413942  17.070805  \n",
       "22  22.940239  25.367527  24.350090  25.905735  \n",
       "23  29.828190  32.615334  31.043741  33.637703  \n",
       "24  35.951912  38.707848  37.523529  40.748180  \n",
       "25  40.622681  43.320438  42.592911  45.904675  \n",
       "26  44.404572  46.926956  46.717934  49.881439  \n",
       "27  46.763161  49.361698  49.220634  52.356319  \n",
       "28  47.504570  50.051456  50.204514  53.180050  \n",
       "29  47.026474  49.578156  49.716343  52.688320  \n",
       "30  44.775650  47.179844  47.505325  50.336075  \n",
       "31  41.614090  44.006359  44.118290  46.976162  \n",
       "32  37.063538  39.377338  39.243500  42.055561  \n",
       "33  31.844326  34.124058  33.557854  35.941757  \n",
       "34  24.945961  27.202299  26.751408  28.041607  \n",
       "35  17.924042  19.670921  19.398064  19.790562  \n",
       "36  10.136093  11.172242  11.213359  11.001766  \n",
       "37   3.046759   3.384630   3.494174   3.226869  \n",
       "38   1.149644   1.899064   1.940590   2.484862  \n",
       "39   8.103583   8.848512   8.873066   8.871959  \n",
       "40  16.120167  17.920708  17.645054  18.492777  \n",
       "41  23.134224  25.733986  24.849573  26.609905  \n",
       "42  30.465097  33.467827  32.167419  35.105759  \n",
       "43  36.225739  39.316746  38.710838  42.183563  \n",
       "44  39.327881  42.588108  42.918091  46.439999  \n",
       "45  41.512123  45.134731  46.614975  49.793106  \n",
       "46  46.274261  49.490059  50.328728  53.756237  \n",
       "47  48.014565  51.141140  52.160442  55.384090  \n",
       "\n",
       "[48 rows x 45 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_0[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L10.1</th>\n",
       "      <th>L10.2</th>\n",
       "      <th>L10.3</th>\n",
       "      <th>L10.4</th>\n",
       "      <th>L10.5</th>\n",
       "      <th>L10.6</th>\n",
       "      <th>L10.7</th>\n",
       "      <th>L10.8</th>\n",
       "      <th>L10.9</th>\n",
       "      <th>D10.1</th>\n",
       "      <th>...</th>\n",
       "      <th>G10.9</th>\n",
       "      <th>M10.1</th>\n",
       "      <th>M10.2</th>\n",
       "      <th>M10.3</th>\n",
       "      <th>M10.4</th>\n",
       "      <th>M10.5</th>\n",
       "      <th>M10.6</th>\n",
       "      <th>M10.7</th>\n",
       "      <th>M10.8</th>\n",
       "      <th>M10.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.24</td>\n",
       "      <td>7.65</td>\n",
       "      <td>13.65</td>\n",
       "      <td>1.089914</td>\n",
       "      <td>...</td>\n",
       "      <td>9.617659</td>\n",
       "      <td>0.329373</td>\n",
       "      <td>1.272975</td>\n",
       "      <td>2.222000</td>\n",
       "      <td>3.875687</td>\n",
       "      <td>5.105513</td>\n",
       "      <td>5.777089</td>\n",
       "      <td>7.476045</td>\n",
       "      <td>10.104208</td>\n",
       "      <td>12.043563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.84</td>\n",
       "      <td>7.56</td>\n",
       "      <td>8.54</td>\n",
       "      <td>11.20</td>\n",
       "      <td>12.59</td>\n",
       "      <td>13.95</td>\n",
       "      <td>15.53</td>\n",
       "      <td>19.48</td>\n",
       "      <td>23.97</td>\n",
       "      <td>2.454007</td>\n",
       "      <td>...</td>\n",
       "      <td>20.866327</td>\n",
       "      <td>1.128118</td>\n",
       "      <td>3.202078</td>\n",
       "      <td>5.518090</td>\n",
       "      <td>9.725550</td>\n",
       "      <td>12.969010</td>\n",
       "      <td>15.099604</td>\n",
       "      <td>18.141224</td>\n",
       "      <td>22.504183</td>\n",
       "      <td>24.998043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.70</td>\n",
       "      <td>8.06</td>\n",
       "      <td>12.87</td>\n",
       "      <td>14.03</td>\n",
       "      <td>16.72</td>\n",
       "      <td>16.80</td>\n",
       "      <td>21.77</td>\n",
       "      <td>30.12</td>\n",
       "      <td>4.152181</td>\n",
       "      <td>...</td>\n",
       "      <td>25.929480</td>\n",
       "      <td>2.160001</td>\n",
       "      <td>5.547177</td>\n",
       "      <td>8.820875</td>\n",
       "      <td>13.377809</td>\n",
       "      <td>16.289724</td>\n",
       "      <td>18.242142</td>\n",
       "      <td>21.373890</td>\n",
       "      <td>25.896143</td>\n",
       "      <td>28.193527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.70</td>\n",
       "      <td>13.68</td>\n",
       "      <td>14.35</td>\n",
       "      <td>12.42</td>\n",
       "      <td>12.63</td>\n",
       "      <td>17.10</td>\n",
       "      <td>22.92</td>\n",
       "      <td>25.48</td>\n",
       "      <td>32.35</td>\n",
       "      <td>7.645403</td>\n",
       "      <td>...</td>\n",
       "      <td>38.971222</td>\n",
       "      <td>3.460238</td>\n",
       "      <td>8.663424</td>\n",
       "      <td>13.986403</td>\n",
       "      <td>20.827868</td>\n",
       "      <td>26.041220</td>\n",
       "      <td>29.857420</td>\n",
       "      <td>33.051517</td>\n",
       "      <td>39.212105</td>\n",
       "      <td>41.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.45</td>\n",
       "      <td>17.75</td>\n",
       "      <td>19.00</td>\n",
       "      <td>14.93</td>\n",
       "      <td>17.01</td>\n",
       "      <td>20.71</td>\n",
       "      <td>25.85</td>\n",
       "      <td>28.44</td>\n",
       "      <td>38.22</td>\n",
       "      <td>9.729984</td>\n",
       "      <td>...</td>\n",
       "      <td>38.998653</td>\n",
       "      <td>5.107563</td>\n",
       "      <td>11.910898</td>\n",
       "      <td>17.513607</td>\n",
       "      <td>23.314449</td>\n",
       "      <td>27.488192</td>\n",
       "      <td>30.451216</td>\n",
       "      <td>32.408348</td>\n",
       "      <td>37.889675</td>\n",
       "      <td>39.588684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.08</td>\n",
       "      <td>28.80</td>\n",
       "      <td>26.85</td>\n",
       "      <td>30.29</td>\n",
       "      <td>26.01</td>\n",
       "      <td>23.81</td>\n",
       "      <td>26.92</td>\n",
       "      <td>30.55</td>\n",
       "      <td>34.15</td>\n",
       "      <td>13.925003</td>\n",
       "      <td>...</td>\n",
       "      <td>36.662949</td>\n",
       "      <td>8.993871</td>\n",
       "      <td>18.460552</td>\n",
       "      <td>25.109615</td>\n",
       "      <td>26.833054</td>\n",
       "      <td>30.154135</td>\n",
       "      <td>33.465408</td>\n",
       "      <td>32.359592</td>\n",
       "      <td>35.644203</td>\n",
       "      <td>35.074295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.33</td>\n",
       "      <td>26.39</td>\n",
       "      <td>22.47</td>\n",
       "      <td>30.44</td>\n",
       "      <td>28.62</td>\n",
       "      <td>28.59</td>\n",
       "      <td>30.50</td>\n",
       "      <td>33.06</td>\n",
       "      <td>34.16</td>\n",
       "      <td>13.758869</td>\n",
       "      <td>...</td>\n",
       "      <td>37.442463</td>\n",
       "      <td>10.363093</td>\n",
       "      <td>19.981592</td>\n",
       "      <td>25.951077</td>\n",
       "      <td>25.325840</td>\n",
       "      <td>28.332447</td>\n",
       "      <td>33.150784</td>\n",
       "      <td>33.018898</td>\n",
       "      <td>35.123093</td>\n",
       "      <td>34.987961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.63</td>\n",
       "      <td>32.86</td>\n",
       "      <td>34.60</td>\n",
       "      <td>38.86</td>\n",
       "      <td>35.82</td>\n",
       "      <td>32.05</td>\n",
       "      <td>33.63</td>\n",
       "      <td>36.78</td>\n",
       "      <td>41.76</td>\n",
       "      <td>16.477924</td>\n",
       "      <td>...</td>\n",
       "      <td>46.160000</td>\n",
       "      <td>9.228159</td>\n",
       "      <td>19.322693</td>\n",
       "      <td>28.750477</td>\n",
       "      <td>31.273363</td>\n",
       "      <td>37.178356</td>\n",
       "      <td>42.135048</td>\n",
       "      <td>40.336819</td>\n",
       "      <td>47.014378</td>\n",
       "      <td>47.310070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.81</td>\n",
       "      <td>31.80</td>\n",
       "      <td>31.75</td>\n",
       "      <td>34.20</td>\n",
       "      <td>27.53</td>\n",
       "      <td>27.53</td>\n",
       "      <td>28.11</td>\n",
       "      <td>33.86</td>\n",
       "      <td>42.06</td>\n",
       "      <td>15.677671</td>\n",
       "      <td>...</td>\n",
       "      <td>46.159149</td>\n",
       "      <td>7.646490</td>\n",
       "      <td>16.922636</td>\n",
       "      <td>25.574295</td>\n",
       "      <td>30.638409</td>\n",
       "      <td>37.012051</td>\n",
       "      <td>41.465981</td>\n",
       "      <td>40.056301</td>\n",
       "      <td>47.252983</td>\n",
       "      <td>49.060436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.39</td>\n",
       "      <td>32.16</td>\n",
       "      <td>33.91</td>\n",
       "      <td>35.44</td>\n",
       "      <td>30.80</td>\n",
       "      <td>29.15</td>\n",
       "      <td>31.71</td>\n",
       "      <td>32.63</td>\n",
       "      <td>36.20</td>\n",
       "      <td>15.143011</td>\n",
       "      <td>...</td>\n",
       "      <td>43.475784</td>\n",
       "      <td>7.260803</td>\n",
       "      <td>16.316357</td>\n",
       "      <td>25.232349</td>\n",
       "      <td>29.263187</td>\n",
       "      <td>35.237740</td>\n",
       "      <td>39.583549</td>\n",
       "      <td>37.688423</td>\n",
       "      <td>44.847450</td>\n",
       "      <td>47.182415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.48</td>\n",
       "      <td>32.10</td>\n",
       "      <td>35.97</td>\n",
       "      <td>38.11</td>\n",
       "      <td>35.66</td>\n",
       "      <td>30.07</td>\n",
       "      <td>32.96</td>\n",
       "      <td>35.88</td>\n",
       "      <td>40.14</td>\n",
       "      <td>14.349978</td>\n",
       "      <td>...</td>\n",
       "      <td>40.346756</td>\n",
       "      <td>8.623682</td>\n",
       "      <td>18.128372</td>\n",
       "      <td>26.824112</td>\n",
       "      <td>27.669594</td>\n",
       "      <td>32.842304</td>\n",
       "      <td>38.008026</td>\n",
       "      <td>36.251068</td>\n",
       "      <td>42.364960</td>\n",
       "      <td>42.644188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.01</td>\n",
       "      <td>31.16</td>\n",
       "      <td>32.61</td>\n",
       "      <td>32.96</td>\n",
       "      <td>30.08</td>\n",
       "      <td>26.93</td>\n",
       "      <td>29.84</td>\n",
       "      <td>34.73</td>\n",
       "      <td>35.22</td>\n",
       "      <td>13.351130</td>\n",
       "      <td>...</td>\n",
       "      <td>39.820618</td>\n",
       "      <td>7.055909</td>\n",
       "      <td>15.890283</td>\n",
       "      <td>24.498707</td>\n",
       "      <td>26.466946</td>\n",
       "      <td>31.005896</td>\n",
       "      <td>35.155045</td>\n",
       "      <td>33.784100</td>\n",
       "      <td>40.154060</td>\n",
       "      <td>42.670391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.13</td>\n",
       "      <td>22.72</td>\n",
       "      <td>31.09</td>\n",
       "      <td>27.32</td>\n",
       "      <td>21.63</td>\n",
       "      <td>31.42</td>\n",
       "      <td>39.63</td>\n",
       "      <td>43.33</td>\n",
       "      <td>50.68</td>\n",
       "      <td>14.480780</td>\n",
       "      <td>...</td>\n",
       "      <td>49.869949</td>\n",
       "      <td>4.818467</td>\n",
       "      <td>12.408165</td>\n",
       "      <td>21.442879</td>\n",
       "      <td>28.834698</td>\n",
       "      <td>35.341663</td>\n",
       "      <td>39.490532</td>\n",
       "      <td>39.256622</td>\n",
       "      <td>46.276611</td>\n",
       "      <td>53.348797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.46</td>\n",
       "      <td>25.70</td>\n",
       "      <td>28.06</td>\n",
       "      <td>27.89</td>\n",
       "      <td>21.79</td>\n",
       "      <td>21.67</td>\n",
       "      <td>24.92</td>\n",
       "      <td>26.49</td>\n",
       "      <td>32.57</td>\n",
       "      <td>12.042791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.038448</td>\n",
       "      <td>5.374687</td>\n",
       "      <td>13.255543</td>\n",
       "      <td>21.458710</td>\n",
       "      <td>24.519558</td>\n",
       "      <td>27.360790</td>\n",
       "      <td>29.561419</td>\n",
       "      <td>29.029062</td>\n",
       "      <td>33.716805</td>\n",
       "      <td>37.098377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.57</td>\n",
       "      <td>28.26</td>\n",
       "      <td>29.63</td>\n",
       "      <td>29.51</td>\n",
       "      <td>23.79</td>\n",
       "      <td>24.61</td>\n",
       "      <td>26.87</td>\n",
       "      <td>30.76</td>\n",
       "      <td>32.48</td>\n",
       "      <td>11.698090</td>\n",
       "      <td>...</td>\n",
       "      <td>35.596138</td>\n",
       "      <td>5.834748</td>\n",
       "      <td>13.915159</td>\n",
       "      <td>21.748260</td>\n",
       "      <td>23.525955</td>\n",
       "      <td>26.235214</td>\n",
       "      <td>29.125406</td>\n",
       "      <td>28.764288</td>\n",
       "      <td>33.514393</td>\n",
       "      <td>36.397358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.89</td>\n",
       "      <td>20.62</td>\n",
       "      <td>26.83</td>\n",
       "      <td>23.85</td>\n",
       "      <td>20.28</td>\n",
       "      <td>20.27</td>\n",
       "      <td>23.67</td>\n",
       "      <td>23.65</td>\n",
       "      <td>30.46</td>\n",
       "      <td>9.471292</td>\n",
       "      <td>...</td>\n",
       "      <td>28.813011</td>\n",
       "      <td>5.123885</td>\n",
       "      <td>12.532187</td>\n",
       "      <td>18.985107</td>\n",
       "      <td>19.002716</td>\n",
       "      <td>20.060062</td>\n",
       "      <td>22.753223</td>\n",
       "      <td>23.539127</td>\n",
       "      <td>26.719624</td>\n",
       "      <td>28.793344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.40</td>\n",
       "      <td>13.89</td>\n",
       "      <td>15.98</td>\n",
       "      <td>14.03</td>\n",
       "      <td>13.04</td>\n",
       "      <td>15.75</td>\n",
       "      <td>17.92</td>\n",
       "      <td>18.60</td>\n",
       "      <td>23.82</td>\n",
       "      <td>8.851833</td>\n",
       "      <td>...</td>\n",
       "      <td>31.159916</td>\n",
       "      <td>3.545650</td>\n",
       "      <td>9.831881</td>\n",
       "      <td>17.147171</td>\n",
       "      <td>20.896095</td>\n",
       "      <td>21.645552</td>\n",
       "      <td>21.813242</td>\n",
       "      <td>22.039639</td>\n",
       "      <td>24.562485</td>\n",
       "      <td>27.073961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.25</td>\n",
       "      <td>7.79</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.09</td>\n",
       "      <td>5.92</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.74</td>\n",
       "      <td>5.95</td>\n",
       "      <td>19.56</td>\n",
       "      <td>4.846483</td>\n",
       "      <td>...</td>\n",
       "      <td>21.074026</td>\n",
       "      <td>1.775307</td>\n",
       "      <td>5.728541</td>\n",
       "      <td>11.096073</td>\n",
       "      <td>15.348503</td>\n",
       "      <td>14.934682</td>\n",
       "      <td>13.533899</td>\n",
       "      <td>13.992954</td>\n",
       "      <td>14.809423</td>\n",
       "      <td>16.402884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.99</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.02</td>\n",
       "      <td>5.89</td>\n",
       "      <td>6.35</td>\n",
       "      <td>7.38</td>\n",
       "      <td>16.96</td>\n",
       "      <td>3.616631</td>\n",
       "      <td>...</td>\n",
       "      <td>14.644279</td>\n",
       "      <td>0.603167</td>\n",
       "      <td>2.393660</td>\n",
       "      <td>4.965306</td>\n",
       "      <td>9.151805</td>\n",
       "      <td>10.362707</td>\n",
       "      <td>10.109591</td>\n",
       "      <td>11.294207</td>\n",
       "      <td>12.022629</td>\n",
       "      <td>15.502774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.866464</td>\n",
       "      <td>...</td>\n",
       "      <td>2.143718</td>\n",
       "      <td>0.281470</td>\n",
       "      <td>0.823242</td>\n",
       "      <td>1.040104</td>\n",
       "      <td>1.075293</td>\n",
       "      <td>1.254039</td>\n",
       "      <td>1.321184</td>\n",
       "      <td>1.716482</td>\n",
       "      <td>2.186939</td>\n",
       "      <td>2.399323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.77</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.21</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.92</td>\n",
       "      <td>7.31</td>\n",
       "      <td>3.013944</td>\n",
       "      <td>...</td>\n",
       "      <td>7.538638</td>\n",
       "      <td>1.152913</td>\n",
       "      <td>3.917951</td>\n",
       "      <td>5.252352</td>\n",
       "      <td>4.937126</td>\n",
       "      <td>4.952584</td>\n",
       "      <td>5.789088</td>\n",
       "      <td>6.475689</td>\n",
       "      <td>7.107688</td>\n",
       "      <td>7.609428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.38</td>\n",
       "      <td>7.75</td>\n",
       "      <td>12.02</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.60</td>\n",
       "      <td>13.55</td>\n",
       "      <td>14.47</td>\n",
       "      <td>14.69</td>\n",
       "      <td>15.12</td>\n",
       "      <td>5.145498</td>\n",
       "      <td>...</td>\n",
       "      <td>15.569941</td>\n",
       "      <td>3.284234</td>\n",
       "      <td>8.551517</td>\n",
       "      <td>10.521102</td>\n",
       "      <td>10.795098</td>\n",
       "      <td>11.350263</td>\n",
       "      <td>13.735605</td>\n",
       "      <td>14.734819</td>\n",
       "      <td>15.409781</td>\n",
       "      <td>15.983940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.96</td>\n",
       "      <td>15.24</td>\n",
       "      <td>16.33</td>\n",
       "      <td>19.96</td>\n",
       "      <td>20.44</td>\n",
       "      <td>20.83</td>\n",
       "      <td>21.77</td>\n",
       "      <td>22.90</td>\n",
       "      <td>22.90</td>\n",
       "      <td>8.716177</td>\n",
       "      <td>...</td>\n",
       "      <td>23.685423</td>\n",
       "      <td>5.160917</td>\n",
       "      <td>12.510571</td>\n",
       "      <td>16.202187</td>\n",
       "      <td>17.685925</td>\n",
       "      <td>18.315889</td>\n",
       "      <td>21.489733</td>\n",
       "      <td>22.719061</td>\n",
       "      <td>23.122620</td>\n",
       "      <td>23.843927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.91</td>\n",
       "      <td>20.67</td>\n",
       "      <td>21.53</td>\n",
       "      <td>25.54</td>\n",
       "      <td>28.95</td>\n",
       "      <td>28.02</td>\n",
       "      <td>27.94</td>\n",
       "      <td>28.91</td>\n",
       "      <td>30.66</td>\n",
       "      <td>12.321924</td>\n",
       "      <td>...</td>\n",
       "      <td>30.588705</td>\n",
       "      <td>7.674736</td>\n",
       "      <td>16.499916</td>\n",
       "      <td>21.969456</td>\n",
       "      <td>24.284307</td>\n",
       "      <td>24.846094</td>\n",
       "      <td>27.991297</td>\n",
       "      <td>29.579254</td>\n",
       "      <td>29.559549</td>\n",
       "      <td>30.446499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17.43</td>\n",
       "      <td>18.60</td>\n",
       "      <td>23.80</td>\n",
       "      <td>25.96</td>\n",
       "      <td>33.75</td>\n",
       "      <td>32.49</td>\n",
       "      <td>34.79</td>\n",
       "      <td>35.18</td>\n",
       "      <td>36.52</td>\n",
       "      <td>14.460339</td>\n",
       "      <td>...</td>\n",
       "      <td>36.885361</td>\n",
       "      <td>9.290116</td>\n",
       "      <td>18.970642</td>\n",
       "      <td>26.583889</td>\n",
       "      <td>29.456167</td>\n",
       "      <td>30.375208</td>\n",
       "      <td>33.649197</td>\n",
       "      <td>35.647919</td>\n",
       "      <td>35.563564</td>\n",
       "      <td>36.364796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15.81</td>\n",
       "      <td>22.40</td>\n",
       "      <td>25.83</td>\n",
       "      <td>29.35</td>\n",
       "      <td>36.73</td>\n",
       "      <td>35.60</td>\n",
       "      <td>38.80</td>\n",
       "      <td>40.25</td>\n",
       "      <td>40.68</td>\n",
       "      <td>16.315401</td>\n",
       "      <td>...</td>\n",
       "      <td>42.073997</td>\n",
       "      <td>11.409750</td>\n",
       "      <td>21.657230</td>\n",
       "      <td>30.451183</td>\n",
       "      <td>34.004562</td>\n",
       "      <td>35.169323</td>\n",
       "      <td>38.207138</td>\n",
       "      <td>40.444073</td>\n",
       "      <td>40.758240</td>\n",
       "      <td>41.143299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21.26</td>\n",
       "      <td>28.23</td>\n",
       "      <td>24.88</td>\n",
       "      <td>25.67</td>\n",
       "      <td>25.76</td>\n",
       "      <td>30.86</td>\n",
       "      <td>38.04</td>\n",
       "      <td>42.85</td>\n",
       "      <td>43.80</td>\n",
       "      <td>17.144218</td>\n",
       "      <td>...</td>\n",
       "      <td>46.211315</td>\n",
       "      <td>12.049514</td>\n",
       "      <td>23.038967</td>\n",
       "      <td>32.320526</td>\n",
       "      <td>36.200386</td>\n",
       "      <td>38.802258</td>\n",
       "      <td>41.891666</td>\n",
       "      <td>44.190384</td>\n",
       "      <td>45.158058</td>\n",
       "      <td>45.590725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22.03</td>\n",
       "      <td>31.71</td>\n",
       "      <td>29.19</td>\n",
       "      <td>30.21</td>\n",
       "      <td>31.31</td>\n",
       "      <td>33.62</td>\n",
       "      <td>38.02</td>\n",
       "      <td>43.82</td>\n",
       "      <td>45.73</td>\n",
       "      <td>18.011995</td>\n",
       "      <td>...</td>\n",
       "      <td>48.538223</td>\n",
       "      <td>13.091581</td>\n",
       "      <td>24.929039</td>\n",
       "      <td>33.709274</td>\n",
       "      <td>37.873466</td>\n",
       "      <td>41.146801</td>\n",
       "      <td>44.239017</td>\n",
       "      <td>46.758072</td>\n",
       "      <td>47.606224</td>\n",
       "      <td>47.952175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22.00</td>\n",
       "      <td>32.56</td>\n",
       "      <td>27.35</td>\n",
       "      <td>30.65</td>\n",
       "      <td>33.70</td>\n",
       "      <td>37.12</td>\n",
       "      <td>41.10</td>\n",
       "      <td>46.73</td>\n",
       "      <td>48.88</td>\n",
       "      <td>17.827007</td>\n",
       "      <td>...</td>\n",
       "      <td>49.593658</td>\n",
       "      <td>12.376309</td>\n",
       "      <td>23.827412</td>\n",
       "      <td>33.132587</td>\n",
       "      <td>37.094582</td>\n",
       "      <td>41.094158</td>\n",
       "      <td>45.106354</td>\n",
       "      <td>47.482559</td>\n",
       "      <td>48.801617</td>\n",
       "      <td>49.283482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.27</td>\n",
       "      <td>27.40</td>\n",
       "      <td>26.75</td>\n",
       "      <td>30.04</td>\n",
       "      <td>29.45</td>\n",
       "      <td>35.11</td>\n",
       "      <td>39.92</td>\n",
       "      <td>44.32</td>\n",
       "      <td>46.44</td>\n",
       "      <td>17.671438</td>\n",
       "      <td>...</td>\n",
       "      <td>49.133965</td>\n",
       "      <td>12.145629</td>\n",
       "      <td>23.385645</td>\n",
       "      <td>32.808437</td>\n",
       "      <td>36.664574</td>\n",
       "      <td>40.496777</td>\n",
       "      <td>44.545433</td>\n",
       "      <td>46.895962</td>\n",
       "      <td>48.306332</td>\n",
       "      <td>48.823807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.36</td>\n",
       "      <td>24.51</td>\n",
       "      <td>28.28</td>\n",
       "      <td>31.83</td>\n",
       "      <td>30.84</td>\n",
       "      <td>36.56</td>\n",
       "      <td>41.49</td>\n",
       "      <td>43.48</td>\n",
       "      <td>44.92</td>\n",
       "      <td>16.460413</td>\n",
       "      <td>...</td>\n",
       "      <td>47.229134</td>\n",
       "      <td>10.337456</td>\n",
       "      <td>20.982071</td>\n",
       "      <td>30.661556</td>\n",
       "      <td>33.958252</td>\n",
       "      <td>37.751331</td>\n",
       "      <td>42.337639</td>\n",
       "      <td>44.389053</td>\n",
       "      <td>46.371582</td>\n",
       "      <td>47.246319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13.02</td>\n",
       "      <td>18.89</td>\n",
       "      <td>26.87</td>\n",
       "      <td>29.48</td>\n",
       "      <td>35.25</td>\n",
       "      <td>36.42</td>\n",
       "      <td>40.61</td>\n",
       "      <td>41.84</td>\n",
       "      <td>43.60</td>\n",
       "      <td>15.189924</td>\n",
       "      <td>...</td>\n",
       "      <td>43.945312</td>\n",
       "      <td>9.023592</td>\n",
       "      <td>19.602280</td>\n",
       "      <td>28.647999</td>\n",
       "      <td>31.638607</td>\n",
       "      <td>34.943623</td>\n",
       "      <td>39.253651</td>\n",
       "      <td>41.278557</td>\n",
       "      <td>42.940140</td>\n",
       "      <td>43.961697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11.26</td>\n",
       "      <td>15.59</td>\n",
       "      <td>27.57</td>\n",
       "      <td>28.44</td>\n",
       "      <td>31.57</td>\n",
       "      <td>31.63</td>\n",
       "      <td>36.37</td>\n",
       "      <td>37.07</td>\n",
       "      <td>38.11</td>\n",
       "      <td>12.523960</td>\n",
       "      <td>...</td>\n",
       "      <td>39.200451</td>\n",
       "      <td>6.627160</td>\n",
       "      <td>17.230516</td>\n",
       "      <td>24.512157</td>\n",
       "      <td>27.162472</td>\n",
       "      <td>30.440798</td>\n",
       "      <td>35.004349</td>\n",
       "      <td>36.729576</td>\n",
       "      <td>37.935066</td>\n",
       "      <td>39.221050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.90</td>\n",
       "      <td>15.70</td>\n",
       "      <td>26.92</td>\n",
       "      <td>21.42</td>\n",
       "      <td>29.22</td>\n",
       "      <td>29.51</td>\n",
       "      <td>31.08</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.98</td>\n",
       "      <td>10.059118</td>\n",
       "      <td>...</td>\n",
       "      <td>33.135654</td>\n",
       "      <td>4.894801</td>\n",
       "      <td>14.552773</td>\n",
       "      <td>20.358345</td>\n",
       "      <td>22.927216</td>\n",
       "      <td>25.654211</td>\n",
       "      <td>29.876604</td>\n",
       "      <td>31.200211</td>\n",
       "      <td>32.052986</td>\n",
       "      <td>33.203243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7.76</td>\n",
       "      <td>13.17</td>\n",
       "      <td>16.99</td>\n",
       "      <td>19.82</td>\n",
       "      <td>22.65</td>\n",
       "      <td>24.78</td>\n",
       "      <td>24.62</td>\n",
       "      <td>25.14</td>\n",
       "      <td>25.97</td>\n",
       "      <td>6.513051</td>\n",
       "      <td>...</td>\n",
       "      <td>26.168776</td>\n",
       "      <td>2.989256</td>\n",
       "      <td>10.662262</td>\n",
       "      <td>14.695687</td>\n",
       "      <td>16.920227</td>\n",
       "      <td>19.461119</td>\n",
       "      <td>23.344776</td>\n",
       "      <td>24.467306</td>\n",
       "      <td>25.432434</td>\n",
       "      <td>26.377892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.68</td>\n",
       "      <td>8.31</td>\n",
       "      <td>12.89</td>\n",
       "      <td>14.46</td>\n",
       "      <td>15.21</td>\n",
       "      <td>15.84</td>\n",
       "      <td>17.08</td>\n",
       "      <td>17.28</td>\n",
       "      <td>18.61</td>\n",
       "      <td>4.290338</td>\n",
       "      <td>...</td>\n",
       "      <td>18.929718</td>\n",
       "      <td>1.914944</td>\n",
       "      <td>7.749857</td>\n",
       "      <td>10.220388</td>\n",
       "      <td>11.601554</td>\n",
       "      <td>13.405719</td>\n",
       "      <td>16.385185</td>\n",
       "      <td>17.604626</td>\n",
       "      <td>18.383070</td>\n",
       "      <td>18.935654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8.62</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.84</td>\n",
       "      <td>8.84</td>\n",
       "      <td>9.06</td>\n",
       "      <td>8.43</td>\n",
       "      <td>8.23</td>\n",
       "      <td>9.62</td>\n",
       "      <td>9.47</td>\n",
       "      <td>2.914204</td>\n",
       "      <td>...</td>\n",
       "      <td>10.889780</td>\n",
       "      <td>1.031875</td>\n",
       "      <td>5.036841</td>\n",
       "      <td>6.353527</td>\n",
       "      <td>6.720687</td>\n",
       "      <td>7.563734</td>\n",
       "      <td>8.989182</td>\n",
       "      <td>9.952747</td>\n",
       "      <td>10.423515</td>\n",
       "      <td>10.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.88</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.83</td>\n",
       "      <td>4.24</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1.145520</td>\n",
       "      <td>...</td>\n",
       "      <td>3.699688</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>1.992132</td>\n",
       "      <td>2.781004</td>\n",
       "      <td>3.468869</td>\n",
       "      <td>3.374558</td>\n",
       "      <td>3.078406</td>\n",
       "      <td>3.169029</td>\n",
       "      <td>3.317488</td>\n",
       "      <td>3.489783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.289500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.049698</td>\n",
       "      <td>0.406368</td>\n",
       "      <td>1.335016</td>\n",
       "      <td>1.928913</td>\n",
       "      <td>2.318510</td>\n",
       "      <td>2.177904</td>\n",
       "      <td>1.495453</td>\n",
       "      <td>1.872091</td>\n",
       "      <td>2.283284</td>\n",
       "      <td>2.301525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.29</td>\n",
       "      <td>3.73</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.83</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.49</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.79</td>\n",
       "      <td>2.512574</td>\n",
       "      <td>...</td>\n",
       "      <td>8.502715</td>\n",
       "      <td>1.864749</td>\n",
       "      <td>4.283177</td>\n",
       "      <td>5.349444</td>\n",
       "      <td>6.777020</td>\n",
       "      <td>7.233482</td>\n",
       "      <td>7.760514</td>\n",
       "      <td>8.442198</td>\n",
       "      <td>8.987455</td>\n",
       "      <td>9.143443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.04</td>\n",
       "      <td>8.84</td>\n",
       "      <td>13.95</td>\n",
       "      <td>14.75</td>\n",
       "      <td>16.22</td>\n",
       "      <td>16.69</td>\n",
       "      <td>17.19</td>\n",
       "      <td>17.47</td>\n",
       "      <td>17.50</td>\n",
       "      <td>5.288871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.503077</td>\n",
       "      <td>3.759428</td>\n",
       "      <td>9.304890</td>\n",
       "      <td>11.806891</td>\n",
       "      <td>12.731577</td>\n",
       "      <td>13.249283</td>\n",
       "      <td>15.654570</td>\n",
       "      <td>16.638840</td>\n",
       "      <td>17.251490</td>\n",
       "      <td>17.565552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.68</td>\n",
       "      <td>13.32</td>\n",
       "      <td>18.85</td>\n",
       "      <td>21.34</td>\n",
       "      <td>22.22</td>\n",
       "      <td>23.12</td>\n",
       "      <td>23.77</td>\n",
       "      <td>24.55</td>\n",
       "      <td>24.52</td>\n",
       "      <td>7.950894</td>\n",
       "      <td>...</td>\n",
       "      <td>24.808882</td>\n",
       "      <td>5.332939</td>\n",
       "      <td>12.702641</td>\n",
       "      <td>16.854210</td>\n",
       "      <td>18.760006</td>\n",
       "      <td>19.594412</td>\n",
       "      <td>22.873831</td>\n",
       "      <td>24.181030</td>\n",
       "      <td>24.577845</td>\n",
       "      <td>25.081758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.50</td>\n",
       "      <td>16.62</td>\n",
       "      <td>23.12</td>\n",
       "      <td>27.73</td>\n",
       "      <td>29.46</td>\n",
       "      <td>29.94</td>\n",
       "      <td>31.29</td>\n",
       "      <td>32.87</td>\n",
       "      <td>32.79</td>\n",
       "      <td>12.124215</td>\n",
       "      <td>...</td>\n",
       "      <td>32.502899</td>\n",
       "      <td>7.741753</td>\n",
       "      <td>16.682230</td>\n",
       "      <td>22.602509</td>\n",
       "      <td>25.337088</td>\n",
       "      <td>26.318483</td>\n",
       "      <td>29.746508</td>\n",
       "      <td>31.490782</td>\n",
       "      <td>31.526134</td>\n",
       "      <td>32.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13.97</td>\n",
       "      <td>23.69</td>\n",
       "      <td>28.18</td>\n",
       "      <td>30.94</td>\n",
       "      <td>34.79</td>\n",
       "      <td>36.23</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.54</td>\n",
       "      <td>37.60</td>\n",
       "      <td>14.166721</td>\n",
       "      <td>...</td>\n",
       "      <td>38.818054</td>\n",
       "      <td>9.150582</td>\n",
       "      <td>18.826040</td>\n",
       "      <td>26.777004</td>\n",
       "      <td>30.070261</td>\n",
       "      <td>31.563866</td>\n",
       "      <td>35.334244</td>\n",
       "      <td>37.491241</td>\n",
       "      <td>37.945538</td>\n",
       "      <td>38.432404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>18.60</td>\n",
       "      <td>25.02</td>\n",
       "      <td>32.07</td>\n",
       "      <td>34.73</td>\n",
       "      <td>37.58</td>\n",
       "      <td>42.45</td>\n",
       "      <td>44.85</td>\n",
       "      <td>45.31</td>\n",
       "      <td>44.62</td>\n",
       "      <td>14.067751</td>\n",
       "      <td>...</td>\n",
       "      <td>43.381569</td>\n",
       "      <td>10.473228</td>\n",
       "      <td>20.132496</td>\n",
       "      <td>29.397827</td>\n",
       "      <td>33.441124</td>\n",
       "      <td>35.708488</td>\n",
       "      <td>39.355759</td>\n",
       "      <td>41.478828</td>\n",
       "      <td>42.847137</td>\n",
       "      <td>43.074329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>14.39</td>\n",
       "      <td>25.44</td>\n",
       "      <td>32.47</td>\n",
       "      <td>37.51</td>\n",
       "      <td>40.66</td>\n",
       "      <td>43.06</td>\n",
       "      <td>46.19</td>\n",
       "      <td>46.57</td>\n",
       "      <td>46.66</td>\n",
       "      <td>13.036249</td>\n",
       "      <td>...</td>\n",
       "      <td>46.934570</td>\n",
       "      <td>10.391986</td>\n",
       "      <td>20.190556</td>\n",
       "      <td>29.753010</td>\n",
       "      <td>34.221390</td>\n",
       "      <td>38.250462</td>\n",
       "      <td>42.568192</td>\n",
       "      <td>44.442184</td>\n",
       "      <td>46.704884</td>\n",
       "      <td>47.349155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.41</td>\n",
       "      <td>29.93</td>\n",
       "      <td>38.53</td>\n",
       "      <td>42.26</td>\n",
       "      <td>45.78</td>\n",
       "      <td>46.49</td>\n",
       "      <td>47.02</td>\n",
       "      <td>48.59</td>\n",
       "      <td>50.05</td>\n",
       "      <td>16.994919</td>\n",
       "      <td>...</td>\n",
       "      <td>50.315735</td>\n",
       "      <td>12.269210</td>\n",
       "      <td>23.013144</td>\n",
       "      <td>33.011841</td>\n",
       "      <td>37.657852</td>\n",
       "      <td>41.880318</td>\n",
       "      <td>45.931225</td>\n",
       "      <td>48.533688</td>\n",
       "      <td>49.954475</td>\n",
       "      <td>50.238041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20.72</td>\n",
       "      <td>32.24</td>\n",
       "      <td>39.67</td>\n",
       "      <td>43.87</td>\n",
       "      <td>44.40</td>\n",
       "      <td>47.57</td>\n",
       "      <td>49.76</td>\n",
       "      <td>50.98</td>\n",
       "      <td>51.73</td>\n",
       "      <td>17.576097</td>\n",
       "      <td>...</td>\n",
       "      <td>51.923138</td>\n",
       "      <td>12.090740</td>\n",
       "      <td>23.145559</td>\n",
       "      <td>33.233517</td>\n",
       "      <td>37.714043</td>\n",
       "      <td>42.672626</td>\n",
       "      <td>47.496857</td>\n",
       "      <td>50.094948</td>\n",
       "      <td>51.758480</td>\n",
       "      <td>52.188717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L10.1  L10.2  L10.3  L10.4  L10.5  L10.6  L10.7  L10.8  L10.9      D10.1  \\\n",
       "0    0.92   1.35   1.73   2.79   2.96   2.62   3.24   7.65  13.65   1.089914   \n",
       "1    4.84   7.56   8.54  11.20  12.59  13.95  15.53  19.48  23.97   2.454007   \n",
       "2    4.69   7.70   8.06  12.87  14.03  16.72  16.80  21.77  30.12   4.152181   \n",
       "3    8.70  13.68  14.35  12.42  12.63  17.10  22.92  25.48  32.35   7.645403   \n",
       "4    9.45  17.75  19.00  14.93  17.01  20.71  25.85  28.44  38.22   9.729984   \n",
       "5   18.08  28.80  26.85  30.29  26.01  23.81  26.92  30.55  34.15  13.925003   \n",
       "6   19.33  26.39  22.47  30.44  28.62  28.59  30.50  33.06  34.16  13.758869   \n",
       "7   22.63  32.86  34.60  38.86  35.82  32.05  33.63  36.78  41.76  16.477924   \n",
       "8   21.81  31.80  31.75  34.20  27.53  27.53  28.11  33.86  42.06  15.677671   \n",
       "9   22.39  32.16  33.91  35.44  30.80  29.15  31.71  32.63  36.20  15.143011   \n",
       "10  22.48  32.10  35.97  38.11  35.66  30.07  32.96  35.88  40.14  14.349978   \n",
       "11  20.01  31.16  32.61  32.96  30.08  26.93  29.84  34.73  35.22  13.351130   \n",
       "12  13.13  22.72  31.09  27.32  21.63  31.42  39.63  43.33  50.68  14.480780   \n",
       "13  18.46  25.70  28.06  27.89  21.79  21.67  24.92  26.49  32.57  12.042791   \n",
       "14  17.57  28.26  29.63  29.51  23.79  24.61  26.87  30.76  32.48  11.698090   \n",
       "15  13.89  20.62  26.83  23.85  20.28  20.27  23.67  23.65  30.46   9.471292   \n",
       "16   9.40  13.89  15.98  14.03  13.04  15.75  17.92  18.60  23.82   8.851833   \n",
       "17   4.25   7.79   8.49   8.09   5.92   6.12   6.74   5.95  19.56   4.846483   \n",
       "18   1.99   1.69   2.97   3.30   2.02   5.89   6.35   7.38  16.96   3.616631   \n",
       "19   0.34   0.95   0.71   0.49   1.80   2.68   2.51   1.92   2.09   0.866464   \n",
       "20   2.77   3.55   4.95   5.75   5.04   5.21   6.59   6.92   7.31   3.013944   \n",
       "21   6.38   7.75  12.02  12.55  12.60  13.55  14.47  14.69  15.12   5.145498   \n",
       "22  11.96  15.24  16.33  19.96  20.44  20.83  21.77  22.90  22.90   8.716177   \n",
       "23  10.91  20.67  21.53  25.54  28.95  28.02  27.94  28.91  30.66  12.321924   \n",
       "24  17.43  18.60  23.80  25.96  33.75  32.49  34.79  35.18  36.52  14.460339   \n",
       "25  15.81  22.40  25.83  29.35  36.73  35.60  38.80  40.25  40.68  16.315401   \n",
       "26  21.26  28.23  24.88  25.67  25.76  30.86  38.04  42.85  43.80  17.144218   \n",
       "27  22.03  31.71  29.19  30.21  31.31  33.62  38.02  43.82  45.73  18.011995   \n",
       "28  22.00  32.56  27.35  30.65  33.70  37.12  41.10  46.73  48.88  17.827007   \n",
       "29  19.27  27.40  26.75  30.04  29.45  35.11  39.92  44.32  46.44  17.671438   \n",
       "30  15.36  24.51  28.28  31.83  30.84  36.56  41.49  43.48  44.92  16.460413   \n",
       "31  13.02  18.89  26.87  29.48  35.25  36.42  40.61  41.84  43.60  15.189924   \n",
       "32  11.26  15.59  27.57  28.44  31.57  31.63  36.37  37.07  38.11  12.523960   \n",
       "33  12.90  15.70  26.92  21.42  29.22  29.51  31.08  31.76  32.98  10.059118   \n",
       "34   7.76  13.17  16.99  19.82  22.65  24.78  24.62  25.14  25.97   6.513051   \n",
       "35   5.68   8.31  12.89  14.46  15.21  15.84  17.08  17.28  18.61   4.290338   \n",
       "36   8.62   7.44   7.84   8.84   9.06   8.43   8.23   9.62   9.47   2.914204   \n",
       "37   3.88   1.33   2.09   3.83   4.24   3.23   2.57   3.06   2.81   1.145520   \n",
       "38   0.30   0.63   1.03   0.50   1.37   1.19   1.19   1.53   2.29   1.289500   \n",
       "39   2.29   3.73   5.13   5.83   7.20   7.49   8.08   8.44   8.79   2.512574   \n",
       "40   6.04   8.84  13.95  14.75  16.22  16.69  17.19  17.47  17.50   5.288871   \n",
       "41   8.68  13.32  18.85  21.34  22.22  23.12  23.77  24.55  24.52   7.950894   \n",
       "42  10.50  16.62  23.12  27.73  29.46  29.94  31.29  32.87  32.79  12.124215   \n",
       "43  13.97  23.69  28.18  30.94  34.79  36.23  37.51  37.54  37.60  14.166721   \n",
       "44  18.60  25.02  32.07  34.73  37.58  42.45  44.85  45.31  44.62  14.067751   \n",
       "45  14.39  25.44  32.47  37.51  40.66  43.06  46.19  46.57  46.66  13.036249   \n",
       "46  19.41  29.93  38.53  42.26  45.78  46.49  47.02  48.59  50.05  16.994919   \n",
       "47  20.72  32.24  39.67  43.87  44.40  47.57  49.76  50.98  51.73  17.576097   \n",
       "\n",
       "    ...      G10.9      M10.1      M10.2      M10.3      M10.4      M10.5  \\\n",
       "0   ...   9.617659   0.329373   1.272975   2.222000   3.875687   5.105513   \n",
       "1   ...  20.866327   1.128118   3.202078   5.518090   9.725550  12.969010   \n",
       "2   ...  25.929480   2.160001   5.547177   8.820875  13.377809  16.289724   \n",
       "3   ...  38.971222   3.460238   8.663424  13.986403  20.827868  26.041220   \n",
       "4   ...  38.998653   5.107563  11.910898  17.513607  23.314449  27.488192   \n",
       "5   ...  36.662949   8.993871  18.460552  25.109615  26.833054  30.154135   \n",
       "6   ...  37.442463  10.363093  19.981592  25.951077  25.325840  28.332447   \n",
       "7   ...  46.160000   9.228159  19.322693  28.750477  31.273363  37.178356   \n",
       "8   ...  46.159149   7.646490  16.922636  25.574295  30.638409  37.012051   \n",
       "9   ...  43.475784   7.260803  16.316357  25.232349  29.263187  35.237740   \n",
       "10  ...  40.346756   8.623682  18.128372  26.824112  27.669594  32.842304   \n",
       "11  ...  39.820618   7.055909  15.890283  24.498707  26.466946  31.005896   \n",
       "12  ...  49.869949   4.818467  12.408165  21.442879  28.834698  35.341663   \n",
       "13  ...  38.038448   5.374687  13.255543  21.458710  24.519558  27.360790   \n",
       "14  ...  35.596138   5.834748  13.915159  21.748260  23.525955  26.235214   \n",
       "15  ...  28.813011   5.123885  12.532187  18.985107  19.002716  20.060062   \n",
       "16  ...  31.159916   3.545650   9.831881  17.147171  20.896095  21.645552   \n",
       "17  ...  21.074026   1.775307   5.728541  11.096073  15.348503  14.934682   \n",
       "18  ...  14.644279   0.603167   2.393660   4.965306   9.151805  10.362707   \n",
       "19  ...   2.143718   0.281470   0.823242   1.040104   1.075293   1.254039   \n",
       "20  ...   7.538638   1.152913   3.917951   5.252352   4.937126   4.952584   \n",
       "21  ...  15.569941   3.284234   8.551517  10.521102  10.795098  11.350263   \n",
       "22  ...  23.685423   5.160917  12.510571  16.202187  17.685925  18.315889   \n",
       "23  ...  30.588705   7.674736  16.499916  21.969456  24.284307  24.846094   \n",
       "24  ...  36.885361   9.290116  18.970642  26.583889  29.456167  30.375208   \n",
       "25  ...  42.073997  11.409750  21.657230  30.451183  34.004562  35.169323   \n",
       "26  ...  46.211315  12.049514  23.038967  32.320526  36.200386  38.802258   \n",
       "27  ...  48.538223  13.091581  24.929039  33.709274  37.873466  41.146801   \n",
       "28  ...  49.593658  12.376309  23.827412  33.132587  37.094582  41.094158   \n",
       "29  ...  49.133965  12.145629  23.385645  32.808437  36.664574  40.496777   \n",
       "30  ...  47.229134  10.337456  20.982071  30.661556  33.958252  37.751331   \n",
       "31  ...  43.945312   9.023592  19.602280  28.647999  31.638607  34.943623   \n",
       "32  ...  39.200451   6.627160  17.230516  24.512157  27.162472  30.440798   \n",
       "33  ...  33.135654   4.894801  14.552773  20.358345  22.927216  25.654211   \n",
       "34  ...  26.168776   2.989256  10.662262  14.695687  16.920227  19.461119   \n",
       "35  ...  18.929718   1.914944   7.749857  10.220388  11.601554  13.405719   \n",
       "36  ...  10.889780   1.031875   5.036841   6.353527   6.720687   7.563734   \n",
       "37  ...   3.699688   0.350504   1.992132   2.781004   3.468869   3.374558   \n",
       "38  ...   3.049698   0.406368   1.335016   1.928913   2.318510   2.177904   \n",
       "39  ...   8.502715   1.864749   4.283177   5.349444   6.777020   7.233482   \n",
       "40  ...  17.503077   3.759428   9.304890  11.806891  12.731577  13.249283   \n",
       "41  ...  24.808882   5.332939  12.702641  16.854210  18.760006  19.594412   \n",
       "42  ...  32.502899   7.741753  16.682230  22.602509  25.337088  26.318483   \n",
       "43  ...  38.818054   9.150582  18.826040  26.777004  30.070261  31.563866   \n",
       "44  ...  43.381569  10.473228  20.132496  29.397827  33.441124  35.708488   \n",
       "45  ...  46.934570  10.391986  20.190556  29.753010  34.221390  38.250462   \n",
       "46  ...  50.315735  12.269210  23.013144  33.011841  37.657852  41.880318   \n",
       "47  ...  51.923138  12.090740  23.145559  33.233517  37.714043  42.672626   \n",
       "\n",
       "        M10.6      M10.7      M10.8      M10.9  \n",
       "0    5.777089   7.476045  10.104208  12.043563  \n",
       "1   15.099604  18.141224  22.504183  24.998043  \n",
       "2   18.242142  21.373890  25.896143  28.193527  \n",
       "3   29.857420  33.051517  39.212105  41.550571  \n",
       "4   30.451216  32.408348  37.889675  39.588684  \n",
       "5   33.465408  32.359592  35.644203  35.074295  \n",
       "6   33.150784  33.018898  35.123093  34.987961  \n",
       "7   42.135048  40.336819  47.014378  47.310070  \n",
       "8   41.465981  40.056301  47.252983  49.060436  \n",
       "9   39.583549  37.688423  44.847450  47.182415  \n",
       "10  38.008026  36.251068  42.364960  42.644188  \n",
       "11  35.155045  33.784100  40.154060  42.670391  \n",
       "12  39.490532  39.256622  46.276611  53.348797  \n",
       "13  29.561419  29.029062  33.716805  37.098377  \n",
       "14  29.125406  28.764288  33.514393  36.397358  \n",
       "15  22.753223  23.539127  26.719624  28.793344  \n",
       "16  21.813242  22.039639  24.562485  27.073961  \n",
       "17  13.533899  13.992954  14.809423  16.402884  \n",
       "18  10.109591  11.294207  12.022629  15.502774  \n",
       "19   1.321184   1.716482   2.186939   2.399323  \n",
       "20   5.789088   6.475689   7.107688   7.609428  \n",
       "21  13.735605  14.734819  15.409781  15.983940  \n",
       "22  21.489733  22.719061  23.122620  23.843927  \n",
       "23  27.991297  29.579254  29.559549  30.446499  \n",
       "24  33.649197  35.647919  35.563564  36.364796  \n",
       "25  38.207138  40.444073  40.758240  41.143299  \n",
       "26  41.891666  44.190384  45.158058  45.590725  \n",
       "27  44.239017  46.758072  47.606224  47.952175  \n",
       "28  45.106354  47.482559  48.801617  49.283482  \n",
       "29  44.545433  46.895962  48.306332  48.823807  \n",
       "30  42.337639  44.389053  46.371582  47.246319  \n",
       "31  39.253651  41.278557  42.940140  43.961697  \n",
       "32  35.004349  36.729576  37.935066  39.221050  \n",
       "33  29.876604  31.200211  32.052986  33.203243  \n",
       "34  23.344776  24.467306  25.432434  26.377892  \n",
       "35  16.385185  17.604626  18.383070  18.935654  \n",
       "36   8.989182   9.952747  10.423515  10.441300  \n",
       "37   3.078406   3.169029   3.317488   3.489783  \n",
       "38   1.495453   1.872091   2.283284   2.301525  \n",
       "39   7.760514   8.442198   8.987455   9.143443  \n",
       "40  15.654570  16.638840  17.251490  17.565552  \n",
       "41  22.873831  24.181030  24.577845  25.081758  \n",
       "42  29.746508  31.490782  31.526134  32.296700  \n",
       "43  35.334244  37.491241  37.945538  38.432404  \n",
       "44  39.355759  41.478828  42.847137  43.074329  \n",
       "45  42.568192  44.442184  46.704884  47.349155  \n",
       "46  45.931225  48.533688  49.954475  50.238041  \n",
       "47  47.496857  50.094948  51.758480  52.188717  \n",
       "\n",
       "[48 rows x 45 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_0.loc[res_0[res_0['L00.1'] == 0].index, ['D00.1','D00.2','D00.3','D00.4','D00.5','D00.6','D00.7','D00.8','D00.9'\n",
    "                                            ,'C00.1','C00.2','C00.3','C00.4','C00.5','C00.6','C00.7','C00.8','C00.9'\n",
    "                                            ,'G00.1','G00.2','G00.3','G00.4','G00.5','G00.6','G00.7','G00.8','G00.9'\n",
    "                                            ,'M00.1','M00.2','M00.3','M00.4','M00.5','M00.6','M00.7','M00.8','M00.9'\n",
    "                                            ]] = 0\n",
    "res_1.loc[res_1[res_1['L10.1'] == 0].index, ['D10.1','D10.2','D10.3','D10.4','D10.5','D10.6','D10.7','D10.8','D10.9'\n",
    "                                            ,'C10.1','C10.2','C10.3','C10.4','C10.5','C10.6','C10.7','C10.8','C10.9'\n",
    "                                            ,'G10.1','G10.2','G10.3','G10.4','G10.5','G10.6','G10.7','G10.8','G10.9'\n",
    "                                            ,'M10.1','M10.2','M10.3','M10.4','M10.5','M10.6','M10.7','M10.8','M10.9'\n",
    "                                            ]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L00.1</th>\n",
       "      <th>L00.2</th>\n",
       "      <th>L00.3</th>\n",
       "      <th>L00.4</th>\n",
       "      <th>L00.5</th>\n",
       "      <th>L00.6</th>\n",
       "      <th>L00.7</th>\n",
       "      <th>L00.8</th>\n",
       "      <th>L00.9</th>\n",
       "      <th>D00.1</th>\n",
       "      <th>...</th>\n",
       "      <th>G00.9</th>\n",
       "      <th>M00.1</th>\n",
       "      <th>M00.2</th>\n",
       "      <th>M00.3</th>\n",
       "      <th>M00.4</th>\n",
       "      <th>M00.5</th>\n",
       "      <th>M00.6</th>\n",
       "      <th>M00.7</th>\n",
       "      <th>M00.8</th>\n",
       "      <th>M00.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.21</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.69</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.82</td>\n",
       "      <td>7.76</td>\n",
       "      <td>13.55</td>\n",
       "      <td>0.907302</td>\n",
       "      <td>...</td>\n",
       "      <td>9.765275</td>\n",
       "      <td>0.651626</td>\n",
       "      <td>1.412930</td>\n",
       "      <td>1.663878</td>\n",
       "      <td>2.391623</td>\n",
       "      <td>3.620630</td>\n",
       "      <td>3.022576</td>\n",
       "      <td>5.746896</td>\n",
       "      <td>6.427562</td>\n",
       "      <td>10.876079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.02</td>\n",
       "      <td>5.08</td>\n",
       "      <td>3.72</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.37</td>\n",
       "      <td>11.08</td>\n",
       "      <td>13.85</td>\n",
       "      <td>16.70</td>\n",
       "      <td>24.47</td>\n",
       "      <td>2.578902</td>\n",
       "      <td>...</td>\n",
       "      <td>21.188997</td>\n",
       "      <td>1.516569</td>\n",
       "      <td>3.200346</td>\n",
       "      <td>5.007691</td>\n",
       "      <td>7.612739</td>\n",
       "      <td>10.807425</td>\n",
       "      <td>10.988094</td>\n",
       "      <td>16.742872</td>\n",
       "      <td>18.460148</td>\n",
       "      <td>25.416058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.95</td>\n",
       "      <td>7.68</td>\n",
       "      <td>6.93</td>\n",
       "      <td>9.15</td>\n",
       "      <td>11.44</td>\n",
       "      <td>13.54</td>\n",
       "      <td>17.00</td>\n",
       "      <td>22.30</td>\n",
       "      <td>30.41</td>\n",
       "      <td>3.995721</td>\n",
       "      <td>...</td>\n",
       "      <td>27.756762</td>\n",
       "      <td>2.490597</td>\n",
       "      <td>5.195635</td>\n",
       "      <td>8.690712</td>\n",
       "      <td>12.623331</td>\n",
       "      <td>16.221693</td>\n",
       "      <td>14.467131</td>\n",
       "      <td>20.739613</td>\n",
       "      <td>22.330959</td>\n",
       "      <td>30.209188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.75</td>\n",
       "      <td>18.21</td>\n",
       "      <td>14.21</td>\n",
       "      <td>12.27</td>\n",
       "      <td>13.04</td>\n",
       "      <td>14.29</td>\n",
       "      <td>24.18</td>\n",
       "      <td>23.67</td>\n",
       "      <td>32.19</td>\n",
       "      <td>7.144335</td>\n",
       "      <td>...</td>\n",
       "      <td>42.049759</td>\n",
       "      <td>3.558703</td>\n",
       "      <td>7.637560</td>\n",
       "      <td>13.491122</td>\n",
       "      <td>18.699293</td>\n",
       "      <td>23.502199</td>\n",
       "      <td>22.880861</td>\n",
       "      <td>31.975574</td>\n",
       "      <td>36.150452</td>\n",
       "      <td>46.415920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.46</td>\n",
       "      <td>19.97</td>\n",
       "      <td>19.76</td>\n",
       "      <td>14.46</td>\n",
       "      <td>14.23</td>\n",
       "      <td>17.93</td>\n",
       "      <td>24.89</td>\n",
       "      <td>24.49</td>\n",
       "      <td>33.79</td>\n",
       "      <td>9.069969</td>\n",
       "      <td>...</td>\n",
       "      <td>41.642868</td>\n",
       "      <td>4.839878</td>\n",
       "      <td>10.198141</td>\n",
       "      <td>17.454243</td>\n",
       "      <td>22.693516</td>\n",
       "      <td>27.092474</td>\n",
       "      <td>24.169703</td>\n",
       "      <td>32.847008</td>\n",
       "      <td>36.482132</td>\n",
       "      <td>46.895279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.49</td>\n",
       "      <td>33.17</td>\n",
       "      <td>31.34</td>\n",
       "      <td>30.79</td>\n",
       "      <td>31.74</td>\n",
       "      <td>29.02</td>\n",
       "      <td>32.47</td>\n",
       "      <td>31.01</td>\n",
       "      <td>35.08</td>\n",
       "      <td>13.219215</td>\n",
       "      <td>...</td>\n",
       "      <td>37.664337</td>\n",
       "      <td>7.798664</td>\n",
       "      <td>15.330933</td>\n",
       "      <td>24.164576</td>\n",
       "      <td>27.350012</td>\n",
       "      <td>31.454496</td>\n",
       "      <td>30.598495</td>\n",
       "      <td>36.305202</td>\n",
       "      <td>37.333523</td>\n",
       "      <td>40.848919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.84</td>\n",
       "      <td>30.46</td>\n",
       "      <td>33.34</td>\n",
       "      <td>34.52</td>\n",
       "      <td>33.37</td>\n",
       "      <td>31.68</td>\n",
       "      <td>34.05</td>\n",
       "      <td>34.45</td>\n",
       "      <td>33.44</td>\n",
       "      <td>13.704938</td>\n",
       "      <td>...</td>\n",
       "      <td>38.413773</td>\n",
       "      <td>9.042477</td>\n",
       "      <td>16.690411</td>\n",
       "      <td>24.624172</td>\n",
       "      <td>27.018827</td>\n",
       "      <td>31.540594</td>\n",
       "      <td>32.735386</td>\n",
       "      <td>37.522675</td>\n",
       "      <td>38.003830</td>\n",
       "      <td>39.672966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.18</td>\n",
       "      <td>34.47</td>\n",
       "      <td>41.16</td>\n",
       "      <td>42.26</td>\n",
       "      <td>45.32</td>\n",
       "      <td>32.25</td>\n",
       "      <td>36.77</td>\n",
       "      <td>36.94</td>\n",
       "      <td>41.94</td>\n",
       "      <td>15.420390</td>\n",
       "      <td>...</td>\n",
       "      <td>46.399887</td>\n",
       "      <td>8.000772</td>\n",
       "      <td>16.136662</td>\n",
       "      <td>27.386908</td>\n",
       "      <td>31.172380</td>\n",
       "      <td>36.419567</td>\n",
       "      <td>36.419098</td>\n",
       "      <td>43.420963</td>\n",
       "      <td>46.874535</td>\n",
       "      <td>51.689362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.98</td>\n",
       "      <td>28.02</td>\n",
       "      <td>33.01</td>\n",
       "      <td>36.39</td>\n",
       "      <td>38.08</td>\n",
       "      <td>30.77</td>\n",
       "      <td>31.88</td>\n",
       "      <td>33.00</td>\n",
       "      <td>40.99</td>\n",
       "      <td>14.241913</td>\n",
       "      <td>...</td>\n",
       "      <td>45.065361</td>\n",
       "      <td>6.773403</td>\n",
       "      <td>14.348423</td>\n",
       "      <td>24.432497</td>\n",
       "      <td>28.812801</td>\n",
       "      <td>33.840446</td>\n",
       "      <td>33.451294</td>\n",
       "      <td>41.137058</td>\n",
       "      <td>45.712769</td>\n",
       "      <td>52.616653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.81</td>\n",
       "      <td>28.88</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.41</td>\n",
       "      <td>35.41</td>\n",
       "      <td>29.31</td>\n",
       "      <td>32.04</td>\n",
       "      <td>30.31</td>\n",
       "      <td>34.51</td>\n",
       "      <td>13.757400</td>\n",
       "      <td>...</td>\n",
       "      <td>42.480476</td>\n",
       "      <td>6.526613</td>\n",
       "      <td>14.123219</td>\n",
       "      <td>23.619312</td>\n",
       "      <td>27.363253</td>\n",
       "      <td>32.228859</td>\n",
       "      <td>32.443634</td>\n",
       "      <td>38.739780</td>\n",
       "      <td>43.119469</td>\n",
       "      <td>48.208645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.53</td>\n",
       "      <td>33.20</td>\n",
       "      <td>35.54</td>\n",
       "      <td>35.72</td>\n",
       "      <td>38.17</td>\n",
       "      <td>29.63</td>\n",
       "      <td>35.03</td>\n",
       "      <td>35.92</td>\n",
       "      <td>38.92</td>\n",
       "      <td>13.774226</td>\n",
       "      <td>...</td>\n",
       "      <td>41.361061</td>\n",
       "      <td>7.603545</td>\n",
       "      <td>15.554159</td>\n",
       "      <td>25.120960</td>\n",
       "      <td>27.971552</td>\n",
       "      <td>32.967682</td>\n",
       "      <td>34.105930</td>\n",
       "      <td>39.612999</td>\n",
       "      <td>42.696678</td>\n",
       "      <td>45.417057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.55</td>\n",
       "      <td>22.72</td>\n",
       "      <td>30.72</td>\n",
       "      <td>34.70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>29.95</td>\n",
       "      <td>31.44</td>\n",
       "      <td>30.88</td>\n",
       "      <td>35.57</td>\n",
       "      <td>12.409553</td>\n",
       "      <td>...</td>\n",
       "      <td>39.996712</td>\n",
       "      <td>6.406276</td>\n",
       "      <td>14.052549</td>\n",
       "      <td>22.800934</td>\n",
       "      <td>25.745050</td>\n",
       "      <td>30.354742</td>\n",
       "      <td>30.901155</td>\n",
       "      <td>35.742340</td>\n",
       "      <td>39.410156</td>\n",
       "      <td>42.511856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.80</td>\n",
       "      <td>21.14</td>\n",
       "      <td>26.15</td>\n",
       "      <td>23.59</td>\n",
       "      <td>20.41</td>\n",
       "      <td>23.02</td>\n",
       "      <td>29.91</td>\n",
       "      <td>39.10</td>\n",
       "      <td>42.60</td>\n",
       "      <td>12.684363</td>\n",
       "      <td>...</td>\n",
       "      <td>49.664555</td>\n",
       "      <td>4.629732</td>\n",
       "      <td>10.896416</td>\n",
       "      <td>19.137058</td>\n",
       "      <td>23.736738</td>\n",
       "      <td>28.941547</td>\n",
       "      <td>29.564463</td>\n",
       "      <td>36.140732</td>\n",
       "      <td>42.907837</td>\n",
       "      <td>50.200787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.49</td>\n",
       "      <td>19.90</td>\n",
       "      <td>25.77</td>\n",
       "      <td>25.05</td>\n",
       "      <td>22.90</td>\n",
       "      <td>23.45</td>\n",
       "      <td>24.93</td>\n",
       "      <td>24.84</td>\n",
       "      <td>30.87</td>\n",
       "      <td>10.829406</td>\n",
       "      <td>...</td>\n",
       "      <td>37.069763</td>\n",
       "      <td>5.115972</td>\n",
       "      <td>11.971090</td>\n",
       "      <td>19.373894</td>\n",
       "      <td>22.384325</td>\n",
       "      <td>26.411833</td>\n",
       "      <td>26.014959</td>\n",
       "      <td>29.550989</td>\n",
       "      <td>32.987003</td>\n",
       "      <td>35.909557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.55</td>\n",
       "      <td>20.48</td>\n",
       "      <td>25.08</td>\n",
       "      <td>27.33</td>\n",
       "      <td>25.55</td>\n",
       "      <td>21.13</td>\n",
       "      <td>24.69</td>\n",
       "      <td>25.98</td>\n",
       "      <td>31.35</td>\n",
       "      <td>10.728248</td>\n",
       "      <td>...</td>\n",
       "      <td>34.808895</td>\n",
       "      <td>5.443573</td>\n",
       "      <td>12.486110</td>\n",
       "      <td>19.612082</td>\n",
       "      <td>22.179161</td>\n",
       "      <td>26.143351</td>\n",
       "      <td>26.252958</td>\n",
       "      <td>29.690475</td>\n",
       "      <td>32.779518</td>\n",
       "      <td>35.155376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.74</td>\n",
       "      <td>19.55</td>\n",
       "      <td>21.24</td>\n",
       "      <td>21.84</td>\n",
       "      <td>24.01</td>\n",
       "      <td>22.53</td>\n",
       "      <td>22.90</td>\n",
       "      <td>23.22</td>\n",
       "      <td>30.14</td>\n",
       "      <td>8.744321</td>\n",
       "      <td>...</td>\n",
       "      <td>27.836548</td>\n",
       "      <td>4.974761</td>\n",
       "      <td>11.723354</td>\n",
       "      <td>17.318130</td>\n",
       "      <td>19.118971</td>\n",
       "      <td>22.304539</td>\n",
       "      <td>22.179451</td>\n",
       "      <td>24.334892</td>\n",
       "      <td>26.449394</td>\n",
       "      <td>27.809347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.43</td>\n",
       "      <td>15.27</td>\n",
       "      <td>14.78</td>\n",
       "      <td>15.09</td>\n",
       "      <td>15.30</td>\n",
       "      <td>14.56</td>\n",
       "      <td>16.53</td>\n",
       "      <td>16.20</td>\n",
       "      <td>16.97</td>\n",
       "      <td>7.892495</td>\n",
       "      <td>...</td>\n",
       "      <td>30.630814</td>\n",
       "      <td>3.637974</td>\n",
       "      <td>8.903531</td>\n",
       "      <td>14.418842</td>\n",
       "      <td>17.392981</td>\n",
       "      <td>20.881630</td>\n",
       "      <td>19.549978</td>\n",
       "      <td>21.511440</td>\n",
       "      <td>24.072803</td>\n",
       "      <td>26.282967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.01</td>\n",
       "      <td>9.46</td>\n",
       "      <td>9.11</td>\n",
       "      <td>6.71</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.98</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.74</td>\n",
       "      <td>14.31</td>\n",
       "      <td>4.481168</td>\n",
       "      <td>...</td>\n",
       "      <td>21.702719</td>\n",
       "      <td>2.095726</td>\n",
       "      <td>5.311701</td>\n",
       "      <td>9.121095</td>\n",
       "      <td>11.956009</td>\n",
       "      <td>15.396475</td>\n",
       "      <td>13.270828</td>\n",
       "      <td>13.999071</td>\n",
       "      <td>15.685595</td>\n",
       "      <td>17.190290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.94</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.32</td>\n",
       "      <td>4.97</td>\n",
       "      <td>6.43</td>\n",
       "      <td>10.87</td>\n",
       "      <td>3.501750</td>\n",
       "      <td>...</td>\n",
       "      <td>15.400671</td>\n",
       "      <td>0.881682</td>\n",
       "      <td>2.370034</td>\n",
       "      <td>4.221588</td>\n",
       "      <td>6.204017</td>\n",
       "      <td>9.654202</td>\n",
       "      <td>9.231308</td>\n",
       "      <td>10.874598</td>\n",
       "      <td>13.524657</td>\n",
       "      <td>16.031055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.083755</td>\n",
       "      <td>...</td>\n",
       "      <td>1.933169</td>\n",
       "      <td>0.658838</td>\n",
       "      <td>1.330434</td>\n",
       "      <td>1.154504</td>\n",
       "      <td>1.063127</td>\n",
       "      <td>1.130794</td>\n",
       "      <td>1.519910</td>\n",
       "      <td>1.990139</td>\n",
       "      <td>2.151956</td>\n",
       "      <td>2.062776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.61</td>\n",
       "      <td>3.59</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.33</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.56</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.57</td>\n",
       "      <td>3.379551</td>\n",
       "      <td>...</td>\n",
       "      <td>7.792755</td>\n",
       "      <td>2.194237</td>\n",
       "      <td>4.143533</td>\n",
       "      <td>6.064661</td>\n",
       "      <td>6.699108</td>\n",
       "      <td>7.300083</td>\n",
       "      <td>6.369847</td>\n",
       "      <td>7.500924</td>\n",
       "      <td>8.008971</td>\n",
       "      <td>8.124584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.16</td>\n",
       "      <td>8.99</td>\n",
       "      <td>13.04</td>\n",
       "      <td>13.06</td>\n",
       "      <td>12.68</td>\n",
       "      <td>13.53</td>\n",
       "      <td>15.22</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.19</td>\n",
       "      <td>6.383345</td>\n",
       "      <td>...</td>\n",
       "      <td>15.665381</td>\n",
       "      <td>5.194424</td>\n",
       "      <td>9.521467</td>\n",
       "      <td>12.363936</td>\n",
       "      <td>14.115209</td>\n",
       "      <td>16.184280</td>\n",
       "      <td>14.823651</td>\n",
       "      <td>16.502480</td>\n",
       "      <td>16.413942</td>\n",
       "      <td>17.070805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.85</td>\n",
       "      <td>19.44</td>\n",
       "      <td>22.57</td>\n",
       "      <td>22.26</td>\n",
       "      <td>20.77</td>\n",
       "      <td>22.25</td>\n",
       "      <td>23.12</td>\n",
       "      <td>23.11</td>\n",
       "      <td>23.16</td>\n",
       "      <td>9.966775</td>\n",
       "      <td>...</td>\n",
       "      <td>23.882532</td>\n",
       "      <td>7.201926</td>\n",
       "      <td>13.911270</td>\n",
       "      <td>18.494589</td>\n",
       "      <td>21.497286</td>\n",
       "      <td>24.298449</td>\n",
       "      <td>22.940239</td>\n",
       "      <td>25.367527</td>\n",
       "      <td>24.350090</td>\n",
       "      <td>25.905735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.35</td>\n",
       "      <td>22.78</td>\n",
       "      <td>23.24</td>\n",
       "      <td>22.13</td>\n",
       "      <td>27.21</td>\n",
       "      <td>28.29</td>\n",
       "      <td>28.58</td>\n",
       "      <td>29.19</td>\n",
       "      <td>30.69</td>\n",
       "      <td>13.693385</td>\n",
       "      <td>...</td>\n",
       "      <td>31.443598</td>\n",
       "      <td>10.162374</td>\n",
       "      <td>19.149075</td>\n",
       "      <td>24.062498</td>\n",
       "      <td>28.397135</td>\n",
       "      <td>31.457529</td>\n",
       "      <td>29.828190</td>\n",
       "      <td>32.615334</td>\n",
       "      <td>31.043741</td>\n",
       "      <td>33.637703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23.16</td>\n",
       "      <td>25.54</td>\n",
       "      <td>27.38</td>\n",
       "      <td>30.68</td>\n",
       "      <td>32.23</td>\n",
       "      <td>33.56</td>\n",
       "      <td>35.70</td>\n",
       "      <td>35.72</td>\n",
       "      <td>36.23</td>\n",
       "      <td>16.060265</td>\n",
       "      <td>...</td>\n",
       "      <td>37.763214</td>\n",
       "      <td>12.351465</td>\n",
       "      <td>23.467091</td>\n",
       "      <td>28.608976</td>\n",
       "      <td>33.889027</td>\n",
       "      <td>37.274853</td>\n",
       "      <td>35.951912</td>\n",
       "      <td>38.707848</td>\n",
       "      <td>37.523529</td>\n",
       "      <td>40.748180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24.20</td>\n",
       "      <td>26.76</td>\n",
       "      <td>34.43</td>\n",
       "      <td>34.61</td>\n",
       "      <td>34.10</td>\n",
       "      <td>37.38</td>\n",
       "      <td>39.56</td>\n",
       "      <td>40.91</td>\n",
       "      <td>40.63</td>\n",
       "      <td>18.122995</td>\n",
       "      <td>...</td>\n",
       "      <td>42.614044</td>\n",
       "      <td>14.922377</td>\n",
       "      <td>28.431149</td>\n",
       "      <td>33.837650</td>\n",
       "      <td>39.051540</td>\n",
       "      <td>42.399414</td>\n",
       "      <td>40.622681</td>\n",
       "      <td>43.320438</td>\n",
       "      <td>42.592911</td>\n",
       "      <td>45.904675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>34.63</td>\n",
       "      <td>44.78</td>\n",
       "      <td>39.29</td>\n",
       "      <td>39.37</td>\n",
       "      <td>41.10</td>\n",
       "      <td>42.40</td>\n",
       "      <td>44.60</td>\n",
       "      <td>45.02</td>\n",
       "      <td>45.32</td>\n",
       "      <td>19.072941</td>\n",
       "      <td>...</td>\n",
       "      <td>46.444283</td>\n",
       "      <td>15.803480</td>\n",
       "      <td>30.593998</td>\n",
       "      <td>36.715950</td>\n",
       "      <td>42.036961</td>\n",
       "      <td>45.731613</td>\n",
       "      <td>44.404572</td>\n",
       "      <td>46.926956</td>\n",
       "      <td>46.717934</td>\n",
       "      <td>49.881439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>35.95</td>\n",
       "      <td>41.92</td>\n",
       "      <td>40.53</td>\n",
       "      <td>41.40</td>\n",
       "      <td>43.92</td>\n",
       "      <td>44.44</td>\n",
       "      <td>47.38</td>\n",
       "      <td>47.46</td>\n",
       "      <td>48.00</td>\n",
       "      <td>20.039961</td>\n",
       "      <td>...</td>\n",
       "      <td>48.781582</td>\n",
       "      <td>17.070126</td>\n",
       "      <td>33.137630</td>\n",
       "      <td>39.420242</td>\n",
       "      <td>44.573887</td>\n",
       "      <td>48.342800</td>\n",
       "      <td>46.763161</td>\n",
       "      <td>49.361698</td>\n",
       "      <td>49.220634</td>\n",
       "      <td>52.356319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>37.22</td>\n",
       "      <td>46.59</td>\n",
       "      <td>43.20</td>\n",
       "      <td>45.22</td>\n",
       "      <td>45.11</td>\n",
       "      <td>46.75</td>\n",
       "      <td>47.83</td>\n",
       "      <td>49.36</td>\n",
       "      <td>49.20</td>\n",
       "      <td>19.868374</td>\n",
       "      <td>...</td>\n",
       "      <td>49.875072</td>\n",
       "      <td>16.520857</td>\n",
       "      <td>32.114845</td>\n",
       "      <td>38.556282</td>\n",
       "      <td>44.032230</td>\n",
       "      <td>48.172718</td>\n",
       "      <td>47.504570</td>\n",
       "      <td>50.051456</td>\n",
       "      <td>50.204514</td>\n",
       "      <td>53.180050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>38.92</td>\n",
       "      <td>47.51</td>\n",
       "      <td>44.49</td>\n",
       "      <td>45.68</td>\n",
       "      <td>44.82</td>\n",
       "      <td>45.24</td>\n",
       "      <td>47.44</td>\n",
       "      <td>47.66</td>\n",
       "      <td>48.24</td>\n",
       "      <td>19.697437</td>\n",
       "      <td>...</td>\n",
       "      <td>49.417213</td>\n",
       "      <td>16.402988</td>\n",
       "      <td>31.783100</td>\n",
       "      <td>38.033119</td>\n",
       "      <td>43.522022</td>\n",
       "      <td>47.672394</td>\n",
       "      <td>47.026474</td>\n",
       "      <td>49.578156</td>\n",
       "      <td>49.716343</td>\n",
       "      <td>52.688320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32.31</td>\n",
       "      <td>40.78</td>\n",
       "      <td>41.03</td>\n",
       "      <td>42.77</td>\n",
       "      <td>41.76</td>\n",
       "      <td>43.91</td>\n",
       "      <td>45.65</td>\n",
       "      <td>46.11</td>\n",
       "      <td>45.99</td>\n",
       "      <td>18.383503</td>\n",
       "      <td>...</td>\n",
       "      <td>47.576416</td>\n",
       "      <td>14.388479</td>\n",
       "      <td>27.978525</td>\n",
       "      <td>34.172054</td>\n",
       "      <td>40.071667</td>\n",
       "      <td>44.455048</td>\n",
       "      <td>44.775650</td>\n",
       "      <td>47.179844</td>\n",
       "      <td>47.505325</td>\n",
       "      <td>50.336075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>28.41</td>\n",
       "      <td>40.74</td>\n",
       "      <td>34.27</td>\n",
       "      <td>37.77</td>\n",
       "      <td>37.54</td>\n",
       "      <td>39.47</td>\n",
       "      <td>42.69</td>\n",
       "      <td>43.06</td>\n",
       "      <td>43.14</td>\n",
       "      <td>16.978943</td>\n",
       "      <td>...</td>\n",
       "      <td>44.174637</td>\n",
       "      <td>12.645197</td>\n",
       "      <td>24.863316</td>\n",
       "      <td>30.909405</td>\n",
       "      <td>36.927879</td>\n",
       "      <td>41.220608</td>\n",
       "      <td>41.614090</td>\n",
       "      <td>44.006359</td>\n",
       "      <td>44.118290</td>\n",
       "      <td>46.976162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20.90</td>\n",
       "      <td>27.69</td>\n",
       "      <td>28.46</td>\n",
       "      <td>33.65</td>\n",
       "      <td>34.02</td>\n",
       "      <td>35.00</td>\n",
       "      <td>37.63</td>\n",
       "      <td>38.57</td>\n",
       "      <td>38.50</td>\n",
       "      <td>14.118104</td>\n",
       "      <td>...</td>\n",
       "      <td>39.584984</td>\n",
       "      <td>9.272047</td>\n",
       "      <td>19.500896</td>\n",
       "      <td>25.967335</td>\n",
       "      <td>31.911280</td>\n",
       "      <td>36.102921</td>\n",
       "      <td>37.063538</td>\n",
       "      <td>39.377338</td>\n",
       "      <td>39.243500</td>\n",
       "      <td>42.055561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>18.31</td>\n",
       "      <td>25.77</td>\n",
       "      <td>28.89</td>\n",
       "      <td>26.08</td>\n",
       "      <td>27.76</td>\n",
       "      <td>31.22</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.45</td>\n",
       "      <td>11.514292</td>\n",
       "      <td>...</td>\n",
       "      <td>33.977402</td>\n",
       "      <td>6.735143</td>\n",
       "      <td>15.393017</td>\n",
       "      <td>22.137846</td>\n",
       "      <td>27.239832</td>\n",
       "      <td>30.955410</td>\n",
       "      <td>31.844326</td>\n",
       "      <td>34.124058</td>\n",
       "      <td>33.557854</td>\n",
       "      <td>35.941757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11.08</td>\n",
       "      <td>23.03</td>\n",
       "      <td>24.38</td>\n",
       "      <td>22.38</td>\n",
       "      <td>24.69</td>\n",
       "      <td>26.11</td>\n",
       "      <td>25.42</td>\n",
       "      <td>25.57</td>\n",
       "      <td>25.94</td>\n",
       "      <td>8.187277</td>\n",
       "      <td>...</td>\n",
       "      <td>26.437605</td>\n",
       "      <td>4.017846</td>\n",
       "      <td>10.450139</td>\n",
       "      <td>16.765533</td>\n",
       "      <td>20.526527</td>\n",
       "      <td>23.926764</td>\n",
       "      <td>24.945961</td>\n",
       "      <td>27.202299</td>\n",
       "      <td>26.751408</td>\n",
       "      <td>28.041607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.36</td>\n",
       "      <td>13.11</td>\n",
       "      <td>16.95</td>\n",
       "      <td>17.69</td>\n",
       "      <td>17.08</td>\n",
       "      <td>17.72</td>\n",
       "      <td>17.97</td>\n",
       "      <td>18.39</td>\n",
       "      <td>18.84</td>\n",
       "      <td>5.701241</td>\n",
       "      <td>...</td>\n",
       "      <td>18.480204</td>\n",
       "      <td>2.785563</td>\n",
       "      <td>7.429151</td>\n",
       "      <td>12.208894</td>\n",
       "      <td>14.666439</td>\n",
       "      <td>17.456865</td>\n",
       "      <td>17.924042</td>\n",
       "      <td>19.670921</td>\n",
       "      <td>19.398064</td>\n",
       "      <td>19.790562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.34</td>\n",
       "      <td>6.68</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.84</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.95</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.87</td>\n",
       "      <td>3.956131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.304486</td>\n",
       "      <td>1.692700</td>\n",
       "      <td>4.617312</td>\n",
       "      <td>7.607981</td>\n",
       "      <td>8.773732</td>\n",
       "      <td>10.247350</td>\n",
       "      <td>10.136093</td>\n",
       "      <td>11.172242</td>\n",
       "      <td>11.213359</td>\n",
       "      <td>11.001766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.06</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.767852</td>\n",
       "      <td>...</td>\n",
       "      <td>3.157816</td>\n",
       "      <td>0.575418</td>\n",
       "      <td>1.738009</td>\n",
       "      <td>2.904547</td>\n",
       "      <td>2.923477</td>\n",
       "      <td>3.138932</td>\n",
       "      <td>3.046759</td>\n",
       "      <td>3.384630</td>\n",
       "      <td>3.494174</td>\n",
       "      <td>3.226869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.549785</td>\n",
       "      <td>...</td>\n",
       "      <td>2.481506</td>\n",
       "      <td>0.802291</td>\n",
       "      <td>1.708197</td>\n",
       "      <td>1.521986</td>\n",
       "      <td>1.702527</td>\n",
       "      <td>1.867783</td>\n",
       "      <td>1.149644</td>\n",
       "      <td>1.899064</td>\n",
       "      <td>1.940590</td>\n",
       "      <td>2.484862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.17</td>\n",
       "      <td>3.61</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.24</td>\n",
       "      <td>7.03</td>\n",
       "      <td>7.36</td>\n",
       "      <td>7.70</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.39</td>\n",
       "      <td>2.886923</td>\n",
       "      <td>...</td>\n",
       "      <td>8.750995</td>\n",
       "      <td>2.696599</td>\n",
       "      <td>4.853239</td>\n",
       "      <td>5.843548</td>\n",
       "      <td>7.078466</td>\n",
       "      <td>8.430592</td>\n",
       "      <td>8.103583</td>\n",
       "      <td>8.848512</td>\n",
       "      <td>8.873066</td>\n",
       "      <td>8.871959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.82</td>\n",
       "      <td>10.20</td>\n",
       "      <td>13.27</td>\n",
       "      <td>15.31</td>\n",
       "      <td>15.99</td>\n",
       "      <td>16.46</td>\n",
       "      <td>17.05</td>\n",
       "      <td>16.86</td>\n",
       "      <td>16.96</td>\n",
       "      <td>6.471984</td>\n",
       "      <td>...</td>\n",
       "      <td>17.885265</td>\n",
       "      <td>5.312920</td>\n",
       "      <td>9.667276</td>\n",
       "      <td>12.834445</td>\n",
       "      <td>14.787426</td>\n",
       "      <td>17.129389</td>\n",
       "      <td>16.120167</td>\n",
       "      <td>17.920708</td>\n",
       "      <td>17.645054</td>\n",
       "      <td>18.492777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>9.21</td>\n",
       "      <td>15.81</td>\n",
       "      <td>19.20</td>\n",
       "      <td>21.31</td>\n",
       "      <td>22.58</td>\n",
       "      <td>22.97</td>\n",
       "      <td>23.40</td>\n",
       "      <td>23.81</td>\n",
       "      <td>25.24</td>\n",
       "      <td>9.221293</td>\n",
       "      <td>...</td>\n",
       "      <td>25.205109</td>\n",
       "      <td>6.630163</td>\n",
       "      <td>12.487499</td>\n",
       "      <td>17.367464</td>\n",
       "      <td>20.572191</td>\n",
       "      <td>23.661013</td>\n",
       "      <td>23.134224</td>\n",
       "      <td>25.733986</td>\n",
       "      <td>24.849573</td>\n",
       "      <td>26.609905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>11.98</td>\n",
       "      <td>21.78</td>\n",
       "      <td>27.90</td>\n",
       "      <td>29.88</td>\n",
       "      <td>30.57</td>\n",
       "      <td>31.18</td>\n",
       "      <td>32.07</td>\n",
       "      <td>32.01</td>\n",
       "      <td>33.51</td>\n",
       "      <td>13.516776</td>\n",
       "      <td>...</td>\n",
       "      <td>33.253918</td>\n",
       "      <td>9.422367</td>\n",
       "      <td>17.129654</td>\n",
       "      <td>22.938807</td>\n",
       "      <td>27.674749</td>\n",
       "      <td>31.207392</td>\n",
       "      <td>30.465097</td>\n",
       "      <td>33.467827</td>\n",
       "      <td>32.167419</td>\n",
       "      <td>35.105759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16.12</td>\n",
       "      <td>28.55</td>\n",
       "      <td>32.32</td>\n",
       "      <td>34.97</td>\n",
       "      <td>35.93</td>\n",
       "      <td>37.32</td>\n",
       "      <td>38.20</td>\n",
       "      <td>37.77</td>\n",
       "      <td>39.81</td>\n",
       "      <td>15.740187</td>\n",
       "      <td>...</td>\n",
       "      <td>39.380211</td>\n",
       "      <td>11.225794</td>\n",
       "      <td>20.144056</td>\n",
       "      <td>26.246883</td>\n",
       "      <td>32.131622</td>\n",
       "      <td>36.278439</td>\n",
       "      <td>36.225739</td>\n",
       "      <td>39.316746</td>\n",
       "      <td>38.710838</td>\n",
       "      <td>42.183563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>16.29</td>\n",
       "      <td>24.97</td>\n",
       "      <td>30.89</td>\n",
       "      <td>35.17</td>\n",
       "      <td>36.30</td>\n",
       "      <td>39.71</td>\n",
       "      <td>42.33</td>\n",
       "      <td>43.93</td>\n",
       "      <td>43.55</td>\n",
       "      <td>15.506078</td>\n",
       "      <td>...</td>\n",
       "      <td>43.815002</td>\n",
       "      <td>12.583164</td>\n",
       "      <td>21.162590</td>\n",
       "      <td>26.808037</td>\n",
       "      <td>33.058434</td>\n",
       "      <td>37.942703</td>\n",
       "      <td>39.327881</td>\n",
       "      <td>42.588108</td>\n",
       "      <td>42.918091</td>\n",
       "      <td>46.439999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17.81</td>\n",
       "      <td>25.01</td>\n",
       "      <td>29.68</td>\n",
       "      <td>33.83</td>\n",
       "      <td>37.27</td>\n",
       "      <td>39.81</td>\n",
       "      <td>42.19</td>\n",
       "      <td>43.91</td>\n",
       "      <td>45.57</td>\n",
       "      <td>14.302635</td>\n",
       "      <td>...</td>\n",
       "      <td>47.527428</td>\n",
       "      <td>12.252638</td>\n",
       "      <td>20.123070</td>\n",
       "      <td>25.582579</td>\n",
       "      <td>32.008797</td>\n",
       "      <td>37.813282</td>\n",
       "      <td>41.512123</td>\n",
       "      <td>45.134731</td>\n",
       "      <td>46.614975</td>\n",
       "      <td>49.793106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.94</td>\n",
       "      <td>36.12</td>\n",
       "      <td>40.64</td>\n",
       "      <td>42.25</td>\n",
       "      <td>46.52</td>\n",
       "      <td>48.62</td>\n",
       "      <td>47.93</td>\n",
       "      <td>49.41</td>\n",
       "      <td>50.03</td>\n",
       "      <td>18.861544</td>\n",
       "      <td>...</td>\n",
       "      <td>50.767487</td>\n",
       "      <td>15.219469</td>\n",
       "      <td>26.853905</td>\n",
       "      <td>33.604534</td>\n",
       "      <td>40.203236</td>\n",
       "      <td>45.115681</td>\n",
       "      <td>46.274261</td>\n",
       "      <td>49.490059</td>\n",
       "      <td>50.328728</td>\n",
       "      <td>53.756237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>21.37</td>\n",
       "      <td>39.09</td>\n",
       "      <td>48.19</td>\n",
       "      <td>45.46</td>\n",
       "      <td>47.59</td>\n",
       "      <td>50.48</td>\n",
       "      <td>50.25</td>\n",
       "      <td>51.04</td>\n",
       "      <td>51.74</td>\n",
       "      <td>19.566372</td>\n",
       "      <td>...</td>\n",
       "      <td>52.336914</td>\n",
       "      <td>15.201172</td>\n",
       "      <td>27.664463</td>\n",
       "      <td>34.931221</td>\n",
       "      <td>41.543274</td>\n",
       "      <td>46.576904</td>\n",
       "      <td>48.014565</td>\n",
       "      <td>51.141140</td>\n",
       "      <td>52.160442</td>\n",
       "      <td>55.384090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L00.1  L00.2  L00.3  L00.4  L00.5  L00.6  L00.7  L00.8  L00.9      D00.1  \\\n",
       "0    1.21   2.60   3.21   2.69   5.25   4.98   5.82   7.76  13.55   0.907302   \n",
       "1    5.02   5.08   3.72   8.10   8.37  11.08  13.85  16.70  24.47   2.578902   \n",
       "2    6.95   7.68   6.93   9.15  11.44  13.54  17.00  22.30  30.41   3.995721   \n",
       "3   10.75  18.21  14.21  12.27  13.04  14.29  24.18  23.67  32.19   7.144335   \n",
       "4   14.46  19.97  19.76  14.46  14.23  17.93  24.89  24.49  33.79   9.069969   \n",
       "5   22.49  33.17  31.34  30.79  31.74  29.02  32.47  31.01  35.08  13.219215   \n",
       "6   23.84  30.46  33.34  34.52  33.37  31.68  34.05  34.45  33.44  13.704938   \n",
       "7   24.18  34.47  41.16  42.26  45.32  32.25  36.77  36.94  41.94  15.420390   \n",
       "8   20.98  28.02  33.01  36.39  38.08  30.77  31.88  33.00  40.99  14.241913   \n",
       "9   20.81  28.88  34.68  35.41  35.41  29.31  32.04  30.31  34.51  13.757400   \n",
       "10  21.53  33.20  35.54  35.72  38.17  29.63  35.03  35.92  38.92  13.774226   \n",
       "11  17.55  22.72  30.72  34.70  33.34  29.95  31.44  30.88  35.57  12.409553   \n",
       "12  15.80  21.14  26.15  23.59  20.41  23.02  29.91  39.10  42.60  12.684363   \n",
       "13  15.49  19.90  25.77  25.05  22.90  23.45  24.93  24.84  30.87  10.829406   \n",
       "14  15.55  20.48  25.08  27.33  25.55  21.13  24.69  25.98  31.35  10.728248   \n",
       "15  10.74  19.55  21.24  21.84  24.01  22.53  22.90  23.22  30.14   8.744321   \n",
       "16   8.43  15.27  14.78  15.09  15.30  14.56  16.53  16.20  16.97   7.892495   \n",
       "17   6.01   9.46   9.11   6.71   7.14   7.98   7.98   5.74  14.31   4.481168   \n",
       "18   1.94   2.65   3.48   1.44   1.90   3.32   4.97   6.43  10.87   3.501750   \n",
       "19  -0.80  -0.38  -0.39   0.92  -0.07   1.34   1.44   2.02   1.83   1.083755   \n",
       "20   3.61   3.59   5.40   5.33   6.67   6.56   7.16   7.21   7.57   3.379551   \n",
       "21   6.16   8.99  13.04  13.06  12.68  13.53  15.22  15.38  15.19   6.383345   \n",
       "22   9.85  19.44  22.57  22.26  20.77  22.25  23.12  23.11  23.16   9.966775   \n",
       "23  15.35  22.78  23.24  22.13  27.21  28.29  28.58  29.19  30.69  13.693385   \n",
       "24  23.16  25.54  27.38  30.68  32.23  33.56  35.70  35.72  36.23  16.060265   \n",
       "25  24.20  26.76  34.43  34.61  34.10  37.38  39.56  40.91  40.63  18.122995   \n",
       "26  34.63  44.78  39.29  39.37  41.10  42.40  44.60  45.02  45.32  19.072941   \n",
       "27  35.95  41.92  40.53  41.40  43.92  44.44  47.38  47.46  48.00  20.039961   \n",
       "28  37.22  46.59  43.20  45.22  45.11  46.75  47.83  49.36  49.20  19.868374   \n",
       "29  38.92  47.51  44.49  45.68  44.82  45.24  47.44  47.66  48.24  19.697437   \n",
       "30  32.31  40.78  41.03  42.77  41.76  43.91  45.65  46.11  45.99  18.383503   \n",
       "31  28.41  40.74  34.27  37.77  37.54  39.47  42.69  43.06  43.14  16.978943   \n",
       "32  20.90  27.69  28.46  33.65  34.02  35.00  37.63  38.57  38.50  14.118104   \n",
       "33  18.31  25.77  28.89  26.08  27.76  31.22  32.09  32.93  32.45  11.514292   \n",
       "34  11.08  23.03  24.38  22.38  24.69  26.11  25.42  25.57  25.94   8.187277   \n",
       "35  10.36  13.11  16.95  17.69  17.08  17.72  17.97  18.39  18.84   5.701241   \n",
       "36   4.34   6.68   6.82   6.94   6.84   8.00   8.95   9.36   9.87   3.956131   \n",
       "37   2.06   2.46   2.53   1.37   1.20   2.03   2.71   2.67   2.64   1.767852   \n",
       "38   0.34   0.72   1.28   1.32   1.95   1.63   1.63   1.46   2.08   1.549785   \n",
       "39   2.17   3.61   5.74   6.24   7.03   7.36   7.70   8.05   8.39   2.886923   \n",
       "40   5.82  10.20  13.27  15.31  15.99  16.46  17.05  16.86  16.96   6.471984   \n",
       "41   9.21  15.81  19.20  21.31  22.58  22.97  23.40  23.81  25.24   9.221293   \n",
       "42  11.98  21.78  27.90  29.88  30.57  31.18  32.07  32.01  33.51  13.516776   \n",
       "43  16.12  28.55  32.32  34.97  35.93  37.32  38.20  37.77  39.81  15.740187   \n",
       "44  16.29  24.97  30.89  35.17  36.30  39.71  42.33  43.93  43.55  15.506078   \n",
       "45  17.81  25.01  29.68  33.83  37.27  39.81  42.19  43.91  45.57  14.302635   \n",
       "46  19.94  36.12  40.64  42.25  46.52  48.62  47.93  49.41  50.03  18.861544   \n",
       "47  21.37  39.09  48.19  45.46  47.59  50.48  50.25  51.04  51.74  19.566372   \n",
       "\n",
       "    ...      G00.9      M00.1      M00.2      M00.3      M00.4      M00.5  \\\n",
       "0   ...   9.765275   0.651626   1.412930   1.663878   2.391623   3.620630   \n",
       "1   ...  21.188997   1.516569   3.200346   5.007691   7.612739  10.807425   \n",
       "2   ...  27.756762   2.490597   5.195635   8.690712  12.623331  16.221693   \n",
       "3   ...  42.049759   3.558703   7.637560  13.491122  18.699293  23.502199   \n",
       "4   ...  41.642868   4.839878  10.198141  17.454243  22.693516  27.092474   \n",
       "5   ...  37.664337   7.798664  15.330933  24.164576  27.350012  31.454496   \n",
       "6   ...  38.413773   9.042477  16.690411  24.624172  27.018827  31.540594   \n",
       "7   ...  46.399887   8.000772  16.136662  27.386908  31.172380  36.419567   \n",
       "8   ...  45.065361   6.773403  14.348423  24.432497  28.812801  33.840446   \n",
       "9   ...  42.480476   6.526613  14.123219  23.619312  27.363253  32.228859   \n",
       "10  ...  41.361061   7.603545  15.554159  25.120960  27.971552  32.967682   \n",
       "11  ...  39.996712   6.406276  14.052549  22.800934  25.745050  30.354742   \n",
       "12  ...  49.664555   4.629732  10.896416  19.137058  23.736738  28.941547   \n",
       "13  ...  37.069763   5.115972  11.971090  19.373894  22.384325  26.411833   \n",
       "14  ...  34.808895   5.443573  12.486110  19.612082  22.179161  26.143351   \n",
       "15  ...  27.836548   4.974761  11.723354  17.318130  19.118971  22.304539   \n",
       "16  ...  30.630814   3.637974   8.903531  14.418842  17.392981  20.881630   \n",
       "17  ...  21.702719   2.095726   5.311701   9.121095  11.956009  15.396475   \n",
       "18  ...  15.400671   0.881682   2.370034   4.221588   6.204017   9.654202   \n",
       "19  ...   1.933169   0.658838   1.330434   1.154504   1.063127   1.130794   \n",
       "20  ...   7.792755   2.194237   4.143533   6.064661   6.699108   7.300083   \n",
       "21  ...  15.665381   5.194424   9.521467  12.363936  14.115209  16.184280   \n",
       "22  ...  23.882532   7.201926  13.911270  18.494589  21.497286  24.298449   \n",
       "23  ...  31.443598  10.162374  19.149075  24.062498  28.397135  31.457529   \n",
       "24  ...  37.763214  12.351465  23.467091  28.608976  33.889027  37.274853   \n",
       "25  ...  42.614044  14.922377  28.431149  33.837650  39.051540  42.399414   \n",
       "26  ...  46.444283  15.803480  30.593998  36.715950  42.036961  45.731613   \n",
       "27  ...  48.781582  17.070126  33.137630  39.420242  44.573887  48.342800   \n",
       "28  ...  49.875072  16.520857  32.114845  38.556282  44.032230  48.172718   \n",
       "29  ...  49.417213  16.402988  31.783100  38.033119  43.522022  47.672394   \n",
       "30  ...  47.576416  14.388479  27.978525  34.172054  40.071667  44.455048   \n",
       "31  ...  44.174637  12.645197  24.863316  30.909405  36.927879  41.220608   \n",
       "32  ...  39.584984   9.272047  19.500896  25.967335  31.911280  36.102921   \n",
       "33  ...  33.977402   6.735143  15.393017  22.137846  27.239832  30.955410   \n",
       "34  ...  26.437605   4.017846  10.450139  16.765533  20.526527  23.926764   \n",
       "35  ...  18.480204   2.785563   7.429151  12.208894  14.666439  17.456865   \n",
       "36  ...  10.304486   1.692700   4.617312   7.607981   8.773732  10.247350   \n",
       "37  ...   3.157816   0.575418   1.738009   2.904547   2.923477   3.138932   \n",
       "38  ...   2.481506   0.802291   1.708197   1.521986   1.702527   1.867783   \n",
       "39  ...   8.750995   2.696599   4.853239   5.843548   7.078466   8.430592   \n",
       "40  ...  17.885265   5.312920   9.667276  12.834445  14.787426  17.129389   \n",
       "41  ...  25.205109   6.630163  12.487499  17.367464  20.572191  23.661013   \n",
       "42  ...  33.253918   9.422367  17.129654  22.938807  27.674749  31.207392   \n",
       "43  ...  39.380211  11.225794  20.144056  26.246883  32.131622  36.278439   \n",
       "44  ...  43.815002  12.583164  21.162590  26.808037  33.058434  37.942703   \n",
       "45  ...  47.527428  12.252638  20.123070  25.582579  32.008797  37.813282   \n",
       "46  ...  50.767487  15.219469  26.853905  33.604534  40.203236  45.115681   \n",
       "47  ...  52.336914  15.201172  27.664463  34.931221  41.543274  46.576904   \n",
       "\n",
       "        M00.6      M00.7      M00.8      M00.9  \n",
       "0    3.022576   5.746896   6.427562  10.876079  \n",
       "1   10.988094  16.742872  18.460148  25.416058  \n",
       "2   14.467131  20.739613  22.330959  30.209188  \n",
       "3   22.880861  31.975574  36.150452  46.415920  \n",
       "4   24.169703  32.847008  36.482132  46.895279  \n",
       "5   30.598495  36.305202  37.333523  40.848919  \n",
       "6   32.735386  37.522675  38.003830  39.672966  \n",
       "7   36.419098  43.420963  46.874535  51.689362  \n",
       "8   33.451294  41.137058  45.712769  52.616653  \n",
       "9   32.443634  38.739780  43.119469  48.208645  \n",
       "10  34.105930  39.612999  42.696678  45.417057  \n",
       "11  30.901155  35.742340  39.410156  42.511856  \n",
       "12  29.564463  36.140732  42.907837  50.200787  \n",
       "13  26.014959  29.550989  32.987003  35.909557  \n",
       "14  26.252958  29.690475  32.779518  35.155376  \n",
       "15  22.179451  24.334892  26.449394  27.809347  \n",
       "16  19.549978  21.511440  24.072803  26.282967  \n",
       "17  13.270828  13.999071  15.685595  17.190290  \n",
       "18   9.231308  10.874598  13.524657  16.031055  \n",
       "19   1.519910   1.990139   2.151956   2.062776  \n",
       "20   6.369847   7.500924   8.008971   8.124584  \n",
       "21  14.823651  16.502480  16.413942  17.070805  \n",
       "22  22.940239  25.367527  24.350090  25.905735  \n",
       "23  29.828190  32.615334  31.043741  33.637703  \n",
       "24  35.951912  38.707848  37.523529  40.748180  \n",
       "25  40.622681  43.320438  42.592911  45.904675  \n",
       "26  44.404572  46.926956  46.717934  49.881439  \n",
       "27  46.763161  49.361698  49.220634  52.356319  \n",
       "28  47.504570  50.051456  50.204514  53.180050  \n",
       "29  47.026474  49.578156  49.716343  52.688320  \n",
       "30  44.775650  47.179844  47.505325  50.336075  \n",
       "31  41.614090  44.006359  44.118290  46.976162  \n",
       "32  37.063538  39.377338  39.243500  42.055561  \n",
       "33  31.844326  34.124058  33.557854  35.941757  \n",
       "34  24.945961  27.202299  26.751408  28.041607  \n",
       "35  17.924042  19.670921  19.398064  19.790562  \n",
       "36  10.136093  11.172242  11.213359  11.001766  \n",
       "37   3.046759   3.384630   3.494174   3.226869  \n",
       "38   1.149644   1.899064   1.940590   2.484862  \n",
       "39   8.103583   8.848512   8.873066   8.871959  \n",
       "40  16.120167  17.920708  17.645054  18.492777  \n",
       "41  23.134224  25.733986  24.849573  26.609905  \n",
       "42  30.465097  33.467827  32.167419  35.105759  \n",
       "43  36.225739  39.316746  38.710838  42.183563  \n",
       "44  39.327881  42.588108  42.918091  46.439999  \n",
       "45  41.512123  45.134731  46.614975  49.793106  \n",
       "46  46.274261  49.490059  50.328728  53.756237  \n",
       "47  48.014565  51.141140  52.160442  55.384090  \n",
       "\n",
       "[48 rows x 45 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_0[:48]#.to_csv('0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L10.1</th>\n",
       "      <th>L10.2</th>\n",
       "      <th>L10.3</th>\n",
       "      <th>L10.4</th>\n",
       "      <th>L10.5</th>\n",
       "      <th>L10.6</th>\n",
       "      <th>L10.7</th>\n",
       "      <th>L10.8</th>\n",
       "      <th>L10.9</th>\n",
       "      <th>D10.1</th>\n",
       "      <th>...</th>\n",
       "      <th>G10.9</th>\n",
       "      <th>M10.1</th>\n",
       "      <th>M10.2</th>\n",
       "      <th>M10.3</th>\n",
       "      <th>M10.4</th>\n",
       "      <th>M10.5</th>\n",
       "      <th>M10.6</th>\n",
       "      <th>M10.7</th>\n",
       "      <th>M10.8</th>\n",
       "      <th>M10.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.24</td>\n",
       "      <td>7.65</td>\n",
       "      <td>13.65</td>\n",
       "      <td>1.089914</td>\n",
       "      <td>...</td>\n",
       "      <td>9.617659</td>\n",
       "      <td>0.329373</td>\n",
       "      <td>1.272975</td>\n",
       "      <td>2.222000</td>\n",
       "      <td>3.875687</td>\n",
       "      <td>5.105513</td>\n",
       "      <td>5.777089</td>\n",
       "      <td>7.476045</td>\n",
       "      <td>10.104208</td>\n",
       "      <td>12.043563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.84</td>\n",
       "      <td>7.56</td>\n",
       "      <td>8.54</td>\n",
       "      <td>11.20</td>\n",
       "      <td>12.59</td>\n",
       "      <td>13.95</td>\n",
       "      <td>15.53</td>\n",
       "      <td>19.48</td>\n",
       "      <td>23.97</td>\n",
       "      <td>2.454007</td>\n",
       "      <td>...</td>\n",
       "      <td>20.866327</td>\n",
       "      <td>1.128118</td>\n",
       "      <td>3.202078</td>\n",
       "      <td>5.518090</td>\n",
       "      <td>9.725550</td>\n",
       "      <td>12.969010</td>\n",
       "      <td>15.099604</td>\n",
       "      <td>18.141224</td>\n",
       "      <td>22.504183</td>\n",
       "      <td>24.998043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.70</td>\n",
       "      <td>8.06</td>\n",
       "      <td>12.87</td>\n",
       "      <td>14.03</td>\n",
       "      <td>16.72</td>\n",
       "      <td>16.80</td>\n",
       "      <td>21.77</td>\n",
       "      <td>30.12</td>\n",
       "      <td>4.152181</td>\n",
       "      <td>...</td>\n",
       "      <td>25.929480</td>\n",
       "      <td>2.160001</td>\n",
       "      <td>5.547177</td>\n",
       "      <td>8.820875</td>\n",
       "      <td>13.377809</td>\n",
       "      <td>16.289724</td>\n",
       "      <td>18.242142</td>\n",
       "      <td>21.373890</td>\n",
       "      <td>25.896143</td>\n",
       "      <td>28.193527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.70</td>\n",
       "      <td>13.68</td>\n",
       "      <td>14.35</td>\n",
       "      <td>12.42</td>\n",
       "      <td>12.63</td>\n",
       "      <td>17.10</td>\n",
       "      <td>22.92</td>\n",
       "      <td>25.48</td>\n",
       "      <td>32.35</td>\n",
       "      <td>7.645403</td>\n",
       "      <td>...</td>\n",
       "      <td>38.971222</td>\n",
       "      <td>3.460238</td>\n",
       "      <td>8.663424</td>\n",
       "      <td>13.986403</td>\n",
       "      <td>20.827868</td>\n",
       "      <td>26.041220</td>\n",
       "      <td>29.857420</td>\n",
       "      <td>33.051517</td>\n",
       "      <td>39.212105</td>\n",
       "      <td>41.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.45</td>\n",
       "      <td>17.75</td>\n",
       "      <td>19.00</td>\n",
       "      <td>14.93</td>\n",
       "      <td>17.01</td>\n",
       "      <td>20.71</td>\n",
       "      <td>25.85</td>\n",
       "      <td>28.44</td>\n",
       "      <td>38.22</td>\n",
       "      <td>9.729984</td>\n",
       "      <td>...</td>\n",
       "      <td>38.998653</td>\n",
       "      <td>5.107563</td>\n",
       "      <td>11.910898</td>\n",
       "      <td>17.513607</td>\n",
       "      <td>23.314449</td>\n",
       "      <td>27.488192</td>\n",
       "      <td>30.451216</td>\n",
       "      <td>32.408348</td>\n",
       "      <td>37.889675</td>\n",
       "      <td>39.588684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.08</td>\n",
       "      <td>28.80</td>\n",
       "      <td>26.85</td>\n",
       "      <td>30.29</td>\n",
       "      <td>26.01</td>\n",
       "      <td>23.81</td>\n",
       "      <td>26.92</td>\n",
       "      <td>30.55</td>\n",
       "      <td>34.15</td>\n",
       "      <td>13.925003</td>\n",
       "      <td>...</td>\n",
       "      <td>36.662949</td>\n",
       "      <td>8.993871</td>\n",
       "      <td>18.460552</td>\n",
       "      <td>25.109615</td>\n",
       "      <td>26.833054</td>\n",
       "      <td>30.154135</td>\n",
       "      <td>33.465408</td>\n",
       "      <td>32.359592</td>\n",
       "      <td>35.644203</td>\n",
       "      <td>35.074295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.33</td>\n",
       "      <td>26.39</td>\n",
       "      <td>22.47</td>\n",
       "      <td>30.44</td>\n",
       "      <td>28.62</td>\n",
       "      <td>28.59</td>\n",
       "      <td>30.50</td>\n",
       "      <td>33.06</td>\n",
       "      <td>34.16</td>\n",
       "      <td>13.758869</td>\n",
       "      <td>...</td>\n",
       "      <td>37.442463</td>\n",
       "      <td>10.363093</td>\n",
       "      <td>19.981592</td>\n",
       "      <td>25.951077</td>\n",
       "      <td>25.325840</td>\n",
       "      <td>28.332447</td>\n",
       "      <td>33.150784</td>\n",
       "      <td>33.018898</td>\n",
       "      <td>35.123093</td>\n",
       "      <td>34.987961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.63</td>\n",
       "      <td>32.86</td>\n",
       "      <td>34.60</td>\n",
       "      <td>38.86</td>\n",
       "      <td>35.82</td>\n",
       "      <td>32.05</td>\n",
       "      <td>33.63</td>\n",
       "      <td>36.78</td>\n",
       "      <td>41.76</td>\n",
       "      <td>16.477924</td>\n",
       "      <td>...</td>\n",
       "      <td>46.160000</td>\n",
       "      <td>9.228159</td>\n",
       "      <td>19.322693</td>\n",
       "      <td>28.750477</td>\n",
       "      <td>31.273363</td>\n",
       "      <td>37.178356</td>\n",
       "      <td>42.135048</td>\n",
       "      <td>40.336819</td>\n",
       "      <td>47.014378</td>\n",
       "      <td>47.310070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.81</td>\n",
       "      <td>31.80</td>\n",
       "      <td>31.75</td>\n",
       "      <td>34.20</td>\n",
       "      <td>27.53</td>\n",
       "      <td>27.53</td>\n",
       "      <td>28.11</td>\n",
       "      <td>33.86</td>\n",
       "      <td>42.06</td>\n",
       "      <td>15.677671</td>\n",
       "      <td>...</td>\n",
       "      <td>46.159149</td>\n",
       "      <td>7.646490</td>\n",
       "      <td>16.922636</td>\n",
       "      <td>25.574295</td>\n",
       "      <td>30.638409</td>\n",
       "      <td>37.012051</td>\n",
       "      <td>41.465981</td>\n",
       "      <td>40.056301</td>\n",
       "      <td>47.252983</td>\n",
       "      <td>49.060436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.39</td>\n",
       "      <td>32.16</td>\n",
       "      <td>33.91</td>\n",
       "      <td>35.44</td>\n",
       "      <td>30.80</td>\n",
       "      <td>29.15</td>\n",
       "      <td>31.71</td>\n",
       "      <td>32.63</td>\n",
       "      <td>36.20</td>\n",
       "      <td>15.143011</td>\n",
       "      <td>...</td>\n",
       "      <td>43.475784</td>\n",
       "      <td>7.260803</td>\n",
       "      <td>16.316357</td>\n",
       "      <td>25.232349</td>\n",
       "      <td>29.263187</td>\n",
       "      <td>35.237740</td>\n",
       "      <td>39.583549</td>\n",
       "      <td>37.688423</td>\n",
       "      <td>44.847450</td>\n",
       "      <td>47.182415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.48</td>\n",
       "      <td>32.10</td>\n",
       "      <td>35.97</td>\n",
       "      <td>38.11</td>\n",
       "      <td>35.66</td>\n",
       "      <td>30.07</td>\n",
       "      <td>32.96</td>\n",
       "      <td>35.88</td>\n",
       "      <td>40.14</td>\n",
       "      <td>14.349978</td>\n",
       "      <td>...</td>\n",
       "      <td>40.346756</td>\n",
       "      <td>8.623682</td>\n",
       "      <td>18.128372</td>\n",
       "      <td>26.824112</td>\n",
       "      <td>27.669594</td>\n",
       "      <td>32.842304</td>\n",
       "      <td>38.008026</td>\n",
       "      <td>36.251068</td>\n",
       "      <td>42.364960</td>\n",
       "      <td>42.644188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.01</td>\n",
       "      <td>31.16</td>\n",
       "      <td>32.61</td>\n",
       "      <td>32.96</td>\n",
       "      <td>30.08</td>\n",
       "      <td>26.93</td>\n",
       "      <td>29.84</td>\n",
       "      <td>34.73</td>\n",
       "      <td>35.22</td>\n",
       "      <td>13.351130</td>\n",
       "      <td>...</td>\n",
       "      <td>39.820618</td>\n",
       "      <td>7.055909</td>\n",
       "      <td>15.890283</td>\n",
       "      <td>24.498707</td>\n",
       "      <td>26.466946</td>\n",
       "      <td>31.005896</td>\n",
       "      <td>35.155045</td>\n",
       "      <td>33.784100</td>\n",
       "      <td>40.154060</td>\n",
       "      <td>42.670391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.13</td>\n",
       "      <td>22.72</td>\n",
       "      <td>31.09</td>\n",
       "      <td>27.32</td>\n",
       "      <td>21.63</td>\n",
       "      <td>31.42</td>\n",
       "      <td>39.63</td>\n",
       "      <td>43.33</td>\n",
       "      <td>50.68</td>\n",
       "      <td>14.480780</td>\n",
       "      <td>...</td>\n",
       "      <td>49.869949</td>\n",
       "      <td>4.818467</td>\n",
       "      <td>12.408165</td>\n",
       "      <td>21.442879</td>\n",
       "      <td>28.834698</td>\n",
       "      <td>35.341663</td>\n",
       "      <td>39.490532</td>\n",
       "      <td>39.256622</td>\n",
       "      <td>46.276611</td>\n",
       "      <td>53.348797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.46</td>\n",
       "      <td>25.70</td>\n",
       "      <td>28.06</td>\n",
       "      <td>27.89</td>\n",
       "      <td>21.79</td>\n",
       "      <td>21.67</td>\n",
       "      <td>24.92</td>\n",
       "      <td>26.49</td>\n",
       "      <td>32.57</td>\n",
       "      <td>12.042791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.038448</td>\n",
       "      <td>5.374687</td>\n",
       "      <td>13.255543</td>\n",
       "      <td>21.458710</td>\n",
       "      <td>24.519558</td>\n",
       "      <td>27.360790</td>\n",
       "      <td>29.561419</td>\n",
       "      <td>29.029062</td>\n",
       "      <td>33.716805</td>\n",
       "      <td>37.098377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.57</td>\n",
       "      <td>28.26</td>\n",
       "      <td>29.63</td>\n",
       "      <td>29.51</td>\n",
       "      <td>23.79</td>\n",
       "      <td>24.61</td>\n",
       "      <td>26.87</td>\n",
       "      <td>30.76</td>\n",
       "      <td>32.48</td>\n",
       "      <td>11.698090</td>\n",
       "      <td>...</td>\n",
       "      <td>35.596138</td>\n",
       "      <td>5.834748</td>\n",
       "      <td>13.915159</td>\n",
       "      <td>21.748260</td>\n",
       "      <td>23.525955</td>\n",
       "      <td>26.235214</td>\n",
       "      <td>29.125406</td>\n",
       "      <td>28.764288</td>\n",
       "      <td>33.514393</td>\n",
       "      <td>36.397358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.89</td>\n",
       "      <td>20.62</td>\n",
       "      <td>26.83</td>\n",
       "      <td>23.85</td>\n",
       "      <td>20.28</td>\n",
       "      <td>20.27</td>\n",
       "      <td>23.67</td>\n",
       "      <td>23.65</td>\n",
       "      <td>30.46</td>\n",
       "      <td>9.471292</td>\n",
       "      <td>...</td>\n",
       "      <td>28.813011</td>\n",
       "      <td>5.123885</td>\n",
       "      <td>12.532187</td>\n",
       "      <td>18.985107</td>\n",
       "      <td>19.002716</td>\n",
       "      <td>20.060062</td>\n",
       "      <td>22.753223</td>\n",
       "      <td>23.539127</td>\n",
       "      <td>26.719624</td>\n",
       "      <td>28.793344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.40</td>\n",
       "      <td>13.89</td>\n",
       "      <td>15.98</td>\n",
       "      <td>14.03</td>\n",
       "      <td>13.04</td>\n",
       "      <td>15.75</td>\n",
       "      <td>17.92</td>\n",
       "      <td>18.60</td>\n",
       "      <td>23.82</td>\n",
       "      <td>8.851833</td>\n",
       "      <td>...</td>\n",
       "      <td>31.159916</td>\n",
       "      <td>3.545650</td>\n",
       "      <td>9.831881</td>\n",
       "      <td>17.147171</td>\n",
       "      <td>20.896095</td>\n",
       "      <td>21.645552</td>\n",
       "      <td>21.813242</td>\n",
       "      <td>22.039639</td>\n",
       "      <td>24.562485</td>\n",
       "      <td>27.073961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.25</td>\n",
       "      <td>7.79</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.09</td>\n",
       "      <td>5.92</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.74</td>\n",
       "      <td>5.95</td>\n",
       "      <td>19.56</td>\n",
       "      <td>4.846483</td>\n",
       "      <td>...</td>\n",
       "      <td>21.074026</td>\n",
       "      <td>1.775307</td>\n",
       "      <td>5.728541</td>\n",
       "      <td>11.096073</td>\n",
       "      <td>15.348503</td>\n",
       "      <td>14.934682</td>\n",
       "      <td>13.533899</td>\n",
       "      <td>13.992954</td>\n",
       "      <td>14.809423</td>\n",
       "      <td>16.402884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.99</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.02</td>\n",
       "      <td>5.89</td>\n",
       "      <td>6.35</td>\n",
       "      <td>7.38</td>\n",
       "      <td>16.96</td>\n",
       "      <td>3.616631</td>\n",
       "      <td>...</td>\n",
       "      <td>14.644279</td>\n",
       "      <td>0.603167</td>\n",
       "      <td>2.393660</td>\n",
       "      <td>4.965306</td>\n",
       "      <td>9.151805</td>\n",
       "      <td>10.362707</td>\n",
       "      <td>10.109591</td>\n",
       "      <td>11.294207</td>\n",
       "      <td>12.022629</td>\n",
       "      <td>15.502774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.866464</td>\n",
       "      <td>...</td>\n",
       "      <td>2.143718</td>\n",
       "      <td>0.281470</td>\n",
       "      <td>0.823242</td>\n",
       "      <td>1.040104</td>\n",
       "      <td>1.075293</td>\n",
       "      <td>1.254039</td>\n",
       "      <td>1.321184</td>\n",
       "      <td>1.716482</td>\n",
       "      <td>2.186939</td>\n",
       "      <td>2.399323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.77</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.21</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.92</td>\n",
       "      <td>7.31</td>\n",
       "      <td>3.013944</td>\n",
       "      <td>...</td>\n",
       "      <td>7.538638</td>\n",
       "      <td>1.152913</td>\n",
       "      <td>3.917951</td>\n",
       "      <td>5.252352</td>\n",
       "      <td>4.937126</td>\n",
       "      <td>4.952584</td>\n",
       "      <td>5.789088</td>\n",
       "      <td>6.475689</td>\n",
       "      <td>7.107688</td>\n",
       "      <td>7.609428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.38</td>\n",
       "      <td>7.75</td>\n",
       "      <td>12.02</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.60</td>\n",
       "      <td>13.55</td>\n",
       "      <td>14.47</td>\n",
       "      <td>14.69</td>\n",
       "      <td>15.12</td>\n",
       "      <td>5.145498</td>\n",
       "      <td>...</td>\n",
       "      <td>15.569941</td>\n",
       "      <td>3.284234</td>\n",
       "      <td>8.551517</td>\n",
       "      <td>10.521102</td>\n",
       "      <td>10.795098</td>\n",
       "      <td>11.350263</td>\n",
       "      <td>13.735605</td>\n",
       "      <td>14.734819</td>\n",
       "      <td>15.409781</td>\n",
       "      <td>15.983940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.96</td>\n",
       "      <td>15.24</td>\n",
       "      <td>16.33</td>\n",
       "      <td>19.96</td>\n",
       "      <td>20.44</td>\n",
       "      <td>20.83</td>\n",
       "      <td>21.77</td>\n",
       "      <td>22.90</td>\n",
       "      <td>22.90</td>\n",
       "      <td>8.716177</td>\n",
       "      <td>...</td>\n",
       "      <td>23.685423</td>\n",
       "      <td>5.160917</td>\n",
       "      <td>12.510571</td>\n",
       "      <td>16.202187</td>\n",
       "      <td>17.685925</td>\n",
       "      <td>18.315889</td>\n",
       "      <td>21.489733</td>\n",
       "      <td>22.719061</td>\n",
       "      <td>23.122620</td>\n",
       "      <td>23.843927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.91</td>\n",
       "      <td>20.67</td>\n",
       "      <td>21.53</td>\n",
       "      <td>25.54</td>\n",
       "      <td>28.95</td>\n",
       "      <td>28.02</td>\n",
       "      <td>27.94</td>\n",
       "      <td>28.91</td>\n",
       "      <td>30.66</td>\n",
       "      <td>12.321924</td>\n",
       "      <td>...</td>\n",
       "      <td>30.588705</td>\n",
       "      <td>7.674736</td>\n",
       "      <td>16.499916</td>\n",
       "      <td>21.969456</td>\n",
       "      <td>24.284307</td>\n",
       "      <td>24.846094</td>\n",
       "      <td>27.991297</td>\n",
       "      <td>29.579254</td>\n",
       "      <td>29.559549</td>\n",
       "      <td>30.446499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17.43</td>\n",
       "      <td>18.60</td>\n",
       "      <td>23.80</td>\n",
       "      <td>25.96</td>\n",
       "      <td>33.75</td>\n",
       "      <td>32.49</td>\n",
       "      <td>34.79</td>\n",
       "      <td>35.18</td>\n",
       "      <td>36.52</td>\n",
       "      <td>14.460339</td>\n",
       "      <td>...</td>\n",
       "      <td>36.885361</td>\n",
       "      <td>9.290116</td>\n",
       "      <td>18.970642</td>\n",
       "      <td>26.583889</td>\n",
       "      <td>29.456167</td>\n",
       "      <td>30.375208</td>\n",
       "      <td>33.649197</td>\n",
       "      <td>35.647919</td>\n",
       "      <td>35.563564</td>\n",
       "      <td>36.364796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15.81</td>\n",
       "      <td>22.40</td>\n",
       "      <td>25.83</td>\n",
       "      <td>29.35</td>\n",
       "      <td>36.73</td>\n",
       "      <td>35.60</td>\n",
       "      <td>38.80</td>\n",
       "      <td>40.25</td>\n",
       "      <td>40.68</td>\n",
       "      <td>16.315401</td>\n",
       "      <td>...</td>\n",
       "      <td>42.073997</td>\n",
       "      <td>11.409750</td>\n",
       "      <td>21.657230</td>\n",
       "      <td>30.451183</td>\n",
       "      <td>34.004562</td>\n",
       "      <td>35.169323</td>\n",
       "      <td>38.207138</td>\n",
       "      <td>40.444073</td>\n",
       "      <td>40.758240</td>\n",
       "      <td>41.143299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21.26</td>\n",
       "      <td>28.23</td>\n",
       "      <td>24.88</td>\n",
       "      <td>25.67</td>\n",
       "      <td>25.76</td>\n",
       "      <td>30.86</td>\n",
       "      <td>38.04</td>\n",
       "      <td>42.85</td>\n",
       "      <td>43.80</td>\n",
       "      <td>17.144218</td>\n",
       "      <td>...</td>\n",
       "      <td>46.211315</td>\n",
       "      <td>12.049514</td>\n",
       "      <td>23.038967</td>\n",
       "      <td>32.320526</td>\n",
       "      <td>36.200386</td>\n",
       "      <td>38.802258</td>\n",
       "      <td>41.891666</td>\n",
       "      <td>44.190384</td>\n",
       "      <td>45.158058</td>\n",
       "      <td>45.590725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22.03</td>\n",
       "      <td>31.71</td>\n",
       "      <td>29.19</td>\n",
       "      <td>30.21</td>\n",
       "      <td>31.31</td>\n",
       "      <td>33.62</td>\n",
       "      <td>38.02</td>\n",
       "      <td>43.82</td>\n",
       "      <td>45.73</td>\n",
       "      <td>18.011995</td>\n",
       "      <td>...</td>\n",
       "      <td>48.538223</td>\n",
       "      <td>13.091581</td>\n",
       "      <td>24.929039</td>\n",
       "      <td>33.709274</td>\n",
       "      <td>37.873466</td>\n",
       "      <td>41.146801</td>\n",
       "      <td>44.239017</td>\n",
       "      <td>46.758072</td>\n",
       "      <td>47.606224</td>\n",
       "      <td>47.952175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22.00</td>\n",
       "      <td>32.56</td>\n",
       "      <td>27.35</td>\n",
       "      <td>30.65</td>\n",
       "      <td>33.70</td>\n",
       "      <td>37.12</td>\n",
       "      <td>41.10</td>\n",
       "      <td>46.73</td>\n",
       "      <td>48.88</td>\n",
       "      <td>17.827007</td>\n",
       "      <td>...</td>\n",
       "      <td>49.593658</td>\n",
       "      <td>12.376309</td>\n",
       "      <td>23.827412</td>\n",
       "      <td>33.132587</td>\n",
       "      <td>37.094582</td>\n",
       "      <td>41.094158</td>\n",
       "      <td>45.106354</td>\n",
       "      <td>47.482559</td>\n",
       "      <td>48.801617</td>\n",
       "      <td>49.283482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.27</td>\n",
       "      <td>27.40</td>\n",
       "      <td>26.75</td>\n",
       "      <td>30.04</td>\n",
       "      <td>29.45</td>\n",
       "      <td>35.11</td>\n",
       "      <td>39.92</td>\n",
       "      <td>44.32</td>\n",
       "      <td>46.44</td>\n",
       "      <td>17.671438</td>\n",
       "      <td>...</td>\n",
       "      <td>49.133965</td>\n",
       "      <td>12.145629</td>\n",
       "      <td>23.385645</td>\n",
       "      <td>32.808437</td>\n",
       "      <td>36.664574</td>\n",
       "      <td>40.496777</td>\n",
       "      <td>44.545433</td>\n",
       "      <td>46.895962</td>\n",
       "      <td>48.306332</td>\n",
       "      <td>48.823807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.36</td>\n",
       "      <td>24.51</td>\n",
       "      <td>28.28</td>\n",
       "      <td>31.83</td>\n",
       "      <td>30.84</td>\n",
       "      <td>36.56</td>\n",
       "      <td>41.49</td>\n",
       "      <td>43.48</td>\n",
       "      <td>44.92</td>\n",
       "      <td>16.460413</td>\n",
       "      <td>...</td>\n",
       "      <td>47.229134</td>\n",
       "      <td>10.337456</td>\n",
       "      <td>20.982071</td>\n",
       "      <td>30.661556</td>\n",
       "      <td>33.958252</td>\n",
       "      <td>37.751331</td>\n",
       "      <td>42.337639</td>\n",
       "      <td>44.389053</td>\n",
       "      <td>46.371582</td>\n",
       "      <td>47.246319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13.02</td>\n",
       "      <td>18.89</td>\n",
       "      <td>26.87</td>\n",
       "      <td>29.48</td>\n",
       "      <td>35.25</td>\n",
       "      <td>36.42</td>\n",
       "      <td>40.61</td>\n",
       "      <td>41.84</td>\n",
       "      <td>43.60</td>\n",
       "      <td>15.189924</td>\n",
       "      <td>...</td>\n",
       "      <td>43.945312</td>\n",
       "      <td>9.023592</td>\n",
       "      <td>19.602280</td>\n",
       "      <td>28.647999</td>\n",
       "      <td>31.638607</td>\n",
       "      <td>34.943623</td>\n",
       "      <td>39.253651</td>\n",
       "      <td>41.278557</td>\n",
       "      <td>42.940140</td>\n",
       "      <td>43.961697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11.26</td>\n",
       "      <td>15.59</td>\n",
       "      <td>27.57</td>\n",
       "      <td>28.44</td>\n",
       "      <td>31.57</td>\n",
       "      <td>31.63</td>\n",
       "      <td>36.37</td>\n",
       "      <td>37.07</td>\n",
       "      <td>38.11</td>\n",
       "      <td>12.523960</td>\n",
       "      <td>...</td>\n",
       "      <td>39.200451</td>\n",
       "      <td>6.627160</td>\n",
       "      <td>17.230516</td>\n",
       "      <td>24.512157</td>\n",
       "      <td>27.162472</td>\n",
       "      <td>30.440798</td>\n",
       "      <td>35.004349</td>\n",
       "      <td>36.729576</td>\n",
       "      <td>37.935066</td>\n",
       "      <td>39.221050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.90</td>\n",
       "      <td>15.70</td>\n",
       "      <td>26.92</td>\n",
       "      <td>21.42</td>\n",
       "      <td>29.22</td>\n",
       "      <td>29.51</td>\n",
       "      <td>31.08</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.98</td>\n",
       "      <td>10.059118</td>\n",
       "      <td>...</td>\n",
       "      <td>33.135654</td>\n",
       "      <td>4.894801</td>\n",
       "      <td>14.552773</td>\n",
       "      <td>20.358345</td>\n",
       "      <td>22.927216</td>\n",
       "      <td>25.654211</td>\n",
       "      <td>29.876604</td>\n",
       "      <td>31.200211</td>\n",
       "      <td>32.052986</td>\n",
       "      <td>33.203243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7.76</td>\n",
       "      <td>13.17</td>\n",
       "      <td>16.99</td>\n",
       "      <td>19.82</td>\n",
       "      <td>22.65</td>\n",
       "      <td>24.78</td>\n",
       "      <td>24.62</td>\n",
       "      <td>25.14</td>\n",
       "      <td>25.97</td>\n",
       "      <td>6.513051</td>\n",
       "      <td>...</td>\n",
       "      <td>26.168776</td>\n",
       "      <td>2.989256</td>\n",
       "      <td>10.662262</td>\n",
       "      <td>14.695687</td>\n",
       "      <td>16.920227</td>\n",
       "      <td>19.461119</td>\n",
       "      <td>23.344776</td>\n",
       "      <td>24.467306</td>\n",
       "      <td>25.432434</td>\n",
       "      <td>26.377892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.68</td>\n",
       "      <td>8.31</td>\n",
       "      <td>12.89</td>\n",
       "      <td>14.46</td>\n",
       "      <td>15.21</td>\n",
       "      <td>15.84</td>\n",
       "      <td>17.08</td>\n",
       "      <td>17.28</td>\n",
       "      <td>18.61</td>\n",
       "      <td>4.290338</td>\n",
       "      <td>...</td>\n",
       "      <td>18.929718</td>\n",
       "      <td>1.914944</td>\n",
       "      <td>7.749857</td>\n",
       "      <td>10.220388</td>\n",
       "      <td>11.601554</td>\n",
       "      <td>13.405719</td>\n",
       "      <td>16.385185</td>\n",
       "      <td>17.604626</td>\n",
       "      <td>18.383070</td>\n",
       "      <td>18.935654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8.62</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.84</td>\n",
       "      <td>8.84</td>\n",
       "      <td>9.06</td>\n",
       "      <td>8.43</td>\n",
       "      <td>8.23</td>\n",
       "      <td>9.62</td>\n",
       "      <td>9.47</td>\n",
       "      <td>2.914204</td>\n",
       "      <td>...</td>\n",
       "      <td>10.889780</td>\n",
       "      <td>1.031875</td>\n",
       "      <td>5.036841</td>\n",
       "      <td>6.353527</td>\n",
       "      <td>6.720687</td>\n",
       "      <td>7.563734</td>\n",
       "      <td>8.989182</td>\n",
       "      <td>9.952747</td>\n",
       "      <td>10.423515</td>\n",
       "      <td>10.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.88</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.83</td>\n",
       "      <td>4.24</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1.145520</td>\n",
       "      <td>...</td>\n",
       "      <td>3.699688</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>1.992132</td>\n",
       "      <td>2.781004</td>\n",
       "      <td>3.468869</td>\n",
       "      <td>3.374558</td>\n",
       "      <td>3.078406</td>\n",
       "      <td>3.169029</td>\n",
       "      <td>3.317488</td>\n",
       "      <td>3.489783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.289500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.049698</td>\n",
       "      <td>0.406368</td>\n",
       "      <td>1.335016</td>\n",
       "      <td>1.928913</td>\n",
       "      <td>2.318510</td>\n",
       "      <td>2.177904</td>\n",
       "      <td>1.495453</td>\n",
       "      <td>1.872091</td>\n",
       "      <td>2.283284</td>\n",
       "      <td>2.301525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.29</td>\n",
       "      <td>3.73</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.83</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.49</td>\n",
       "      <td>8.08</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.79</td>\n",
       "      <td>2.512574</td>\n",
       "      <td>...</td>\n",
       "      <td>8.502715</td>\n",
       "      <td>1.864749</td>\n",
       "      <td>4.283177</td>\n",
       "      <td>5.349444</td>\n",
       "      <td>6.777020</td>\n",
       "      <td>7.233482</td>\n",
       "      <td>7.760514</td>\n",
       "      <td>8.442198</td>\n",
       "      <td>8.987455</td>\n",
       "      <td>9.143443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.04</td>\n",
       "      <td>8.84</td>\n",
       "      <td>13.95</td>\n",
       "      <td>14.75</td>\n",
       "      <td>16.22</td>\n",
       "      <td>16.69</td>\n",
       "      <td>17.19</td>\n",
       "      <td>17.47</td>\n",
       "      <td>17.50</td>\n",
       "      <td>5.288871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.503077</td>\n",
       "      <td>3.759428</td>\n",
       "      <td>9.304890</td>\n",
       "      <td>11.806891</td>\n",
       "      <td>12.731577</td>\n",
       "      <td>13.249283</td>\n",
       "      <td>15.654570</td>\n",
       "      <td>16.638840</td>\n",
       "      <td>17.251490</td>\n",
       "      <td>17.565552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.68</td>\n",
       "      <td>13.32</td>\n",
       "      <td>18.85</td>\n",
       "      <td>21.34</td>\n",
       "      <td>22.22</td>\n",
       "      <td>23.12</td>\n",
       "      <td>23.77</td>\n",
       "      <td>24.55</td>\n",
       "      <td>24.52</td>\n",
       "      <td>7.950894</td>\n",
       "      <td>...</td>\n",
       "      <td>24.808882</td>\n",
       "      <td>5.332939</td>\n",
       "      <td>12.702641</td>\n",
       "      <td>16.854210</td>\n",
       "      <td>18.760006</td>\n",
       "      <td>19.594412</td>\n",
       "      <td>22.873831</td>\n",
       "      <td>24.181030</td>\n",
       "      <td>24.577845</td>\n",
       "      <td>25.081758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.50</td>\n",
       "      <td>16.62</td>\n",
       "      <td>23.12</td>\n",
       "      <td>27.73</td>\n",
       "      <td>29.46</td>\n",
       "      <td>29.94</td>\n",
       "      <td>31.29</td>\n",
       "      <td>32.87</td>\n",
       "      <td>32.79</td>\n",
       "      <td>12.124215</td>\n",
       "      <td>...</td>\n",
       "      <td>32.502899</td>\n",
       "      <td>7.741753</td>\n",
       "      <td>16.682230</td>\n",
       "      <td>22.602509</td>\n",
       "      <td>25.337088</td>\n",
       "      <td>26.318483</td>\n",
       "      <td>29.746508</td>\n",
       "      <td>31.490782</td>\n",
       "      <td>31.526134</td>\n",
       "      <td>32.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13.97</td>\n",
       "      <td>23.69</td>\n",
       "      <td>28.18</td>\n",
       "      <td>30.94</td>\n",
       "      <td>34.79</td>\n",
       "      <td>36.23</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.54</td>\n",
       "      <td>37.60</td>\n",
       "      <td>14.166721</td>\n",
       "      <td>...</td>\n",
       "      <td>38.818054</td>\n",
       "      <td>9.150582</td>\n",
       "      <td>18.826040</td>\n",
       "      <td>26.777004</td>\n",
       "      <td>30.070261</td>\n",
       "      <td>31.563866</td>\n",
       "      <td>35.334244</td>\n",
       "      <td>37.491241</td>\n",
       "      <td>37.945538</td>\n",
       "      <td>38.432404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>18.60</td>\n",
       "      <td>25.02</td>\n",
       "      <td>32.07</td>\n",
       "      <td>34.73</td>\n",
       "      <td>37.58</td>\n",
       "      <td>42.45</td>\n",
       "      <td>44.85</td>\n",
       "      <td>45.31</td>\n",
       "      <td>44.62</td>\n",
       "      <td>14.067751</td>\n",
       "      <td>...</td>\n",
       "      <td>43.381569</td>\n",
       "      <td>10.473228</td>\n",
       "      <td>20.132496</td>\n",
       "      <td>29.397827</td>\n",
       "      <td>33.441124</td>\n",
       "      <td>35.708488</td>\n",
       "      <td>39.355759</td>\n",
       "      <td>41.478828</td>\n",
       "      <td>42.847137</td>\n",
       "      <td>43.074329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>14.39</td>\n",
       "      <td>25.44</td>\n",
       "      <td>32.47</td>\n",
       "      <td>37.51</td>\n",
       "      <td>40.66</td>\n",
       "      <td>43.06</td>\n",
       "      <td>46.19</td>\n",
       "      <td>46.57</td>\n",
       "      <td>46.66</td>\n",
       "      <td>13.036249</td>\n",
       "      <td>...</td>\n",
       "      <td>46.934570</td>\n",
       "      <td>10.391986</td>\n",
       "      <td>20.190556</td>\n",
       "      <td>29.753010</td>\n",
       "      <td>34.221390</td>\n",
       "      <td>38.250462</td>\n",
       "      <td>42.568192</td>\n",
       "      <td>44.442184</td>\n",
       "      <td>46.704884</td>\n",
       "      <td>47.349155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19.41</td>\n",
       "      <td>29.93</td>\n",
       "      <td>38.53</td>\n",
       "      <td>42.26</td>\n",
       "      <td>45.78</td>\n",
       "      <td>46.49</td>\n",
       "      <td>47.02</td>\n",
       "      <td>48.59</td>\n",
       "      <td>50.05</td>\n",
       "      <td>16.994919</td>\n",
       "      <td>...</td>\n",
       "      <td>50.315735</td>\n",
       "      <td>12.269210</td>\n",
       "      <td>23.013144</td>\n",
       "      <td>33.011841</td>\n",
       "      <td>37.657852</td>\n",
       "      <td>41.880318</td>\n",
       "      <td>45.931225</td>\n",
       "      <td>48.533688</td>\n",
       "      <td>49.954475</td>\n",
       "      <td>50.238041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20.72</td>\n",
       "      <td>32.24</td>\n",
       "      <td>39.67</td>\n",
       "      <td>43.87</td>\n",
       "      <td>44.40</td>\n",
       "      <td>47.57</td>\n",
       "      <td>49.76</td>\n",
       "      <td>50.98</td>\n",
       "      <td>51.73</td>\n",
       "      <td>17.576097</td>\n",
       "      <td>...</td>\n",
       "      <td>51.923138</td>\n",
       "      <td>12.090740</td>\n",
       "      <td>23.145559</td>\n",
       "      <td>33.233517</td>\n",
       "      <td>37.714043</td>\n",
       "      <td>42.672626</td>\n",
       "      <td>47.496857</td>\n",
       "      <td>50.094948</td>\n",
       "      <td>51.758480</td>\n",
       "      <td>52.188717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L10.1  L10.2  L10.3  L10.4  L10.5  L10.6  L10.7  L10.8  L10.9      D10.1  \\\n",
       "0    0.92   1.35   1.73   2.79   2.96   2.62   3.24   7.65  13.65   1.089914   \n",
       "1    4.84   7.56   8.54  11.20  12.59  13.95  15.53  19.48  23.97   2.454007   \n",
       "2    4.69   7.70   8.06  12.87  14.03  16.72  16.80  21.77  30.12   4.152181   \n",
       "3    8.70  13.68  14.35  12.42  12.63  17.10  22.92  25.48  32.35   7.645403   \n",
       "4    9.45  17.75  19.00  14.93  17.01  20.71  25.85  28.44  38.22   9.729984   \n",
       "5   18.08  28.80  26.85  30.29  26.01  23.81  26.92  30.55  34.15  13.925003   \n",
       "6   19.33  26.39  22.47  30.44  28.62  28.59  30.50  33.06  34.16  13.758869   \n",
       "7   22.63  32.86  34.60  38.86  35.82  32.05  33.63  36.78  41.76  16.477924   \n",
       "8   21.81  31.80  31.75  34.20  27.53  27.53  28.11  33.86  42.06  15.677671   \n",
       "9   22.39  32.16  33.91  35.44  30.80  29.15  31.71  32.63  36.20  15.143011   \n",
       "10  22.48  32.10  35.97  38.11  35.66  30.07  32.96  35.88  40.14  14.349978   \n",
       "11  20.01  31.16  32.61  32.96  30.08  26.93  29.84  34.73  35.22  13.351130   \n",
       "12  13.13  22.72  31.09  27.32  21.63  31.42  39.63  43.33  50.68  14.480780   \n",
       "13  18.46  25.70  28.06  27.89  21.79  21.67  24.92  26.49  32.57  12.042791   \n",
       "14  17.57  28.26  29.63  29.51  23.79  24.61  26.87  30.76  32.48  11.698090   \n",
       "15  13.89  20.62  26.83  23.85  20.28  20.27  23.67  23.65  30.46   9.471292   \n",
       "16   9.40  13.89  15.98  14.03  13.04  15.75  17.92  18.60  23.82   8.851833   \n",
       "17   4.25   7.79   8.49   8.09   5.92   6.12   6.74   5.95  19.56   4.846483   \n",
       "18   1.99   1.69   2.97   3.30   2.02   5.89   6.35   7.38  16.96   3.616631   \n",
       "19   0.34   0.95   0.71   0.49   1.80   2.68   2.51   1.92   2.09   0.866464   \n",
       "20   2.77   3.55   4.95   5.75   5.04   5.21   6.59   6.92   7.31   3.013944   \n",
       "21   6.38   7.75  12.02  12.55  12.60  13.55  14.47  14.69  15.12   5.145498   \n",
       "22  11.96  15.24  16.33  19.96  20.44  20.83  21.77  22.90  22.90   8.716177   \n",
       "23  10.91  20.67  21.53  25.54  28.95  28.02  27.94  28.91  30.66  12.321924   \n",
       "24  17.43  18.60  23.80  25.96  33.75  32.49  34.79  35.18  36.52  14.460339   \n",
       "25  15.81  22.40  25.83  29.35  36.73  35.60  38.80  40.25  40.68  16.315401   \n",
       "26  21.26  28.23  24.88  25.67  25.76  30.86  38.04  42.85  43.80  17.144218   \n",
       "27  22.03  31.71  29.19  30.21  31.31  33.62  38.02  43.82  45.73  18.011995   \n",
       "28  22.00  32.56  27.35  30.65  33.70  37.12  41.10  46.73  48.88  17.827007   \n",
       "29  19.27  27.40  26.75  30.04  29.45  35.11  39.92  44.32  46.44  17.671438   \n",
       "30  15.36  24.51  28.28  31.83  30.84  36.56  41.49  43.48  44.92  16.460413   \n",
       "31  13.02  18.89  26.87  29.48  35.25  36.42  40.61  41.84  43.60  15.189924   \n",
       "32  11.26  15.59  27.57  28.44  31.57  31.63  36.37  37.07  38.11  12.523960   \n",
       "33  12.90  15.70  26.92  21.42  29.22  29.51  31.08  31.76  32.98  10.059118   \n",
       "34   7.76  13.17  16.99  19.82  22.65  24.78  24.62  25.14  25.97   6.513051   \n",
       "35   5.68   8.31  12.89  14.46  15.21  15.84  17.08  17.28  18.61   4.290338   \n",
       "36   8.62   7.44   7.84   8.84   9.06   8.43   8.23   9.62   9.47   2.914204   \n",
       "37   3.88   1.33   2.09   3.83   4.24   3.23   2.57   3.06   2.81   1.145520   \n",
       "38   0.30   0.63   1.03   0.50   1.37   1.19   1.19   1.53   2.29   1.289500   \n",
       "39   2.29   3.73   5.13   5.83   7.20   7.49   8.08   8.44   8.79   2.512574   \n",
       "40   6.04   8.84  13.95  14.75  16.22  16.69  17.19  17.47  17.50   5.288871   \n",
       "41   8.68  13.32  18.85  21.34  22.22  23.12  23.77  24.55  24.52   7.950894   \n",
       "42  10.50  16.62  23.12  27.73  29.46  29.94  31.29  32.87  32.79  12.124215   \n",
       "43  13.97  23.69  28.18  30.94  34.79  36.23  37.51  37.54  37.60  14.166721   \n",
       "44  18.60  25.02  32.07  34.73  37.58  42.45  44.85  45.31  44.62  14.067751   \n",
       "45  14.39  25.44  32.47  37.51  40.66  43.06  46.19  46.57  46.66  13.036249   \n",
       "46  19.41  29.93  38.53  42.26  45.78  46.49  47.02  48.59  50.05  16.994919   \n",
       "47  20.72  32.24  39.67  43.87  44.40  47.57  49.76  50.98  51.73  17.576097   \n",
       "\n",
       "    ...      G10.9      M10.1      M10.2      M10.3      M10.4      M10.5  \\\n",
       "0   ...   9.617659   0.329373   1.272975   2.222000   3.875687   5.105513   \n",
       "1   ...  20.866327   1.128118   3.202078   5.518090   9.725550  12.969010   \n",
       "2   ...  25.929480   2.160001   5.547177   8.820875  13.377809  16.289724   \n",
       "3   ...  38.971222   3.460238   8.663424  13.986403  20.827868  26.041220   \n",
       "4   ...  38.998653   5.107563  11.910898  17.513607  23.314449  27.488192   \n",
       "5   ...  36.662949   8.993871  18.460552  25.109615  26.833054  30.154135   \n",
       "6   ...  37.442463  10.363093  19.981592  25.951077  25.325840  28.332447   \n",
       "7   ...  46.160000   9.228159  19.322693  28.750477  31.273363  37.178356   \n",
       "8   ...  46.159149   7.646490  16.922636  25.574295  30.638409  37.012051   \n",
       "9   ...  43.475784   7.260803  16.316357  25.232349  29.263187  35.237740   \n",
       "10  ...  40.346756   8.623682  18.128372  26.824112  27.669594  32.842304   \n",
       "11  ...  39.820618   7.055909  15.890283  24.498707  26.466946  31.005896   \n",
       "12  ...  49.869949   4.818467  12.408165  21.442879  28.834698  35.341663   \n",
       "13  ...  38.038448   5.374687  13.255543  21.458710  24.519558  27.360790   \n",
       "14  ...  35.596138   5.834748  13.915159  21.748260  23.525955  26.235214   \n",
       "15  ...  28.813011   5.123885  12.532187  18.985107  19.002716  20.060062   \n",
       "16  ...  31.159916   3.545650   9.831881  17.147171  20.896095  21.645552   \n",
       "17  ...  21.074026   1.775307   5.728541  11.096073  15.348503  14.934682   \n",
       "18  ...  14.644279   0.603167   2.393660   4.965306   9.151805  10.362707   \n",
       "19  ...   2.143718   0.281470   0.823242   1.040104   1.075293   1.254039   \n",
       "20  ...   7.538638   1.152913   3.917951   5.252352   4.937126   4.952584   \n",
       "21  ...  15.569941   3.284234   8.551517  10.521102  10.795098  11.350263   \n",
       "22  ...  23.685423   5.160917  12.510571  16.202187  17.685925  18.315889   \n",
       "23  ...  30.588705   7.674736  16.499916  21.969456  24.284307  24.846094   \n",
       "24  ...  36.885361   9.290116  18.970642  26.583889  29.456167  30.375208   \n",
       "25  ...  42.073997  11.409750  21.657230  30.451183  34.004562  35.169323   \n",
       "26  ...  46.211315  12.049514  23.038967  32.320526  36.200386  38.802258   \n",
       "27  ...  48.538223  13.091581  24.929039  33.709274  37.873466  41.146801   \n",
       "28  ...  49.593658  12.376309  23.827412  33.132587  37.094582  41.094158   \n",
       "29  ...  49.133965  12.145629  23.385645  32.808437  36.664574  40.496777   \n",
       "30  ...  47.229134  10.337456  20.982071  30.661556  33.958252  37.751331   \n",
       "31  ...  43.945312   9.023592  19.602280  28.647999  31.638607  34.943623   \n",
       "32  ...  39.200451   6.627160  17.230516  24.512157  27.162472  30.440798   \n",
       "33  ...  33.135654   4.894801  14.552773  20.358345  22.927216  25.654211   \n",
       "34  ...  26.168776   2.989256  10.662262  14.695687  16.920227  19.461119   \n",
       "35  ...  18.929718   1.914944   7.749857  10.220388  11.601554  13.405719   \n",
       "36  ...  10.889780   1.031875   5.036841   6.353527   6.720687   7.563734   \n",
       "37  ...   3.699688   0.350504   1.992132   2.781004   3.468869   3.374558   \n",
       "38  ...   3.049698   0.406368   1.335016   1.928913   2.318510   2.177904   \n",
       "39  ...   8.502715   1.864749   4.283177   5.349444   6.777020   7.233482   \n",
       "40  ...  17.503077   3.759428   9.304890  11.806891  12.731577  13.249283   \n",
       "41  ...  24.808882   5.332939  12.702641  16.854210  18.760006  19.594412   \n",
       "42  ...  32.502899   7.741753  16.682230  22.602509  25.337088  26.318483   \n",
       "43  ...  38.818054   9.150582  18.826040  26.777004  30.070261  31.563866   \n",
       "44  ...  43.381569  10.473228  20.132496  29.397827  33.441124  35.708488   \n",
       "45  ...  46.934570  10.391986  20.190556  29.753010  34.221390  38.250462   \n",
       "46  ...  50.315735  12.269210  23.013144  33.011841  37.657852  41.880318   \n",
       "47  ...  51.923138  12.090740  23.145559  33.233517  37.714043  42.672626   \n",
       "\n",
       "        M10.6      M10.7      M10.8      M10.9  \n",
       "0    5.777089   7.476045  10.104208  12.043563  \n",
       "1   15.099604  18.141224  22.504183  24.998043  \n",
       "2   18.242142  21.373890  25.896143  28.193527  \n",
       "3   29.857420  33.051517  39.212105  41.550571  \n",
       "4   30.451216  32.408348  37.889675  39.588684  \n",
       "5   33.465408  32.359592  35.644203  35.074295  \n",
       "6   33.150784  33.018898  35.123093  34.987961  \n",
       "7   42.135048  40.336819  47.014378  47.310070  \n",
       "8   41.465981  40.056301  47.252983  49.060436  \n",
       "9   39.583549  37.688423  44.847450  47.182415  \n",
       "10  38.008026  36.251068  42.364960  42.644188  \n",
       "11  35.155045  33.784100  40.154060  42.670391  \n",
       "12  39.490532  39.256622  46.276611  53.348797  \n",
       "13  29.561419  29.029062  33.716805  37.098377  \n",
       "14  29.125406  28.764288  33.514393  36.397358  \n",
       "15  22.753223  23.539127  26.719624  28.793344  \n",
       "16  21.813242  22.039639  24.562485  27.073961  \n",
       "17  13.533899  13.992954  14.809423  16.402884  \n",
       "18  10.109591  11.294207  12.022629  15.502774  \n",
       "19   1.321184   1.716482   2.186939   2.399323  \n",
       "20   5.789088   6.475689   7.107688   7.609428  \n",
       "21  13.735605  14.734819  15.409781  15.983940  \n",
       "22  21.489733  22.719061  23.122620  23.843927  \n",
       "23  27.991297  29.579254  29.559549  30.446499  \n",
       "24  33.649197  35.647919  35.563564  36.364796  \n",
       "25  38.207138  40.444073  40.758240  41.143299  \n",
       "26  41.891666  44.190384  45.158058  45.590725  \n",
       "27  44.239017  46.758072  47.606224  47.952175  \n",
       "28  45.106354  47.482559  48.801617  49.283482  \n",
       "29  44.545433  46.895962  48.306332  48.823807  \n",
       "30  42.337639  44.389053  46.371582  47.246319  \n",
       "31  39.253651  41.278557  42.940140  43.961697  \n",
       "32  35.004349  36.729576  37.935066  39.221050  \n",
       "33  29.876604  31.200211  32.052986  33.203243  \n",
       "34  23.344776  24.467306  25.432434  26.377892  \n",
       "35  16.385185  17.604626  18.383070  18.935654  \n",
       "36   8.989182   9.952747  10.423515  10.441300  \n",
       "37   3.078406   3.169029   3.317488   3.489783  \n",
       "38   1.495453   1.872091   2.283284   2.301525  \n",
       "39   7.760514   8.442198   8.987455   9.143443  \n",
       "40  15.654570  16.638840  17.251490  17.565552  \n",
       "41  22.873831  24.181030  24.577845  25.081758  \n",
       "42  29.746508  31.490782  31.526134  32.296700  \n",
       "43  35.334244  37.491241  37.945538  38.432404  \n",
       "44  39.355759  41.478828  42.847137  43.074329  \n",
       "45  42.568192  44.442184  46.704884  47.349155  \n",
       "46  45.931225  48.533688  49.954475  50.238041  \n",
       "47  47.496857  50.094948  51.758480  52.188717  \n",
       "\n",
       "[48 rows x 45 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1[:48]#.to_csv('0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    res_0[\"L00.\"+str(i)] = (res_0[\"L00.\"+str(i)] + res_0[\"D00.\"+str(i)] + res_0[\"C00.\"+str(i)] + res_0[\"G00.\"+str(i)] + res_0[\"M00.\"+str(i)])/5\n",
    "    res_1[\"L10.\"+str(i)] = (res_1[\"L10.\"+str(i)] + res_1[\"D10.\"+str(i)] + res_1[\"C10.\"+str(i)] + res_1[\"G10.\"+str(i)] + res_1[\"M10.\"+str(i)])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.469267</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>68.92</td>\n",
       "      <td>-5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.877069</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63.50</td>\n",
       "      <td>-5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.191010</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>62.54</td>\n",
       "      <td>-5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.692657</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>61.26</td>\n",
       "      <td>-5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.382006</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>60.80</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "      <td>19.891246</td>\n",
       "      <td>130</td>\n",
       "      <td>244</td>\n",
       "      <td>1.7</td>\n",
       "      <td>32.01</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "      <td>12.666762</td>\n",
       "      <td>91</td>\n",
       "      <td>181</td>\n",
       "      <td>1.4</td>\n",
       "      <td>41.65</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "      <td>6.849547</td>\n",
       "      <td>54</td>\n",
       "      <td>126</td>\n",
       "      <td>1.2</td>\n",
       "      <td>45.74</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>2.251943</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.81</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>0.093831</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>55.62</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day  Hour     TARGET  DHI  DNI   WS     RH     T\n",
       "303    0     7   0.469267    5    0  4.5  68.92  -5.4\n",
       "304    0     8   1.877069   20    0  5.0  63.50  -5.4\n",
       "305    0     8   3.191010   34    0  5.3  62.54  -5.2\n",
       "306    0     9   4.692657   50    1  5.6  61.26  -5.1\n",
       "307    0     9   6.382006   66    7  5.8  60.80  -5.0\n",
       "..   ...   ...        ...  ...  ...  ...    ...   ...\n",
       "323   80    17  19.891246  130  244  1.7  32.01  20.6\n",
       "324   80    18  12.666762   91  181  1.4  41.65  19.4\n",
       "325   80    18   6.849547   54  126  1.2  45.74  17.9\n",
       "326   80    19   2.251943   21   51  1.0  53.81  16.4\n",
       "327   80    19   0.093831    1    1  0.9  55.62  15.9\n",
       "\n",
       "[2008 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.TARGET > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1539, 45)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Day', 'Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1539.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3078/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2008, 3)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0 = df_test[df_test.TARGET > 0][['Day', 'Hour', 'Minute']]\n",
    "test0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc0 = pd.concat([test0[['Day', 'Hour', 'Minute']].reset_index(drop=True), res_0[['L00.1', 'L00.2', 'L00.3', 'L00.4', 'L00.5', 'L00.6', 'L00.7', 'L00.8','L00.9']].reset_index(drop=True)]\n",
    "          , axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc1 = pd.concat([test0[['Day', 'Hour', 'Minute']].reset_index(drop=True), res_1[['L10.1', 'L10.2', 'L10.3', 'L10.4', 'L10.5', 'L10.6', 'L10.7', 'L10.8','L10.9']].reset_index(drop=True)]\n",
    "          , axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc0.columns = ['Day', 'Hour', 'Minute','q_0.1', 'q_0.2', 'q_0.3', 'q_0.4', 'q_0.5', 'q_0.6', 'q_0.7','q_0.8', 'q_0.9']\n",
    "conc1.columns = ['Day', 'Hour', 'Minute','q_0.1', 'q_0.2', 'q_0.3', 'q_0.4', 'q_0.5', 'q_0.6', 'q_0.7','q_0.8', 'q_0.9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2008, 12), (3888, 9), (2008, 12))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conc0.shape, df_test.shape, conc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0.647914</td>\n",
       "      <td>1.196131</td>\n",
       "      <td>1.434812</td>\n",
       "      <td>1.876562</td>\n",
       "      <td>2.847241</td>\n",
       "      <td>3.010897</td>\n",
       "      <td>4.749901</td>\n",
       "      <td>6.106939</td>\n",
       "      <td>11.110855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.342538</td>\n",
       "      <td>3.169679</td>\n",
       "      <td>3.466623</td>\n",
       "      <td>5.777014</td>\n",
       "      <td>6.937122</td>\n",
       "      <td>7.978345</td>\n",
       "      <td>12.368717</td>\n",
       "      <td>15.660684</td>\n",
       "      <td>23.320770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>3.764487</td>\n",
       "      <td>5.131396</td>\n",
       "      <td>5.780598</td>\n",
       "      <td>8.174553</td>\n",
       "      <td>10.221474</td>\n",
       "      <td>10.855183</td>\n",
       "      <td>15.906742</td>\n",
       "      <td>20.214463</td>\n",
       "      <td>28.603241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6.827724</td>\n",
       "      <td>11.519275</td>\n",
       "      <td>12.081998</td>\n",
       "      <td>14.989933</td>\n",
       "      <td>17.776440</td>\n",
       "      <td>18.666013</td>\n",
       "      <td>26.654293</td>\n",
       "      <td>31.151393</td>\n",
       "      <td>41.051707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>9.155107</td>\n",
       "      <td>14.038509</td>\n",
       "      <td>15.364830</td>\n",
       "      <td>17.498668</td>\n",
       "      <td>19.854481</td>\n",
       "      <td>21.263618</td>\n",
       "      <td>27.800950</td>\n",
       "      <td>31.694239</td>\n",
       "      <td>40.773613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day  Hour  Minute     q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0     7      30  0.647914   1.196131   1.434812   1.876562   2.847241   \n",
       "1    0     8       0  2.342538   3.169679   3.466623   5.777014   6.937122   \n",
       "2    0     8      30  3.764487   5.131396   5.780598   8.174553  10.221474   \n",
       "3    0     9       0  6.827724  11.519275  12.081998  14.989933  17.776440   \n",
       "4    0     9      30  9.155107  14.038509  15.364830  17.498668  19.854481   \n",
       "\n",
       "       q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0   3.010897   4.749901   6.106939  11.110855  \n",
       "1   7.978345  12.368717  15.660684  23.320770  \n",
       "2  10.855183  15.906742  20.214463  28.603241  \n",
       "3  18.666013  26.654293  31.151393  41.051707  \n",
       "4  21.263618  27.800950  31.694239  40.773613  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conc0[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3888, 3)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub = df_test[['Day', 'Hour', 'Minute']]\n",
    "test_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub0 = test_sub.merge(conc0, on=['Day','Hour', 'Minute'], how='left').fillna(0)\n",
    "sub1 = test_sub.merge(conc1, on=['Day','Hour', 'Minute'], how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>0.647914</td>\n",
       "      <td>1.196131</td>\n",
       "      <td>1.434812</td>\n",
       "      <td>1.876562</td>\n",
       "      <td>2.847241</td>\n",
       "      <td>3.010897</td>\n",
       "      <td>4.749901</td>\n",
       "      <td>6.106939</td>\n",
       "      <td>11.110855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>2.342538</td>\n",
       "      <td>3.169679</td>\n",
       "      <td>3.466623</td>\n",
       "      <td>5.777014</td>\n",
       "      <td>6.937122</td>\n",
       "      <td>7.978345</td>\n",
       "      <td>12.368717</td>\n",
       "      <td>15.660684</td>\n",
       "      <td>23.320770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>3.764487</td>\n",
       "      <td>5.131396</td>\n",
       "      <td>5.780598</td>\n",
       "      <td>8.174553</td>\n",
       "      <td>10.221474</td>\n",
       "      <td>10.855183</td>\n",
       "      <td>15.906742</td>\n",
       "      <td>20.214463</td>\n",
       "      <td>28.603241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>6.827724</td>\n",
       "      <td>11.519275</td>\n",
       "      <td>12.081998</td>\n",
       "      <td>14.989933</td>\n",
       "      <td>17.776440</td>\n",
       "      <td>18.666013</td>\n",
       "      <td>26.654293</td>\n",
       "      <td>31.151393</td>\n",
       "      <td>41.051707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>9.155107</td>\n",
       "      <td>14.038509</td>\n",
       "      <td>15.364830</td>\n",
       "      <td>17.498668</td>\n",
       "      <td>19.854481</td>\n",
       "      <td>21.263618</td>\n",
       "      <td>27.800950</td>\n",
       "      <td>31.694239</td>\n",
       "      <td>40.773613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>14.749902</td>\n",
       "      <td>22.617628</td>\n",
       "      <td>22.842079</td>\n",
       "      <td>26.032562</td>\n",
       "      <td>29.320459</td>\n",
       "      <td>30.794608</td>\n",
       "      <td>35.223428</td>\n",
       "      <td>36.611290</td>\n",
       "      <td>37.813263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>16.173029</td>\n",
       "      <td>23.112013</td>\n",
       "      <td>23.933141</td>\n",
       "      <td>27.488401</td>\n",
       "      <td>30.909007</td>\n",
       "      <td>33.216843</td>\n",
       "      <td>36.761622</td>\n",
       "      <td>37.384641</td>\n",
       "      <td>36.897692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>16.426821</td>\n",
       "      <td>26.053065</td>\n",
       "      <td>29.484095</td>\n",
       "      <td>33.055222</td>\n",
       "      <td>36.969997</td>\n",
       "      <td>36.866481</td>\n",
       "      <td>42.803111</td>\n",
       "      <td>44.911212</td>\n",
       "      <td>48.197853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>14.299969</td>\n",
       "      <td>22.946029</td>\n",
       "      <td>26.454925</td>\n",
       "      <td>30.554265</td>\n",
       "      <td>33.956063</td>\n",
       "      <td>34.508111</td>\n",
       "      <td>39.825702</td>\n",
       "      <td>42.465823</td>\n",
       "      <td>47.440210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>14.354370</td>\n",
       "      <td>23.664936</td>\n",
       "      <td>27.840844</td>\n",
       "      <td>31.278611</td>\n",
       "      <td>33.470843</td>\n",
       "      <td>34.512053</td>\n",
       "      <td>38.934425</td>\n",
       "      <td>40.669088</td>\n",
       "      <td>44.326502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>15.531860</td>\n",
       "      <td>25.554445</td>\n",
       "      <td>28.090584</td>\n",
       "      <td>31.390530</td>\n",
       "      <td>34.181892</td>\n",
       "      <td>35.440082</td>\n",
       "      <td>40.346569</td>\n",
       "      <td>41.946109</td>\n",
       "      <td>43.480342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>13.546332</td>\n",
       "      <td>21.471896</td>\n",
       "      <td>25.893541</td>\n",
       "      <td>29.936203</td>\n",
       "      <td>31.358507</td>\n",
       "      <td>33.410350</td>\n",
       "      <td>37.133354</td>\n",
       "      <td>38.273399</td>\n",
       "      <td>41.194468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>11.341948</td>\n",
       "      <td>19.048765</td>\n",
       "      <td>23.592624</td>\n",
       "      <td>26.606028</td>\n",
       "      <td>27.983123</td>\n",
       "      <td>31.886530</td>\n",
       "      <td>37.181906</td>\n",
       "      <td>41.407018</td>\n",
       "      <td>48.291655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>11.400205</td>\n",
       "      <td>17.907213</td>\n",
       "      <td>21.574918</td>\n",
       "      <td>24.272150</td>\n",
       "      <td>25.548979</td>\n",
       "      <td>28.357063</td>\n",
       "      <td>31.323465</td>\n",
       "      <td>32.245893</td>\n",
       "      <td>35.944974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>11.719312</td>\n",
       "      <td>18.329089</td>\n",
       "      <td>21.655830</td>\n",
       "      <td>24.807223</td>\n",
       "      <td>26.223239</td>\n",
       "      <td>28.036834</td>\n",
       "      <td>31.335007</td>\n",
       "      <td>32.457287</td>\n",
       "      <td>34.943558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>9.678371</td>\n",
       "      <td>16.003707</td>\n",
       "      <td>17.833460</td>\n",
       "      <td>20.362823</td>\n",
       "      <td>22.376087</td>\n",
       "      <td>24.558149</td>\n",
       "      <td>26.300958</td>\n",
       "      <td>26.686249</td>\n",
       "      <td>28.753224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>7.576892</td>\n",
       "      <td>13.247754</td>\n",
       "      <td>14.555794</td>\n",
       "      <td>16.606966</td>\n",
       "      <td>17.988379</td>\n",
       "      <td>20.175519</td>\n",
       "      <td>23.002521</td>\n",
       "      <td>23.576699</td>\n",
       "      <td>26.344938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>4.731129</td>\n",
       "      <td>7.175627</td>\n",
       "      <td>7.707377</td>\n",
       "      <td>8.755568</td>\n",
       "      <td>9.286008</td>\n",
       "      <td>10.233490</td>\n",
       "      <td>12.641261</td>\n",
       "      <td>12.558183</td>\n",
       "      <td>18.136562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>2.234353</td>\n",
       "      <td>3.161373</td>\n",
       "      <td>3.476654</td>\n",
       "      <td>4.084902</td>\n",
       "      <td>4.590130</td>\n",
       "      <td>5.469642</td>\n",
       "      <td>8.178518</td>\n",
       "      <td>9.446882</td>\n",
       "      <td>17.098003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1    0.csv_Day7_0h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2    0.csv_Day7_1h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3    0.csv_Day7_1h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4    0.csv_Day7_2h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5    0.csv_Day7_2h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "6    0.csv_Day7_3h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "7    0.csv_Day7_3h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "8    0.csv_Day7_4h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "9    0.csv_Day7_4h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "10   0.csv_Day7_5h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "11   0.csv_Day7_5h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12   0.csv_Day7_6h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "13   0.csv_Day7_6h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "14   0.csv_Day7_7h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "15   0.csv_Day7_7h30m   0.647914   1.196131   1.434812   1.876562   2.847241   \n",
       "16   0.csv_Day7_8h00m   2.342538   3.169679   3.466623   5.777014   6.937122   \n",
       "17   0.csv_Day7_8h30m   3.764487   5.131396   5.780598   8.174553  10.221474   \n",
       "18   0.csv_Day7_9h00m   6.827724  11.519275  12.081998  14.989933  17.776440   \n",
       "19   0.csv_Day7_9h30m   9.155107  14.038509  15.364830  17.498668  19.854481   \n",
       "20  0.csv_Day7_10h00m  14.749902  22.617628  22.842079  26.032562  29.320459   \n",
       "21  0.csv_Day7_10h30m  16.173029  23.112013  23.933141  27.488401  30.909007   \n",
       "22  0.csv_Day7_11h00m  16.426821  26.053065  29.484095  33.055222  36.969997   \n",
       "23  0.csv_Day7_11h30m  14.299969  22.946029  26.454925  30.554265  33.956063   \n",
       "24  0.csv_Day7_12h00m  14.354370  23.664936  27.840844  31.278611  33.470843   \n",
       "25  0.csv_Day7_12h30m  15.531860  25.554445  28.090584  31.390530  34.181892   \n",
       "26  0.csv_Day7_13h00m  13.546332  21.471896  25.893541  29.936203  31.358507   \n",
       "27  0.csv_Day7_13h30m  11.341948  19.048765  23.592624  26.606028  27.983123   \n",
       "28  0.csv_Day7_14h00m  11.400205  17.907213  21.574918  24.272150  25.548979   \n",
       "29  0.csv_Day7_14h30m  11.719312  18.329089  21.655830  24.807223  26.223239   \n",
       "30  0.csv_Day7_15h00m   9.678371  16.003707  17.833460  20.362823  22.376087   \n",
       "31  0.csv_Day7_15h30m   7.576892  13.247754  14.555794  16.606966  17.988379   \n",
       "32  0.csv_Day7_16h00m   4.731129   7.175627   7.707377   8.755568   9.286008   \n",
       "33  0.csv_Day7_16h30m   2.234353   3.161373   3.476654   4.084902   4.590130   \n",
       "34  0.csv_Day7_17h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "35  0.csv_Day7_17h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "36  0.csv_Day7_18h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "37  0.csv_Day7_18h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "38  0.csv_Day7_19h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "39  0.csv_Day7_19h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "40  0.csv_Day7_20h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "41  0.csv_Day7_20h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "42  0.csv_Day7_21h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "43  0.csv_Day7_21h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "44  0.csv_Day7_22h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "45  0.csv_Day7_22h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "46  0.csv_Day7_23h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "47  0.csv_Day7_23h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.000000   0.000000   0.000000   0.000000  \n",
       "1    0.000000   0.000000   0.000000   0.000000  \n",
       "2    0.000000   0.000000   0.000000   0.000000  \n",
       "3    0.000000   0.000000   0.000000   0.000000  \n",
       "4    0.000000   0.000000   0.000000   0.000000  \n",
       "5    0.000000   0.000000   0.000000   0.000000  \n",
       "6    0.000000   0.000000   0.000000   0.000000  \n",
       "7    0.000000   0.000000   0.000000   0.000000  \n",
       "8    0.000000   0.000000   0.000000   0.000000  \n",
       "9    0.000000   0.000000   0.000000   0.000000  \n",
       "10   0.000000   0.000000   0.000000   0.000000  \n",
       "11   0.000000   0.000000   0.000000   0.000000  \n",
       "12   0.000000   0.000000   0.000000   0.000000  \n",
       "13   0.000000   0.000000   0.000000   0.000000  \n",
       "14   0.000000   0.000000   0.000000   0.000000  \n",
       "15   3.010897   4.749901   6.106939  11.110855  \n",
       "16   7.978345  12.368717  15.660684  23.320770  \n",
       "17  10.855183  15.906742  20.214463  28.603241  \n",
       "18  18.666013  26.654293  31.151393  41.051707  \n",
       "19  21.263618  27.800950  31.694239  40.773613  \n",
       "20  30.794608  35.223428  36.611290  37.813263  \n",
       "21  33.216843  36.761622  37.384641  36.897692  \n",
       "22  36.866481  42.803111  44.911212  48.197853  \n",
       "23  34.508111  39.825702  42.465823  47.440210  \n",
       "24  34.512053  38.934425  40.669088  44.326502  \n",
       "25  35.440082  40.346569  41.946109  43.480342  \n",
       "26  33.410350  37.133354  38.273399  41.194468  \n",
       "27  31.886530  37.181906  41.407018  48.291655  \n",
       "28  28.357063  31.323465  32.245893  35.944974  \n",
       "29  28.036834  31.335007  32.457287  34.943558  \n",
       "30  24.558149  26.300958  26.686249  28.753224  \n",
       "31  20.175519  23.002521  23.576699  26.344938  \n",
       "32  10.233490  12.641261  12.558183  18.136562  \n",
       "33   5.469642   8.178518   9.446882  17.098003  \n",
       "34   0.000000   0.000000   0.000000   0.000000  \n",
       "35   0.000000   0.000000   0.000000   0.000000  \n",
       "36   0.000000   0.000000   0.000000   0.000000  \n",
       "37   0.000000   0.000000   0.000000   0.000000  \n",
       "38   0.000000   0.000000   0.000000   0.000000  \n",
       "39   0.000000   0.000000   0.000000   0.000000  \n",
       "40   0.000000   0.000000   0.000000   0.000000  \n",
       "41   0.000000   0.000000   0.000000   0.000000  \n",
       "42   0.000000   0.000000   0.000000   0.000000  \n",
       "43   0.000000   0.000000   0.000000   0.000000  \n",
       "44   0.000000   0.000000   0.000000   0.000000  \n",
       "45   0.000000   0.000000   0.000000   0.000000  \n",
       "46   0.000000   0.000000   0.000000   0.000000  \n",
       "47   0.000000   0.000000   0.000000   0.000000  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.loc[submission.id.str.contains(\"Day7\"), \"q_0.1\":] = sub0[['q_0.1', 'q_0.2', 'q_0.3', 'q_0.4', 'q_0.5', 'q_0.6', 'q_0.7','q_0.8', 'q_0.9']].values\n",
    "submission.loc[submission.id.str.contains(\"Day8\"), \"q_0.1\":] = sub1[['q_0.1', 'q_0.2', 'q_0.3', 'q_0.4', 'q_0.5', 'q_0.6', 'q_0.7','q_0.8', 'q_0.9']].values\n",
    "submission[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission/submission_20210124-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
