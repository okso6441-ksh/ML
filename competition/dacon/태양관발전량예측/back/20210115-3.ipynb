{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, is_train=True):\n",
    "    \n",
    "    temp = data.copy()\n",
    "    \n",
    "    temp['TARGET_0'] = 0\n",
    "    temp.loc[temp.TARGET > 0, ['TARGET_0']] = 1\n",
    "    \n",
    "    temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET_0']]\n",
    "\n",
    "    if is_train==True:          \n",
    "    \n",
    "        temp['Target1'] = temp['TARGET'].shift(-48).fillna(method='ffill')\n",
    "        temp['Target2'] = temp['TARGET'].shift(-48*2).fillna(method='ffill')\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        return temp.iloc[:-96]\n",
    "\n",
    "    elif is_train==False:\n",
    "        \n",
    "        temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T', 'TARGET_0']]\n",
    "                              \n",
    "        return temp.iloc[-48:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train/train.csv')\n",
    "\n",
    "test = []\n",
    "\n",
    "for i in range(81):\n",
    "    file_path = './data/test/' + str(i) + '.csv'\n",
    "    temp = pd.read_csv(file_path)\n",
    "    temp = preprocess_data(temp, is_train=False)\n",
    "    test.append(temp)\n",
    "\n",
    "df_test = pd.concat(test)\n",
    "\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52464, 10), (3888, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess_data(train)\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_train[['Hour','DHI','DNI','WS','RH','T']] = scaler.fit_transform(df_train[['Hour','DHI','DNI','WS','RH','T']])\n",
    "df_test[['Hour','DHI','DNI','WS','RH','T']] = scaler.fit_transform(df_test[['Hour','DHI','DNI','WS','RH','T']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day  = df_train.iloc[:, :-2]\n",
    "Day7 = df_train.iloc[:, -2]\n",
    "Day8 = df_train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>WS</th>\n",
       "      <th>RH</th>\n",
       "      <th>T</th>\n",
       "      <th>TARGET_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.661325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.669437</td>\n",
       "      <td>0.556754</td>\n",
       "      <td>-2.092343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.661325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.669437</td>\n",
       "      <td>0.555848</td>\n",
       "      <td>-2.092343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.516862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.599382</td>\n",
       "      <td>0.679120</td>\n",
       "      <td>-2.092343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.516862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.599382</td>\n",
       "      <td>0.677760</td>\n",
       "      <td>-2.092343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.372399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.599382</td>\n",
       "      <td>0.834117</td>\n",
       "      <td>-2.092343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.372399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.669437</td>\n",
       "      <td>0.566272</td>\n",
       "      <td>-1.994101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.227936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.669437</td>\n",
       "      <td>0.714470</td>\n",
       "      <td>-1.994101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.227936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.739491</td>\n",
       "      <td>0.714017</td>\n",
       "      <td>-1.994101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.083473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.809545</td>\n",
       "      <td>0.807831</td>\n",
       "      <td>-1.994101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.083473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.809545</td>\n",
       "      <td>0.807377</td>\n",
       "      <td>-1.994101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.939010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.809545</td>\n",
       "      <td>0.767948</td>\n",
       "      <td>-1.994101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.939010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.809545</td>\n",
       "      <td>0.767495</td>\n",
       "      <td>-1.994101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.794547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.739491</td>\n",
       "      <td>0.699061</td>\n",
       "      <td>-2.092343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.794547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.739491</td>\n",
       "      <td>0.699061</td>\n",
       "      <td>-2.092343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.650084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.739491</td>\n",
       "      <td>0.610686</td>\n",
       "      <td>-2.092343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.650084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.599382</td>\n",
       "      <td>0.364142</td>\n",
       "      <td>-1.895859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.505621</td>\n",
       "      <td>7.039287</td>\n",
       "      <td>-0.340641</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>-0.459274</td>\n",
       "      <td>0.392241</td>\n",
       "      <td>-1.797617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.505621</td>\n",
       "      <td>5.912871</td>\n",
       "      <td>-0.032837</td>\n",
       "      <td>-0.651370</td>\n",
       "      <td>-0.389219</td>\n",
       "      <td>-0.040571</td>\n",
       "      <td>-1.601133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.361158</td>\n",
       "      <td>22.337268</td>\n",
       "      <td>-0.061693</td>\n",
       "      <td>1.453396</td>\n",
       "      <td>-0.249111</td>\n",
       "      <td>0.026956</td>\n",
       "      <td>-1.502891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.361158</td>\n",
       "      <td>29.469529</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>1.647858</td>\n",
       "      <td>-0.389219</td>\n",
       "      <td>-0.165203</td>\n",
       "      <td>-1.306407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.216695</td>\n",
       "      <td>25.339762</td>\n",
       "      <td>0.707816</td>\n",
       "      <td>0.380995</td>\n",
       "      <td>-0.459274</td>\n",
       "      <td>-0.036493</td>\n",
       "      <td>-1.208165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.216695</td>\n",
       "      <td>25.152060</td>\n",
       "      <td>1.092571</td>\n",
       "      <td>-0.030807</td>\n",
       "      <td>-0.389219</td>\n",
       "      <td>-0.037399</td>\n",
       "      <td>-1.208165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.072232</td>\n",
       "      <td>28.718397</td>\n",
       "      <td>1.236854</td>\n",
       "      <td>0.075003</td>\n",
       "      <td>-0.319165</td>\n",
       "      <td>0.074090</td>\n",
       "      <td>-1.208165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.072232</td>\n",
       "      <td>33.129393</td>\n",
       "      <td>1.198378</td>\n",
       "      <td>0.369556</td>\n",
       "      <td>-0.109002</td>\n",
       "      <td>0.073183</td>\n",
       "      <td>-1.208165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.072232</td>\n",
       "      <td>19.427151</td>\n",
       "      <td>1.207997</td>\n",
       "      <td>-0.565578</td>\n",
       "      <td>0.101161</td>\n",
       "      <td>0.108533</td>\n",
       "      <td>-1.208165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.072232</td>\n",
       "      <td>25.715166</td>\n",
       "      <td>1.429231</td>\n",
       "      <td>-0.291043</td>\n",
       "      <td>0.311324</td>\n",
       "      <td>0.108080</td>\n",
       "      <td>-1.208165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.216695</td>\n",
       "      <td>24.589225</td>\n",
       "      <td>1.409993</td>\n",
       "      <td>-0.345378</td>\n",
       "      <td>0.521487</td>\n",
       "      <td>0.293442</td>\n",
       "      <td>-1.306407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.216695</td>\n",
       "      <td>21.304405</td>\n",
       "      <td>1.159903</td>\n",
       "      <td>-0.382555</td>\n",
       "      <td>0.451433</td>\n",
       "      <td>0.293442</td>\n",
       "      <td>-1.306407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.361158</td>\n",
       "      <td>11.731500</td>\n",
       "      <td>0.573152</td>\n",
       "      <td>-0.665669</td>\n",
       "      <td>0.381379</td>\n",
       "      <td>0.273954</td>\n",
       "      <td>-1.306407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.361158</td>\n",
       "      <td>14.734764</td>\n",
       "      <td>0.678959</td>\n",
       "      <td>-0.474066</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.274407</td>\n",
       "      <td>-1.306407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.505621</td>\n",
       "      <td>5.818888</td>\n",
       "      <td>-0.023218</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>0.031107</td>\n",
       "      <td>0.532734</td>\n",
       "      <td>-1.404649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.505621</td>\n",
       "      <td>7.602096</td>\n",
       "      <td>0.082590</td>\n",
       "      <td>-0.559859</td>\n",
       "      <td>-0.179056</td>\n",
       "      <td>0.532734</td>\n",
       "      <td>-1.404649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.650084</td>\n",
       "      <td>4.035725</td>\n",
       "      <td>-0.225214</td>\n",
       "      <td>-0.639931</td>\n",
       "      <td>-0.319165</td>\n",
       "      <td>0.610686</td>\n",
       "      <td>-1.502891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.650084</td>\n",
       "      <td>0.938541</td>\n",
       "      <td>-0.523399</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.319165</td>\n",
       "      <td>0.611139</td>\n",
       "      <td>-1.502891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.794547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.319165</td>\n",
       "      <td>0.658726</td>\n",
       "      <td>-1.601133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.794547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.319165</td>\n",
       "      <td>0.659632</td>\n",
       "      <td>-1.601133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.939010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.249111</td>\n",
       "      <td>0.889861</td>\n",
       "      <td>-1.699375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.939010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.179056</td>\n",
       "      <td>0.890314</td>\n",
       "      <td>-1.699375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.083473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.109002</td>\n",
       "      <td>0.903004</td>\n",
       "      <td>-1.699375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.083473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.179056</td>\n",
       "      <td>0.903004</td>\n",
       "      <td>-1.699375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.227936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.179056</td>\n",
       "      <td>0.938807</td>\n",
       "      <td>-1.699375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.227936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.319165</td>\n",
       "      <td>0.938807</td>\n",
       "      <td>-1.699375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.372399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.389219</td>\n",
       "      <td>1.208465</td>\n",
       "      <td>-1.797617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.372399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.459274</td>\n",
       "      <td>1.208465</td>\n",
       "      <td>-1.797617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.516862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.459274</td>\n",
       "      <td>1.203933</td>\n",
       "      <td>-1.797617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.516862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.529328</td>\n",
       "      <td>1.203933</td>\n",
       "      <td>-1.797617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.661325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.529328</td>\n",
       "      <td>1.543838</td>\n",
       "      <td>-1.895859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.661325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.619588</td>\n",
       "      <td>-0.671388</td>\n",
       "      <td>-0.599382</td>\n",
       "      <td>1.543384</td>\n",
       "      <td>-1.895859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Hour     TARGET       DHI       DNI        WS        RH         T  \\\n",
       "0  -1.661325   0.000000 -0.619588 -0.671388 -0.669437  0.556754 -2.092343   \n",
       "1  -1.661325   0.000000 -0.619588 -0.671388 -0.669437  0.555848 -2.092343   \n",
       "2  -1.516862   0.000000 -0.619588 -0.671388 -0.599382  0.679120 -2.092343   \n",
       "3  -1.516862   0.000000 -0.619588 -0.671388 -0.599382  0.677760 -2.092343   \n",
       "4  -1.372399   0.000000 -0.619588 -0.671388 -0.599382  0.834117 -2.092343   \n",
       "5  -1.372399   0.000000 -0.619588 -0.671388 -0.669437  0.566272 -1.994101   \n",
       "6  -1.227936   0.000000 -0.619588 -0.671388 -0.669437  0.714470 -1.994101   \n",
       "7  -1.227936   0.000000 -0.619588 -0.671388 -0.739491  0.714017 -1.994101   \n",
       "8  -1.083473   0.000000 -0.619588 -0.671388 -0.809545  0.807831 -1.994101   \n",
       "9  -1.083473   0.000000 -0.619588 -0.671388 -0.809545  0.807377 -1.994101   \n",
       "10 -0.939010   0.000000 -0.619588 -0.671388 -0.809545  0.767948 -1.994101   \n",
       "11 -0.939010   0.000000 -0.619588 -0.671388 -0.809545  0.767495 -1.994101   \n",
       "12 -0.794547   0.000000 -0.619588 -0.671388 -0.739491  0.699061 -2.092343   \n",
       "13 -0.794547   0.000000 -0.619588 -0.671388 -0.739491  0.699061 -2.092343   \n",
       "14 -0.650084   0.000000 -0.619588 -0.671388 -0.739491  0.610686 -2.092343   \n",
       "15 -0.650084   0.000000 -0.619588 -0.671388 -0.599382  0.364142 -1.895859   \n",
       "16 -0.505621   7.039287 -0.340641  0.741321 -0.459274  0.392241 -1.797617   \n",
       "17 -0.505621   5.912871 -0.032837 -0.651370 -0.389219 -0.040571 -1.601133   \n",
       "18 -0.361158  22.337268 -0.061693  1.453396 -0.249111  0.026956 -1.502891   \n",
       "19 -0.361158  29.469529  0.024876  1.647858 -0.389219 -0.165203 -1.306407   \n",
       "20 -0.216695  25.339762  0.707816  0.380995 -0.459274 -0.036493 -1.208165   \n",
       "21 -0.216695  25.152060  1.092571 -0.030807 -0.389219 -0.037399 -1.208165   \n",
       "22 -0.072232  28.718397  1.236854  0.075003 -0.319165  0.074090 -1.208165   \n",
       "23 -0.072232  33.129393  1.198378  0.369556 -0.109002  0.073183 -1.208165   \n",
       "24  0.072232  19.427151  1.207997 -0.565578  0.101161  0.108533 -1.208165   \n",
       "25  0.072232  25.715166  1.429231 -0.291043  0.311324  0.108080 -1.208165   \n",
       "26  0.216695  24.589225  1.409993 -0.345378  0.521487  0.293442 -1.306407   \n",
       "27  0.216695  21.304405  1.159903 -0.382555  0.451433  0.293442 -1.306407   \n",
       "28  0.361158  11.731500  0.573152 -0.665669  0.381379  0.273954 -1.306407   \n",
       "29  0.361158  14.734764  0.678959 -0.474066  0.171215  0.274407 -1.306407   \n",
       "30  0.505621   5.818888 -0.023218 -0.671388  0.031107  0.532734 -1.404649   \n",
       "31  0.505621   7.602096  0.082590 -0.559859 -0.179056  0.532734 -1.404649   \n",
       "32  0.650084   4.035725 -0.225214 -0.639931 -0.319165  0.610686 -1.502891   \n",
       "33  0.650084   0.938541 -0.523399 -0.671388 -0.319165  0.611139 -1.502891   \n",
       "34  0.794547   0.000000 -0.619588 -0.671388 -0.319165  0.658726 -1.601133   \n",
       "35  0.794547   0.000000 -0.619588 -0.671388 -0.319165  0.659632 -1.601133   \n",
       "36  0.939010   0.000000 -0.619588 -0.671388 -0.249111  0.889861 -1.699375   \n",
       "37  0.939010   0.000000 -0.619588 -0.671388 -0.179056  0.890314 -1.699375   \n",
       "38  1.083473   0.000000 -0.619588 -0.671388 -0.109002  0.903004 -1.699375   \n",
       "39  1.083473   0.000000 -0.619588 -0.671388 -0.179056  0.903004 -1.699375   \n",
       "40  1.227936   0.000000 -0.619588 -0.671388 -0.179056  0.938807 -1.699375   \n",
       "41  1.227936   0.000000 -0.619588 -0.671388 -0.319165  0.938807 -1.699375   \n",
       "42  1.372399   0.000000 -0.619588 -0.671388 -0.389219  1.208465 -1.797617   \n",
       "43  1.372399   0.000000 -0.619588 -0.671388 -0.459274  1.208465 -1.797617   \n",
       "44  1.516862   0.000000 -0.619588 -0.671388 -0.459274  1.203933 -1.797617   \n",
       "45  1.516862   0.000000 -0.619588 -0.671388 -0.529328  1.203933 -1.797617   \n",
       "46  1.661325   0.000000 -0.619588 -0.671388 -0.529328  1.543838 -1.895859   \n",
       "47  1.661325   0.000000 -0.619588 -0.671388 -0.599382  1.543384 -1.895859   \n",
       "\n",
       "    TARGET_0  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  \n",
       "10         0  \n",
       "11         0  \n",
       "12         0  \n",
       "13         0  \n",
       "14         0  \n",
       "15         0  \n",
       "16         1  \n",
       "17         1  \n",
       "18         1  \n",
       "19         1  \n",
       "20         1  \n",
       "21         1  \n",
       "22         1  \n",
       "23         1  \n",
       "24         1  \n",
       "25         1  \n",
       "26         1  \n",
       "27         1  \n",
       "28         1  \n",
       "29         1  \n",
       "30         1  \n",
       "31         1  \n",
       "32         1  \n",
       "33         1  \n",
       "34         0  \n",
       "35         0  \n",
       "36         0  \n",
       "37         0  \n",
       "38         0  \n",
       "39         0  \n",
       "40         0  \n",
       "41         0  \n",
       "42         0  \n",
       "43         0  \n",
       "44         0  \n",
       "45         0  \n",
       "46         0  \n",
       "47         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Day[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import mean, maximum\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(q, y, pred):\n",
    "    err = (y-pred)\n",
    "    return mean(maximum(q*err, (q-1)*err), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lst = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39348, 8), (13116, 8), (39348,), (13116,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_1, X_valid_1, Y_train_1, Y_valid_1 = train_test_split(Day, Day7, test_size=0.25, random_state=42, shuffle=True)\n",
    "X_train_2, X_valid_2, Y_train_2, Y_valid_2 = train_test_split(Day, Day8, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "X_train_1.shape, X_valid_1.shape, Y_train_1.shape, Y_valid_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(Day.shape)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model8 = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(Day.shape)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "563/615 [==========================>...] - ETA: 0s - loss: 276.9822WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 269.6839 - val_loss: 148.4303\n",
      "Epoch 2/25\n",
      "615/615 [==============================] - 1s 950us/step - loss: 145.1299 - val_loss: 138.3991\n",
      "Epoch 3/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.1215 - val_loss: 134.9041\n",
      "Epoch 4/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.0068 - val_loss: 132.1010\n",
      "Epoch 5/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 130.9286 - val_loss: 130.1156\n",
      "Epoch 6/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 131.4046 - val_loss: 129.6014\n",
      "Epoch 7/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 131.9779 - val_loss: 128.2699\n",
      "Epoch 8/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 126.4749 - val_loss: 127.3567\n",
      "Epoch 9/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 131.2392 - val_loss: 132.2218\n",
      "Epoch 10/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 129.6527 - val_loss: 129.4363\n",
      "Epoch 11/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.4768 - val_loss: 127.2156\n",
      "Epoch 12/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 128.8792 - val_loss: 126.5447\n",
      "Epoch 13/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 129.8434 - val_loss: 128.7724\n",
      "Epoch 14/25\n",
      "615/615 [==============================] - 1s 992us/step - loss: 129.7349 - val_loss: 126.5611\n",
      "Epoch 15/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 125.4931 - val_loss: 127.5643\n",
      "Epoch 16/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 130.1487 - val_loss: 127.8139\n",
      "Epoch 17/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 131.0301 - val_loss: 127.2001\n",
      "Epoch 18/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 128.0497 - val_loss: 128.9032\n",
      "Epoch 19/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 126.4709 - val_loss: 125.8391\n",
      "Epoch 20/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 124.4742 - val_loss: 127.3660\n",
      "Epoch 21/25\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 127.3971 - val_loss: 128.6725\n",
      "Epoch 22/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 126.6652 - val_loss: 127.9217\n",
      "Epoch 23/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 127.0192 - val_loss: 135.8047\n",
      "Epoch 24/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 126.2614 - val_loss: 130.2208\n",
      "Epoch 25/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 125.7930 - val_loss: 127.0717\n",
      "410/410 [==============================] - 0s 740us/step - loss: 127.4491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "127.44905090332031"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.compile(loss='mse', optimizer='adam')\n",
    "hist7 = model7.fit(X_train_1, Y_train_1, epochs=25, batch_size=48, validation_split=0.25)\n",
    "model7.evaluate(X_valid_1, Y_valid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist7.history['loss'], 'b-', label='loss')\n",
    "plt.plot(hist7.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "569/615 [==========================>...] - ETA: 0s - loss: 368.1589WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 357.2846 - val_loss: 163.9644\n",
      "Epoch 2/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 159.2920 - val_loss: 153.6815\n",
      "Epoch 3/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 147.0089 - val_loss: 145.1745\n",
      "Epoch 4/25\n",
      "615/615 [==============================] - 1s 988us/step - loss: 146.1913 - val_loss: 142.5911\n",
      "Epoch 5/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 141.7762 - val_loss: 140.1252\n",
      "Epoch 6/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 143.3518 - val_loss: 139.4403\n",
      "Epoch 7/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 141.3068 - val_loss: 138.3840\n",
      "Epoch 8/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 134.7648 - val_loss: 138.6545\n",
      "Epoch 9/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.4281 - val_loss: 135.3657\n",
      "Epoch 10/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 140.9365 - val_loss: 135.2582\n",
      "Epoch 11/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 145.8118 - val_loss: 137.3086\n",
      "Epoch 12/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 136.6200 - val_loss: 131.7370\n",
      "Epoch 13/25\n",
      "615/615 [==============================] - ETA: 0s - loss: 133.842 - 1s 1ms/step - loss: 134.1112 - val_loss: 133.0971\n",
      "Epoch 14/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.0758 - val_loss: 133.6523\n",
      "Epoch 15/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 131.8471 - val_loss: 132.9171\n",
      "Epoch 16/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 139.1715 - val_loss: 132.7020\n",
      "Epoch 17/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 140.3570 - val_loss: 134.5566\n",
      "Epoch 18/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 134.0042 - val_loss: 132.9095\n",
      "Epoch 19/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.7659 - val_loss: 133.3175\n",
      "Epoch 20/25\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 130.4894 - val_loss: 134.0609\n",
      "Epoch 21/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.8165 - val_loss: 136.5060\n",
      "Epoch 22/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.9256 - val_loss: 138.8835\n",
      "Epoch 23/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.3566 - val_loss: 132.1111\n",
      "Epoch 24/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 135.4825 - val_loss: 131.7845\n",
      "Epoch 25/25\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 131.3052 - val_loss: 131.4200\n",
      "410/410 [==============================] - 0s 736us/step - loss: 130.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "130.95970153808594"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.compile(loss='mse', optimizer='adam')\n",
    "hist8 = model8.fit(X_train_2, Y_train_2, epochs=25, batch_size=48, validation_split=0.25)\n",
    "model8.evaluate(X_valid_2, Y_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist8.history['loss'], 'b-', label='loss')\n",
    "plt.plot(hist8.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "811/820 [============================>.] - ETA: 0s - loss: 1.4895WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4884 - val_loss: 1.5686\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3713 - val_loss: 1.5789\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3629 - val_loss: 1.5534\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3549 - val_loss: 1.5496\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3660 - val_loss: 1.5544\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3428 - val_loss: 1.6064\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3532 - val_loss: 1.5794\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3675 - val_loss: 1.5463\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3544 - val_loss: 1.5645\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3642 - val_loss: 1.5586\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.3341 - val_loss: 1.5503\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3294 - val_loss: 1.5758\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3463 - val_loss: 1.5438\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3279 - val_loss: 1.5565\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3595 - val_loss: 1.5630\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3504 - val_loss: 1.5559\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3541 - val_loss: 1.5619\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3367 - val_loss: 1.5534\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3424 - val_loss: 1.5509\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3484 - val_loss: 1.5526\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 1.3465 - val_loss: 1.5609\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3269 - val_loss: 1.5568\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3265 - val_loss: 1.5527\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3376 - val_loss: 1.5707\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3269 - val_loss: 1.5456\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "797/820 [============================>.] - ETA: 0s - loss: 2.1606WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1604 - val_loss: 2.5171\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1429 - val_loss: 2.5208\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1382 - val_loss: 2.5085\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1204 - val_loss: 2.4885\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1473 - val_loss: 2.5460\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1315 - val_loss: 2.5287\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1361 - val_loss: 2.5413\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1707 - val_loss: 2.5483\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 2ms/step - loss: 2.1379 - val_loss: 2.5075\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1666 - val_loss: 2.5070\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0987 - val_loss: 2.5071\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0992 - val_loss: 2.5316\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1362 - val_loss: 2.5333\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1234 - val_loss: 2.5161\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1461 - val_loss: 2.5421\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1332 - val_loss: 2.5165\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1349 - val_loss: 2.5800\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1258 - val_loss: 2.5377\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1372 - val_loss: 2.5240\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1473 - val_loss: 2.5330\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1413 - val_loss: 2.4970\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1185 - val_loss: 2.5222\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1170 - val_loss: 2.5469\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1443 - val_loss: 2.5211\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.0995 - val_loss: 2.5006\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799/820 [============================>.] - ETA: 0s - loss: 2.5359WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5359 - val_loss: 2.9679\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5070 - val_loss: 2.9557\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5111 - val_loss: 2.9784\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4941 - val_loss: 2.9422\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5255 - val_loss: 2.9987\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5186 - val_loss: 2.9746\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5258 - val_loss: 2.9666\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5705 - val_loss: 2.9632\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5140 - val_loss: 2.9897\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5626 - val_loss: 2.9469\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4646 - val_loss: 2.9632\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4715 - val_loss: 2.9843\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5151 - val_loss: 2.9757\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5156 - val_loss: 2.9864\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5160 - val_loss: 3.0258\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5134 - val_loss: 2.9601\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5177 - val_loss: 3.0188\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5171 - val_loss: 2.9654\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5209 - val_loss: 2.9726\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5323 - val_loss: 3.0027\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5456 - val_loss: 2.9543\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5117 - val_loss: 2.9528\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5095 - val_loss: 2.9839\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5273 - val_loss: 2.9706\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4847 - val_loss: 2.9448\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "791/820 [===========================>..] - ETA: 0s - loss: 2.6218WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6218 - val_loss: 3.0699\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5874 - val_loss: 3.1067\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5877 - val_loss: 3.0885\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5711 - val_loss: 3.0978\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5990 - val_loss: 3.1100\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6001 - val_loss: 3.0703\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6149 - val_loss: 3.0832\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6554 - val_loss: 3.0738\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5794 - val_loss: 3.0701\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6571 - val_loss: 3.0513\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5369 - val_loss: 3.0691\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5492 - val_loss: 3.0716\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5884 - val_loss: 3.1239\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5914 - val_loss: 3.1022\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5880 - val_loss: 3.0851\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5726 - val_loss: 3.0915\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5891 - val_loss: 3.0883\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6000 - val_loss: 3.0976\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5954 - val_loss: 3.0969\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6161 - val_loss: 3.0847\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6290 - val_loss: 3.0908\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5967 - val_loss: 3.1196\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5876 - val_loss: 3.1188\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6080 - val_loss: 3.1000\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5588 - val_loss: 3.0854\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "764/820 [==========================>...] - ETA: 0s - loss: 2.4987WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4983 - val_loss: 2.9497\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4533 - val_loss: 2.9543\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4558 - val_loss: 2.9560\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4536 - val_loss: 2.9835\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4636 - val_loss: 2.9611\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4766 - val_loss: 3.0087\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5025 - val_loss: 2.9630\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5323 - val_loss: 2.9706\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4616 - val_loss: 2.9597\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5313 - val_loss: 2.9386\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4207 - val_loss: 2.9693\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4356 - val_loss: 2.9715\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4634 - val_loss: 2.9859\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4618 - val_loss: 2.9784\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4538 - val_loss: 2.9600\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4519 - val_loss: 2.9596\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4768 - val_loss: 2.9745\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4720 - val_loss: 2.9481\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4735 - val_loss: 2.9821\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4941 - val_loss: 2.9380\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.5084 - val_loss: 2.9684\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4695 - val_loss: 2.9672\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4653 - val_loss: 2.9765\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4901 - val_loss: 2.9535\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.4382 - val_loss: 2.9407\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "806/820 [============================>.] - ETA: 0s - loss: 2.2206WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2206 - val_loss: 2.6405\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1835 - val_loss: 2.6661\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1899 - val_loss: 2.6525\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1896 - val_loss: 2.6733\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1917 - val_loss: 2.6705\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2050 - val_loss: 2.6706\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2230 - val_loss: 2.6779\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2538 - val_loss: 2.6459\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1880 - val_loss: 2.6332\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2456 - val_loss: 2.6212\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1573 - val_loss: 2.6500\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1745 - val_loss: 2.6272\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1996 - val_loss: 2.6858\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1866 - val_loss: 2.6578\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1831 - val_loss: 2.6574\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1851 - val_loss: 2.6283\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2038 - val_loss: 2.6350\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1951 - val_loss: 2.6326\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1929 - val_loss: 2.6587\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2217 - val_loss: 2.6079\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2271 - val_loss: 2.6230\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1884 - val_loss: 2.6337\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1863 - val_loss: 2.6551\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2146 - val_loss: 2.6321\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1611 - val_loss: 2.6187\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "769/820 [===========================>..] - ETA: 0s - loss: 1.8306WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8306 - val_loss: 2.1875\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7949 - val_loss: 2.2012\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8097 - val_loss: 2.2005\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8018 - val_loss: 2.2231\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8017 - val_loss: 2.1877\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8113 - val_loss: 2.1392\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8310 - val_loss: 2.1889\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8484 - val_loss: 2.2199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8014 - val_loss: 2.1602\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8441 - val_loss: 2.1360\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7692 - val_loss: 2.1840\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7878 - val_loss: 2.1612\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8152 - val_loss: 2.1644\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7967 - val_loss: 2.1449\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7945 - val_loss: 2.2087\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7932 - val_loss: 2.1613\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8136 - val_loss: 2.1471\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8049 - val_loss: 2.1786\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7998 - val_loss: 2.1740\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8218 - val_loss: 2.1415\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8327 - val_loss: 2.1650\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7977 - val_loss: 2.1534\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8069 - val_loss: 2.1538\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8167 - val_loss: 2.1587\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.7765 - val_loss: 2.1185\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "779/820 [===========================>..] - ETA: 0s - loss: 1.3393WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3393 - val_loss: 1.5929\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3000 - val_loss: 1.5910\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3199 - val_loss: 1.6072\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3104 - val_loss: 1.6256\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3073 - val_loss: 1.5931\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3168 - val_loss: 1.5575\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3321 - val_loss: 1.6037\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3415 - val_loss: 1.6050\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3075 - val_loss: 1.5646\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3347 - val_loss: 1.5745\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2823 - val_loss: 1.5694\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3060 - val_loss: 1.5857\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3121 - val_loss: 1.5976\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3056 - val_loss: 1.5735\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3075 - val_loss: 1.6105\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3071 - val_loss: 1.5893\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3181 - val_loss: 1.5487\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3089 - val_loss: 1.5724\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3068 - val_loss: 1.5859\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3186 - val_loss: 1.5663\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3369 - val_loss: 1.5903\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3077 - val_loss: 1.5389\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3076 - val_loss: 1.5712\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3174 - val_loss: 1.6037\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.2897 - val_loss: 1.5305\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "786/820 [===========================>..] - ETA: 0s - loss: 0.7456WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7455 - val_loss: 0.8953\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7194 - val_loss: 0.8745\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7369 - val_loss: 0.9097\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7262 - val_loss: 0.8949\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7245 - val_loss: 0.8934\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7348 - val_loss: 0.8710\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7399 - val_loss: 0.8919\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7433 - val_loss: 0.8692\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7224 - val_loss: 0.8834\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7424 - val_loss: 0.8790\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7100 - val_loss: 0.8919\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7246 - val_loss: 0.8886\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7282 - val_loss: 0.8893\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7228 - val_loss: 0.8763\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7252 - val_loss: 0.9143\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7306 - val_loss: 0.8758\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7291 - val_loss: 0.8599\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7240 - val_loss: 0.8710\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7235 - val_loss: 0.8818\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7259 - val_loss: 0.8663\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7416 - val_loss: 0.8684\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7210 - val_loss: 0.8575\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7233 - val_loss: 0.9187\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7272 - val_loss: 0.8929\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7112 - val_loss: 0.8583\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 8).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results7 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    model7.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model7.fit(Day, Day7, epochs=25, batch_size=48, validation_split=0.25)\n",
    "    pred = pd.DataFrame(model7.predict(df_test))\n",
    "    results7 = pd.concat([results7, pred], axis=1)\n",
    "\n",
    "results7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "807/820 [============================>.] - ETA: 0s - loss: 1.4841WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4831 - val_loss: 1.5788\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4042 - val_loss: 1.5540\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3902 - val_loss: 1.5730\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3738 - val_loss: 1.5697\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3931 - val_loss: 1.5680\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3872 - val_loss: 1.5582\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3926 - val_loss: 1.5621\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3940 - val_loss: 1.5763\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4017 - val_loss: 1.5568\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3963 - val_loss: 1.5620\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3744 - val_loss: 1.5764\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3734 - val_loss: 1.5605\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3867 - val_loss: 1.5641\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3603 - val_loss: 1.5723\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3957 - val_loss: 1.5865\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3814 - val_loss: 1.5561\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3732 - val_loss: 1.5772\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3851 - val_loss: 1.5884\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3718 - val_loss: 1.5641\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3803 - val_loss: 1.5518\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3817 - val_loss: 1.5589\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3664 - val_loss: 1.5663\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3667 - val_loss: 1.5641\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3620 - val_loss: 1.5572\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3713 - val_loss: 1.5804\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "793/820 [============================>.] - ETA: 0s - loss: 2.2705WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.2697 - val_loss: 2.5821\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2422 - val_loss: 2.5439\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2376 - val_loss: 2.5407\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2191 - val_loss: 2.5708\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2415 - val_loss: 2.6169\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2274 - val_loss: 2.5552\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2444 - val_loss: 2.5525\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2485 - val_loss: 2.6034\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2508 - val_loss: 2.5326\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2483 - val_loss: 2.5704\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2062 - val_loss: 2.5599\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2166 - val_loss: 2.5741\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2248 - val_loss: 2.6191\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2027 - val_loss: 2.5879\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2497 - val_loss: 2.5882\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2208 - val_loss: 2.5960\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2260 - val_loss: 2.5812\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2332 - val_loss: 2.5836\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.1991 - val_loss: 2.5953\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2311 - val_loss: 2.5495\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2274 - val_loss: 2.5788\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2060 - val_loss: 2.5738\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2002 - val_loss: 2.5544\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2104 - val_loss: 2.5692\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2054 - val_loss: 2.5704\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/820 [===========================>..] - ETA: 0s - loss: 2.6897WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6888 - val_loss: 3.0790\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6591 - val_loss: 3.1435\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6751 - val_loss: 3.0633\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6590 - val_loss: 3.0932\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6839 - val_loss: 3.1066\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6673 - val_loss: 3.0280\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6846 - val_loss: 3.0862\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6824 - val_loss: 3.0804\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6811 - val_loss: 3.0911\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6834 - val_loss: 3.0841\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6374 - val_loss: 3.0676\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6468 - val_loss: 3.0930\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6629 - val_loss: 3.1131\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6350 - val_loss: 3.0947\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6767 - val_loss: 3.0797\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6505 - val_loss: 3.1567\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6796 - val_loss: 3.1126\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6659 - val_loss: 3.0594\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6308 - val_loss: 3.0774\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6520 - val_loss: 3.0993\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6563 - val_loss: 3.0952\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6447 - val_loss: 3.0825\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6250 - val_loss: 3.0721\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6484 - val_loss: 3.0929\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6237 - val_loss: 3.1074\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "809/820 [============================>.] - ETA: 0s - loss: 2.8029WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8027 - val_loss: 3.2463\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7796 - val_loss: 3.2638\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7838 - val_loss: 3.2694\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7875 - val_loss: 3.2261\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7987 - val_loss: 3.2549\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7661 - val_loss: 3.2179\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8014 - val_loss: 3.2227\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8089 - val_loss: 3.2293\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7785 - val_loss: 3.2497\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7952 - val_loss: 3.2432\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7487 - val_loss: 3.2199\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7552 - val_loss: 3.2365\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7841 - val_loss: 3.2567\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7524 - val_loss: 3.2242\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7896 - val_loss: 3.2505\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7473 - val_loss: 3.2683\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.8003 - val_loss: 3.2468\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7684 - val_loss: 3.2106\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7466 - val_loss: 3.2212\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7571 - val_loss: 3.2339\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7856 - val_loss: 3.2177\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7567 - val_loss: 3.2287\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7454 - val_loss: 3.2369\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7711 - val_loss: 3.2338\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7288 - val_loss: 3.3039\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "767/820 [===========================>..] - ETA: 0s - loss: 2.6663WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6657 - val_loss: 3.0704\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6541 - val_loss: 3.0994\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6526 - val_loss: 3.1016\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6574 - val_loss: 3.1352\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6639 - val_loss: 3.0945\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6305 - val_loss: 3.0593\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6754 - val_loss: 3.0833\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6784 - val_loss: 3.1614\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6409 - val_loss: 3.0937\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6676 - val_loss: 3.1072\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6305 - val_loss: 3.0697\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6399 - val_loss: 3.1069\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6550 - val_loss: 3.1043\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6309 - val_loss: 3.1385\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6459 - val_loss: 3.0954\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6108 - val_loss: 3.1673\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6692 - val_loss: 3.1343\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6297 - val_loss: 3.1149\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6274 - val_loss: 3.0896\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6180 - val_loss: 3.0891\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6528 - val_loss: 3.0887\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6318 - val_loss: 3.0954\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6132 - val_loss: 3.0865\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6433 - val_loss: 3.1004\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6015 - val_loss: 3.1672\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "808/820 [============================>.] - ETA: 0s - loss: 2.3510WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.3510 - val_loss: 2.7353\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3495 - val_loss: 2.7904\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3500 - val_loss: 2.7707\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3545 - val_loss: 2.8073\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3525 - val_loss: 2.7691\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3143 - val_loss: 2.7322\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3675 - val_loss: 2.7454\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3619 - val_loss: 2.7575\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3305 - val_loss: 2.7427\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3582 - val_loss: 2.7814\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3246 - val_loss: 2.7362\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3398 - val_loss: 2.7728\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3419 - val_loss: 2.7600\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3314 - val_loss: 2.8030\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3347 - val_loss: 2.7746\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3152 - val_loss: 2.8069\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3600 - val_loss: 2.7731\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3199 - val_loss: 2.7717\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3205 - val_loss: 2.7633\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3158 - val_loss: 2.7466\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3475 - val_loss: 2.7536\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3149 - val_loss: 2.7670\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3062 - val_loss: 2.7481\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3371 - val_loss: 2.7681\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2951 - val_loss: 2.7717\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "779/820 [===========================>..] - ETA: 0s - loss: 1.9184WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 1.9181 - val_loss: 2.2669\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9116 - val_loss: 2.2810\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9130 - val_loss: 2.2704\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9194 - val_loss: 2.2779\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9086 - val_loss: 2.2652\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8824 - val_loss: 2.2612\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9272 - val_loss: 2.2577\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9143 - val_loss: 2.3017\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8935 - val_loss: 2.2515\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9227 - val_loss: 2.2689\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8829 - val_loss: 2.2509\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9052 - val_loss: 2.2634\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9064 - val_loss: 2.2803\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9015 - val_loss: 2.2947\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8952 - val_loss: 2.2348\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8826 - val_loss: 2.2973\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9191 - val_loss: 2.2775\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8851 - val_loss: 2.2829\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8917 - val_loss: 2.2555\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8795 - val_loss: 2.2207\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9086 - val_loss: 2.2741\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8845 - val_loss: 2.2648\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8776 - val_loss: 2.2654\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9004 - val_loss: 2.2471\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8692 - val_loss: 2.2878\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "787/820 [===========================>..] - ETA: 0s - loss: 1.38490 - ETA: 0s - lWARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3847 - val_loss: 1.6655\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3832 - val_loss: 1.6847\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3807 - val_loss: 1.6569\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3853 - val_loss: 1.6566\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3773 - val_loss: 1.6600\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3546 - val_loss: 1.6513\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3912 - val_loss: 1.6539\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3809 - val_loss: 1.6522\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3643 - val_loss: 1.6408\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3893 - val_loss: 1.6439\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3529 - val_loss: 1.6425\n",
      "Epoch 12/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3720 - val_loss: 1.6524\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3724 - val_loss: 1.6629\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3760 - val_loss: 1.6550\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3614 - val_loss: 1.6555\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3565 - val_loss: 1.6588\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3793 - val_loss: 1.6425\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3532 - val_loss: 1.6928\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3673 - val_loss: 1.6284\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3560 - val_loss: 1.6226\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3791 - val_loss: 1.6508\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3611 - val_loss: 1.6448\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3529 - val_loss: 1.6546\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3718 - val_loss: 1.6294\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3445 - val_loss: 1.6761\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "801/820 [============================>.] - ETA: 0s - loss: 0.7696WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7695 - val_loss: 0.9240\n",
      "Epoch 2/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7610 - val_loss: 0.9656\n",
      "Epoch 3/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7640 - val_loss: 0.9346\n",
      "Epoch 4/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7648 - val_loss: 0.9180\n",
      "Epoch 5/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7595 - val_loss: 0.9600\n",
      "Epoch 6/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7473 - val_loss: 0.9285\n",
      "Epoch 7/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7647 - val_loss: 0.9055\n",
      "Epoch 8/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7584 - val_loss: 0.9165\n",
      "Epoch 9/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7510 - val_loss: 0.9143\n",
      "Epoch 10/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7716 - val_loss: 0.9400\n",
      "Epoch 11/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7493 - val_loss: 0.9110\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7576 - val_loss: 0.9451\n",
      "Epoch 13/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7568 - val_loss: 0.9120\n",
      "Epoch 14/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7626 - val_loss: 0.9347\n",
      "Epoch 15/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7537 - val_loss: 0.9199\n",
      "Epoch 16/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7473 - val_loss: 0.9273\n",
      "Epoch 17/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7624 - val_loss: 0.9221\n",
      "Epoch 18/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7424 - val_loss: 0.9430\n",
      "Epoch 19/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7518 - val_loss: 0.9248\n",
      "Epoch 20/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7479 - val_loss: 0.9045\n",
      "Epoch 21/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7633 - val_loss: 0.9052\n",
      "Epoch 22/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7466 - val_loss: 0.9093\n",
      "Epoch 23/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7441 - val_loss: 0.9194\n",
      "Epoch 24/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7566 - val_loss: 0.9214\n",
      "Epoch 25/25\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7430 - val_loss: 0.9248\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 8), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 8).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results8 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    model8.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model8.fit(Day, Day8, epochs=25, batch_size=48, validation_split=0.25)\n",
    "    pred = pd.DataFrame(model8.predict(df_test))\n",
    "    results8 = pd.concat([results8, pred], axis=1)\n",
    "\n",
    "results8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>-0.247501</td>\n",
       "      <td>0.010660</td>\n",
       "      <td>-0.097710</td>\n",
       "      <td>0.108984</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.062183</td>\n",
       "      <td>0.151767</td>\n",
       "      <td>0.204766</td>\n",
       "      <td>0.246349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>-0.243526</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>-0.094219</td>\n",
       "      <td>0.109927</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.062991</td>\n",
       "      <td>0.148053</td>\n",
       "      <td>0.202285</td>\n",
       "      <td>0.257550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>-0.244798</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.110853</td>\n",
       "      <td>0.101353</td>\n",
       "      <td>0.013860</td>\n",
       "      <td>0.056877</td>\n",
       "      <td>0.131290</td>\n",
       "      <td>0.190248</td>\n",
       "      <td>0.235175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>-0.248765</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>-0.111846</td>\n",
       "      <td>0.102820</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>0.057319</td>\n",
       "      <td>0.134996</td>\n",
       "      <td>0.190352</td>\n",
       "      <td>0.243547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>-0.239216</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>-0.106596</td>\n",
       "      <td>0.094087</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>0.057580</td>\n",
       "      <td>0.122366</td>\n",
       "      <td>0.180570</td>\n",
       "      <td>0.216401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>80.csv_Day8_21h30m</td>\n",
       "      <td>-0.383539</td>\n",
       "      <td>-0.156595</td>\n",
       "      <td>-0.077136</td>\n",
       "      <td>-0.118234</td>\n",
       "      <td>-0.111821</td>\n",
       "      <td>-0.126860</td>\n",
       "      <td>-0.102690</td>\n",
       "      <td>-0.015240</td>\n",
       "      <td>0.047616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>80.csv_Day8_22h00m</td>\n",
       "      <td>-0.425080</td>\n",
       "      <td>-0.168810</td>\n",
       "      <td>-0.084092</td>\n",
       "      <td>-0.127617</td>\n",
       "      <td>-0.125691</td>\n",
       "      <td>-0.142833</td>\n",
       "      <td>-0.111034</td>\n",
       "      <td>-0.010770</td>\n",
       "      <td>0.046572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>80.csv_Day8_22h30m</td>\n",
       "      <td>-0.428563</td>\n",
       "      <td>-0.172226</td>\n",
       "      <td>-0.085872</td>\n",
       "      <td>-0.129303</td>\n",
       "      <td>-0.128496</td>\n",
       "      <td>-0.145187</td>\n",
       "      <td>-0.109024</td>\n",
       "      <td>-0.010141</td>\n",
       "      <td>0.050087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>80.csv_Day8_23h00m</td>\n",
       "      <td>-0.468362</td>\n",
       "      <td>-0.184636</td>\n",
       "      <td>-0.091739</td>\n",
       "      <td>-0.137675</td>\n",
       "      <td>-0.135714</td>\n",
       "      <td>-0.155986</td>\n",
       "      <td>-0.110771</td>\n",
       "      <td>-0.008116</td>\n",
       "      <td>0.050096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>80.csv_Day8_23h30m</td>\n",
       "      <td>-0.473063</td>\n",
       "      <td>-0.189439</td>\n",
       "      <td>-0.094120</td>\n",
       "      <td>-0.139718</td>\n",
       "      <td>-0.139226</td>\n",
       "      <td>-0.157194</td>\n",
       "      <td>-0.108130</td>\n",
       "      <td>-0.007333</td>\n",
       "      <td>0.066054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     q_0.1     q_0.2     q_0.3     q_0.4     q_0.5  \\\n",
       "0       0.csv_Day7_0h00m -0.247501  0.010660 -0.097710  0.108984  0.000941   \n",
       "1       0.csv_Day7_0h30m -0.243526  0.019556 -0.094219  0.109927  0.004256   \n",
       "2       0.csv_Day7_1h00m -0.244798  0.000770 -0.110853  0.101353  0.013860   \n",
       "3       0.csv_Day7_1h30m -0.248765  0.002135 -0.111846  0.102820  0.010559   \n",
       "4       0.csv_Day7_2h00m -0.239216  0.001941 -0.106596  0.094087  0.018916   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "7771  80.csv_Day8_21h30m -0.383539 -0.156595 -0.077136 -0.118234 -0.111821   \n",
       "7772  80.csv_Day8_22h00m -0.425080 -0.168810 -0.084092 -0.127617 -0.125691   \n",
       "7773  80.csv_Day8_22h30m -0.428563 -0.172226 -0.085872 -0.129303 -0.128496   \n",
       "7774  80.csv_Day8_23h00m -0.468362 -0.184636 -0.091739 -0.137675 -0.135714   \n",
       "7775  80.csv_Day8_23h30m -0.473063 -0.189439 -0.094120 -0.139718 -0.139226   \n",
       "\n",
       "         q_0.6     q_0.7     q_0.8     q_0.9  \n",
       "0     0.062183  0.151767  0.204766  0.246349  \n",
       "1     0.062991  0.148053  0.202285  0.257550  \n",
       "2     0.056877  0.131290  0.190248  0.235175  \n",
       "3     0.057319  0.134996  0.190352  0.243547  \n",
       "4     0.057580  0.122366  0.180570  0.216401  \n",
       "...        ...       ...       ...       ...  \n",
       "7771 -0.126860 -0.102690 -0.015240  0.047616  \n",
       "7772 -0.142833 -0.111034 -0.010770  0.046572  \n",
       "7773 -0.145187 -0.109024 -0.010141  0.050087  \n",
       "7774 -0.155986 -0.110771 -0.008116  0.050096  \n",
       "7775 -0.157194 -0.108130 -0.007333  0.066054  \n",
       "\n",
       "[7776 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission.loc[submission.id.str.contains(\"Day7\"), \"q_0.1\":] = results7.sort_index().values\n",
    "submission.loc[submission.id.str.contains(\"Day8\"), \"q_0.1\":] = results8.sort_index().values\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7776, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([df_test, df_test])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7772</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7773</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7774</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7776 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TARGET\n",
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "...      ...\n",
       "7771     0.0\n",
       "7772     0.0\n",
       "7773     0.0\n",
       "7774     0.0\n",
       "7775     0.0\n",
       "\n",
       "[7776 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['TARGET']].reset_index()[['TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7776, 10), (7776, 8))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission/submission_20210115-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7776, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat([submission, test[['TARGET']].reset_index()[['TARGET']]], axis=1)\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[submission.TARGET == 0, ['q_0.1', 'q_0.2', 'q_0.3', 'q_0.4', 'q_0.5', 'q_0.6', 'q_0.7','q_0.8', 'q_0.9']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.drop('TARGET', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>0.270775</td>\n",
       "      <td>1.494306</td>\n",
       "      <td>4.809710</td>\n",
       "      <td>5.007898</td>\n",
       "      <td>6.191067</td>\n",
       "      <td>7.178010</td>\n",
       "      <td>7.932549</td>\n",
       "      <td>13.782493</td>\n",
       "      <td>23.259171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>5.035101</td>\n",
       "      <td>10.566395</td>\n",
       "      <td>14.169788</td>\n",
       "      <td>14.383174</td>\n",
       "      <td>15.836102</td>\n",
       "      <td>17.428556</td>\n",
       "      <td>19.822842</td>\n",
       "      <td>29.284679</td>\n",
       "      <td>39.328617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>7.274327</td>\n",
       "      <td>13.248617</td>\n",
       "      <td>16.665253</td>\n",
       "      <td>17.630135</td>\n",
       "      <td>18.371826</td>\n",
       "      <td>19.827761</td>\n",
       "      <td>22.744843</td>\n",
       "      <td>30.339581</td>\n",
       "      <td>41.048004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>15.250032</td>\n",
       "      <td>22.187557</td>\n",
       "      <td>28.374422</td>\n",
       "      <td>30.391068</td>\n",
       "      <td>33.038685</td>\n",
       "      <td>33.989208</td>\n",
       "      <td>34.507500</td>\n",
       "      <td>41.694504</td>\n",
       "      <td>50.256950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>17.878054</td>\n",
       "      <td>25.847679</td>\n",
       "      <td>31.166662</td>\n",
       "      <td>33.613941</td>\n",
       "      <td>34.940090</td>\n",
       "      <td>35.972641</td>\n",
       "      <td>37.886600</td>\n",
       "      <td>44.733028</td>\n",
       "      <td>51.456772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>27.104237</td>\n",
       "      <td>30.540882</td>\n",
       "      <td>36.638256</td>\n",
       "      <td>40.678062</td>\n",
       "      <td>40.507221</td>\n",
       "      <td>39.465935</td>\n",
       "      <td>44.467129</td>\n",
       "      <td>47.033039</td>\n",
       "      <td>51.475117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>26.499123</td>\n",
       "      <td>30.416746</td>\n",
       "      <td>35.291309</td>\n",
       "      <td>39.075157</td>\n",
       "      <td>38.623001</td>\n",
       "      <td>38.674080</td>\n",
       "      <td>45.310471</td>\n",
       "      <td>46.917793</td>\n",
       "      <td>46.483692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>31.684881</td>\n",
       "      <td>36.034744</td>\n",
       "      <td>42.973103</td>\n",
       "      <td>45.778549</td>\n",
       "      <td>46.717892</td>\n",
       "      <td>48.464329</td>\n",
       "      <td>52.173626</td>\n",
       "      <td>54.363533</td>\n",
       "      <td>58.918285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>32.589088</td>\n",
       "      <td>35.676136</td>\n",
       "      <td>41.714569</td>\n",
       "      <td>43.331730</td>\n",
       "      <td>43.378605</td>\n",
       "      <td>45.409107</td>\n",
       "      <td>48.673161</td>\n",
       "      <td>52.657524</td>\n",
       "      <td>58.496174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>30.419119</td>\n",
       "      <td>34.596558</td>\n",
       "      <td>41.294392</td>\n",
       "      <td>42.003925</td>\n",
       "      <td>42.429741</td>\n",
       "      <td>44.983387</td>\n",
       "      <td>49.160927</td>\n",
       "      <td>53.132961</td>\n",
       "      <td>57.722763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>29.263901</td>\n",
       "      <td>34.220383</td>\n",
       "      <td>41.489063</td>\n",
       "      <td>43.693310</td>\n",
       "      <td>44.614475</td>\n",
       "      <td>46.409283</td>\n",
       "      <td>51.069969</td>\n",
       "      <td>52.462093</td>\n",
       "      <td>56.291027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>27.895123</td>\n",
       "      <td>31.784969</td>\n",
       "      <td>37.224163</td>\n",
       "      <td>38.001659</td>\n",
       "      <td>39.551155</td>\n",
       "      <td>42.379559</td>\n",
       "      <td>48.394112</td>\n",
       "      <td>53.595070</td>\n",
       "      <td>56.830917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>27.881529</td>\n",
       "      <td>31.427189</td>\n",
       "      <td>36.544952</td>\n",
       "      <td>36.154583</td>\n",
       "      <td>36.865662</td>\n",
       "      <td>39.553036</td>\n",
       "      <td>45.583149</td>\n",
       "      <td>53.504963</td>\n",
       "      <td>57.309151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>24.683949</td>\n",
       "      <td>27.399136</td>\n",
       "      <td>31.985235</td>\n",
       "      <td>32.164032</td>\n",
       "      <td>33.721664</td>\n",
       "      <td>35.748005</td>\n",
       "      <td>41.540798</td>\n",
       "      <td>51.472565</td>\n",
       "      <td>54.486053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>24.268045</td>\n",
       "      <td>26.584929</td>\n",
       "      <td>31.558748</td>\n",
       "      <td>32.018471</td>\n",
       "      <td>34.248528</td>\n",
       "      <td>36.285160</td>\n",
       "      <td>41.847614</td>\n",
       "      <td>51.280548</td>\n",
       "      <td>54.064186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>20.263796</td>\n",
       "      <td>21.948013</td>\n",
       "      <td>26.315268</td>\n",
       "      <td>26.389652</td>\n",
       "      <td>28.269745</td>\n",
       "      <td>29.995209</td>\n",
       "      <td>35.808254</td>\n",
       "      <td>44.504135</td>\n",
       "      <td>47.680752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>19.023174</td>\n",
       "      <td>18.204834</td>\n",
       "      <td>23.003397</td>\n",
       "      <td>22.537582</td>\n",
       "      <td>26.512394</td>\n",
       "      <td>27.811838</td>\n",
       "      <td>31.207794</td>\n",
       "      <td>40.540970</td>\n",
       "      <td>44.873405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>11.929479</td>\n",
       "      <td>9.692602</td>\n",
       "      <td>11.979445</td>\n",
       "      <td>13.787859</td>\n",
       "      <td>15.188926</td>\n",
       "      <td>16.822172</td>\n",
       "      <td>19.500511</td>\n",
       "      <td>27.392990</td>\n",
       "      <td>28.485458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>2.110414</td>\n",
       "      <td>2.735447</td>\n",
       "      <td>3.554962</td>\n",
       "      <td>4.266885</td>\n",
       "      <td>5.363832</td>\n",
       "      <td>6.839540</td>\n",
       "      <td>9.066148</td>\n",
       "      <td>12.064198</td>\n",
       "      <td>15.193425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1    0.csv_Day7_0h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2    0.csv_Day7_1h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3    0.csv_Day7_1h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4    0.csv_Day7_2h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5    0.csv_Day7_2h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "6    0.csv_Day7_3h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "7    0.csv_Day7_3h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "8    0.csv_Day7_4h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "9    0.csv_Day7_4h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "10   0.csv_Day7_5h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "11   0.csv_Day7_5h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12   0.csv_Day7_6h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "13   0.csv_Day7_6h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "14   0.csv_Day7_7h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "15   0.csv_Day7_7h30m   0.270775   1.494306   4.809710   5.007898   6.191067   \n",
       "16   0.csv_Day7_8h00m   5.035101  10.566395  14.169788  14.383174  15.836102   \n",
       "17   0.csv_Day7_8h30m   7.274327  13.248617  16.665253  17.630135  18.371826   \n",
       "18   0.csv_Day7_9h00m  15.250032  22.187557  28.374422  30.391068  33.038685   \n",
       "19   0.csv_Day7_9h30m  17.878054  25.847679  31.166662  33.613941  34.940090   \n",
       "20  0.csv_Day7_10h00m  27.104237  30.540882  36.638256  40.678062  40.507221   \n",
       "21  0.csv_Day7_10h30m  26.499123  30.416746  35.291309  39.075157  38.623001   \n",
       "22  0.csv_Day7_11h00m  31.684881  36.034744  42.973103  45.778549  46.717892   \n",
       "23  0.csv_Day7_11h30m  32.589088  35.676136  41.714569  43.331730  43.378605   \n",
       "24  0.csv_Day7_12h00m  30.419119  34.596558  41.294392  42.003925  42.429741   \n",
       "25  0.csv_Day7_12h30m  29.263901  34.220383  41.489063  43.693310  44.614475   \n",
       "26  0.csv_Day7_13h00m  27.895123  31.784969  37.224163  38.001659  39.551155   \n",
       "27  0.csv_Day7_13h30m  27.881529  31.427189  36.544952  36.154583  36.865662   \n",
       "28  0.csv_Day7_14h00m  24.683949  27.399136  31.985235  32.164032  33.721664   \n",
       "29  0.csv_Day7_14h30m  24.268045  26.584929  31.558748  32.018471  34.248528   \n",
       "30  0.csv_Day7_15h00m  20.263796  21.948013  26.315268  26.389652  28.269745   \n",
       "31  0.csv_Day7_15h30m  19.023174  18.204834  23.003397  22.537582  26.512394   \n",
       "32  0.csv_Day7_16h00m  11.929479   9.692602  11.979445  13.787859  15.188926   \n",
       "33  0.csv_Day7_16h30m   2.110414   2.735447   3.554962   4.266885   5.363832   \n",
       "34  0.csv_Day7_17h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "35  0.csv_Day7_17h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "36  0.csv_Day7_18h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "37  0.csv_Day7_18h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "38  0.csv_Day7_19h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "39  0.csv_Day7_19h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "40  0.csv_Day7_20h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "41  0.csv_Day7_20h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "42  0.csv_Day7_21h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "43  0.csv_Day7_21h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "44  0.csv_Day7_22h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "45  0.csv_Day7_22h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "46  0.csv_Day7_23h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "47  0.csv_Day7_23h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.000000   0.000000   0.000000   0.000000  \n",
       "1    0.000000   0.000000   0.000000   0.000000  \n",
       "2    0.000000   0.000000   0.000000   0.000000  \n",
       "3    0.000000   0.000000   0.000000   0.000000  \n",
       "4    0.000000   0.000000   0.000000   0.000000  \n",
       "5    0.000000   0.000000   0.000000   0.000000  \n",
       "6    0.000000   0.000000   0.000000   0.000000  \n",
       "7    0.000000   0.000000   0.000000   0.000000  \n",
       "8    0.000000   0.000000   0.000000   0.000000  \n",
       "9    0.000000   0.000000   0.000000   0.000000  \n",
       "10   0.000000   0.000000   0.000000   0.000000  \n",
       "11   0.000000   0.000000   0.000000   0.000000  \n",
       "12   0.000000   0.000000   0.000000   0.000000  \n",
       "13   0.000000   0.000000   0.000000   0.000000  \n",
       "14   0.000000   0.000000   0.000000   0.000000  \n",
       "15   7.178010   7.932549  13.782493  23.259171  \n",
       "16  17.428556  19.822842  29.284679  39.328617  \n",
       "17  19.827761  22.744843  30.339581  41.048004  \n",
       "18  33.989208  34.507500  41.694504  50.256950  \n",
       "19  35.972641  37.886600  44.733028  51.456772  \n",
       "20  39.465935  44.467129  47.033039  51.475117  \n",
       "21  38.674080  45.310471  46.917793  46.483692  \n",
       "22  48.464329  52.173626  54.363533  58.918285  \n",
       "23  45.409107  48.673161  52.657524  58.496174  \n",
       "24  44.983387  49.160927  53.132961  57.722763  \n",
       "25  46.409283  51.069969  52.462093  56.291027  \n",
       "26  42.379559  48.394112  53.595070  56.830917  \n",
       "27  39.553036  45.583149  53.504963  57.309151  \n",
       "28  35.748005  41.540798  51.472565  54.486053  \n",
       "29  36.285160  41.847614  51.280548  54.064186  \n",
       "30  29.995209  35.808254  44.504135  47.680752  \n",
       "31  27.811838  31.207794  40.540970  44.873405  \n",
       "32  16.822172  19.500511  27.392990  28.485458  \n",
       "33   6.839540   9.066148  12.064198  15.193425  \n",
       "34   0.000000   0.000000   0.000000   0.000000  \n",
       "35   0.000000   0.000000   0.000000   0.000000  \n",
       "36   0.000000   0.000000   0.000000   0.000000  \n",
       "37   0.000000   0.000000   0.000000   0.000000  \n",
       "38   0.000000   0.000000   0.000000   0.000000  \n",
       "39   0.000000   0.000000   0.000000   0.000000  \n",
       "40   0.000000   0.000000   0.000000   0.000000  \n",
       "41   0.000000   0.000000   0.000000   0.000000  \n",
       "42   0.000000   0.000000   0.000000   0.000000  \n",
       "43   0.000000   0.000000   0.000000   0.000000  \n",
       "44   0.000000   0.000000   0.000000   0.000000  \n",
       "45   0.000000   0.000000   0.000000   0.000000  \n",
       "46   0.000000   0.000000   0.000000   0.000000  \n",
       "47   0.000000   0.000000   0.000000   0.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[:48]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
