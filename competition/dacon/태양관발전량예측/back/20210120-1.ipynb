{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, is_train=True):\n",
    "    \n",
    "    temp = data.copy()\n",
    "    temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "\n",
    "    if is_train==True:          \n",
    "    \n",
    "        temp['Target1'] = temp['TARGET'].shift(-48).fillna(method='ffill')\n",
    "        temp['Target2'] = temp['TARGET'].shift(-48*2).fillna(method='ffill')\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        return temp.iloc[:-96]\n",
    "\n",
    "    elif is_train==False:\n",
    "        \n",
    "        temp = temp[['Hour', 'TARGET', 'DHI', 'DNI', 'WS', 'RH', 'T']]\n",
    "                              \n",
    "        return temp.iloc[-48:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train/train.csv')\n",
    "\n",
    "test = []\n",
    "\n",
    "for i in range(81):\n",
    "    file_path = './data/test/' + str(i) + '.csv'\n",
    "    temp = pd.read_csv(file_path)\n",
    "    temp = preprocess_data(temp, is_train=False)\n",
    "    test.append(temp)\n",
    "\n",
    "df_test = pd.concat(test)\n",
    "\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52464, 9), (3888, 7))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess_data(train)\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = df_train[['Hour','DHI','DNI','WS','RH','T']].min()\n",
    "max  = df_train[['Hour','DHI','DNI','WS','RH','T']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Hour','DHI','DNI','WS','RH','T']):\n",
    "    df_train[col] = (df_train[col] - min[i]) / (max[i] - min[i])\n",
    "    df_test[col] = (df_test[col] - min[i]) / (max[i] - min[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day  = df_train.iloc[:, :-2]\n",
    "Day7 = df_train.iloc[:, -2]\n",
    "Day8 = df_train.iloc[:, -1]\n",
    "Day78 = df_train.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(q, y, pred):\n",
    "    err = (y-pred)\n",
    "    return mean(maximum(q*err, (q-1)*err), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lst = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39348, 7), (13116, 7), (39348, 2), (13116, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(Day, Day78, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train_1, X_valid_1, Y_train_1, Y_valid_1 = train_test_split(Day, Day7, test_size=0.25, random_state=42)\n",
    "X_train_2, X_valid_2, Y_train_2, Y_valid_2 = train_test_split(Day, Day8, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import mean, maximum\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(Day.shape)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "599/615 [============================>.] - ETA: 0s - loss: 374.1756WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "615/615 [==============================] - 2s 2ms/step - loss: 370.4143 - val_loss: 175.5633\n",
      "Epoch 2/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 169.9044 - val_loss: 157.3284\n",
      "Epoch 3/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 152.4468 - val_loss: 149.5892\n",
      "Epoch 4/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 153.5761 - val_loss: 147.8619\n",
      "Epoch 5/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 147.7484 - val_loss: 147.8122\n",
      "Epoch 6/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 149.6038 - val_loss: 151.3657\n",
      "Epoch 7/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 149.6172 - val_loss: 147.0415\n",
      "Epoch 8/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 142.2509 - val_loss: 152.3711\n",
      "Epoch 9/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 149.2954 - val_loss: 147.6583\n",
      "Epoch 10/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 148.8397 - val_loss: 142.7948\n",
      "Epoch 11/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 152.9332 - val_loss: 147.6022\n",
      "Epoch 12/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 145.1340 - val_loss: 142.4872\n",
      "Epoch 13/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 143.8952 - val_loss: 140.3544\n",
      "Epoch 14/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 145.1227 - val_loss: 139.6483\n",
      "Epoch 15/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.3808 - val_loss: 139.4052\n",
      "Epoch 16/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 144.1668 - val_loss: 138.1532\n",
      "Epoch 17/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 145.2854 - val_loss: 139.9868\n",
      "Epoch 18/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.7452 - val_loss: 138.5823\n",
      "Epoch 19/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 140.9201 - val_loss: 135.6353\n",
      "Epoch 20/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 134.4722 - val_loss: 136.5116\n",
      "Epoch 21/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.2686 - val_loss: 146.1366\n",
      "Epoch 22/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 140.0425 - val_loss: 135.1114\n",
      "Epoch 23/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.0929 - val_loss: 143.9767\n",
      "Epoch 24/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 137.3309 - val_loss: 132.7405\n",
      "Epoch 25/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 134.1046 - val_loss: 132.9609\n",
      "Epoch 26/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 138.0068 - val_loss: 137.5400\n",
      "Epoch 27/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 139.6765 - val_loss: 131.6952\n",
      "Epoch 28/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 133.0996 - val_loss: 134.0677\n",
      "Epoch 29/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 136.2175 - val_loss: 132.8486\n",
      "Epoch 30/100\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 135.3982 - val_loss: 138.0644\n",
      "Epoch 00030: early stopping\n",
      "410/410 [==============================] - 0s 714us/step - loss: 136.3020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "136.302001953125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "hist = model.fit(X_train, Y_train, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], 'b-', label='loss')\n",
    "plt.plot(hist.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "785/820 [===========================>..] - ETA: 0s - loss: 1.4499WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 1.4483 - val_loss: 1.5774\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.4007 - val_loss: 1.5916\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3897 - val_loss: 1.5876\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3827 - val_loss: 1.5768\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3955 - val_loss: 1.5852\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3861 - val_loss: 1.5943\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3928 - val_loss: 1.5911\n",
      "Epoch 00007: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "793/820 [============================>.] - ETA: 0s - loss: 2.2656WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 2.2653 - val_loss: 2.5861\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2413 - val_loss: 2.5794\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2416 - val_loss: 2.5821\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2297 - val_loss: 2.5598\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2480 - val_loss: 2.5730\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2415 - val_loss: 2.5461\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2533 - val_loss: 2.5711\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2619 - val_loss: 2.6094\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.2419 - val_loss: 2.5618\n",
      "Epoch 00009: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "787/820 [===========================>..] - ETA: 0s - loss: 2.6847WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.6842 - val_loss: 3.0570\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6568 - val_loss: 3.0701\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6566 - val_loss: 3.0830\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6403 - val_loss: 3.0327\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6642 - val_loss: 3.0904\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6550 - val_loss: 3.0508\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6795 - val_loss: 3.0299\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6899 - val_loss: 3.0605\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6647 - val_loss: 3.0359\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6957 - val_loss: 3.0107\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6120 - val_loss: 3.0242\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6271 - val_loss: 3.0407\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6516 - val_loss: 3.0984\n",
      "Epoch 00013: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "805/820 [============================>.] - ETA: 0s - loss: 2.7862WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 2.7859 - val_loss: 3.1404\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7428 - val_loss: 3.1617\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7569 - val_loss: 3.1800\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 1s 1ms/step - loss: 2.7427 - val_loss: 3.1560\n",
      "Epoch 00004: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "785/820 [===========================>..] - ETA: 0s - loss: 2.6505WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 2.6503 - val_loss: 3.0179\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6172 - val_loss: 3.0192\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6241 - val_loss: 2.9968\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6248 - val_loss: 3.0859\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6254 - val_loss: 3.0436\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.6226 - val_loss: 2.9981\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "811/820 [============================>.] - ETA: 0s - loss: 2.3403WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 2.3403 - val_loss: 2.6802\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3168 - val_loss: 2.6758\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3281 - val_loss: 2.7223\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3261 - val_loss: 2.7081\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3309 - val_loss: 2.6713\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3237 - val_loss: 2.6847\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3566 - val_loss: 2.7002\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 2.3766 - val_loss: 2.6867\n",
      "Epoch 00008: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "811/820 [============================>.] - ETA: 0s - loss: 1.9129WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 1.9130 - val_loss: 2.2169\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8985 - val_loss: 2.2082\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8985 - val_loss: 2.1915\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9067 - val_loss: 2.2184\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9036 - val_loss: 2.1809\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8961 - val_loss: 2.1545\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9259 - val_loss: 2.2083\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.9385 - val_loss: 2.2027\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.8867 - val_loss: 2.2048\n",
      "Epoch 00009: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "801/820 [============================>.] - ETA: 0s - loss: 1.3877WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 1.3878 - val_loss: 1.5924\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3854 - val_loss: 1.6155\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3834 - val_loss: 1.5800\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3840 - val_loss: 1.5952\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3817 - val_loss: 1.6248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 1.3809 - val_loss: 1.5889\n",
      "Epoch 00006: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "803/820 [============================>.] - ETA: 0s - loss: 0.7781WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n",
      "820/820 [==============================] - 2s 1ms/step - loss: 0.7780 - val_loss: 0.8960\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7671 - val_loss: 0.9577\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7748 - val_loss: 0.8861\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7689 - val_loss: 0.9138\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7690 - val_loss: 0.8798\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7647 - val_loss: 0.9059\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7790 - val_loss: 0.9289\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 1s 1ms/step - loss: 0.7827 - val_loss: 0.8960\n",
      "Epoch 00008: early stopping\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 52464, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 52464, 7), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    model.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model.fit(Day, Day78, epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred = pd.DataFrame(model.predict(df_test))\n",
    "    results = pd.concat([results, pred], axis=1)\n",
    "\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.34889\n",
      "Early stopping, best iteration is:\n",
      "[418]\tvalid_0's quantile: 1.34812\n",
      "0.2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.14466\n",
      "[1000]\tvalid_0's quantile: 2.13764\n",
      "[1500]\tvalid_0's quantile: 2.13582\n",
      "[2000]\tvalid_0's quantile: 2.1334\n",
      "Early stopping, best iteration is:\n",
      "[1749]\tvalid_0's quantile: 2.13312\n",
      "0.3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.53565\n",
      "[1000]\tvalid_0's quantile: 2.50726\n",
      "[1500]\tvalid_0's quantile: 2.49215\n",
      "Early stopping, best iteration is:\n",
      "[1604]\tvalid_0's quantile: 2.48959\n",
      "0.4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.66191\n",
      "[1000]\tvalid_0's quantile: 2.62846\n",
      "[1500]\tvalid_0's quantile: 2.61266\n",
      "[2000]\tvalid_0's quantile: 2.6059\n",
      "[2500]\tvalid_0's quantile: 2.59923\n",
      "[3000]\tvalid_0's quantile: 2.59644\n",
      "Early stopping, best iteration is:\n",
      "[2707]\tvalid_0's quantile: 2.59598\n",
      "0.5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.55537\n",
      "[1000]\tvalid_0's quantile: 2.54183\n",
      "[1500]\tvalid_0's quantile: 2.52395\n",
      "[2000]\tvalid_0's quantile: 2.5191\n",
      "[2500]\tvalid_0's quantile: 2.51606\n",
      "[3000]\tvalid_0's quantile: 2.51386\n",
      "[3500]\tvalid_0's quantile: 2.5086\n",
      "[4000]\tvalid_0's quantile: 2.50447\n",
      "[4500]\tvalid_0's quantile: 2.50257\n",
      "[5000]\tvalid_0's quantile: 2.50037\n",
      "[5500]\tvalid_0's quantile: 2.49801\n",
      "[6000]\tvalid_0's quantile: 2.49694\n",
      "[6500]\tvalid_0's quantile: 2.49596\n",
      "Early stopping, best iteration is:\n",
      "[6563]\tvalid_0's quantile: 2.49582\n",
      "0.6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.28838\n",
      "[1000]\tvalid_0's quantile: 2.26798\n",
      "[1500]\tvalid_0's quantile: 2.25775\n",
      "[2000]\tvalid_0's quantile: 2.25273\n",
      "[2500]\tvalid_0's quantile: 2.24936\n",
      "[3000]\tvalid_0's quantile: 2.24642\n",
      "[3500]\tvalid_0's quantile: 2.24451\n",
      "[4000]\tvalid_0's quantile: 2.24427\n",
      "Early stopping, best iteration is:\n",
      "[3735]\tvalid_0's quantile: 2.24391\n",
      "0.7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.87856\n",
      "[1000]\tvalid_0's quantile: 1.86236\n",
      "[1500]\tvalid_0's quantile: 1.85737\n",
      "[2000]\tvalid_0's quantile: 1.85491\n",
      "Early stopping, best iteration is:\n",
      "[1840]\tvalid_0's quantile: 1.85404\n",
      "0.8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.34949\n",
      "[1000]\tvalid_0's quantile: 1.34333\n",
      "Early stopping, best iteration is:\n",
      "[898]\tvalid_0's quantile: 1.34271\n",
      "0.9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 0.748569\n",
      "[1000]\tvalid_0's quantile: 0.746233\n",
      "[1500]\tvalid_0's quantile: 0.74548\n",
      "Early stopping, best iteration is:\n",
      "[1284]\tvalid_0's quantile: 0.745153\n",
      "0.1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.39392\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's quantile: 1.3933\n",
      "0.2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.19349\n",
      "Early stopping, best iteration is:\n",
      "[616]\tvalid_0's quantile: 2.18577\n",
      "0.3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.61892\n",
      "[1000]\tvalid_0's quantile: 2.57944\n",
      "[1500]\tvalid_0's quantile: 2.578\n",
      "Early stopping, best iteration is:\n",
      "[1380]\tvalid_0's quantile: 2.57785\n",
      "0.4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.7433\n",
      "[1000]\tvalid_0's quantile: 2.70695\n",
      "[1500]\tvalid_0's quantile: 2.70092\n",
      "[2000]\tvalid_0's quantile: 2.69464\n",
      "[2500]\tvalid_0's quantile: 2.68927\n",
      "[3000]\tvalid_0's quantile: 2.68204\n",
      "[3500]\tvalid_0's quantile: 2.67218\n",
      "[4000]\tvalid_0's quantile: 2.66515\n",
      "[4500]\tvalid_0's quantile: 2.66079\n",
      "Early stopping, best iteration is:\n",
      "[4475]\tvalid_0's quantile: 2.66079\n",
      "0.5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.6458\n",
      "[1000]\tvalid_0's quantile: 2.62814\n",
      "[1500]\tvalid_0's quantile: 2.61626\n",
      "[2000]\tvalid_0's quantile: 2.60023\n",
      "[2500]\tvalid_0's quantile: 2.58706\n",
      "[3000]\tvalid_0's quantile: 2.58403\n",
      "Early stopping, best iteration is:\n",
      "[2807]\tvalid_0's quantile: 2.58403\n",
      "0.6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 2.36786\n",
      "[1000]\tvalid_0's quantile: 2.35343\n",
      "[1500]\tvalid_0's quantile: 2.33476\n",
      "[2000]\tvalid_0's quantile: 2.32426\n",
      "[2500]\tvalid_0's quantile: 2.31984\n",
      "[3000]\tvalid_0's quantile: 2.31736\n",
      "Early stopping, best iteration is:\n",
      "[2871]\tvalid_0's quantile: 2.31729\n",
      "0.7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.96038\n",
      "[1000]\tvalid_0's quantile: 1.93778\n",
      "[1500]\tvalid_0's quantile: 1.92682\n",
      "[2000]\tvalid_0's quantile: 1.91583\n",
      "[2500]\tvalid_0's quantile: 1.91245\n",
      "Early stopping, best iteration is:\n",
      "[2560]\tvalid_0's quantile: 1.91213\n",
      "0.8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 1.40785\n",
      "[1000]\tvalid_0's quantile: 1.39944\n",
      "[1500]\tvalid_0's quantile: 1.39438\n",
      "[2000]\tvalid_0's quantile: 1.39224\n",
      "[2500]\tvalid_0's quantile: 1.39124\n",
      "Early stopping, best iteration is:\n",
      "[2308]\tvalid_0's quantile: 1.39107\n",
      "0.9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's quantile: 0.780444\n",
      "[1000]\tvalid_0's quantile: 0.777171\n",
      "[1500]\tvalid_0's quantile: 0.775623\n",
      "[2000]\tvalid_0's quantile: 0.775235\n",
      "Early stopping, best iteration is:\n",
      "[1831]\tvalid_0's quantile: 0.774894\n"
     ]
    }
   ],
   "source": [
    "def LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "    \n",
    "    # (a) Modeling  \n",
    "    model = LGBMRegressor(objective='quantile', alpha=q,\n",
    "                         n_estimators=10000, bagging_fraction=0.7, learning_rate=0.027, subsample=0.7)                   \n",
    "                         \n",
    "                         \n",
    "    model.fit(X_train, Y_train, eval_metric = ['quantile'], \n",
    "          eval_set=[(X_valid, Y_valid)], early_stopping_rounds=300, verbose=500)\n",
    "\n",
    "    # (b) Predictions\n",
    "    pred = pd.Series(model.predict(X_test).round(2))\n",
    "    return pred, model\n",
    "\n",
    "def train_data(X_train, Y_train, X_valid, Y_valid, X_test):\n",
    "\n",
    "    LGBM_models=[]\n",
    "    LGBM_actual_pred = pd.DataFrame()\n",
    "\n",
    "    for q in q_lst:\n",
    "        print(q)\n",
    "        pred , model = LGBM(q, X_train, Y_train, X_valid, Y_valid, X_test)\n",
    "        LGBM_models.append(model)\n",
    "        LGBM_actual_pred = pd.concat([LGBM_actual_pred,pred],axis=1)\n",
    "\n",
    "    LGBM_actual_pred.columns=q_lst\n",
    "    \n",
    "    return LGBM_models, LGBM_actual_pred\n",
    "\n",
    "models_1, results_1 = train_data(X_train_1, Y_train_1, X_valid_1, Y_valid_1, df_test)\n",
    "models_2, results_2 = train_data(X_train_2, Y_train_2, X_valid_2, Y_valid_2, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.06666667, 0.79352884,\n",
       "        0.3       ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.075     , 0.80012986,\n",
       "        0.29814815],\n",
       "       [0.04347826, 0.        , 0.        , ..., 0.08333333, 0.78259929,\n",
       "        0.2962963 ],\n",
       "       ...,\n",
       "       [0.95652174, 0.        , 0.        , ..., 0.05833333, 0.63315658,\n",
       "        0.58888889],\n",
       "       [1.        , 0.        , 0.        , ..., 0.05      , 0.64982145,\n",
       "        0.58148148],\n",
       "       [1.        , 0.        , 0.        , ..., 0.05      , 0.66929986,\n",
       "        0.57407407]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np.array(df_test).reshape(3888, 7, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 4s 3ms/step - loss: 1.4437 - val_loss: 1.5996\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4209 - val_loss: 1.5991\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4129 - val_loss: 1.5982\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4163 - val_loss: 1.5972\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4235 - val_loss: 1.6036\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4159 - val_loss: 1.6140\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4177 - val_loss: 1.6135\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4327 - val_loss: 1.5973\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4212 - val_loss: 1.6002\n",
      "Epoch 00009: early stopping\n",
      "0.2\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.2701 - val_loss: 2.5974\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2603 - val_loss: 2.5972\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2502 - val_loss: 2.5915\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2518 - val_loss: 2.5880\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2629 - val_loss: 2.5911\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2604 - val_loss: 2.6117\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2675 - val_loss: 2.5888\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2742 - val_loss: 2.5691\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2487 - val_loss: 2.5666\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2781 - val_loss: 2.5452\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2035 - val_loss: 2.5595\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2011 - val_loss: 2.5621\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2221 - val_loss: 2.5752\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2219 - val_loss: 2.5457\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2241 - val_loss: 2.5523\n",
      "Epoch 00015: early stopping\n",
      "0.3\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.6387 - val_loss: 3.0143\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6169 - val_loss: 2.9967\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6082 - val_loss: 3.0172\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5808 - val_loss: 3.0089\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6181 - val_loss: 2.9938\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6133 - val_loss: 3.0042\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6185 - val_loss: 2.9795\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6498 - val_loss: 3.0136\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5930 - val_loss: 2.9964\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6544 - val_loss: 2.9461\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5460 - val_loss: 3.0280\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5470 - val_loss: 2.9832\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5862 - val_loss: 2.9686\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5940 - val_loss: 2.9936\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5921 - val_loss: 3.0566\n",
      "Epoch 00015: early stopping\n",
      "0.4\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.7133 - val_loss: 3.0583\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6775 - val_loss: 3.0582\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6773 - val_loss: 3.1536\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6599 - val_loss: 3.0944\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6899 - val_loss: 3.0942\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7012 - val_loss: 3.1115\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7235 - val_loss: 3.0526\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7494 - val_loss: 3.1223\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6791 - val_loss: 3.0763\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7366 - val_loss: 3.0291\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6216 - val_loss: 3.0610\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6313 - val_loss: 3.0564\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6867 - val_loss: 3.0876\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6866 - val_loss: 3.0949\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6769 - val_loss: 3.0885\n",
      "Epoch 00015: early stopping\n",
      "0.5\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.5888 - val_loss: 2.9015\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5405 - val_loss: 2.9592\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5511 - val_loss: 2.9234\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5335 - val_loss: 2.9333\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5507 - val_loss: 2.9722\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.5700 - val_loss: 2.9911\n",
      "Epoch 00006: early stopping\n",
      "0.6\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.2902 - val_loss: 2.6032\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2629 - val_loss: 2.6128\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2650 - val_loss: 2.6449\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2554 - val_loss: 2.6564\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2645 - val_loss: 2.6602\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2947 - val_loss: 2.6958\n",
      "Epoch 00006: early stopping\n",
      "0.7\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 1.8832 - val_loss: 2.1763\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.8601 - val_loss: 2.1888\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.8643 - val_loss: 2.1818\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.8596 - val_loss: 2.1992\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.8639 - val_loss: 2.1660\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.8815 - val_loss: 2.1196\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.8880 - val_loss: 2.1439\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9158 - val_loss: 2.1295\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.8579 - val_loss: 2.2166\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9026 - val_loss: 2.1197\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.8274 - val_loss: 2.1306\n",
      "Epoch 00011: early stopping\n",
      "0.8\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 1.3749 - val_loss: 1.5778\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3568 - val_loss: 1.6001\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3692 - val_loss: 1.6292\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3641 - val_loss: 1.6699\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3646 - val_loss: 1.6785\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3756 - val_loss: 1.5752\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3763 - val_loss: 1.5950\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3958 - val_loss: 1.5843\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3550 - val_loss: 1.5490\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3819 - val_loss: 1.5438\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3272 - val_loss: 1.5404\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3443 - val_loss: 1.5757\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3544 - val_loss: 1.5756\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3513 - val_loss: 1.5562\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3476 - val_loss: 1.5624\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3524 - val_loss: 1.5286\n",
      "Epoch 17/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3609 - val_loss: 1.5792\n",
      "Epoch 18/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3691 - val_loss: 1.5369\n",
      "Epoch 19/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3605 - val_loss: 1.5480\n",
      "Epoch 20/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3798 - val_loss: 1.5177\n",
      "Epoch 21/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3810 - val_loss: 1.5694\n",
      "Epoch 22/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3480 - val_loss: 1.5405\n",
      "Epoch 23/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3528 - val_loss: 1.5969\n",
      "Epoch 24/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3620 - val_loss: 1.5748\n",
      "Epoch 25/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3397 - val_loss: 1.5263\n",
      "Epoch 00025: early stopping\n",
      "0.9\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 0.7655 - val_loss: 0.8482\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7460 - val_loss: 0.8569\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 0.7527 - val_loss: 0.8534\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7564 - val_loss: 0.8581\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7461 - val_loss: 0.8511\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7558 - val_loss: 0.8509\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 9)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7 = tf.keras.Sequential([\n",
    "    layers.Conv1D(filters=128, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result7 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model7.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model7.fit(np.array(Day).reshape(52464, 1, 7), np.array(Day7).reshape(52464, 1), epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred7 = np.squeeze(model7.predict(np.array(df_test).reshape(3888, 1, 7)))\n",
    "    pred7 = pd.DataFrame(pred7)\n",
    "    result7 = pd.concat([result7, pred7], axis=1)\n",
    "    \n",
    "result7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4556 - val_loss: 1.6441\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4438 - val_loss: 1.6422\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4334 - val_loss: 1.6404\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4251 - val_loss: 1.6403\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4422 - val_loss: 1.6395\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 2ms/step - loss: 1.4355 - val_loss: 1.6459\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4438 - val_loss: 1.6486\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4506 - val_loss: 1.6405\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4505 - val_loss: 1.6416\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4594 - val_loss: 1.6350\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4246 - val_loss: 1.6434\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4359 - val_loss: 1.6343\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4399 - val_loss: 1.6298\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4202 - val_loss: 1.6453\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4462 - val_loss: 1.6465\n",
      "Epoch 16/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 1.4341 - val_loss: 1.6253\n",
      "Epoch 17/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4242 - val_loss: 1.6311\n",
      "Epoch 18/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4356 - val_loss: 1.6275\n",
      "Epoch 19/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4299 - val_loss: 1.6180\n",
      "Epoch 20/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4314 - val_loss: 1.6179\n",
      "Epoch 21/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4248 - val_loss: 1.6185\n",
      "Epoch 22/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4146 - val_loss: 1.6192\n",
      "Epoch 23/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4104 - val_loss: 1.6333\n",
      "Epoch 24/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4125 - val_loss: 1.6090\n",
      "Epoch 25/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4237 - val_loss: 1.6076\n",
      "Epoch 26/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4109 - val_loss: 1.6004\n",
      "Epoch 27/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4184 - val_loss: 1.6169\n",
      "Epoch 28/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4072 - val_loss: 1.6180\n",
      "Epoch 29/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3960 - val_loss: 1.6064\n",
      "Epoch 30/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4216 - val_loss: 1.6185\n",
      "Epoch 31/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4240 - val_loss: 1.5981\n",
      "Epoch 32/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4080 - val_loss: 1.6130\n",
      "Epoch 33/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4106 - val_loss: 1.5987\n",
      "Epoch 34/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3994 - val_loss: 1.5954\n",
      "Epoch 35/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3945 - val_loss: 1.5959\n",
      "Epoch 36/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4094 - val_loss: 1.6168\n",
      "Epoch 37/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4022 - val_loss: 1.5862\n",
      "Epoch 38/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4066 - val_loss: 1.5883\n",
      "Epoch 39/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4107 - val_loss: 1.5856\n",
      "Epoch 40/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4191 - val_loss: 1.6065\n",
      "Epoch 41/100\n",
      "820/820 [==============================] - 3s 4ms/step - loss: 1.3859 - val_loss: 1.5792\n",
      "Epoch 42/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3969 - val_loss: 1.5858\n",
      "Epoch 43/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 1.4001 - val_loss: 1.5858\n",
      "Epoch 44/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3830 - val_loss: 1.5964\n",
      "Epoch 45/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.3855 - val_loss: 1.5962\n",
      "Epoch 46/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4027 - val_loss: 1.5856\n",
      "Epoch 00046: early stopping\n",
      "0.2\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.3217 - val_loss: 2.6171\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.3080 - val_loss: 2.6139\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2911 - val_loss: 2.6245\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.2840 - val_loss: 2.6052\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2985 - val_loss: 2.6042\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2968 - val_loss: 2.5812\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.3142 - val_loss: 2.6365\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.3009 - val_loss: 2.6675\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.3115 - val_loss: 2.6033\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.3132 - val_loss: 2.6030\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.2615 - val_loss: 2.5951\n",
      "Epoch 00011: early stopping\n",
      "0.3\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.7720 - val_loss: 3.0801\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7453 - val_loss: 3.1231\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7430 - val_loss: 3.1231\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7272 - val_loss: 3.0793\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7440 - val_loss: 3.1721\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7477 - val_loss: 3.0815\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7632 - val_loss: 3.0996\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7571 - val_loss: 3.0933\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.7551 - val_loss: 3.1268\n",
      "Epoch 00009: early stopping\n",
      "0.4\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.8850 - val_loss: 3.2163\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8609 - val_loss: 3.2760\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8612 - val_loss: 3.2285\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8478 - val_loss: 3.2337\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8628 - val_loss: 3.2901\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8396 - val_loss: 3.2061\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8718 - val_loss: 3.2298\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8783 - val_loss: 3.2618\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8530 - val_loss: 3.1989\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8747 - val_loss: 3.1928\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8139 - val_loss: 3.2530\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8315 - val_loss: 3.2630\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8476 - val_loss: 3.2342\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8234 - val_loss: 3.2481\n",
      "Epoch 15/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.8568 - val_loss: 3.2635\n",
      "Epoch 00015: early stopping\n",
      "0.5\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.7209 - val_loss: 3.0771\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7172 - val_loss: 3.0993\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7101 - val_loss: 3.0884\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7081 - val_loss: 3.1509\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.7296 - val_loss: 3.1483\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.6884 - val_loss: 3.0820\n",
      "Epoch 00006: early stopping\n",
      "0.6\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 2.4007 - val_loss: 2.7318\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.4042 - val_loss: 2.7623\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.4039 - val_loss: 2.7485\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.4091 - val_loss: 2.8345\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.4138 - val_loss: 2.7366\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 2.3788 - val_loss: 2.7407\n",
      "Epoch 00006: early stopping\n",
      "0.7\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 1.9768 - val_loss: 2.2287\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9672 - val_loss: 2.2703\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9603 - val_loss: 2.2787\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9674 - val_loss: 2.2474\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9684 - val_loss: 2.2184\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9417 - val_loss: 2.2426\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9684 - val_loss: 2.2367\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9768 - val_loss: 2.2870\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 1.9445 - val_loss: 2.1991\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9665 - val_loss: 2.2193\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9200 - val_loss: 2.2190\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9508 - val_loss: 2.2599\n",
      "Epoch 13/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9528 - val_loss: 2.2470\n",
      "Epoch 14/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.9555 - val_loss: 2.2636\n",
      "Epoch 00014: early stopping\n",
      "0.8\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 1.4241 - val_loss: 1.6075\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4280 - val_loss: 1.6630\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4272 - val_loss: 1.6455\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4270 - val_loss: 1.5919\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4252 - val_loss: 1.6146\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4067 - val_loss: 1.6103\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4242 - val_loss: 1.6397\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4304 - val_loss: 1.6296\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 1.4142 - val_loss: 1.5998\n",
      "Epoch 00009: early stopping\n",
      "0.9\n",
      "Epoch 1/100\n",
      "820/820 [==============================] - 3s 3ms/step - loss: 0.8221 - val_loss: 0.9388\n",
      "Epoch 2/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7980 - val_loss: 0.9446\n",
      "Epoch 3/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7953 - val_loss: 0.8983\n",
      "Epoch 4/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7935 - val_loss: 0.8891\n",
      "Epoch 5/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7928 - val_loss: 0.8948\n",
      "Epoch 6/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7850 - val_loss: 0.8940\n",
      "Epoch 7/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7992 - val_loss: 0.8809\n",
      "Epoch 8/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7952 - val_loss: 0.9125\n",
      "Epoch 9/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7930 - val_loss: 0.9385\n",
      "Epoch 10/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7990 - val_loss: 0.8871\n",
      "Epoch 11/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7745 - val_loss: 0.9161\n",
      "Epoch 12/100\n",
      "820/820 [==============================] - 2s 3ms/step - loss: 0.7843 - val_loss: 0.8996\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3888, 9)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = tf.keras.Sequential([\n",
    "    layers.Conv1D(filters=128, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "result8 = pd.DataFrame()\n",
    "\n",
    "for q in q_lst:\n",
    "    print(q)\n",
    "    model8.compile(loss=lambda y,pred: quantile_loss(q,y,pred), optimizer='adam')\n",
    "    model8.fit(np.array(Day).reshape(52464, 1, 7), np.array(Day8).reshape(52464, 1), epochs=epoch, batch_size=48, validation_split=0.25, \n",
    "                callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, mode='min', monitor='val_loss', verbose=1)])\n",
    "    pred8 = np.squeeze(model8.predict(np.array(df_test).reshape(3888, 1, 7)))\n",
    "    pred8 = pd.DataFrame(pred8)\n",
    "    result8 = pd.concat([result8, pred8], axis=1)\n",
    "    \n",
    "result8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_L0 = pd.DataFrame(results_1.sort_index())\n",
    "res_L0.columns = ['L00.1','L00.2','L00.3','L00.4','L00.5','L00.6','L00.7','L00.8','L00.9']\n",
    "res_L1 = pd.DataFrame(results_1.sort_index())\n",
    "res_L1.columns = ['L10.1','L10.2','L10.3','L10.4','L10.5','L10.6','L10.7','L10.8','L10.9']\n",
    "\n",
    "res_D0 = pd.DataFrame(results[0].sort_index())\n",
    "res_D0.columns = ['D00.1','D00.2','D00.3','D00.4','D00.5','D00.6','D00.7','D00.8','D00.9']\n",
    "res_D1 = pd.DataFrame(results[1].sort_index())\n",
    "res_D1.columns = ['D10.1','D10.2','D10.3','D10.4','D10.5','D10.6','D10.7','D10.8','D10.9']\n",
    "\n",
    "res_C0 = pd.DataFrame(result7.sort_index())\n",
    "res_C0.columns = ['C00.1','C00.2','C00.3','C00.4','C00.5','C00.6','C00.7','C00.8','C00.9']\n",
    "res_C1 = pd.DataFrame(result8.sort_index())\n",
    "res_C1.columns = ['C10.1','C10.2','C10.3','C10.4','C10.5','C10.6','C10.7','C10.8','C10.9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_0 = pd.concat([res_L0, res_D0, res_C0], axis=1)\n",
    "res_1 = pd.concat([res_L1, res_D1, res_C1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_0.loc[res_0[res_0['L00.1'] == 0].index, ['D00.1','D00.2','D00.3','D00.4','D00.5','D00.6','D00.7','D00.8','D00.9'\n",
    "                                            ,'C00.1','C00.2','C00.3','C00.4','C00.5','C00.6','C00.7','C00.8','C00.9']] = 0\n",
    "res_1.loc[res_1[res_1['L10.1'] == 0].index, ['D10.1','D10.2','D10.3','D10.4','D10.5','D10.6','D10.7','D10.8','D10.9'\n",
    "                                            ,'C10.1','C10.2','C10.3','C10.4','C10.5','C10.6','C10.7','C10.8','C10.9']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    res_0[\"L00.\"+str(i)] = (res_0[\"L00.\"+str(i)] + res_0[\"D00.\"+str(i)] + res_0[\"C00.\"+str(i)])/3\n",
    "    res_1[\"L10.\"+str(i)] = (res_1[\"L10.\"+str(i)] + res_1[\"D10.\"+str(i)] + res_1[\"C10.\"+str(i)])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q_0.1</th>\n",
       "      <th>q_0.2</th>\n",
       "      <th>q_0.3</th>\n",
       "      <th>q_0.4</th>\n",
       "      <th>q_0.5</th>\n",
       "      <th>q_0.6</th>\n",
       "      <th>q_0.7</th>\n",
       "      <th>q_0.8</th>\n",
       "      <th>q_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.csv_Day7_0h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.csv_Day7_0h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.csv_Day7_1h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.csv_Day7_1h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.csv_Day7_2h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.csv_Day7_2h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.csv_Day7_3h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.csv_Day7_3h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.csv_Day7_4h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.csv_Day7_4h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.csv_Day7_5h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.csv_Day7_5h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.csv_Day7_6h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.csv_Day7_6h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.csv_Day7_7h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.csv_Day7_7h30m</td>\n",
       "      <td>0.670348</td>\n",
       "      <td>0.976538</td>\n",
       "      <td>1.254458</td>\n",
       "      <td>1.627492</td>\n",
       "      <td>2.783118</td>\n",
       "      <td>3.329506</td>\n",
       "      <td>5.493195</td>\n",
       "      <td>6.924651</td>\n",
       "      <td>9.170937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.csv_Day7_8h00m</td>\n",
       "      <td>1.861552</td>\n",
       "      <td>3.655368</td>\n",
       "      <td>4.978284</td>\n",
       "      <td>6.108570</td>\n",
       "      <td>7.594404</td>\n",
       "      <td>9.742779</td>\n",
       "      <td>12.425624</td>\n",
       "      <td>15.115226</td>\n",
       "      <td>20.860126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.csv_Day7_8h30m</td>\n",
       "      <td>2.516230</td>\n",
       "      <td>5.751475</td>\n",
       "      <td>6.849532</td>\n",
       "      <td>7.980479</td>\n",
       "      <td>10.138132</td>\n",
       "      <td>12.285669</td>\n",
       "      <td>15.672460</td>\n",
       "      <td>18.928251</td>\n",
       "      <td>24.937116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.csv_Day7_9h00m</td>\n",
       "      <td>5.579493</td>\n",
       "      <td>12.403871</td>\n",
       "      <td>15.382547</td>\n",
       "      <td>16.206658</td>\n",
       "      <td>19.681456</td>\n",
       "      <td>22.560487</td>\n",
       "      <td>21.839069</td>\n",
       "      <td>27.212036</td>\n",
       "      <td>34.608351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.csv_Day7_9h30m</td>\n",
       "      <td>7.294264</td>\n",
       "      <td>15.501713</td>\n",
       "      <td>16.618343</td>\n",
       "      <td>18.898386</td>\n",
       "      <td>22.928481</td>\n",
       "      <td>23.875435</td>\n",
       "      <td>23.713088</td>\n",
       "      <td>27.700030</td>\n",
       "      <td>34.974950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.csv_Day7_10h00m</td>\n",
       "      <td>11.906105</td>\n",
       "      <td>23.341080</td>\n",
       "      <td>24.581016</td>\n",
       "      <td>27.504580</td>\n",
       "      <td>32.915264</td>\n",
       "      <td>35.754908</td>\n",
       "      <td>34.931855</td>\n",
       "      <td>34.006901</td>\n",
       "      <td>36.950760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.csv_Day7_10h30m</td>\n",
       "      <td>12.704471</td>\n",
       "      <td>23.339947</td>\n",
       "      <td>25.738966</td>\n",
       "      <td>28.709961</td>\n",
       "      <td>34.914893</td>\n",
       "      <td>36.567016</td>\n",
       "      <td>37.440440</td>\n",
       "      <td>36.493382</td>\n",
       "      <td>36.781703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.csv_Day7_11h00m</td>\n",
       "      <td>14.318488</td>\n",
       "      <td>27.024650</td>\n",
       "      <td>32.772986</td>\n",
       "      <td>33.754043</td>\n",
       "      <td>40.521176</td>\n",
       "      <td>43.598265</td>\n",
       "      <td>43.711541</td>\n",
       "      <td>42.149206</td>\n",
       "      <td>46.820049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.csv_Day7_11h30m</td>\n",
       "      <td>12.459179</td>\n",
       "      <td>24.099264</td>\n",
       "      <td>29.309647</td>\n",
       "      <td>30.694923</td>\n",
       "      <td>36.350638</td>\n",
       "      <td>39.627160</td>\n",
       "      <td>41.956591</td>\n",
       "      <td>38.050486</td>\n",
       "      <td>46.171075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.csv_Day7_12h00m</td>\n",
       "      <td>12.512456</td>\n",
       "      <td>23.788494</td>\n",
       "      <td>30.471384</td>\n",
       "      <td>31.288157</td>\n",
       "      <td>37.591481</td>\n",
       "      <td>38.704659</td>\n",
       "      <td>38.936355</td>\n",
       "      <td>37.659054</td>\n",
       "      <td>42.865126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.csv_Day7_12h30m</td>\n",
       "      <td>13.238962</td>\n",
       "      <td>25.097827</td>\n",
       "      <td>31.739816</td>\n",
       "      <td>32.379763</td>\n",
       "      <td>37.137430</td>\n",
       "      <td>40.806388</td>\n",
       "      <td>41.483590</td>\n",
       "      <td>39.861493</td>\n",
       "      <td>43.210801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.csv_Day7_13h00m</td>\n",
       "      <td>11.616798</td>\n",
       "      <td>21.458890</td>\n",
       "      <td>28.201853</td>\n",
       "      <td>29.991212</td>\n",
       "      <td>36.151867</td>\n",
       "      <td>37.563651</td>\n",
       "      <td>38.157318</td>\n",
       "      <td>37.240601</td>\n",
       "      <td>40.383502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.csv_Day7_13h30m</td>\n",
       "      <td>9.543122</td>\n",
       "      <td>19.903277</td>\n",
       "      <td>26.853509</td>\n",
       "      <td>28.594791</td>\n",
       "      <td>32.958442</td>\n",
       "      <td>35.389927</td>\n",
       "      <td>37.343214</td>\n",
       "      <td>36.737537</td>\n",
       "      <td>47.109237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.csv_Day7_14h00m</td>\n",
       "      <td>7.898810</td>\n",
       "      <td>17.845597</td>\n",
       "      <td>22.710380</td>\n",
       "      <td>24.231767</td>\n",
       "      <td>28.752430</td>\n",
       "      <td>30.929779</td>\n",
       "      <td>31.561758</td>\n",
       "      <td>30.836534</td>\n",
       "      <td>36.250036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.csv_Day7_14h30m</td>\n",
       "      <td>8.208150</td>\n",
       "      <td>18.562868</td>\n",
       "      <td>23.118165</td>\n",
       "      <td>24.270332</td>\n",
       "      <td>28.619150</td>\n",
       "      <td>30.268398</td>\n",
       "      <td>32.693604</td>\n",
       "      <td>31.395787</td>\n",
       "      <td>34.764350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.csv_Day7_15h00m</td>\n",
       "      <td>5.668010</td>\n",
       "      <td>14.720924</td>\n",
       "      <td>18.320840</td>\n",
       "      <td>18.982046</td>\n",
       "      <td>23.971508</td>\n",
       "      <td>25.281532</td>\n",
       "      <td>28.252436</td>\n",
       "      <td>27.376041</td>\n",
       "      <td>29.954772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.csv_Day7_15h30m</td>\n",
       "      <td>4.732307</td>\n",
       "      <td>13.647396</td>\n",
       "      <td>14.932599</td>\n",
       "      <td>15.596947</td>\n",
       "      <td>18.950637</td>\n",
       "      <td>21.114230</td>\n",
       "      <td>23.474828</td>\n",
       "      <td>22.579649</td>\n",
       "      <td>28.228046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.csv_Day7_16h00m</td>\n",
       "      <td>2.818693</td>\n",
       "      <td>7.379301</td>\n",
       "      <td>9.020992</td>\n",
       "      <td>8.426414</td>\n",
       "      <td>10.987165</td>\n",
       "      <td>12.345268</td>\n",
       "      <td>13.098501</td>\n",
       "      <td>14.476607</td>\n",
       "      <td>18.969643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.csv_Day7_16h30m</td>\n",
       "      <td>1.297238</td>\n",
       "      <td>3.436587</td>\n",
       "      <td>5.036658</td>\n",
       "      <td>3.806583</td>\n",
       "      <td>4.197420</td>\n",
       "      <td>6.778886</td>\n",
       "      <td>7.888670</td>\n",
       "      <td>9.782859</td>\n",
       "      <td>16.279590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.csv_Day7_17h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.csv_Day7_17h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.csv_Day7_18h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.csv_Day7_18h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.csv_Day7_19h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.csv_Day7_19h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.csv_Day7_20h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.csv_Day7_20h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.csv_Day7_21h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.csv_Day7_21h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.csv_Day7_22h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.csv_Day7_22h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.csv_Day7_23h00m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.csv_Day7_23h30m</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      q_0.1      q_0.2      q_0.3      q_0.4      q_0.5  \\\n",
       "0    0.csv_Day7_0h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1    0.csv_Day7_0h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2    0.csv_Day7_1h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3    0.csv_Day7_1h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4    0.csv_Day7_2h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5    0.csv_Day7_2h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "6    0.csv_Day7_3h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "7    0.csv_Day7_3h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "8    0.csv_Day7_4h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "9    0.csv_Day7_4h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "10   0.csv_Day7_5h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "11   0.csv_Day7_5h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12   0.csv_Day7_6h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "13   0.csv_Day7_6h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "14   0.csv_Day7_7h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "15   0.csv_Day7_7h30m   0.670348   0.976538   1.254458   1.627492   2.783118   \n",
       "16   0.csv_Day7_8h00m   1.861552   3.655368   4.978284   6.108570   7.594404   \n",
       "17   0.csv_Day7_8h30m   2.516230   5.751475   6.849532   7.980479  10.138132   \n",
       "18   0.csv_Day7_9h00m   5.579493  12.403871  15.382547  16.206658  19.681456   \n",
       "19   0.csv_Day7_9h30m   7.294264  15.501713  16.618343  18.898386  22.928481   \n",
       "20  0.csv_Day7_10h00m  11.906105  23.341080  24.581016  27.504580  32.915264   \n",
       "21  0.csv_Day7_10h30m  12.704471  23.339947  25.738966  28.709961  34.914893   \n",
       "22  0.csv_Day7_11h00m  14.318488  27.024650  32.772986  33.754043  40.521176   \n",
       "23  0.csv_Day7_11h30m  12.459179  24.099264  29.309647  30.694923  36.350638   \n",
       "24  0.csv_Day7_12h00m  12.512456  23.788494  30.471384  31.288157  37.591481   \n",
       "25  0.csv_Day7_12h30m  13.238962  25.097827  31.739816  32.379763  37.137430   \n",
       "26  0.csv_Day7_13h00m  11.616798  21.458890  28.201853  29.991212  36.151867   \n",
       "27  0.csv_Day7_13h30m   9.543122  19.903277  26.853509  28.594791  32.958442   \n",
       "28  0.csv_Day7_14h00m   7.898810  17.845597  22.710380  24.231767  28.752430   \n",
       "29  0.csv_Day7_14h30m   8.208150  18.562868  23.118165  24.270332  28.619150   \n",
       "30  0.csv_Day7_15h00m   5.668010  14.720924  18.320840  18.982046  23.971508   \n",
       "31  0.csv_Day7_15h30m   4.732307  13.647396  14.932599  15.596947  18.950637   \n",
       "32  0.csv_Day7_16h00m   2.818693   7.379301   9.020992   8.426414  10.987165   \n",
       "33  0.csv_Day7_16h30m   1.297238   3.436587   5.036658   3.806583   4.197420   \n",
       "34  0.csv_Day7_17h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "35  0.csv_Day7_17h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "36  0.csv_Day7_18h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "37  0.csv_Day7_18h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "38  0.csv_Day7_19h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "39  0.csv_Day7_19h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "40  0.csv_Day7_20h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "41  0.csv_Day7_20h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "42  0.csv_Day7_21h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "43  0.csv_Day7_21h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "44  0.csv_Day7_22h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "45  0.csv_Day7_22h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "46  0.csv_Day7_23h00m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "47  0.csv_Day7_23h30m   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "        q_0.6      q_0.7      q_0.8      q_0.9  \n",
       "0    0.000000   0.000000   0.000000   0.000000  \n",
       "1    0.000000   0.000000   0.000000   0.000000  \n",
       "2    0.000000   0.000000   0.000000   0.000000  \n",
       "3    0.000000   0.000000   0.000000   0.000000  \n",
       "4    0.000000   0.000000   0.000000   0.000000  \n",
       "5    0.000000   0.000000   0.000000   0.000000  \n",
       "6    0.000000   0.000000   0.000000   0.000000  \n",
       "7    0.000000   0.000000   0.000000   0.000000  \n",
       "8    0.000000   0.000000   0.000000   0.000000  \n",
       "9    0.000000   0.000000   0.000000   0.000000  \n",
       "10   0.000000   0.000000   0.000000   0.000000  \n",
       "11   0.000000   0.000000   0.000000   0.000000  \n",
       "12   0.000000   0.000000   0.000000   0.000000  \n",
       "13   0.000000   0.000000   0.000000   0.000000  \n",
       "14   0.000000   0.000000   0.000000   0.000000  \n",
       "15   3.329506   5.493195   6.924651   9.170937  \n",
       "16   9.742779  12.425624  15.115226  20.860126  \n",
       "17  12.285669  15.672460  18.928251  24.937116  \n",
       "18  22.560487  21.839069  27.212036  34.608351  \n",
       "19  23.875435  23.713088  27.700030  34.974950  \n",
       "20  35.754908  34.931855  34.006901  36.950760  \n",
       "21  36.567016  37.440440  36.493382  36.781703  \n",
       "22  43.598265  43.711541  42.149206  46.820049  \n",
       "23  39.627160  41.956591  38.050486  46.171075  \n",
       "24  38.704659  38.936355  37.659054  42.865126  \n",
       "25  40.806388  41.483590  39.861493  43.210801  \n",
       "26  37.563651  38.157318  37.240601  40.383502  \n",
       "27  35.389927  37.343214  36.737537  47.109237  \n",
       "28  30.929779  31.561758  30.836534  36.250036  \n",
       "29  30.268398  32.693604  31.395787  34.764350  \n",
       "30  25.281532  28.252436  27.376041  29.954772  \n",
       "31  21.114230  23.474828  22.579649  28.228046  \n",
       "32  12.345268  13.098501  14.476607  18.969643  \n",
       "33   6.778886   7.888670   9.782859  16.279590  \n",
       "34   0.000000   0.000000   0.000000   0.000000  \n",
       "35   0.000000   0.000000   0.000000   0.000000  \n",
       "36   0.000000   0.000000   0.000000   0.000000  \n",
       "37   0.000000   0.000000   0.000000   0.000000  \n",
       "38   0.000000   0.000000   0.000000   0.000000  \n",
       "39   0.000000   0.000000   0.000000   0.000000  \n",
       "40   0.000000   0.000000   0.000000   0.000000  \n",
       "41   0.000000   0.000000   0.000000   0.000000  \n",
       "42   0.000000   0.000000   0.000000   0.000000  \n",
       "43   0.000000   0.000000   0.000000   0.000000  \n",
       "44   0.000000   0.000000   0.000000   0.000000  \n",
       "45   0.000000   0.000000   0.000000   0.000000  \n",
       "46   0.000000   0.000000   0.000000   0.000000  \n",
       "47   0.000000   0.000000   0.000000   0.000000  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.loc[submission.id.str.contains(\"Day7\"), \"q_0.1\":] = res_0[['L00.1','L00.2','L00.3','L00.4','L00.5','L00.6','L00.7','L00.8','L00.9']].values\n",
    "submission.loc[submission.id.str.contains(\"Day8\"), \"q_0.1\":] = res_1[['L10.1','L10.2','L10.3','L10.4','L10.5','L10.6','L10.7','L10.8','L10.9']].values\n",
    "submission[:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission/submission_20210120-1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
